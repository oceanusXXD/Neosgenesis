#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Neogenesis System - MAB Optimization & Persistent Learning
å¤šè‡‚è€è™æœºä¼˜åŒ–ä¸æŒä¹…åŒ–å­¦ä¹ ï¼šé«˜çº§æƒé‡ç®¡ç†å’Œæ™ºèƒ½ç­–ç•¥é€‰æ‹©
"""

import json
import logging
import math
import time
import threading
import numpy as np
from typing import Any, Dict, List, Optional, Tuple, Callable
from dataclasses import dataclass, field, asdict
from enum import Enum
from collections import defaultdict, deque
import uuid

from .persistent_storage import PersistentStorageEngine, StorageConfig
from .distributed_state import DistributedStateManager

logger = logging.getLogger(__name__)

# =============================================================================
# MABé…ç½®å’Œæšä¸¾
# =============================================================================

class MABAlgorithm(Enum):
    """å¤šè‡‚è€è™æœºç®—æ³•ç±»å‹"""
    EPSILON_GREEDY = "epsilon_greedy"
    UCB1 = "ucb1"
    THOMPSON_SAMPLING = "thompson_sampling"
    SOFTMAX = "softmax"
    ADAPTIVE_GREEDY = "adaptive_greedy"

class RewardType(Enum):
    """å¥–åŠ±ç±»å‹"""
    BINARY = "binary"           # 0æˆ–1
    CONTINUOUS = "continuous"   # è¿ç»­å€¼
    CATEGORICAL = "categorical" # åˆ†ç±»å¥–åŠ±
    CUSTOM = "custom"          # è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°

class LearningMode(Enum):
    """å­¦ä¹ æ¨¡å¼"""
    ONLINE = "online"           # åœ¨çº¿å­¦ä¹ 
    BATCH = "batch"            # æ‰¹é‡å­¦ä¹ 
    HYBRID = "hybrid"          # æ··åˆå­¦ä¹ 

@dataclass
class MABArm:
    """å¤šè‡‚è€è™æœºè‡‚"""
    arm_id: str
    name: str
    description: str = ""
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_pulls: int = 0
    total_reward: float = 0.0
    success_count: int = 0
    failure_count: int = 0
    
    # é«˜çº§ç»Ÿè®¡
    reward_history: List[float] = field(default_factory=list)
    pull_timestamps: List[float] = field(default_factory=list)
    last_updated: float = field(default_factory=time.time)
    
    # ç®—æ³•ç›¸å…³å‚æ•°
    confidence_radius: float = 0.0
    thompson_alpha: float = 1.0
    thompson_beta: float = 1.0
    
    @property
    def average_reward(self) -> float:
        """å¹³å‡å¥–åŠ±"""
        return self.total_reward / max(self.total_pulls, 1)
    
    @property
    def success_rate(self) -> float:
        """æˆåŠŸç‡"""
        total_attempts = self.success_count + self.failure_count
        return self.success_count / max(total_attempts, 1)
    
    @property
    def confidence_interval(self) -> Tuple[float, float]:
        """ç½®ä¿¡åŒºé—´"""
        if self.total_pulls == 0:
            return (0.0, 1.0)
        
        mean = self.average_reward
        std_error = math.sqrt(self.confidence_radius / self.total_pulls)
        return (max(0.0, mean - 1.96 * std_error), min(1.0, mean + 1.96 * std_error))

@dataclass
class MABContext:
    """MABä¸Šä¸‹æ–‡ä¿¡æ¯"""
    context_id: str
    features: Dict[str, Any] = field(default_factory=dict)
    timestamp: float = field(default_factory=time.time)
    user_id: Optional[str] = None
    session_id: Optional[str] = None

@dataclass
class MABAction:
    """MABåŠ¨ä½œè®°å½•"""
    action_id: str
    arm_id: str
    context: MABContext
    timestamp: float = field(default_factory=time.time)
    reward: Optional[float] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class MABConfiguration:
    """MABé…ç½®"""
    algorithm: MABAlgorithm = MABAlgorithm.UCB1
    epsilon: float = 0.1              # Îµ-è´ªå¿ƒå‚æ•°
    temperature: float = 1.0          # Softmaxæ¸©åº¦å‚æ•°
    ucb_c: float = 1.0               # UCBç½®ä¿¡å‚æ•°
    learning_rate: float = 0.01       # å­¦ä¹ ç‡
    decay_factor: float = 0.99        # è¡°å‡å› å­
    
    # æŒä¹…åŒ–è®¾ç½®
    auto_save_interval: float = 60.0  # è‡ªåŠ¨ä¿å­˜é—´éš”ï¼ˆç§’ï¼‰
    max_history_length: int = 1000    # æœ€å¤§å†å²é•¿åº¦
    enable_contextual: bool = False   # æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥
    enable_cold_start: bool = True    # æ˜¯å¦å¯ç”¨å†·å¯åŠ¨ä¼˜åŒ–

# =============================================================================
# æ™ºèƒ½MABç®—æ³•å®ç°
# =============================================================================

class IntelligentMABEngine:
    """æ™ºèƒ½å¤šè‡‚è€è™æœºå¼•æ“"""
    
    def __init__(self,
                 config: MABConfiguration = None,
                 storage_engine: PersistentStorageEngine = None):
        """
        åˆå§‹åŒ–æ™ºèƒ½MABå¼•æ“
        
        Args:
            config: MABé…ç½®
            storage_engine: å­˜å‚¨å¼•æ“
        """
        self.config = config or MABConfiguration()
        self.storage_engine = storage_engine
        
        # MABçŠ¶æ€
        self.arms: Dict[str, MABArm] = {}
        self.actions_history: deque = deque(maxlen=self.config.max_history_length)
        self.total_rounds: int = 0
        
        # ä¸Šä¸‹æ–‡æ„ŸçŸ¥
        self.contextual_models = {}
        self.feature_importance = defaultdict(float)
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            "total_actions": 0,
            "total_reward": 0.0,
            "cumulative_regret": 0.0,
            "algorithm_switches": 0,
            "cold_start_actions": 0
        }
        
        # çº¿ç¨‹å®‰å…¨
        self._lock = threading.RLock()
        
        # è‡ªåŠ¨ä¿å­˜
        self.auto_save_timer = None
        if self.storage_engine and self.config.auto_save_interval > 0:
            self._start_auto_save()
        
        logger.info(f"ğŸ° æ™ºèƒ½MABå¼•æ“åˆå§‹åŒ–: {self.config.algorithm.value}")
    
    def add_arm(self, arm: MABArm) -> bool:
        """æ·»åŠ è‡‚"""
        with self._lock:
            if arm.arm_id in self.arms:
                logger.warning(f"âš ï¸ è‡‚å·²å­˜åœ¨: {arm.arm_id}")
                return False
            
            self.arms[arm.arm_id] = arm
            logger.info(f"â• æ·»åŠ MABè‡‚: {arm.arm_id} ({arm.name})")
            
            # å¦‚æœå¯ç”¨äº†å†·å¯åŠ¨ï¼Œç»™æ–°è‡‚ä¸€äº›åˆå§‹æ¢ç´¢æœºä¼š
            if self.config.enable_cold_start:
                arm.total_pulls = 1
                arm.total_reward = 0.5  # ä¸­æ€§åˆå§‹å¥–åŠ±
            
            return True
    
    def remove_arm(self, arm_id: str) -> bool:
        """ç§»é™¤è‡‚"""
        with self._lock:
            if arm_id not in self.arms:
                logger.warning(f"âš ï¸ è‡‚ä¸å­˜åœ¨: {arm_id}")
                return False
            
            del self.arms[arm_id]
            logger.info(f"â– ç§»é™¤MABè‡‚: {arm_id}")
            return True
    
    def select_arm(self, context: MABContext = None) -> Optional[str]:
        """
        é€‰æ‹©è‡‚
        
        Args:
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            é€‰æ‹©çš„è‡‚ID
        """
        with self._lock:
            if not self.arms:
                logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„è‡‚")
                return None
            
            # æ ¹æ®ç®—æ³•é€‰æ‹©è‡‚
            if self.config.algorithm == MABAlgorithm.EPSILON_GREEDY:
                selected_arm = self._epsilon_greedy_selection()
            elif self.config.algorithm == MABAlgorithm.UCB1:
                selected_arm = self._ucb1_selection()
            elif self.config.algorithm == MABAlgorithm.THOMPSON_SAMPLING:
                selected_arm = self._thompson_sampling_selection()
            elif self.config.algorithm == MABAlgorithm.SOFTMAX:
                selected_arm = self._softmax_selection()
            else:
                selected_arm = self._adaptive_greedy_selection()
            
            # è®°å½•åŠ¨ä½œ
            if selected_arm:
                action = MABAction(
                    action_id=f"action_{uuid.uuid4().hex[:8]}",
                    arm_id=selected_arm,
                    context=context or MABContext(f"ctx_{uuid.uuid4().hex[:8]}")
                )
                self.actions_history.append(action)
                
                # æ›´æ–°ç»Ÿè®¡
                self.performance_stats["total_actions"] += 1
                if self.arms[selected_arm].total_pulls == 0:
                    self.performance_stats["cold_start_actions"] += 1
            
            logger.debug(f"ğŸ¯ é€‰æ‹©è‡‚: {selected_arm}")
            return selected_arm
    
    def update_reward(self, arm_id: str, reward: float, context: MABContext = None) -> bool:
        """
        æ›´æ–°å¥–åŠ±
        
        Args:
            arm_id: è‡‚ID
            reward: å¥–åŠ±å€¼
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        with self._lock:
            if arm_id not in self.arms:
                logger.warning(f"âš ï¸ è‡‚ä¸å­˜åœ¨: {arm_id}")
                return False
            
            arm = self.arms[arm_id]
            current_time = time.time()
            
            # æ›´æ–°è‡‚ç»Ÿè®¡
            arm.total_pulls += 1
            arm.total_reward += reward
            arm.reward_history.append(reward)
            arm.pull_timestamps.append(current_time)
            arm.last_updated = current_time
            
            # æ›´æ–°æˆåŠŸ/å¤±è´¥è®¡æ•°ï¼ˆäºŒå…ƒå¥–åŠ±ï¼‰
            if reward > 0.5:  # ç®€åŒ–çš„æˆåŠŸåˆ¤å®š
                arm.success_count += 1
            else:
                arm.failure_count += 1
            
            # æ›´æ–°Thompson Samplingå‚æ•°
            arm.thompson_alpha += reward
            arm.thompson_beta += (1.0 - reward)
            
            # è®¡ç®—ç½®ä¿¡åŠå¾„
            arm.confidence_radius = math.log(self.total_rounds + 1) / max(arm.total_pulls, 1)
            
            # é™åˆ¶å†å²é•¿åº¦
            max_history = self.config.max_history_length
            if len(arm.reward_history) > max_history:
                arm.reward_history = arm.reward_history[-max_history:]
                arm.pull_timestamps = arm.pull_timestamps[-max_history:]
            
            # æ›´æ–°å…¨å±€ç»Ÿè®¡
            self.total_rounds += 1
            self.performance_stats["total_reward"] += reward
            
            # æ›´æ–°æœ€è¿‘åŠ¨ä½œçš„å¥–åŠ±
            if self.actions_history:
                last_action = self.actions_history[-1]
                if last_action.arm_id == arm_id and last_action.reward is None:
                    last_action.reward = reward
                    last_action.context = context or last_action.context
            
            logger.debug(f"ğŸ“Š æ›´æ–°å¥–åŠ±: {arm_id} = {reward:.3f}")
            return True
    
    def _epsilon_greedy_selection(self) -> str:
        """Îµ-è´ªå¿ƒé€‰æ‹©"""
        if np.random.random() < self.config.epsilon:
            # æ¢ç´¢ï¼šéšæœºé€‰æ‹©
            return np.random.choice(list(self.arms.keys()))
        else:
            # åˆ©ç”¨ï¼šé€‰æ‹©æœ€é«˜å¹³å‡å¥–åŠ±çš„è‡‚
            best_arm = max(self.arms.keys(), key=lambda x: self.arms[x].average_reward)
            return best_arm
    
    def _ucb1_selection(self) -> str:
        """UCB1é€‰æ‹©"""
        if self.total_rounds == 0:
            return np.random.choice(list(self.arms.keys()))
        
        def ucb1_value(arm: MABArm) -> float:
            if arm.total_pulls == 0:
                return float('inf')  # æœªæ‹‰è¿‡çš„è‡‚ä¼˜å…ˆ
            
            confidence_term = self.config.ucb_c * math.sqrt(
                math.log(self.total_rounds) / arm.total_pulls
            )
            return arm.average_reward + confidence_term
        
        best_arm = max(self.arms.keys(), key=lambda x: ucb1_value(self.arms[x]))
        return best_arm
    
    def _thompson_sampling_selection(self) -> str:
        """Thompsoné‡‡æ ·é€‰æ‹©"""
        arm_scores = {}
        
        for arm_id, arm in self.arms.items():
            # ä»Betaåˆ†å¸ƒé‡‡æ ·
            score = np.random.beta(arm.thompson_alpha, arm.thompson_beta)
            arm_scores[arm_id] = score
        
        best_arm = max(arm_scores.keys(), key=lambda x: arm_scores[x])
        return best_arm
    
    def _softmax_selection(self) -> str:
        """Softmaxé€‰æ‹©"""
        if not self.arms:
            return None
        
        # è®¡ç®—softmaxæ¦‚ç‡
        arm_ids = list(self.arms.keys())
        values = [self.arms[arm_id].average_reward for arm_id in arm_ids]
        
        # é˜²æ­¢æ•°å€¼æº¢å‡º
        max_value = max(values)
        exp_values = [math.exp((v - max_value) / self.config.temperature) for v in values]
        sum_exp = sum(exp_values)
        
        probabilities = [exp_v / sum_exp for exp_v in exp_values]
        
        # æ ¹æ®æ¦‚ç‡é€‰æ‹©
        selected_idx = np.random.choice(len(arm_ids), p=probabilities)
        return arm_ids[selected_idx]
    
    def _adaptive_greedy_selection(self) -> str:
        """è‡ªé€‚åº”è´ªå¿ƒé€‰æ‹©"""
        # åŠ¨æ€è°ƒæ•´æ¢ç´¢ç‡
        if self.total_rounds < 100:
            epsilon = 0.3  # æ—©æœŸé«˜æ¢ç´¢
        elif self.total_rounds < 1000:
            epsilon = 0.1  # ä¸­æœŸé€‚åº¦æ¢ç´¢
        else:
            epsilon = 0.05  # åæœŸä½æ¢ç´¢
        
        if np.random.random() < epsilon:
            return np.random.choice(list(self.arms.keys()))
        else:
            # è€ƒè™‘ç½®ä¿¡åŒºé—´çš„é€‰æ‹©
            def adaptive_value(arm: MABArm) -> float:
                if arm.total_pulls == 0:
                    return 1.0
                
                lower_bound, upper_bound = arm.confidence_interval
                # ä¹è§‚ä¼°è®¡ï¼šä½¿ç”¨ç½®ä¿¡åŒºé—´ä¸Šç•Œ
                return upper_bound
            
            best_arm = max(self.arms.keys(), key=lambda x: adaptive_value(self.arms[x]))
            return best_arm
    
    def get_arm_rankings(self) -> List[Tuple[str, float]]:
        """è·å–è‡‚æ’å"""
        with self._lock:
            rankings = [(arm_id, arm.average_reward) for arm_id, arm in self.arms.items()]
            rankings.sort(key=lambda x: x[1], reverse=True)
            return rankings
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        with self._lock:
            total_actions = self.performance_stats["total_actions"]
            
            # è®¡ç®—ç´¯ç§¯åæ‚”
            if total_actions > 0:
                best_possible_reward = max(arm.average_reward for arm in self.arms.values()) if self.arms else 0
                actual_average_reward = self.performance_stats["total_reward"] / total_actions
                cumulative_regret = (best_possible_reward - actual_average_reward) * total_actions
            else:
                cumulative_regret = 0
            
            # è®¡ç®—æ¢ç´¢åˆ©ç”¨æ¯”ç‡
            exploration_actions = sum(1 for action in self.actions_history 
                                    if self._is_exploration_action(action))
            exploration_rate = exploration_actions / max(total_actions, 1)
            
            return {
                "total_rounds": self.total_rounds,
                "total_actions": total_actions,
                "average_reward": self.performance_stats["total_reward"] / max(total_actions, 1),
                "cumulative_regret": cumulative_regret,
                "exploration_rate": exploration_rate,
                "cold_start_actions": self.performance_stats["cold_start_actions"],
                "algorithm": self.config.algorithm.value,
                "arms_count": len(self.arms),
                "active_arms": len([arm for arm in self.arms.values() if arm.total_pulls > 0])
            }
    
    def _is_exploration_action(self, action: MABAction) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ¢ç´¢åŠ¨ä½œ"""
        if not self.arms or action.arm_id not in self.arms:
            return True
        
        arm = self.arms[action.arm_id]
        rankings = self.get_arm_rankings()
        
        # å¦‚æœé€‰æ‹©çš„ä¸æ˜¯å½“å‰æœ€ä½³è‡‚ï¼Œåˆ™è®¤ä¸ºæ˜¯æ¢ç´¢
        best_arm_id = rankings[0][0] if rankings else None
        return action.arm_id != best_arm_id
    
    def save_state(self, key: str = "mab_state") -> bool:
        """ä¿å­˜MABçŠ¶æ€"""
        if not self.storage_engine:
            logger.warning("âš ï¸ æ²¡æœ‰å­˜å‚¨å¼•æ“ï¼Œæ— æ³•ä¿å­˜çŠ¶æ€")
            return False
        
        try:
            with self._lock:
                state_data = {
                    "config": asdict(self.config),
                    "arms": {arm_id: asdict(arm) for arm_id, arm in self.arms.items()},
                    "total_rounds": self.total_rounds,
                    "performance_stats": self.performance_stats,
                    "actions_history": [asdict(action) for action in list(self.actions_history)[-100:]],  # åªä¿å­˜æœ€è¿‘100ä¸ª
                    "saved_at": time.time()
                }
                
                success = self.storage_engine.store(key, state_data)
                if success:
                    logger.info(f"ğŸ’¾ MABçŠ¶æ€ä¿å­˜æˆåŠŸ: {key}")
                
                return success
                
        except Exception as e:
            logger.error(f"âŒ MABçŠ¶æ€ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def load_state(self, key: str = "mab_state") -> bool:
        """åŠ è½½MABçŠ¶æ€"""
        if not self.storage_engine:
            logger.warning("âš ï¸ æ²¡æœ‰å­˜å‚¨å¼•æ“ï¼Œæ— æ³•åŠ è½½çŠ¶æ€")
            return False
        
        try:
            state_data = self.storage_engine.retrieve(key)
            if not state_data:
                logger.info("â„¹ï¸ æ²¡æœ‰æ‰¾åˆ°MABçŠ¶æ€æ•°æ®")
                return False
            
            with self._lock:
                # æ¢å¤é…ç½®
                if "config" in state_data:
                    config_data = state_data["config"]
                    config_data["algorithm"] = MABAlgorithm(config_data["algorithm"])
                    self.config = MABConfiguration(**config_data)
                
                # æ¢å¤è‡‚
                if "arms" in state_data:
                    self.arms = {}
                    for arm_id, arm_data in state_data["arms"].items():
                        self.arms[arm_id] = MABArm(**arm_data)
                
                # æ¢å¤ç»Ÿè®¡ä¿¡æ¯
                self.total_rounds = state_data.get("total_rounds", 0)
                self.performance_stats = state_data.get("performance_stats", {})
                
                # æ¢å¤åŠ¨ä½œå†å²
                if "actions_history" in state_data:
                    self.actions_history.clear()
                    for action_data in state_data["actions_history"]:
                        context_data = action_data["context"]
                        action_data["context"] = MABContext(**context_data)
                        self.actions_history.append(MABAction(**action_data))
                
                saved_at = state_data.get("saved_at", 0)
                logger.info(f"ğŸ“¥ MABçŠ¶æ€åŠ è½½æˆåŠŸ: {key} (ä¿å­˜äº: {time.ctime(saved_at)})")
                
                return True
                
        except Exception as e:
            logger.error(f"âŒ MABçŠ¶æ€åŠ è½½å¤±è´¥: {e}")
            return False
    
    def _start_auto_save(self):
        """å¯åŠ¨è‡ªåŠ¨ä¿å­˜"""
        def auto_save_loop():
            while True:
                try:
                    time.sleep(self.config.auto_save_interval)
                    self.save_state()
                except Exception as e:
                    logger.error(f"âŒ è‡ªåŠ¨ä¿å­˜å¤±è´¥: {e}")
        
        auto_save_thread = threading.Thread(target=auto_save_loop, daemon=True)
        auto_save_thread.start()
        logger.info(f"â° è‡ªåŠ¨ä¿å­˜å·²å¯åŠ¨: é—´éš” {self.config.auto_save_interval}s")
    
    def reset(self):
        """é‡ç½®MABçŠ¶æ€"""
        with self._lock:
            for arm in self.arms.values():
                arm.total_pulls = 0
                arm.total_reward = 0.0
                arm.success_count = 0
                arm.failure_count = 0
                arm.reward_history.clear()
                arm.pull_timestamps.clear()
                arm.thompson_alpha = 1.0
                arm.thompson_beta = 1.0
            
            self.actions_history.clear()
            self.total_rounds = 0
            self.performance_stats = {
                "total_actions": 0,
                "total_reward": 0.0,
                "cumulative_regret": 0.0,
                "algorithm_switches": 0,
                "cold_start_actions": 0
            }
            
            logger.info("ğŸ”„ MABçŠ¶æ€å·²é‡ç½®")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.auto_save_timer:
            self.auto_save_timer.cancel()
        
        # æœ€åä¿å­˜ä¸€æ¬¡
        if self.storage_engine:
            self.save_state()
        
        logger.info("ğŸ§¹ æ™ºèƒ½MABå¼•æ“æ¸…ç†å®Œæˆ")

# =============================================================================
# é«˜çº§MABç®¡ç†å™¨
# =============================================================================

class AdvancedMABManager:
    """
    é«˜çº§MABç®¡ç†å™¨
    
    åŠŸèƒ½ï¼š
    - å¤šMABå¼•æ“ç®¡ç†
    - ç­–ç•¥è‡ªåŠ¨åˆ‡æ¢
    - A/Bæµ‹è¯•æ”¯æŒ
    - æ€§èƒ½å¯¹æ¯”åˆ†æ
    """
    
    def __init__(self,
                 storage_engine: PersistentStorageEngine = None,
                 distributed_state_manager: DistributedStateManager = None):
        """
        åˆå§‹åŒ–é«˜çº§MABç®¡ç†å™¨
        
        Args:
            storage_engine: å­˜å‚¨å¼•æ“
            distributed_state_manager: åˆ†å¸ƒå¼çŠ¶æ€ç®¡ç†å™¨
        """
        self.storage_engine = storage_engine
        self.distributed_state_manager = distributed_state_manager
        
        # MABå¼•æ“ç®¡ç†
        self.mab_engines: Dict[str, IntelligentMABEngine] = {}
        self.active_engine_id: str = "default"
        
        # A/Bæµ‹è¯•
        self.ab_test_configs = {}
        self.ab_test_results = defaultdict(list)
        
        # æ€§èƒ½ç›‘æ§
        self.performance_history = deque(maxlen=1000)
        self.algorithm_performance = defaultdict(list)
        
        # çº¿ç¨‹å®‰å…¨
        self._lock = threading.RLock()
        
        # åˆ›å»ºé»˜è®¤å¼•æ“
        self._create_default_engine()
        
        logger.info("ğŸ° é«˜çº§MABç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _create_default_engine(self):
        """åˆ›å»ºé»˜è®¤MABå¼•æ“"""
        default_config = MABConfiguration(
            algorithm=MABAlgorithm.UCB1,
            enable_cold_start=True,
            auto_save_interval=300.0  # 5åˆ†é’Ÿè‡ªåŠ¨ä¿å­˜
        )
        
        default_engine = IntelligentMABEngine(
            config=default_config,
            storage_engine=self.storage_engine
        )
        
        self.mab_engines["default"] = default_engine
        self.active_engine_id = "default"
    
    def create_engine(self, 
                     engine_id: str,
                     config: MABConfiguration,
                     arms: List[MABArm] = None) -> bool:
        """åˆ›å»ºæ–°çš„MABå¼•æ“"""
        with self._lock:
            if engine_id in self.mab_engines:
                logger.warning(f"âš ï¸ MABå¼•æ“å·²å­˜åœ¨: {engine_id}")
                return False
            
            engine = IntelligentMABEngine(
                config=config,
                storage_engine=self.storage_engine
            )
            
            # æ·»åŠ è‡‚
            if arms:
                for arm in arms:
                    engine.add_arm(arm)
            
            self.mab_engines[engine_id] = engine
            logger.info(f"â• åˆ›å»ºMABå¼•æ“: {engine_id}")
            
            return True
    
    def switch_engine(self, engine_id: str) -> bool:
        """åˆ‡æ¢æ´»è·ƒå¼•æ“"""
        with self._lock:
            if engine_id not in self.mab_engines:
                logger.warning(f"âš ï¸ MABå¼•æ“ä¸å­˜åœ¨: {engine_id}")
                return False
            
            old_engine_id = self.active_engine_id
            self.active_engine_id = engine_id
            
            logger.info(f"ğŸ”„ åˆ‡æ¢MABå¼•æ“: {old_engine_id} -> {engine_id}")
            return True
    
    def get_active_engine(self) -> IntelligentMABEngine:
        """è·å–æ´»è·ƒå¼•æ“"""
        return self.mab_engines[self.active_engine_id]
    
    def select_arm(self, context: MABContext = None, engine_id: str = None) -> Optional[str]:
        """é€‰æ‹©è‡‚"""
        engine = self.mab_engines.get(engine_id or self.active_engine_id)
        if not engine:
            logger.warning(f"âš ï¸ MABå¼•æ“ä¸å­˜åœ¨: {engine_id}")
            return None
        
        return engine.select_arm(context)
    
    def update_reward(self, 
                     arm_id: str, 
                     reward: float, 
                     context: MABContext = None,
                     engine_id: str = None) -> bool:
        """æ›´æ–°å¥–åŠ±"""
        engine = self.mab_engines.get(engine_id or self.active_engine_id)
        if not engine:
            logger.warning(f"âš ï¸ MABå¼•æ“ä¸å­˜åœ¨: {engine_id}")
            return False
        
        success = engine.update_reward(arm_id, reward, context)
        
        # è®°å½•æ€§èƒ½å†å²
        if success:
            performance_record = {
                "timestamp": time.time(),
                "engine_id": engine_id or self.active_engine_id,
                "arm_id": arm_id,
                "reward": reward,
                "algorithm": engine.config.algorithm.value
            }
            self.performance_history.append(performance_record)
            self.algorithm_performance[engine.config.algorithm.value].append(reward)
        
        return success
    
    def run_ab_test(self,
                   test_name: str,
                   engines: List[str],
                   duration: float = 3600.0,
                   traffic_split: List[float] = None) -> Dict[str, Any]:
        """
        è¿è¡ŒA/Bæµ‹è¯•
        
        Args:
            test_name: æµ‹è¯•åç§°
            engines: å‚ä¸æµ‹è¯•çš„å¼•æ“IDåˆ—è¡¨
            duration: æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
            traffic_split: æµé‡åˆ†é…æ¯”ä¾‹
            
        Returns:
            A/Bæµ‹è¯•ç»“æœ
        """
        if traffic_split is None:
            traffic_split = [1.0 / len(engines)] * len(engines)
        
        if len(engines) != len(traffic_split) or abs(sum(traffic_split) - 1.0) > 0.01:
            logger.error("âŒ å¼•æ“æ•°é‡ä¸æµé‡åˆ†é…ä¸åŒ¹é…")
            return {}
        
        # é…ç½®A/Bæµ‹è¯•
        ab_config = {
            "test_name": test_name,
            "engines": engines,
            "traffic_split": traffic_split,
            "start_time": time.time(),
            "duration": duration,
            "status": "running"
        }
        
        self.ab_test_configs[test_name] = ab_config
        
        logger.info(f"ğŸ§ª A/Bæµ‹è¯•å¼€å§‹: {test_name} ({len(engines)} ä¸ªå¼•æ“)")
        
        # æ³¨æ„ï¼šå®é™…çš„A/Bæµ‹è¯•æ‰§è¡Œéœ€è¦åœ¨select_armæ–¹æ³•ä¸­å®ç°æµé‡åˆ†é…é€»è¾‘
        # è¿™é‡Œåªæ˜¯é…ç½®æµ‹è¯•å‚æ•°
        
        return ab_config
    
    def get_ab_test_results(self, test_name: str) -> Dict[str, Any]:
        """è·å–A/Bæµ‹è¯•ç»“æœ"""
        if test_name not in self.ab_test_configs:
            return {}
        
        config = self.ab_test_configs[test_name]
        results = {}
        
        for engine_id in config["engines"]:
            if engine_id in self.mab_engines:
                engine = self.mab_engines[engine_id]
                metrics = engine.get_performance_metrics()
                results[engine_id] = metrics
        
        return {
            "test_config": config,
            "engine_results": results,
            "generated_at": time.time()
        }
    
    def get_global_performance_summary(self) -> Dict[str, Any]:
        """è·å–å…¨å±€æ€§èƒ½æ‘˜è¦"""
        with self._lock:
            total_actions = len(self.performance_history)
            if total_actions == 0:
                return {"total_actions": 0}
            
            # ç®—æ³•æ€§èƒ½å¯¹æ¯”
            algorithm_stats = {}
            for algorithm, rewards in self.algorithm_performance.items():
                if rewards:
                    algorithm_stats[algorithm] = {
                        "avg_reward": np.mean(rewards),
                        "std_reward": np.std(rewards),
                        "total_actions": len(rewards),
                        "best_reward": max(rewards),
                        "worst_reward": min(rewards)
                    }
            
            # å¼•æ“æ€§èƒ½å¯¹æ¯”
            engine_stats = {}
            for engine_id, engine in self.mab_engines.items():
                engine_stats[engine_id] = engine.get_performance_metrics()
            
            # æœ€è¿‘æ€§èƒ½è¶‹åŠ¿
            recent_performance = list(self.performance_history)[-100:]  # æœ€è¿‘100ä¸ªåŠ¨ä½œ
            recent_avg_reward = np.mean([r["reward"] for r in recent_performance]) if recent_performance else 0
            
            return {
                "total_actions": total_actions,
                "active_engine": self.active_engine_id,
                "engines_count": len(self.mab_engines),
                "recent_avg_reward": recent_avg_reward,
                "algorithm_performance": algorithm_stats,
                "engine_performance": engine_stats,
                "active_ab_tests": len([config for config in self.ab_test_configs.values() 
                                      if config["status"] == "running"])
            }
    
    def auto_optimize_algorithm(self) -> str:
        """è‡ªåŠ¨ä¼˜åŒ–ç®—æ³•é€‰æ‹©"""
        if len(self.algorithm_performance) < 2:
            logger.info("â„¹ï¸ ç®—æ³•æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè‡ªåŠ¨ä¼˜åŒ–")
            return self.get_active_engine().config.algorithm.value
        
        # è®¡ç®—å„ç®—æ³•çš„æ€§èƒ½
        best_algorithm = None
        best_performance = -float('inf')
        
        for algorithm, rewards in self.algorithm_performance.items():
            if len(rewards) >= 10:  # è‡³å°‘éœ€è¦10ä¸ªæ ·æœ¬
                performance = np.mean(rewards[-50:])  # ä½¿ç”¨æœ€è¿‘50ä¸ªæ ·æœ¬
                if performance > best_performance:
                    best_performance = performance
                    best_algorithm = algorithm
        
        if best_algorithm and best_algorithm != self.get_active_engine().config.algorithm.value:
            # åˆ›å»ºæ–°çš„ä¼˜åŒ–å¼•æ“
            optimized_config = MABConfiguration(algorithm=MABAlgorithm(best_algorithm))
            optimized_engine_id = f"optimized_{best_algorithm}_{int(time.time())}"
            
            if self.create_engine(optimized_engine_id, optimized_config):
                # å¤åˆ¶å½“å‰å¼•æ“çš„è‡‚
                current_engine = self.get_active_engine()
                optimized_engine = self.mab_engines[optimized_engine_id]
                
                for arm_id, arm in current_engine.arms.items():
                    optimized_engine.add_arm(arm)
                
                logger.info(f"ğŸ¯ è‡ªåŠ¨ä¼˜åŒ–: åˆ‡æ¢åˆ°ç®—æ³• {best_algorithm}")
                return best_algorithm
        
        return self.get_active_engine().config.algorithm.value
    
    def save_all_states(self) -> bool:
        """ä¿å­˜æ‰€æœ‰å¼•æ“çŠ¶æ€"""
        success_count = 0
        total_count = len(self.mab_engines)
        
        for engine_id, engine in self.mab_engines.items():
            if engine.save_state(f"mab_engine_{engine_id}"):
                success_count += 1
        
        # ä¿å­˜ç®¡ç†å™¨çŠ¶æ€
        manager_state = {
            "active_engine_id": self.active_engine_id,
            "ab_test_configs": self.ab_test_configs,
            "performance_history": list(self.performance_history)[-100:],  # åªä¿å­˜æœ€è¿‘100ä¸ª
            "saved_at": time.time()
        }
        
        if self.storage_engine:
            if self.storage_engine.store("mab_manager_state", manager_state):
                success_count += 1
                total_count += 1
        
        logger.info(f"ğŸ’¾ ä¿å­˜MABçŠ¶æ€: {success_count}/{total_count} æˆåŠŸ")
        return success_count == total_count
    
    def load_all_states(self) -> bool:
        """åŠ è½½æ‰€æœ‰å¼•æ“çŠ¶æ€"""
        # åŠ è½½ç®¡ç†å™¨çŠ¶æ€
        if self.storage_engine:
            manager_state = self.storage_engine.retrieve("mab_manager_state")
            if manager_state:
                self.active_engine_id = manager_state.get("active_engine_id", "default")
                self.ab_test_configs = manager_state.get("ab_test_configs", {})
                
                # æ¢å¤æ€§èƒ½å†å²
                history_data = manager_state.get("performance_history", [])
                self.performance_history.clear()
                self.performance_history.extend(history_data)
                
                logger.info("ğŸ“¥ MABç®¡ç†å™¨çŠ¶æ€åŠ è½½æˆåŠŸ")
        
        # åŠ è½½å¼•æ“çŠ¶æ€
        success_count = 0
        for engine_id, engine in self.mab_engines.items():
            if engine.load_state(f"mab_engine_{engine_id}"):
                success_count += 1
        
        logger.info(f"ğŸ“¥ åŠ è½½MABå¼•æ“çŠ¶æ€: {success_count}/{len(self.mab_engines)} æˆåŠŸ")
        return success_count > 0
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        # ä¿å­˜æ‰€æœ‰çŠ¶æ€
        self.save_all_states()
        
        # æ¸…ç†æ‰€æœ‰å¼•æ“
        for engine in self.mab_engines.values():
            engine.cleanup()
        
        logger.info("ğŸ§¹ é«˜çº§MABç®¡ç†å™¨æ¸…ç†å®Œæˆ")

# =============================================================================
# å·¥å‚å‡½æ•°
# =============================================================================

def create_mab_manager(
    storage_backend: str = "file_system",
    storage_path: str = "./neogenesis_mab",
    algorithm: str = "ucb1",
    **kwargs
) -> AdvancedMABManager:
    """
    åˆ›å»ºMABç®¡ç†å™¨
    
    Args:
        storage_backend: å­˜å‚¨åç«¯ç±»å‹
        storage_path: å­˜å‚¨è·¯å¾„
        algorithm: é»˜è®¤ç®—æ³•
        **kwargs: å…¶ä»–é…ç½®å‚æ•°
        
    Returns:
        é«˜çº§MABç®¡ç†å™¨å®ä¾‹
    """
    from .persistent_storage import create_storage_engine
    
    storage_engine = create_storage_engine(storage_backend, storage_path, **kwargs)
    manager = AdvancedMABManager(storage_engine=storage_engine)
    
    # é…ç½®é»˜è®¤å¼•æ“
    if algorithm != "ucb1":
        default_engine = manager.get_active_engine()
        default_engine.config.algorithm = MABAlgorithm(algorithm)
    
    return manager

# =============================================================================
# æµ‹è¯•å’Œæ¼”ç¤º
# =============================================================================

if __name__ == "__main__":
    # æµ‹è¯•MABä¼˜åŒ–ç³»ç»Ÿ
    print("ğŸ§ª æµ‹è¯•MABä¼˜åŒ–ä¸æŒä¹…åŒ–ç³»ç»Ÿ...")
    
    # åˆ›å»ºMABç®¡ç†å™¨
    manager = create_mab_manager("memory", algorithm="ucb1")
    
    # æ·»åŠ æµ‹è¯•è‡‚
    arms = [
        MABArm("strategy_analytical", "åˆ†æå‹ç­–ç•¥", "ç³»ç»Ÿæ€§åˆ†ææ–¹æ³•"),
        MABArm("strategy_creative", "åˆ›æ–°å‹ç­–ç•¥", "åˆ›é€ æ€§æ€ç»´æ–¹æ³•"),
        MABArm("strategy_practical", "å®ç”¨å‹ç­–ç•¥", "å®è·µå¯¼å‘æ–¹æ³•"),
        MABArm("strategy_research", "ç ”ç©¶å‹ç­–ç•¥", "æ·±åº¦ç ”ç©¶æ–¹æ³•")
    ]
    
    active_engine = manager.get_active_engine()
    for arm in arms:
        active_engine.add_arm(arm)
    
    print(f"âœ… æ·»åŠ  {len(arms)} ä¸ªç­–ç•¥è‡‚")
    
    # æ¨¡æ‹ŸMABå­¦ä¹ è¿‡ç¨‹
    print("\nğŸ° æ¨¡æ‹ŸMABå­¦ä¹ è¿‡ç¨‹:")
    for round_num in range(50):
        # é€‰æ‹©ç­–ç•¥
        context = MABContext(f"context_{round_num}", {"round": round_num})
        selected_arm = manager.select_arm(context)
        
        if selected_arm:
            # æ¨¡æ‹Ÿå¥–åŠ±ï¼ˆä¸åŒç­–ç•¥æœ‰ä¸åŒçš„æœŸæœ›å¥–åŠ±ï¼‰
            if selected_arm == "strategy_analytical":
                reward = np.random.beta(8, 3)  # é«˜å¥–åŠ±ç­–ç•¥
            elif selected_arm == "strategy_creative":
                reward = np.random.beta(6, 4)  # ä¸­ç­‰å¥–åŠ±ç­–ç•¥
            elif selected_arm == "strategy_practical":
                reward = np.random.beta(7, 4)  # ä¸­é«˜å¥–åŠ±ç­–ç•¥
            else:
                reward = np.random.beta(5, 5)  # å¹³å‡å¥–åŠ±ç­–ç•¥
            
            # æ›´æ–°å¥–åŠ±
            manager.update_reward(selected_arm, reward, context)
            
            if round_num % 10 == 9:
                rankings = active_engine.get_arm_rankings()
                best_arm = rankings[0]
                print(f"   è½®æ¬¡ {round_num+1}: æœ€ä½³ç­–ç•¥ = {best_arm[0]} (å¥–åŠ±: {best_arm[1]:.3f})")
    
    # è·å–æœ€ç»ˆæ€§èƒ½
    print("\nğŸ“Š æœ€ç»ˆæ€§èƒ½åˆ†æ:")
    rankings = active_engine.get_arm_rankings()
    for i, (arm_id, avg_reward) in enumerate(rankings):
        arm = active_engine.arms[arm_id]
        print(f"   æ’å {i+1}: {arm.name} - å¹³å‡å¥–åŠ±: {avg_reward:.3f} (æ‹‰å–æ¬¡æ•°: {arm.total_pulls})")
    
    # è·å–æ€§èƒ½æŒ‡æ ‡
    metrics = active_engine.get_performance_metrics()
    print(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
    print(f"   æ€»è½®æ¬¡: {metrics['total_rounds']}")
    print(f"   å¹³å‡å¥–åŠ±: {metrics['average_reward']:.3f}")
    print(f"   æ¢ç´¢ç‡: {metrics['exploration_rate']:.3f}")
    print(f"   ç´¯ç§¯åæ‚”: {metrics['cumulative_regret']:.3f}")
    
    # æµ‹è¯•çŠ¶æ€ä¿å­˜å’ŒåŠ è½½
    print("\nğŸ’¾ æµ‹è¯•çŠ¶æ€æŒä¹…åŒ–:")
    save_success = manager.save_all_states()
    print(f"âœ… çŠ¶æ€ä¿å­˜: {'æˆåŠŸ' if save_success else 'å¤±è´¥'}")
    
    # é‡ç½®å¹¶åŠ è½½
    active_engine.reset()
    load_success = manager.load_all_states()
    print(f"âœ… çŠ¶æ€åŠ è½½: {'æˆåŠŸ' if load_success else 'å¤±è´¥'}")
    
    # éªŒè¯æ¢å¤
    if load_success:
        restored_rankings = active_engine.get_arm_rankings()
        print(f"âœ… çŠ¶æ€æ¢å¤éªŒè¯: æœ€ä½³ç­–ç•¥ = {restored_rankings[0][0]}")
    
    # æ¸…ç†
    manager.cleanup()
    
    print("âœ… MABä¼˜åŒ–ä¸æŒä¹…åŒ–ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
