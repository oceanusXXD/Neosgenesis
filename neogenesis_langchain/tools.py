#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Neogenesis System - LangChain Tools
å°†Neogenesis Systemçš„æ ¸å¿ƒç»„ä»¶å°è£…ä¸ºLangChainå·¥å…·
"""

import json
import logging
import time
from typing import Any, Dict, List, Optional, Type, Union
from dataclasses import asdict
from abc import ABC

try:
    from langchain.tools import BaseTool
    from langchain.callbacks.manager import CallbackManagerForToolRun
    from pydantic import BaseModel, Field
    LANGCHAIN_AVAILABLE = True
except ImportError:
    # å¦‚æœLangChainä¸å¯ç”¨ï¼Œåˆ›å»ºå…¼å®¹çš„åŸºç±»
    LANGCHAIN_AVAILABLE = False
    
    class BaseModel:
        pass
    
    class BaseTool(ABC):
        name: str
        description: str
        
        def _run(self, *args, **kwargs):
            raise NotImplementedError
            
        def run(self, *args, **kwargs):
            return self._run(*args, **kwargs)

# å¯¼å…¥Neogenesisæ ¸å¿ƒç»„ä»¶
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from neogenesis_system.meta_mab.reasoner import PriorReasoner
from neogenesis_system.meta_mab.rag_seed_generator import RAGSeedGenerator
from neogenesis_system.meta_mab.path_generator import PathGenerator
from neogenesis_system.meta_mab.mab_converger import MABConverger
from neogenesis_system.meta_mab.utils.search_tools import IdeaVerificationTool as OriginalIdeaVerificationTool
from neogenesis_system.meta_mab.utils.search_client import WebSearchClient

logger = logging.getLogger(__name__)

# =============================================================================
# è¾“å…¥æ¨¡å‹å®šä¹‰
# =============================================================================

class ThinkingSeedInput(BaseModel):
    """æ€ç»´ç§å­ç”Ÿæˆå·¥å…·çš„è¾“å…¥æ¨¡å‹"""
    user_query: str = Field(description="ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬")
    execution_context: Optional[Dict[str, Any]] = Field(
        default=None, 
        description="æ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰"
    )

class RAGSeedInput(BaseModel):
    """RAGç§å­ç”Ÿæˆå·¥å…·çš„è¾“å…¥æ¨¡å‹"""
    user_query: str = Field(description="ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬")
    execution_context: Optional[Dict[str, Any]] = Field(
        default=None,
        description="æ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰"
    )

class PathGeneratorInput(BaseModel):
    """è·¯å¾„ç”Ÿæˆå·¥å…·çš„è¾“å…¥æ¨¡å‹"""
    thinking_seed: str = Field(description="æ€ç»´ç§å­")
    task: str = Field(description="åŸå§‹ä»»åŠ¡æè¿°")
    max_paths: int = Field(default=4, description="æœ€å¤§ç”Ÿæˆè·¯å¾„æ•°")
    mode: str = Field(default='normal', description="ç”Ÿæˆæ¨¡å¼ï¼šnormal æˆ– creative_bypass")

class MABDecisionInput(BaseModel):
    """MABå†³ç­–å·¥å…·çš„è¾“å…¥æ¨¡å‹"""
    reasoning_paths: List[Dict[str, Any]] = Field(description="æ€ç»´è·¯å¾„åˆ—è¡¨")
    user_query: str = Field(description="ç”¨æˆ·æŸ¥è¯¢")
    execution_context: Optional[Dict[str, Any]] = Field(
        default=None,
        description="æ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰"
    )

class IdeaVerificationInput(BaseModel):
    """æƒ³æ³•éªŒè¯å·¥å…·çš„è¾“å…¥æ¨¡å‹"""
    idea_text: str = Field(description="éœ€è¦éªŒè¯çš„æƒ³æ³•æ–‡æœ¬")
    context: Optional[Dict[str, Any]] = Field(
        default=None,
        description="éªŒè¯ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰"
    )

# =============================================================================
# æ ¸å¿ƒå·¥å…·ç±»
# =============================================================================

class NeogenesisThinkingSeedTool(BaseTool):
    """
    Neogenesisæ€ç»´ç§å­ç”Ÿæˆå·¥å…·
    
    åŠŸèƒ½ï¼šåŸºäºç”¨æˆ·æŸ¥è¯¢å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡çš„æ€ç»´ç§å­
    ä¼˜åŠ¿ï¼šæä¾›ä¸“å®¶çº§çš„ä»»åŠ¡åˆ†æå’Œæ€ç»´èµ·ç‚¹
    """
    
    name: str = "neogenesis_thinking_seed"
    description: str = """
    ç”Ÿæˆé«˜è´¨é‡çš„æ€ç»´ç§å­ï¼Œç”¨äºå¤æ‚å†³ç­–ä»»åŠ¡çš„èµ·ç‚¹ã€‚
    
    è¾“å…¥ï¼š
    - user_query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
    - execution_context: å¯é€‰çš„æ‰§è¡Œä¸Šä¸‹æ–‡
    
    è¾“å‡ºï¼šç»“æ„åŒ–çš„æ€ç»´ç§å­æ–‡æœ¬ï¼ŒåŒ…å«é—®é¢˜åˆ†æã€å¤æ‚åº¦è¯„ä¼°å’Œæ¨èç­–ç•¥
    
    é€‚ç”¨åœºæ™¯ï¼šéœ€è¦ç³»ç»Ÿæ€§æ€è€ƒå’Œåˆ†æçš„å¤æ‚ä»»åŠ¡
    """
    args_schema: Type[BaseModel] = ThinkingSeedInput
    
    def __init__(self, api_key: str = "", **kwargs):
        super().__init__(**kwargs)
        # ä½¿ç”¨object.__setattr__ç»•è¿‡Pydanticçš„å­—æ®µéªŒè¯
        object.__setattr__(self, 'reasoner', PriorReasoner(api_key=api_key))
        logger.info("ğŸ§  NeogenesisThinkingSeedTool åˆå§‹åŒ–å®Œæˆ")
    
    def _run(
        self, 
        user_query: str,
        execution_context: Optional[Dict[str, Any]] = None,
        run_manager: Optional[CallbackManagerForToolRun] = None
    ) -> str:
        """
        æ‰§è¡Œæ€ç»´ç§å­ç”Ÿæˆ
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            run_manager: LangChainå›è°ƒç®¡ç†å™¨
            
        Returns:
            æ€ç»´ç§å­æ–‡æœ¬
        """
        try:
            logger.info(f"ğŸŒ± å¼€å§‹ç”Ÿæˆæ€ç»´ç§å­: {user_query[:50]}...")
            
            # è°ƒç”¨åŸå§‹çš„reasoneré€»è¾‘
            thinking_seed = self.reasoner.get_thinking_seed(
                user_query=user_query,
                execution_context=execution_context
            )
            
            # è·å–ç½®ä¿¡åº¦è¯„ä¼°
            confidence = self.reasoner.assess_task_confidence(
                user_query=user_query,
                execution_context=execution_context
            )
            
            # è·å–å¤æ‚åº¦åˆ†æ
            complexity_info = self.reasoner.analyze_task_complexity(user_query)
            
            # æ„å»ºå¢å¼ºçš„è¾“å‡º
            enhanced_output = {
                "thinking_seed": thinking_seed,
                "confidence_score": confidence,
                "complexity_analysis": complexity_info,
                "tool_metadata": {
                    "tool_name": self.name,
                    "generation_time": time.time(),
                    "query_length": len(user_query)
                }
            }
            
            logger.info(f"âœ… æ€ç»´ç§å­ç”Ÿæˆå®Œæˆ (ç½®ä¿¡åº¦: {confidence:.3f})")
            return json.dumps(enhanced_output, ensure_ascii=False, indent=2)
            
        except Exception as e:
            error_msg = f"æ€ç»´ç§å­ç”Ÿæˆå¤±è´¥: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            return json.dumps({
                "error": error_msg,
                "fallback_seed": f"é’ˆå¯¹'{user_query}'è¿™ä¸ªä»»åŠ¡ï¼Œéœ€è¦è¿›è¡Œç³»ç»Ÿæ€§çš„åˆ†æå’Œè§£å†³ã€‚",
                "tool_metadata": {"tool_name": self.name, "error_time": time.time()}
            }, ensure_ascii=False)

class NeogenesisRAGSeedTool(BaseTool):
    """
    Neogenesis RAGå¢å¼ºç§å­ç”Ÿæˆå·¥å…·
    
    åŠŸèƒ½ï¼šç»“åˆå®æ—¶ä¿¡æ¯æœç´¢ç”Ÿæˆå¢å¼ºçš„æ€ç»´ç§å­
    ä¼˜åŠ¿ï¼šæ•´åˆæœ€æ–°ä¿¡æ¯ï¼Œæä¾›ä¿¡æ¯ä¸°å¯Œçš„åˆ†æèµ·ç‚¹
    """
    
    name: str = "neogenesis_rag_seed"
    description: str = """
    ä½¿ç”¨RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æŠ€æœ¯ç”Ÿæˆä¿¡æ¯ä¸°å¯Œçš„æ€ç»´ç§å­ã€‚
    
    è¾“å…¥ï¼š
    - user_query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
    - execution_context: å¯é€‰çš„æ‰§è¡Œä¸Šä¸‹æ–‡
    
    è¾“å‡ºï¼šåŒ…å«å®æ—¶ä¿¡æ¯çš„å¢å¼ºæ€ç»´ç§å­ï¼Œæ•´åˆäº†ç½‘ç»œæœç´¢ç»“æœ
    
    é€‚ç”¨åœºæ™¯ï¼šéœ€è¦æœ€æ–°ä¿¡æ¯æ”¯æŒçš„å†³ç­–ä»»åŠ¡ã€ç ”ç©¶åˆ†æç­‰
    """
    args_schema: Type[BaseModel] = RAGSeedInput
    
    def __init__(self, api_key: str = "", search_engine: str = "duckduckgo", 
                 web_search_client=None, llm_client=None, **kwargs):
        super().__init__(**kwargs)
        # ä½¿ç”¨object.__setattr__ç»•è¿‡Pydanticçš„å­—æ®µéªŒè¯
        object.__setattr__(self, 'rag_generator', RAGSeedGenerator(
            api_key=api_key,
            search_engine=search_engine,
            web_search_client=web_search_client,
            llm_client=llm_client
        ))
        logger.info("ğŸ” NeogenesisRAGSeedTool åˆå§‹åŒ–å®Œæˆ")
    
    def _run(
        self, 
        user_query: str,
        execution_context: Optional[Dict[str, Any]] = None,
        run_manager: Optional[CallbackManagerForToolRun] = None
    ) -> str:
        """
        æ‰§è¡ŒRAGå¢å¼ºç§å­ç”Ÿæˆ
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            run_manager: LangChainå›è°ƒç®¡ç†å™¨
            
        Returns:
            RAGå¢å¼ºçš„æ€ç»´ç§å­
        """
        try:
            logger.info(f"ğŸ” å¼€å§‹RAGå¢å¼ºç§å­ç”Ÿæˆ: {user_query[:50]}...")
            
            # è°ƒç”¨åŸå§‹çš„RAGç”Ÿæˆé€»è¾‘
            rag_seed = self.rag_generator.generate_rag_seed(
                user_query=user_query,
                execution_context=execution_context
            )
            
            # è·å–æ€§èƒ½ç»Ÿè®¡
            performance_stats = self.rag_generator.get_rag_performance_stats()
            
            # æ„å»ºè¾“å‡º
            output = {
                "rag_enhanced_seed": rag_seed,
                "performance_stats": performance_stats,
                "tool_metadata": {
                    "tool_name": self.name,
                    "generation_time": time.time(),
                    "search_enabled": True
                }
            }
            
            logger.info("âœ… RAGå¢å¼ºç§å­ç”Ÿæˆå®Œæˆ")
            return json.dumps(output, ensure_ascii=False, indent=2)
            
        except Exception as e:
            error_msg = f"RAGç§å­ç”Ÿæˆå¤±è´¥: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            
            # å›é€€åˆ°åŸºç¡€ç§å­ç”Ÿæˆ
            fallback_output = {
                "error": error_msg,
                "fallback_seed": f"åŸºäº'{user_query}'çš„åŸºç¡€åˆ†æï¼Œå»ºè®®é‡‡ç”¨ç³»ç»Ÿæ€§æ–¹æ³•è¿›è¡Œå¤„ç†ã€‚",
                "tool_metadata": {"tool_name": self.name, "error_time": time.time()}
            }
            return json.dumps(fallback_output, ensure_ascii=False)

class NeogenesisPathGeneratorTool(BaseTool):
    """
    Neogenesisæ€ç»´è·¯å¾„ç”Ÿæˆå·¥å…·
    
    åŠŸèƒ½ï¼šåŸºäºæ€ç»´ç§å­ç”Ÿæˆå¤šæ ·åŒ–çš„æ€ç»´è·¯å¾„
    ä¼˜åŠ¿ï¼šæä¾›å¤šè§’åº¦æ€è€ƒæ–¹æ¡ˆï¼Œæ”¯æŒåˆ›é€ æ€§ç»•é“æ¨¡å¼
    """
    
    name: str = "neogenesis_path_generator"
    description: str = """
    åŸºäºæ€ç»´ç§å­ç”Ÿæˆå¤šæ ·åŒ–çš„æ€ç»´è·¯å¾„ã€‚
    
    è¾“å…¥ï¼š
    - thinking_seed: æ€ç»´ç§å­æ–‡æœ¬
    - task: åŸå§‹ä»»åŠ¡æè¿°
    - max_paths: æœ€å¤§ç”Ÿæˆè·¯å¾„æ•°ï¼ˆé»˜è®¤4ï¼‰
    - mode: ç”Ÿæˆæ¨¡å¼ï¼ˆnormal æˆ– creative_bypassï¼‰
    
    è¾“å‡ºï¼šåŒ…å«å¤šä¸ªæ€ç»´è·¯å¾„çš„ç»“æ„åŒ–åˆ—è¡¨ï¼Œæ¯ä¸ªè·¯å¾„æœ‰ä¸åŒçš„æ€è€ƒè§’åº¦
    
    é€‚ç”¨åœºæ™¯ï¼šéœ€è¦å¤šè§’åº¦åˆ†æã€åˆ›æ–°æ€ç»´ã€å¤æ‚å†³ç­–çš„ä»»åŠ¡
    """
    args_schema: Type[BaseModel] = PathGeneratorInput
    
    def __init__(self, api_key: str = "", llm_client=None, **kwargs):
        super().__init__(**kwargs)
        # ä½¿ç”¨object.__setattr__ç»•è¿‡Pydanticçš„å­—æ®µéªŒè¯
        object.__setattr__(self, 'path_generator', PathGenerator(
            api_key=api_key,
            llm_client=llm_client
        ))
        logger.info("ğŸ›¤ï¸ NeogenesisPathGeneratorTool åˆå§‹åŒ–å®Œæˆ")
    
    def _run(
        self, 
        thinking_seed: str,
        task: str,
        max_paths: int = 4,
        mode: str = 'normal',
        run_manager: Optional[CallbackManagerForToolRun] = None
    ) -> str:
        """
        æ‰§è¡Œæ€ç»´è·¯å¾„ç”Ÿæˆ
        
        Args:
            thinking_seed: æ€ç»´ç§å­
            task: ä»»åŠ¡æè¿°
            max_paths: æœ€å¤§è·¯å¾„æ•°
            mode: ç”Ÿæˆæ¨¡å¼
            run_manager: LangChainå›è°ƒç®¡ç†å™¨
            
        Returns:
            æ€ç»´è·¯å¾„åˆ—è¡¨çš„JSONå­—ç¬¦ä¸²
        """
        try:
            logger.info(f"ğŸ›¤ï¸ å¼€å§‹ç”Ÿæˆæ€ç»´è·¯å¾„: æ¨¡å¼={mode}, æœ€å¤§è·¯å¾„æ•°={max_paths}")
            
            # è°ƒç”¨åŸå§‹çš„è·¯å¾„ç”Ÿæˆé€»è¾‘
            reasoning_paths = self.path_generator.generate_paths(
                thinking_seed=thinking_seed,
                task=task,
                max_paths=max_paths,
                mode=mode
            )
            
            # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
            paths_data = []
            for path in reasoning_paths:
                path_dict = {
                    "path_id": path.path_id,
                    "path_type": path.path_type,
                    "description": path.description,
                    "prompt_template": path.prompt_template,
                    "strategy_id": getattr(path, 'strategy_id', path.path_type),
                    "instance_id": getattr(path, 'instance_id', path.path_id)
                }
                paths_data.append(path_dict)
            
            # è·å–ç”Ÿæˆç»Ÿè®¡
            generation_stats = self.path_generator.get_generation_statistics()
            
            # æ„å»ºè¾“å‡º
            output = {
                "reasoning_paths": paths_data,
                "generation_stats": generation_stats,
                "generation_mode": mode,
                "tool_metadata": {
                    "tool_name": self.name,
                    "generation_time": time.time(),
                    "total_paths": len(paths_data)
                }
            }
            
            logger.info(f"âœ… æ€ç»´è·¯å¾„ç”Ÿæˆå®Œæˆ: {len(paths_data)}æ¡è·¯å¾„")
            return json.dumps(output, ensure_ascii=False, indent=2)
            
        except Exception as e:
            error_msg = f"æ€ç»´è·¯å¾„ç”Ÿæˆå¤±è´¥: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            
            # å›é€€è·¯å¾„
            fallback_paths = [
                {
                    "path_id": "fallback_systematic",
                    "path_type": "ç³»ç»Ÿåˆ†æå‹",
                    "description": "åŸºç¡€çš„ç³»ç»Ÿæ€§åˆ†ææ–¹æ³•",
                    "prompt_template": f"è¯·ç³»ç»Ÿæ€§åˆ†æ: {task}ã€‚åŸºäºç§å­: {thinking_seed[:100]}..."
                }
            ]
            
            fallback_output = {
                "error": error_msg,
                "reasoning_paths": fallback_paths,
                "tool_metadata": {"tool_name": self.name, "error_time": time.time()}
            }
            return json.dumps(fallback_output, ensure_ascii=False)

class NeogenesisMABDecisionTool(BaseTool):
    """
    Neogenesiså¤šè‡‚è€è™æœºå†³ç­–å·¥å…·
    
    åŠŸèƒ½ï¼šä½¿ç”¨MABç®—æ³•ä»å¤šä¸ªæ€ç»´è·¯å¾„ä¸­é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ
    ä¼˜åŠ¿ï¼šå…·å¤‡å­¦ä¹ èƒ½åŠ›ï¼Œåœ¨ä½¿ç”¨ä¸­ä¸æ–­ä¼˜åŒ–å†³ç­–è´¨é‡
    """
    
    name: str = "neogenesis_mab_decision"
    description: str = """
    ä½¿ç”¨å¤šè‡‚è€è™æœºï¼ˆMABï¼‰ç®—æ³•è¿›è¡Œæ™ºèƒ½å†³ç­–ã€‚
    
    è¾“å…¥ï¼š
    - reasoning_paths: æ€ç»´è·¯å¾„åˆ—è¡¨
    - user_query: ç”¨æˆ·æŸ¥è¯¢
    - execution_context: å¯é€‰çš„æ‰§è¡Œä¸Šä¸‹æ–‡
    
    è¾“å‡ºï¼šç»è¿‡MABç®—æ³•é€‰æ‹©çš„æœ€ä¼˜è·¯å¾„å’Œå†³ç­–ç»“æœ
    
    é€‚ç”¨åœºæ™¯ï¼šéœ€è¦åœ¨å¤šä¸ªæ–¹æ¡ˆä¸­è¿›è¡Œæ™ºèƒ½é€‰æ‹©ï¼Œè¦æ±‚å†³ç­–è´¨é‡å’Œå­¦ä¹ èƒ½åŠ›
    """
    args_schema: Type[BaseModel] = MABDecisionInput
    
    def __init__(self, api_key: str = "", llm_client=None, **kwargs):
        super().__init__(**kwargs)
        # åˆå§‹åŒ–çœŸæ­£çš„MABConvergerï¼Œä½¿ç”¨object.__setattr__ç»•è¿‡PydanticéªŒè¯
        try:
            object.__setattr__(self, 'mab_converger', MABConverger())
            object.__setattr__(self, '_initialized', True)
            logger.info("ğŸ° MABConvergeråˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ MABConvergeråˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨å›é€€é€»è¾‘: {e}")
            object.__setattr__(self, 'mab_converger', None)
            object.__setattr__(self, '_initialized', False)
        
        object.__setattr__(self, '_api_key', api_key)
        object.__setattr__(self, '_llm_client', llm_client)
        logger.info("ğŸ° NeogenesisMABDecisionTool åˆå§‹åŒ–å®Œæˆ")
    
    def _run(
        self, 
        reasoning_paths: List[Dict[str, Any]],
        user_query: str,
        execution_context: Optional[Dict[str, Any]] = None,
        run_manager: Optional[CallbackManagerForToolRun] = None
    ) -> str:
        """
        æ‰§è¡ŒMABå†³ç­–
        
        Args:
            reasoning_paths: æ€ç»´è·¯å¾„åˆ—è¡¨
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            run_manager: LangChainå›è°ƒç®¡ç†å™¨
            
        Returns:
            MABå†³ç­–ç»“æœçš„JSONå­—ç¬¦ä¸²
        """
        try:
            logger.info(f"ğŸ° å¼€å§‹MABå†³ç­–: {len(reasoning_paths)}æ¡è·¯å¾„")
            
            if not reasoning_paths:
                raise ValueError("æ€ç»´è·¯å¾„åˆ—è¡¨ä¸ºç©º")
            
            if self._initialized and self.mab_converger:
                # ä½¿ç”¨çœŸæ­£çš„MABConvergerè¿›è¡Œå†³ç­–
                selected_path, mab_stats = self._use_mab_converger(reasoning_paths, user_query)
            else:
                # å›é€€åˆ°ç®€åŒ–é€»è¾‘
                logger.info("ğŸ”„ ä½¿ç”¨å›é€€å†³ç­–é€»è¾‘")
                selected_path, mab_stats = self._fallback_decision(reasoning_paths)
            
            # æ„å»ºè¾“å‡º
            output = {
                "selected_path": selected_path,
                "mab_statistics": mab_stats,
                "decision_reasoning": "åŸºäºMABç®—æ³•é€‰æ‹©çš„æœ€ä¼˜è·¯å¾„",
                "tool_metadata": {
                    "tool_name": self.name,
                    "decision_time": time.time(),
                    "total_candidates": len(reasoning_paths)
                }
            }
            
            logger.info(f"âœ… MABå†³ç­–å®Œæˆ: é€‰æ‹©è·¯å¾„ {selected_path.get('path_type', 'unknown')}")
            return json.dumps(output, ensure_ascii=False, indent=2)
            
        except Exception as e:
            error_msg = f"MABå†³ç­–å¤±è´¥: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            
            # å›é€€å†³ç­–
            fallback_output = {
                "error": error_msg,
                "fallback_decision": "é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨è·¯å¾„" if reasoning_paths else "æ— å¯ç”¨è·¯å¾„",
                "tool_metadata": {"tool_name": self.name, "error_time": time.time()}
            }
            return json.dumps(fallback_output, ensure_ascii=False)
    
    def _use_mab_converger(self, reasoning_paths: List[Dict[str, Any]], user_query: str) -> tuple:
        """ä½¿ç”¨çœŸæ­£çš„MABConvergerè¿›è¡Œå†³ç­–"""
        try:
            # å°†Dictæ ¼å¼çš„è·¯å¾„è½¬æ¢ä¸ºReasoningPathå¯¹è±¡
            from neogenesis_system.meta_mab.data_structures import ReasoningPath
            
            path_objects = []
            for i, path_dict in enumerate(reasoning_paths):
                # åˆ›å»ºReasoningPathå¯¹è±¡
                reasoning_path = ReasoningPath(
                    path_id=path_dict.get("path_id", f"path_{i}"),
                    strategy_id=path_dict.get("strategy_id", path_dict.get("path_type", f"strategy_{i}")),
                    path_type=path_dict.get("path_type", "æœªçŸ¥ç±»å‹"),
                    description=path_dict.get("description", ""),
                    expected_outcome=path_dict.get("expected_outcome", ""),
                    confidence_score=path_dict.get("confidence_score", 0.5),
                    keywords=path_dict.get("keywords", []),
                    reasoning_steps=path_dict.get("reasoning_steps", [])
                )
                path_objects.append(reasoning_path)
            
            # ä½¿ç”¨MABConvergeré€‰æ‹©æœ€ä½³è·¯å¾„
            selected_path_obj = self.mab_converger.select_best_path(
                paths=path_objects,
                algorithm='auto'
            )
            
            # è½¬æ¢å›Dictæ ¼å¼
            selected_path_dict = {
                "path_id": selected_path_obj.path_id,
                "strategy_id": selected_path_obj.strategy_id,
                "path_type": selected_path_obj.path_type,
                "description": selected_path_obj.description,
                "expected_outcome": selected_path_obj.expected_outcome,
                "confidence_score": selected_path_obj.confidence_score,
                "keywords": selected_path_obj.keywords,
                "reasoning_steps": selected_path_obj.reasoning_steps
            }
            
            # è·å–MABç»Ÿè®¡ä¿¡æ¯
            mab_stats = {
                "total_arms": len(reasoning_paths),
                "selected_arm": selected_path_obj.strategy_id,
                "confidence_score": selected_path_obj.confidence_score,
                "total_selections": self.mab_converger.total_path_selections,
                "algorithm_used": "mab_converger",
                "golden_template_used": hasattr(selected_path_obj, 'from_golden_template')
            }
            
            logger.info(f"ğŸ¯ MABConvergeré€‰æ‹©è·¯å¾„: {selected_path_obj.path_type}")
            return selected_path_dict, mab_stats
            
        except Exception as e:
            logger.error(f"âŒ MABConvergeræ‰§è¡Œå¤±è´¥: {e}")
            # å›é€€åˆ°ç®€åŒ–é€»è¾‘
            return self._fallback_decision(reasoning_paths)
    
    def _fallback_decision(self, reasoning_paths: List[Dict[str, Any]]) -> tuple:
        """å›é€€å†³ç­–é€»è¾‘"""
        logger.info("ğŸ”„ ä½¿ç”¨ç®€åŒ–å†³ç­–é€»è¾‘")
        
        if not reasoning_paths:
            return {}, {"error": "æ— å¯ç”¨è·¯å¾„"}
        
        # ç®€å•é€‰æ‹©ï¼šä¼˜å…ˆé€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„è·¯å¾„
        selected_path = max(reasoning_paths, 
                          key=lambda x: x.get("confidence_score", 0))
        
        # æ¨¡æ‹ŸMABç»Ÿè®¡ä¿¡æ¯
        mab_stats = {
            "total_arms": len(reasoning_paths),
            "selected_arm": selected_path.get("strategy_id", selected_path.get("path_id")),
            "confidence_score": selected_path.get("confidence_score", 0.8),
            "algorithm_used": "fallback_highest_confidence",
            "exploration_rate": 0.0
        }
        
        return selected_path, mab_stats

class NeogenesisIdeaVerificationTool(BaseTool):
    """
    Neogenesisæƒ³æ³•éªŒè¯å·¥å…·
    
    åŠŸèƒ½ï¼šéªŒè¯æƒ³æ³•çš„å¯è¡Œæ€§ï¼Œæä¾›è¯¦ç»†åˆ†æå’Œå»ºè®®
    ä¼˜åŠ¿ï¼šåŸºäºç½‘ç»œæœç´¢çš„å®æ—¶éªŒè¯ï¼Œæä¾›å¯è¡Œæ€§è¯„åˆ†
    """
    
    name: str = "neogenesis_idea_verification"
    description: str = """
    éªŒè¯æƒ³æ³•æˆ–æ¦‚å¿µçš„å¯è¡Œæ€§ï¼Œæä¾›è¯¦ç»†åˆ†æå’Œå»ºè®®ã€‚
    
    è¾“å…¥ï¼š
    - idea_text: éœ€è¦éªŒè¯çš„æƒ³æ³•æ–‡æœ¬
    - context: å¯é€‰çš„éªŒè¯ä¸Šä¸‹æ–‡
    
    è¾“å‡ºï¼šåŒ…å«å¯è¡Œæ€§è¯„åˆ†ã€åˆ†ææ‘˜è¦å’Œç›¸å…³æœç´¢ç»“æœçš„éªŒè¯æŠ¥å‘Š
    
    é€‚ç”¨åœºæ™¯ï¼šåˆ›æ„è¯„ä¼°ã€æŠ•èµ„å†³ç­–ã€äº§å“è§„åˆ’ã€æŠ€æœ¯å¯è¡Œæ€§åˆ†æ
    """
    args_schema: Type[BaseModel] = IdeaVerificationInput
    
    def __init__(self, search_engine: str = "duckduckgo", max_results: int = 5, **kwargs):
        super().__init__(**kwargs)
        # ä½¿ç”¨object.__setattr__ç»•è¿‡Pydanticçš„å­—æ®µéªŒè¯
        object.__setattr__(self, 'verification_tool', OriginalIdeaVerificationTool(
            search_engine=search_engine,
            max_results=max_results
        ))
        logger.info("ğŸ’¡ NeogenesisIdeaVerificationTool åˆå§‹åŒ–å®Œæˆ")
    
    def _run(
        self, 
        idea_text: str,
        context: Optional[Dict[str, Any]] = None,
        run_manager: Optional[CallbackManagerForToolRun] = None
    ) -> str:
        """
        æ‰§è¡Œæƒ³æ³•éªŒè¯
        
        Args:
            idea_text: æƒ³æ³•æ–‡æœ¬
            context: éªŒè¯ä¸Šä¸‹æ–‡
            run_manager: LangChainå›è°ƒç®¡ç†å™¨
            
        Returns:
            éªŒè¯ç»“æœçš„JSONå­—ç¬¦ä¸²
        """
        try:
            logger.info(f"ğŸ’¡ å¼€å§‹éªŒè¯æƒ³æ³•: {idea_text[:50]}...")
            
            # è°ƒç”¨åŸå§‹çš„éªŒè¯å·¥å…·
            verification_result = self.verification_tool.execute(
                idea_text=idea_text,
                context=context
            )
            
            # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
            if verification_result.success:
                output = {
                    "verification_success": True,
                    "verification_data": verification_result.data,
                    "execution_time": verification_result.execution_time,
                    "tool_metadata": {
                        "tool_name": self.name,
                        "verification_time": time.time()
                    }
                }
            else:
                output = {
                    "verification_success": False,
                    "error_message": verification_result.error_message,
                    "execution_time": verification_result.execution_time,
                    "tool_metadata": {
                        "tool_name": self.name,
                        "verification_time": time.time()
                    }
                }
            
            logger.info("âœ… æƒ³æ³•éªŒè¯å®Œæˆ")
            return json.dumps(output, ensure_ascii=False, indent=2)
            
        except Exception as e:
            error_msg = f"æƒ³æ³•éªŒè¯å¤±è´¥: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            
            fallback_output = {
                "verification_success": False,
                "error": error_msg,
                "fallback_analysis": "æ— æ³•è¿›è¡Œè‡ªåŠ¨éªŒè¯ï¼Œå»ºè®®äººå·¥è¯„ä¼°",
                "tool_metadata": {"tool_name": self.name, "error_time": time.time()}
            }
            return json.dumps(fallback_output, ensure_ascii=False)

# =============================================================================
# å®Œæ•´äº”é˜¶æ®µå†³ç­–å·¥å…·
# =============================================================================

class NeogenesisFiveStageDecisionInput(BaseModel):
    """äº”é˜¶æ®µå†³ç­–å·¥å…·çš„è¾“å…¥æ¨¡å‹"""
    user_query: str = Field(description="ç”¨æˆ·æŸ¥è¯¢æˆ–å†³ç­–é—®é¢˜")
    execution_context: Optional[Dict[str, Any]] = Field(
        default=None,
        description="æ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰"
    )
    use_rag_enhancement: bool = Field(
        default=True,
        description="æ˜¯å¦ä½¿ç”¨RAGå¢å¼ºï¼ˆé˜¶æ®µä¸€ï¼‰"
    )
    enable_seed_verification: bool = Field(
        default=True,
        description="æ˜¯å¦å¯ç”¨ç§å­éªŒè¯ï¼ˆé˜¶æ®µäºŒï¼‰"
    )
    max_paths: int = Field(
        default=4,
        description="æœ€å¤§ç”Ÿæˆè·¯å¾„æ•°ï¼ˆé˜¶æ®µä¸‰ï¼‰"
    )
    enable_path_verification: bool = Field(
        default=True,
        description="æ˜¯å¦å¯ç”¨è·¯å¾„éªŒè¯ï¼ˆé˜¶æ®µå››ï¼‰"
    )
    use_mab_algorithm: bool = Field(
        default=True,
        description="æ˜¯å¦ä½¿ç”¨MABç®—æ³•ï¼ˆé˜¶æ®µäº”ï¼‰"
    )

class NeogenesisFiveStageDecisionTool(BaseTool):
    """
    Neogenesiså®Œæ•´äº”é˜¶æ®µå†³ç­–å·¥å…·
    
    åŠŸèƒ½ï¼šæ‰§è¡Œå®Œæ•´çš„äº”é˜¶æ®µAIå†³ç­–æµç¨‹ï¼Œä¸ºLangChainç”¨æˆ·æä¾›ç«¯åˆ°ç«¯çš„æ™ºèƒ½å†³ç­–
    ä¼˜åŠ¿ï¼šä¸€æ¬¡è°ƒç”¨å®Œæˆæ‰€æœ‰é˜¶æ®µï¼Œè¾“å‡ºè¯¦ç»†çš„å†³ç­–æŠ¥å‘Š
    """
    
    name: str = "neogenesis_five_stage_decision"
    description: str = """
    æ‰§è¡Œå®Œæ•´çš„Neogenesisäº”é˜¶æ®µAIå†³ç­–æµç¨‹ï¼Œæä¾›ç«¯åˆ°ç«¯çš„æ™ºèƒ½å†³ç­–æ”¯æŒã€‚
    
    äº”ä¸ªé˜¶æ®µï¼š
    1. æ€ç»´ç§å­ç”Ÿæˆ - ç†è§£é—®é¢˜ï¼Œç”Ÿæˆåˆ†æåŸºç¡€
    2. ç§å­éªŒè¯æ£€æŸ¥ - éªŒè¯æ€ç»´æ–¹å‘çš„æ­£ç¡®æ€§  
    3. æ€ç»´è·¯å¾„ç”Ÿæˆ - ç”Ÿæˆå¤šç§è§£å†³æ–¹æ¡ˆè·¯å¾„
    4. è·¯å¾„éªŒè¯å­¦ä¹  - éªŒè¯å’Œè¯„ä¼°å„ä¸ªè·¯å¾„
    5. æ™ºèƒ½æœ€ç»ˆå†³ç­– - ä½¿ç”¨MABç®—æ³•é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ
    
    è¾“å…¥ï¼šuser_queryï¼ˆå¿…éœ€ï¼‰å’Œå„é˜¶æ®µé…ç½®å‚æ•°
    è¾“å‡ºï¼šå®Œæ•´çš„äº”é˜¶æ®µå†³ç­–æŠ¥å‘Šï¼ŒåŒ…å«æ¯ä¸ªé˜¶æ®µçš„è¯¦ç»†ç»“æœå’Œæœ€ç»ˆå»ºè®®
    
    é€‚ç”¨åœºæ™¯ï¼šå¤æ‚å†³ç­–é—®é¢˜ã€æˆ˜ç•¥è§„åˆ’ã€æ–¹æ¡ˆé€‰æ‹©ã€äº§å“è®¾è®¡
    """
    args_schema: Type[BaseModel] = NeogenesisFiveStageDecisionInput
    
    def __init__(self, 
                 api_key: str = "",
                 search_engine: str = "duckduckgo",
                 llm_client=None,
                 web_search_client=None,
                 **kwargs):
        super().__init__(**kwargs)
        
        # åˆå§‹åŒ–å„é˜¶æ®µå·¥å…·ï¼Œä½¿ç”¨object.__setattr__ç»•è¿‡PydanticéªŒè¯
        object.__setattr__(self, 'thinking_seed_tool', NeogenesisThinkingSeedTool(api_key=api_key))
        object.__setattr__(self, 'rag_seed_tool', NeogenesisRAGSeedTool(
            api_key=api_key,
            search_engine=search_engine,
            llm_client=llm_client,
            web_search_client=web_search_client
        ) if llm_client or web_search_client else None)
        object.__setattr__(self, 'verification_tool', NeogenesisIdeaVerificationTool(search_engine=search_engine))
        object.__setattr__(self, 'path_generator_tool', NeogenesisPathGeneratorTool(
            api_key=api_key,
            llm_client=llm_client
        ))
        object.__setattr__(self, 'mab_decision_tool', NeogenesisMABDecisionTool(
            api_key=api_key,
            llm_client=llm_client
        ))
        
        logger.info("ğŸ”— NeogenesisFiveStageDecisionTool åˆå§‹åŒ–å®Œæˆ")
    
    def _run(
        self,
        user_query: str,
        execution_context: Optional[Dict[str, Any]] = None,
        use_rag_enhancement: bool = True,
        enable_seed_verification: bool = True,
        max_paths: int = 4,
        enable_path_verification: bool = True,
        use_mab_algorithm: bool = True,
        run_manager: Optional[CallbackManagerForToolRun] = None
    ) -> str:
        """
        æ‰§è¡Œå®Œæ•´çš„äº”é˜¶æ®µå†³ç­–æµç¨‹
        """
        try:
            logger.info(f"ğŸš€ å¼€å§‹äº”é˜¶æ®µå†³ç­–æµç¨‹: {user_query[:50]}...")
            start_time = time.time()
            
            stage_results = {}
            
            # ğŸ§  é˜¶æ®µä¸€ï¼šæ€ç»´ç§å­ç”Ÿæˆ
            logger.info("ğŸ§  é˜¶æ®µä¸€ï¼šæ€ç»´ç§å­ç”Ÿæˆ")
            try:
                if use_rag_enhancement and self.rag_seed_tool:
                    seed_result = self.rag_seed_tool._run(
                        user_query=user_query,
                        execution_context=execution_context
                    )
                    seed_data = json.loads(seed_result)
                    thinking_seed = seed_data.get("rag_enhanced_seed", "")
                    stage_results["stage_1"] = {"type": "rag_enhanced", "data": seed_data, "success": True}
                else:
                    seed_result = self.thinking_seed_tool._run(
                        user_query=user_query,
                        execution_context=execution_context
                    )
                    seed_data = json.loads(seed_result)
                    thinking_seed = seed_data.get("thinking_seed", "")
                    stage_results["stage_1"] = {"type": "basic_thinking", "data": seed_data, "success": True}
                
                logger.info("âœ… é˜¶æ®µä¸€å®Œæˆ")
                
            except Exception as e:
                logger.error(f"âŒ é˜¶æ®µä¸€å¤±è´¥: {e}")
                thinking_seed = f"åŸºäºé—®é¢˜çš„åŸºç¡€åˆ†æï¼š{user_query}"
                stage_results["stage_1"] = {"success": False, "error": str(e)}
            
            # ğŸ” é˜¶æ®µäºŒï¼šç§å­éªŒè¯æ£€æŸ¥
            if enable_seed_verification:
                logger.info("ğŸ” é˜¶æ®µäºŒï¼šç§å­éªŒè¯æ£€æŸ¥")
                try:
                    verification_result = self.verification_tool._run(
                        idea_text=thinking_seed,
                        context={"stage": "seed_verification", "query": user_query}
                    )
                    verification_data = json.loads(verification_result)
                    stage_results["stage_2"] = {"type": "verification", "data": verification_data, "success": True}
                    logger.info("âœ… é˜¶æ®µäºŒå®Œæˆ")
                except Exception as e:
                    logger.error(f"âŒ é˜¶æ®µäºŒå¤±è´¥: {e}")
                    stage_results["stage_2"] = {"success": False, "error": str(e)}
            else:
                stage_results["stage_2"] = {"type": "skipped", "message": "éªŒè¯å·²ç¦ç”¨"}
            
            # ğŸ›¤ï¸ é˜¶æ®µä¸‰ï¼šæ€ç»´è·¯å¾„ç”Ÿæˆ
            logger.info("ğŸ›¤ï¸ é˜¶æ®µä¸‰ï¼šæ€ç»´è·¯å¾„ç”Ÿæˆ")
            try:
                paths_result = self.path_generator_tool._run(
                    thinking_seed=thinking_seed,
                    task=user_query,
                    max_paths=max_paths
                )
                paths_data = json.loads(paths_result)
                reasoning_paths = paths_data.get("reasoning_paths", [])
                stage_results["stage_3"] = {"type": "path_generation", "data": paths_data, "success": True}
                logger.info(f"âœ… é˜¶æ®µä¸‰å®Œæˆï¼šç”Ÿæˆ{len(reasoning_paths)}æ¡è·¯å¾„")
            except Exception as e:
                logger.error(f"âŒ é˜¶æ®µä¸‰å¤±è´¥: {e}")
                reasoning_paths = [{"path_type": "ç›´æ¥åˆ†æ", "description": thinking_seed, "confidence_score": 0.6}]
                stage_results["stage_3"] = {"success": False, "error": str(e)}
            
            # ğŸ”¬ é˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯å­¦ä¹ 
            if enable_path_verification and reasoning_paths:
                logger.info("ğŸ”¬ é˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯å­¦ä¹ ")
                try:
                    verified_paths = []
                    for i, path in enumerate(reasoning_paths):
                        try:
                            path_text = f"{path.get('path_type', '')}: {path.get('description', '')}"
                            path_verification = self.verification_tool._run(
                                idea_text=path_text,
                                context={"stage": "path_verification", "path_index": i}
                            )
                            verification_data = json.loads(path_verification)
                            path["verification_result"] = verification_data
                            verified_paths.append(path)
                        except:
                            verified_paths.append(path)  # ä¿ç•™åŸè·¯å¾„
                    
                    reasoning_paths = verified_paths
                    stage_results["stage_4"] = {"type": "path_verification", "verified_count": len(verified_paths), "success": True}
                    logger.info(f"âœ… é˜¶æ®µå››å®Œæˆï¼šéªŒè¯{len(verified_paths)}æ¡è·¯å¾„")
                except Exception as e:
                    logger.error(f"âŒ é˜¶æ®µå››å¤±è´¥: {e}")
                    stage_results["stage_4"] = {"success": False, "error": str(e)}
            else:
                stage_results["stage_4"] = {"type": "skipped", "message": "è·¯å¾„éªŒè¯å·²ç¦ç”¨"}
            
            # ğŸ† é˜¶æ®µäº”ï¼šæ™ºèƒ½æœ€ç»ˆå†³ç­–
            logger.info("ğŸ† é˜¶æ®µäº”ï¼šæ™ºèƒ½æœ€ç»ˆå†³ç­–")
            try:
                if use_mab_algorithm and reasoning_paths:
                    decision_result = self.mab_decision_tool._run(
                        reasoning_paths=reasoning_paths,
                        user_query=user_query,
                        execution_context=execution_context
                    )
                    decision_data = json.loads(decision_result)
                    final_decision = decision_data.get("selected_path", {})
                    stage_results["stage_5"] = {"type": "mab_decision", "data": decision_data, "success": True}
                else:
                    final_decision = reasoning_paths[0] if reasoning_paths else {}
                    stage_results["stage_5"] = {"type": "simple_selection", "selected": final_decision, "success": True}
                
                logger.info("âœ… é˜¶æ®µäº”å®Œæˆ")
            except Exception as e:
                logger.error(f"âŒ é˜¶æ®µäº”å¤±è´¥: {e}")
                final_decision = reasoning_paths[0] if reasoning_paths else {"description": "æ— æ³•å®Œæˆå†³ç­–"}
                stage_results["stage_5"] = {"success": False, "error": str(e)}
            
            # æ„å»ºå®Œæ•´æŠ¥å‘Š
            end_time = time.time()
            complete_report = {
                "success": True,
                "user_query": user_query,
                "execution_time": end_time - start_time,
                "thinking_seed": thinking_seed,
                "stage_results": stage_results,
                "final_recommendation": final_decision,
                "summary": {
                    "stages_completed": len([s for s in stage_results.values() if s.get("success", False)]),
                    "success_rate": len([s for s in stage_results.values() if s.get("success", False)]) / 5 * 100,
                    "paths_generated": len(reasoning_paths) if reasoning_paths else 0
                }
            }
            
            logger.info("ğŸ‰ äº”é˜¶æ®µå†³ç­–æµç¨‹å®Œæˆ")
            return json.dumps(complete_report, ensure_ascii=False, indent=2)
            
        except Exception as e:
            logger.error(f"âŒ äº”é˜¶æ®µæµç¨‹å¤±è´¥: {e}")
            return json.dumps({
                "success": False,
                "error": str(e),
                "user_query": user_query
            }, ensure_ascii=False)

# =============================================================================
# å·¥å…·æ³¨å†Œå’Œç®¡ç†
# =============================================================================

def get_all_neogenesis_tools(
    api_key: str = "",
    search_engine: str = "duckduckgo",
    llm_client=None,
    web_search_client=None
) -> List[BaseTool]:
    """
    è·å–æ‰€æœ‰Neogenesiså·¥å…·çš„åˆ—è¡¨
    
    Args:
        api_key: APIå¯†é’¥
        search_engine: æœç´¢å¼•æ“ç±»å‹
        llm_client: LLMå®¢æˆ·ç«¯
        web_search_client: ç½‘ç»œæœç´¢å®¢æˆ·ç«¯
        
    Returns:
        å·¥å…·åˆ—è¡¨
    """
    tools = [
        NeogenesisThinkingSeedTool(api_key=api_key),
        NeogenesisRAGSeedTool(
            api_key=api_key,
            search_engine=search_engine,
            web_search_client=web_search_client,
            llm_client=llm_client
        ),
        NeogenesisPathGeneratorTool(
            api_key=api_key,
            llm_client=llm_client
        ),
        NeogenesisMABDecisionTool(
            api_key=api_key,
            llm_client=llm_client
        ),
        NeogenesisIdeaVerificationTool(
            search_engine=search_engine
        ),
        NeogenesisFiveStageDecisionTool(
            api_key=api_key,
            search_engine=search_engine,
            llm_client=llm_client,
            web_search_client=web_search_client
        )
    ]
    
    logger.info(f"ğŸ”§ åˆ›å»ºäº† {len(tools)} ä¸ªNeogenesiså·¥å…·")
    return tools

def create_neogenesis_toolset(config: Dict[str, Any] = None) -> Dict[str, BaseTool]:
    """
    åˆ›å»ºNeogenesiså·¥å…·é›†åˆ
    
    Args:
        config: é…ç½®å­—å…¸
        
    Returns:
        å·¥å…·åç§°åˆ°å·¥å…·å¯¹è±¡çš„æ˜ å°„
    """
    if config is None:
        config = {}
    
    tools_list = get_all_neogenesis_tools(**config)
    tools_dict = {tool.name: tool for tool in tools_list}
    
    logger.info(f"ğŸ› ï¸ Neogenesiså·¥å…·é›†åˆåˆ›å»ºå®Œæˆ: {list(tools_dict.keys())}")
    return tools_dict

# =============================================================================
# å…¼å®¹æ€§æ£€æŸ¥
# =============================================================================

def check_langchain_compatibility() -> Dict[str, Any]:
    """
    æ£€æŸ¥LangChainå…¼å®¹æ€§
    
    Returns:
        å…¼å®¹æ€§ä¿¡æ¯
    """
    compatibility_info = {
        "langchain_available": LANGCHAIN_AVAILABLE,
        "required_packages": ["langchain", "langchain-core"],
        "optional_packages": ["langchain-openai", "langchain-anthropic"],
        "recommendation": "Install LangChain for full functionality"
    }
    
    if LANGCHAIN_AVAILABLE:
        try:
            from langchain import __version__ as langchain_version
            compatibility_info["langchain_version"] = langchain_version
        except:
            compatibility_info["langchain_version"] = "unknown"
    
    return compatibility_info

if __name__ == "__main__":
    # æµ‹è¯•å·¥å…·åˆ›å»º
    print("ğŸ§ª æµ‹è¯•Neogenesiså·¥å…·åˆ›å»º...")
    
    # æ£€æŸ¥å…¼å®¹æ€§
    compat_info = check_langchain_compatibility()
    print(f"å…¼å®¹æ€§ä¿¡æ¯: {compat_info}")
    
    # åˆ›å»ºå·¥å…·
    try:
        tools = get_all_neogenesis_tools()
        print(f"âœ… æˆåŠŸåˆ›å»º {len(tools)} ä¸ªå·¥å…·:")
        for tool in tools:
            print(f"  - {tool.name}: {tool.description[:50]}...")
    except Exception as e:
        print(f"âŒ å·¥å…·åˆ›å»ºå¤±è´¥: {e}")
