
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä¸»æ§åˆ¶å™¨ - åè°ƒå„ä¸ªç»„ä»¶çš„å·¥ä½œ
Main Controller - coordinates the work of all components
"""

import time
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass

from .reasoner import PriorReasoner
from .path_generator import PathGenerator
from .mab_converger import MABConverger
from .data_structures import DecisionResult, SystemStatus
from .utils.search_client import WebSearchClient, IdeaVerificationSearchClient, SearchResponse
from .utils.performance_optimizer import PerformanceOptimizer
from .utils.shutdown_manager import shutdown_neogenesis_system, register_for_shutdown
from config import SYSTEM_LIMITS, FEATURE_FLAGS, PROMPT_TEMPLATES, PERFORMANCE_CONFIG

logger = logging.getLogger(__name__)




@dataclass
class MainController:
    """ä¸»æ§åˆ¶å™¨ - åè°ƒå„ä¸ªç»„ä»¶çš„å·¥ä½œ"""
    
    def __init__(self, api_key: str = "", config=None):
        self.api_key = api_key
        self.config = config
        
        # ğŸ—ï¸ å¤šLLMæ”¯æŒï¼šä½¿ç”¨ç»Ÿä¸€çš„LLMç®¡ç†å™¨
        from .llm_manager import LLMManager
        
        logger.info(f"ğŸ”§ æ­£åœ¨åˆå§‹åŒ–LLMç®¡ç†å™¨...")
        
        # å¦‚æœæä¾›äº†APIå¯†é’¥ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå‘åå…¼å®¹ï¼‰
        if api_key and api_key.strip():
            import os
            os.environ.setdefault("DEEPSEEK_API_KEY", api_key.strip())
            logger.info(f"ğŸ”‘ APIå¯†é’¥å·²è®¾ç½®ä¸ºDEEPSEEK_API_KEYç¯å¢ƒå˜é‡")
        
        # åˆ›å»ºLLMç®¡ç†å™¨
        try:
            self.llm_manager = LLMManager()
            self.llm_client = self.llm_manager  # å‘åå…¼å®¹
            
            status = self.llm_manager.get_provider_status()
            logger.info("ğŸ§  LLMç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            logger.info(f"   æ€»æä¾›å•†: {status['total_providers']}")
            logger.info(f"   å¥åº·æä¾›å•†: {status['healthy_providers']}")
            logger.info(f"   åˆå§‹åŒ–çŠ¶æ€: {'âœ…' if status['initialized'] else 'âŒ'}")
            
        except Exception as e:
            logger.error(f"âŒ LLMç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            logger.error(f"   è¯¦ç»†å †æ ˆ: {traceback.format_exc()}")
            
            # å›é€€åˆ°å•ä¸€å®¢æˆ·ç«¯æ¨¡å¼
            logger.warning("ğŸ”„ å›é€€åˆ°å•ä¸€DeepSeekå®¢æˆ·ç«¯æ¨¡å¼")
            self.llm_manager = None
            self.llm_client = self._create_fallback_client(api_key)
    
    def _create_fallback_client(self, api_key: str):
        """åˆ›å»ºå›é€€å®¢æˆ·ç«¯"""
        if api_key and api_key.strip():
            try:
                from .utils.client_adapter import DeepSeekClientAdapter
                return DeepSeekClientAdapter(api_key.strip())
            except Exception as e:
                logger.error(f"âŒ å›é€€å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {e}")
                return None
        return None
        
        # åˆ›å»ºå…±äº«çš„æœç´¢å®¢æˆ·ç«¯
        self.web_search_client = WebSearchClient(search_engine="duckduckgo", max_results=5)
        self.idea_verification_client = IdeaVerificationSearchClient(self.web_search_client)
        
        # ğŸ”§ åˆå§‹åŒ–å„ä¸ªç»„ä»¶ - æ³¨å…¥å…±äº«ä¾èµ–
        self.prior_reasoner = PriorReasoner(api_key)  # è½»é‡çº§ï¼Œä¸éœ€è¦LLMå®¢æˆ·ç«¯
        self.path_generator = PathGenerator(api_key, llm_client=self.llm_client)  # æ³¨å…¥LLMå®¢æˆ·ç«¯
        self.mab_converger = MABConverger()
        
        # ğŸš€ æ–°å¢ï¼šæ€§èƒ½ä¼˜åŒ–å™¨
        if FEATURE_FLAGS.get("enable_performance_optimization", False):
            self.performance_optimizer = PerformanceOptimizer(PERFORMANCE_CONFIG)
            logger.info("ğŸš€ æ€§èƒ½ä¼˜åŒ–å™¨å·²å¯ç”¨")
        else:
            self.performance_optimizer = None
            logger.info("ğŸ“Š æ€§èƒ½ä¼˜åŒ–å™¨å·²ç¦ç”¨")
        
        # æ³¨å†Œç³»ç»Ÿå…³é—­å›è°ƒ - æš‚æ—¶ç¦ç”¨é¿å…é€’å½’é—®é¢˜
        # register_for_shutdown(lambda: shutdown_neogenesis_system(self), "MainController")
        logger.debug("âš ï¸ å…³é—­å›è°ƒå·²ç¦ç”¨ï¼Œé¿å…é€’å½’é—®é¢˜")
        
        # ç³»ç»ŸçŠ¶æ€
        self.total_rounds = 0
        self.decision_history = []
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            'total_decisions': 0,
            'successful_decisions': 0,
            'avg_decision_time': 0.0,
            'component_performance': {
                'prior_reasoner': {'calls': 0, 'avg_time': 0.0},
                'path_generator': {'calls': 0, 'avg_time': 0.0},
                'mab_converger': {'calls': 0, 'avg_time': 0.0},
                'idea_verification': {'calls': 0, 'avg_time': 0.0, 'success_rate': 0.0}  # æ–°å¢éªŒè¯ç»Ÿè®¡
            }
        }
        
        # ğŸ’¡ Aha-Momentå†³ç­–ç³»ç»Ÿ
        self.aha_moment_stats = {
            'consecutive_failures': 0,         # è¿ç»­å¤±è´¥æ¬¡æ•°
            'last_failure_timestamp': None,    # æœ€åå¤±è´¥æ—¶é—´
            'total_aha_moments': 0,            # æ€»Aha-Momentæ¬¡æ•°
            'aha_success_rate': 0.0,           # Aha-MomentæˆåŠŸç‡
            'last_decision_success': True,     # ä¸Šæ¬¡å†³ç­–æ˜¯å¦æˆåŠŸ
            'failure_threshold': 3,            # è¿ç»­å¤±è´¥é˜ˆå€¼
            'confidence_threshold': 0.3,       # ç½®ä¿¡åº¦é˜ˆå€¼
            'aha_decision_history': []         # Aha-Momentå†³ç­–å†å²
        }
        

            
        logger.info("ğŸš€ MainControlleråˆå§‹åŒ–å®Œæˆ - ä½¿ç”¨å¤šLLMæ”¯æŒçš„ç»„ä»¶åŒ–æ¶æ„")
        logger.info(f"ğŸ” ç ”ç©¶å‘˜å·¥å…·å·²è£…å¤‡: {'âœ…' if self.web_search_client else 'âŒ'} æœç´¢å¼•æ“")
        
        # æ˜¾ç¤ºLLMç³»ç»ŸçŠ¶æ€
        if self.llm_manager:
            status = self.llm_manager.get_provider_status()
            logger.info(f"ğŸ§  LLMç³»ç»Ÿå·²è£…å¤‡: âœ… ç®¡ç†å™¨æ¨¡å¼")
            logger.info(f"   å¯ç”¨æä¾›å•†: {status['healthy_providers']}/{status['total_providers']}")
            
            # æ˜¾ç¤ºä¸»è¦æä¾›å•†
            if status['providers']:
                healthy_providers = [name for name, info in status['providers'].items() if info['healthy']]
                if healthy_providers:
                    logger.info(f"   æ´»è·ƒæä¾›å•†: {', '.join(healthy_providers)}")
        else:
            logger.info(f"ğŸ§  LLMç³»ç»Ÿå·²è£…å¤‡: {'âœ…' if self.llm_client else 'âŒ'} å›é€€æ¨¡å¼")
    
    def make_decision(self, user_query: str, deepseek_confidence: float = 0.5, 
                     execution_context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        ğŸš€ äº”é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–æµç¨‹ - å†…ç½®æœç´¢éªŒè¯ç³»ç»Ÿ
        
        é˜¶æ®µä¸€ï¼šæ€ç»´ç§å­ç”Ÿæˆ (PriorReasoner) - ç†è§£é—®é¢˜ï¼Œç”Ÿæˆæ€ç»´ç§å­
        é˜¶æ®µäºŒï¼šç§å­éªŒè¯æ£€æŸ¥ (æ–°å¢) - éªŒè¯æ€ç»´ç§å­çš„å®è§‚æ–¹å‘
        é˜¶æ®µä¸‰ï¼šæ€ç»´è·¯å¾„ç”Ÿæˆ (PathGenerator) - åŸºäºç§å­ç”Ÿæˆå¤šæ¡è·¯å¾„
        é˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯å­¦ä¹  (æ ¸å¿ƒåˆ›æ–°) - é€ä¸€éªŒè¯è·¯å¾„å¹¶å³æ—¶å­¦ä¹ 
        é˜¶æ®µäº”ï¼šæ™ºèƒ½æœ€ç»ˆå†³ç­– (å‡çº§) - åŸºäºéªŒè¯ç»“æœæ™ºèƒ½å†³ç­–
        
        æ ¸å¿ƒåˆ›æ–°ï¼šAIåœ¨æ€è€ƒé˜¶æ®µå°±è·å¾—å³æ—¶åé¦ˆï¼Œä¸å†ç­‰å¾…æœ€ç»ˆæ‰§è¡Œç»“æœ
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            deepseek_confidence: DeepSeekå¯¹è¯¥ä»»åŠ¡çš„ç½®ä¿¡åº¦
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            å†³ç­–ç»“æœ
        """
        start_time = time.time()
        self.total_rounds += 1
        
        logger.info(f"ğŸš€ å¼€å§‹ç¬¬ {self.total_rounds} è½®äº”é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–")
        logger.info(f"   æŸ¥è¯¢: {user_query[:50]}...")
        logger.info(f"   DeepSeekç½®ä¿¡åº¦: {deepseek_confidence:.2f}")
        
        try:
            # ğŸ§  é˜¶æ®µä¸€ï¼šå…ˆéªŒæ¨ç† - ç”Ÿæˆæ€ç»´ç§å­ï¼ˆä¸å˜ï¼‰
            reasoner_start = time.time()
            thinking_seed = self.prior_reasoner.get_thinking_seed(user_query, execution_context)
            
            # å…¼å®¹æ€§ï¼šåŒæ—¶è·å–æ—§æ ¼å¼çš„æ•°æ®ç”¨äºå‘åå…¼å®¹
            task_confidence = self.prior_reasoner.assess_task_confidence(user_query, execution_context)
            complexity_info = self.prior_reasoner.analyze_task_complexity(user_query)
            
            reasoner_time = time.time() - reasoner_start
            self._update_component_performance('prior_reasoner', reasoner_time)
            
            logger.info(f"ğŸ§  é˜¶æ®µä¸€å®Œæˆ: æ€ç»´ç§å­ç”Ÿæˆ (é•¿åº¦: {len(thinking_seed)} å­—ç¬¦)")
            logger.debug(f"ğŸŒ± æ€ç»´ç§å­é¢„è§ˆ: {thinking_seed[:100]}...")
            
            # ğŸ” é˜¶æ®µäºŒï¼šéªŒè¯æ€ç»´ç§å­ï¼ˆæ–°å¢ï¼‰- å¯¹å®è§‚æ–¹å‘è¿›è¡Œå¿«é€ŸéªŒè¯
            seed_verification_start = time.time()
            seed_verification_result = self.verify_idea_feasibility(
                idea_text=thinking_seed,
                context={
                    'stage': 'thinking_seed',
                    'domain': 'strategic_planning',
                    'query': user_query,
                    **(execution_context if execution_context else {})
                }
            )
            seed_verification_time = time.time() - seed_verification_start
            
            # åˆ†æç§å­éªŒè¯ç»“æœ
            seed_feasibility = seed_verification_result.get('feasibility_analysis', {}).get('feasibility_score', 0.5)
            seed_reward = seed_verification_result.get('reward_score', 0.0)
            
            logger.info(f"ğŸ” é˜¶æ®µäºŒå®Œæˆ: æ€ç»´ç§å­éªŒè¯ (å¯è¡Œæ€§: {seed_feasibility:.2f}, å¥–åŠ±: {seed_reward:+.3f})")
            
            if seed_feasibility < 0.3:
                logger.warning(f"âš ï¸ æ€ç»´ç§å­æ–¹å‘å­˜åœ¨é—®é¢˜ (å¯è¡Œæ€§: {seed_feasibility:.2f})ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
            
            # ğŸ›¤ï¸ é˜¶æ®µä¸‰ï¼šè·¯å¾„ç”Ÿæˆ - åŸºäºï¼ˆå·²éªŒè¯çš„ï¼‰æ€ç»´ç§å­ç”Ÿæˆæ€ç»´è·¯å¾„åˆ—è¡¨ï¼ˆä¸å˜ï¼‰
            generator_start = time.time()
            all_reasoning_paths = self.path_generator.generate_paths(
                thinking_seed=thinking_seed, 
                task=user_query,
                max_paths=6  # é™åˆ¶è·¯å¾„æ•°é‡ä»¥æé«˜æ€§èƒ½
            )
            generator_time = time.time() - generator_start
            self._update_component_performance('path_generator', generator_time)
            
            logger.info(f"ğŸ›¤ï¸ é˜¶æ®µä¸‰å®Œæˆ: ç”Ÿæˆäº† {len(all_reasoning_paths)} æ¡æ€ç»´è·¯å¾„")
            for i, path in enumerate(all_reasoning_paths[:3], 1):  # è®°å½•å‰3ä¸ªè·¯å¾„
                logger.debug(f"   è·¯å¾„{i}: {path.path_type} (ID: {path.path_id})")
            
            # ğŸš€ é˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯å­¦ä¹ ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰- é€ä¸€éªŒè¯è·¯å¾„å¹¶å³æ—¶å­¦ä¹ 
            path_verification_start = time.time()
            # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šæ™ºèƒ½è·¯å¾„éªŒè¯ï¼ˆæ”¯æŒå¹¶è¡ŒåŒ–å’Œè‡ªé€‚åº”ï¼‰
            verified_paths = []
            all_infeasible = True  # æ ‡è®°æ˜¯å¦æ‰€æœ‰è·¯å¾„éƒ½ä¸å¯è¡Œ
            
            # ç¡®å®šè¦éªŒè¯çš„è·¯å¾„æ•°é‡ï¼ˆè‡ªé€‚åº”ä¼˜åŒ–ï¼‰
            original_path_count = len(all_reasoning_paths)
            if self.performance_optimizer and PERFORMANCE_CONFIG.get("enable_adaptive_path_count", False):
                # æå–å¤æ‚åº¦åˆ†æ•°
                complexity_score = complexity_info.get('overall_score', 0.5) if isinstance(complexity_info, dict) else 0.5
                optimal_count = self.performance_optimizer.adaptive_selector.get_optimal_path_count(
                    confidence=deepseek_confidence,
                    complexity=complexity_score
                )
                # åªéªŒè¯å‰Næ¡æœ€æœ‰æ½œåŠ›çš„è·¯å¾„
                paths_to_verify = all_reasoning_paths[:optimal_count]
                logger.info(f"ğŸ¯ è‡ªé€‚åº”ä¼˜åŒ–: ä»{original_path_count}æ¡è·¯å¾„ä¸­é€‰æ‹©{optimal_count}æ¡è¿›è¡ŒéªŒè¯")
            else:
                paths_to_verify = all_reasoning_paths
            
            logger.info(f"ğŸ”¬ é˜¶æ®µå››å¼€å§‹: éªŒè¯ {len(paths_to_verify)} æ¡æ€ç»´è·¯å¾„")
            
            # ğŸš€ å¹¶è¡ŒéªŒè¯è·¯å¾„ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
            if (self.performance_optimizer and 
                PERFORMANCE_CONFIG.get("enable_parallel_path_verification", False) and 
                len(paths_to_verify) > 1):
                
                logger.info(f"âš¡ å¯ç”¨å¹¶è¡ŒéªŒè¯æ¨¡å¼ - æœ€å¤§å¹¶å‘æ•°: {PERFORMANCE_CONFIG.get('max_concurrent_verifications', 3)}")
                
                # åˆ›å»ºéªŒè¯ä»»åŠ¡
                def create_verification_task(path):
                    def verify_single_path(p):
                        return self.verify_idea_feasibility(
                            idea_text=f"{p.path_type}: {p.description}",
                            context={
                                'stage': 'reasoning_path',
                                'path_id': p.path_id,
                                'path_type': p.path_type,
                                'query': user_query,
                                **(execution_context if execution_context else {})
                            }
                        )
                    return (path, verify_single_path)
                
                verification_tasks = [create_verification_task(path) for path in paths_to_verify]
                
                # å¹¶è¡Œæ‰§è¡ŒéªŒè¯
                parallel_results = self.performance_optimizer.parallel_verifier.verify_paths_parallel(verification_tasks)
                
                # å¤„ç†å¹¶è¡ŒéªŒè¯ç»“æœ
                for i, (path, result) in enumerate(zip(paths_to_verify, parallel_results)):
                    if result is None:
                        logger.warning(f"âš ï¸ è·¯å¾„ {path.path_type} å¹¶è¡ŒéªŒè¯å¤±è´¥ï¼Œè·³è¿‡")
                        continue
                    
                    # æå–éªŒè¯ç»“æœ
                    path_feasibility = result.get('feasibility_analysis', {}).get('feasibility_score', 0.5)
                    path_reward = result.get('reward_score', 0.0)
                    verification_success = not result.get('fallback', False)
                    
                    # ğŸ’¡ å³æ—¶å­¦ä¹ ï¼šç«‹å³å°†éªŒè¯ç»“æœåé¦ˆç»™MABç³»ç»Ÿ
                    if verification_success and path_feasibility > 0.3:
                        # å¯è¡Œçš„è·¯å¾„ - æ­£é¢å­¦ä¹ ä¿¡å·
                        self.mab_converger.update_path_performance(
                            path_id=path.strategy_id,  # ğŸ¯ æ ¹æºä¿®å¤ï¼šä½¿ç”¨ç­–ç•¥IDè¿›è¡Œå­¦ä¹ 
                            success=True,
                            reward=path_reward
                        )
                        all_infeasible = False  # è‡³å°‘æœ‰ä¸€ä¸ªè·¯å¾„å¯è¡Œ
                        logger.debug(f"âœ… è·¯å¾„ {path.path_type} éªŒè¯é€šè¿‡: å¯è¡Œæ€§={path_feasibility:.2f}, å¥–åŠ±={path_reward:+.3f}")
                    else:
                        # ä¸å¯è¡Œçš„è·¯å¾„ - è´Ÿé¢å­¦ä¹ ä¿¡å·
                        self.mab_converger.update_path_performance(
                            path_id=path.strategy_id,  # ğŸ¯ æ ¹æºä¿®å¤ï¼šä½¿ç”¨ç­–ç•¥IDè¿›è¡Œå­¦ä¹ 
                            success=False,
                            reward=path_reward  # å¯èƒ½æ˜¯è´Ÿå€¼
                        )
                        logger.debug(f"âŒ è·¯å¾„ {path.path_type} éªŒè¯å¤±è´¥: å¯è¡Œæ€§={path_feasibility:.2f}, å¥–åŠ±={path_reward:+.3f}")
                    
                    # è®°å½•éªŒè¯ç»“æœ
                    verified_paths.append({
                        'path': path,
                        'verification_result': result,
                        'feasibility_score': path_feasibility,
                        'reward_score': path_reward,
                        'is_feasible': path_feasibility > 0.3
                    })
                    
                    # ğŸ”„ æ—©æœŸç»ˆæ­¢æ£€æŸ¥ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
                    if (PERFORMANCE_CONFIG.get("enable_early_termination", False) and 
                        len(verified_paths) >= 3 and
                        self.performance_optimizer.adaptive_selector.should_early_terminate(verified_paths)):
                        logger.info(f"ğŸ”„ æ—©æœŸç»ˆæ­¢: å·²éªŒè¯{len(verified_paths)}æ¡è·¯å¾„ï¼Œç»“æœä¸€è‡´æ€§è¶³å¤Ÿ")
                        break
                
            else:
                # ğŸ”„ ä¼ ç»Ÿä¸²è¡ŒéªŒè¯ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
                logger.info("ğŸ“Š ä½¿ç”¨ä¼ ç»Ÿä¸²è¡ŒéªŒè¯æ¨¡å¼")
                
                for i, path in enumerate(paths_to_verify, 1):
                    logger.debug(f"ğŸ”¬ éªŒè¯è·¯å¾„ {i}/{len(paths_to_verify)}: {path.path_type}")
                    
                    # ğŸ§  æ™ºèƒ½ç¼“å­˜æ£€æŸ¥
                    cache_key = f"{path.path_type}_{path.description[:50]}"
                    cached_result = None
                    if (self.performance_optimizer and 
                        PERFORMANCE_CONFIG.get("enable_intelligent_caching", False)):
                        cached_result = self.performance_optimizer.cache.get(cache_key, execution_context)
                    
                    if cached_result:
                        logger.debug(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜ç»“æœ: {path.path_type}")
                        path_verification_result = cached_result
                    else:
                        # éªŒè¯å•ä¸ªè·¯å¾„
                        path_verification_result = self.verify_idea_feasibility(
                            idea_text=f"{path.path_type}: {path.description}",
                            context={
                                'stage': 'reasoning_path',
                                'path_id': path.path_id,
                                'path_type': path.path_type,
                                'query': user_query,
                                **(execution_context if execution_context else {})
                            }
                        )
                        
                        # ğŸ’¾ ç¼“å­˜ç»“æœ
                        if (self.performance_optimizer and 
                            PERFORMANCE_CONFIG.get("enable_intelligent_caching", False)):
                            self.performance_optimizer.cache.set(cache_key, path_verification_result, execution_context)
                    
                    # æå–éªŒè¯ç»“æœ
                    path_feasibility = path_verification_result.get('feasibility_analysis', {}).get('feasibility_score', 0.5)
                    path_reward = path_verification_result.get('reward_score', 0.0)
                    verification_success = not path_verification_result.get('fallback', False)
                    
                    # ğŸ’¡ å³æ—¶å­¦ä¹ ï¼šç«‹å³å°†éªŒè¯ç»“æœåé¦ˆç»™MABç³»ç»Ÿ
                    if verification_success and path_feasibility > 0.3:
                        # å¯è¡Œçš„è·¯å¾„ - æ­£é¢å­¦ä¹ ä¿¡å·
                        self.mab_converger.update_path_performance(
                            path_id=path.strategy_id,  # ğŸ¯ æ ¹æºä¿®å¤ï¼šä½¿ç”¨ç­–ç•¥IDè¿›è¡Œå­¦ä¹ 
                            success=True,
                            reward=path_reward
                        )
                        all_infeasible = False  # è‡³å°‘æœ‰ä¸€ä¸ªè·¯å¾„å¯è¡Œ
                        logger.debug(f"âœ… è·¯å¾„ {path.path_type} éªŒè¯é€šè¿‡: å¯è¡Œæ€§={path_feasibility:.2f}, å¥–åŠ±={path_reward:+.3f}")
                    else:
                        # ä¸å¯è¡Œçš„è·¯å¾„ - è´Ÿé¢å­¦ä¹ ä¿¡å·
                        self.mab_converger.update_path_performance(
                            path_id=path.strategy_id,  # ğŸ¯ æ ¹æºä¿®å¤ï¼šä½¿ç”¨ç­–ç•¥IDè¿›è¡Œå­¦ä¹ 
                            success=False,
                            reward=path_reward  # å¯èƒ½æ˜¯è´Ÿå€¼
                        )
                        logger.debug(f"âŒ è·¯å¾„ {path.path_type} éªŒè¯å¤±è´¥: å¯è¡Œæ€§={path_feasibility:.2f}, å¥–åŠ±={path_reward:+.3f}")
                    
                    # è®°å½•éªŒè¯ç»“æœ
                    verified_paths.append({
                        'path': path,
                        'verification_result': path_verification_result,
                        'feasibility_score': path_feasibility,
                        'reward_score': path_reward,
                        'is_feasible': path_feasibility > 0.3
                    })
                    
                    # ğŸ”„ æ—©æœŸç»ˆæ­¢æ£€æŸ¥ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
                    if (self.performance_optimizer and 
                        PERFORMANCE_CONFIG.get("enable_early_termination", False) and 
                        len(verified_paths) >= 3 and
                        self.performance_optimizer.adaptive_selector.should_early_terminate(verified_paths)):
                        logger.info(f"ğŸ”„ æ—©æœŸç»ˆæ­¢: å·²éªŒè¯{len(verified_paths)}æ¡è·¯å¾„ï¼Œç»“æœä¸€è‡´æ€§è¶³å¤Ÿ")
                        break
            
            path_verification_time = time.time() - path_verification_start
            feasible_count = sum(1 for vp in verified_paths if vp['is_feasible'])
            
            logger.info(f"ğŸ”¬ é˜¶æ®µå››å®Œæˆ: {feasible_count}/{len(all_reasoning_paths)} æ¡è·¯å¾„å¯è¡Œ")
            logger.info(f"   ğŸ’¡ å³æ—¶å­¦ä¹ : MABç³»ç»Ÿå·²æ›´æ–°æ‰€æœ‰è·¯å¾„æƒé‡")
            
            # ğŸ¯ é˜¶æ®µäº”ï¼šæ™ºèƒ½æœ€ç»ˆå†³ç­–ï¼ˆå‡çº§ï¼‰- åŸºäºéªŒè¯ç»“æœæ™ºèƒ½å†³ç­–
            final_decision_start = time.time()
            
            if all_infeasible:
                # ğŸš¨ æ‰€æœ‰è·¯å¾„éƒ½ä¸å¯è¡Œ - è§¦å‘æ™ºèƒ½ç»•é“æ€è€ƒ
                logger.warning("ğŸš¨ æ‰€æœ‰æ€ç»´è·¯å¾„éƒ½è¢«éªŒè¯ä¸ºä¸å¯è¡Œï¼Œè§¦å‘æ™ºèƒ½ç»•é“æ€è€ƒ")
                
                # è¿™æ˜¯æ›´æ™ºèƒ½çš„Aha-Momentè§¦å‘å™¨
                chosen_path, mab_decision = self._execute_intelligent_detour_thinking(
                    user_query, thinking_seed, all_reasoning_paths, verified_paths
                )
                
                mab_decision.update({
                    'selection_algorithm': 'intelligent_detour',
                    'all_paths_infeasible': True,
                    'detour_triggered': True,
                    'verification_triggered_detour': True
                })
                
                logger.info(f"ğŸš€ æ™ºèƒ½ç»•é“å®Œæˆ: é€‰æ‹©åˆ›æ–°è·¯å¾„ '{chosen_path.path_type}'")
                
            else:
                # âœ… è‡³å°‘æœ‰å¯è¡Œè·¯å¾„ - ä½¿ç”¨å¢å¼ºçš„MABé€‰æ‹©
                logger.info("âœ… å‘ç°å¯è¡Œè·¯å¾„ï¼Œä½¿ç”¨éªŒè¯å¢å¼ºçš„MABå†³ç­–")
                
                # MABç°åœ¨å·²ç»æœ‰äº†å³æ—¶å­¦ä¹ çš„æƒé‡ï¼Œä¼šè‡ªç„¶å€¾å‘äºå¯è¡Œè·¯å¾„
                chosen_path = self.mab_converger.select_best_path(all_reasoning_paths)
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼ ç»Ÿçš„Aha-Momentï¼ˆä½œä¸ºé¢å¤–ä¿é™©ï¼‰
                aha_triggered, aha_reason = self._check_aha_moment_trigger(chosen_path)
                
                if aha_triggered:
                    logger.info(f"ğŸ’¡ é¢å¤–è§¦å‘ä¼ ç»ŸAha-Moment: {aha_reason}")
                    chosen_path, _ = self._execute_aha_moment_thinking(
                        user_query, thinking_seed, chosen_path, all_reasoning_paths
                    )
                
                mab_decision = {
                    'chosen_path': chosen_path,
                    'available_paths': all_reasoning_paths,
                    'verified_paths': verified_paths,
                    'selection_algorithm': 'verification_enhanced_mab',
                    'converged': self.mab_converger.check_path_convergence(),
                    'all_paths_infeasible': False,
                    'feasible_paths_count': feasible_count,
                    'total_paths_count': len(all_reasoning_paths),
                    'verification_triggered_detour': False,
                    'traditional_aha_triggered': aha_triggered
                }
                
                logger.info(f"ğŸ¯ æ™ºèƒ½å†³ç­–å®Œæˆ: é€‰æ‹©éªŒè¯ä¼˜åŒ–è·¯å¾„ '{chosen_path.path_type}'")
            
            final_decision_time = time.time() - final_decision_start
            total_mab_time = path_verification_time + final_decision_time
            self._update_component_performance('mab_converger', total_mab_time)
            
            # è®¡ç®—æ€»ä½“å†³ç­–æ—¶é—´
            total_decision_time = time.time() - start_time
            
            # æ„å»ºå‡çº§ç‰ˆäº”é˜¶æ®µå†³ç­–ç»“æœ
            decision_result = {
                # åŸºæœ¬ä¿¡æ¯
                'timestamp': time.time(),
                'round_number': self.total_rounds,
                'user_query': user_query,
                'deepseek_confidence': deepseek_confidence,
                'execution_context': execution_context,
                
                # ğŸš€ äº”é˜¶æ®µå†³ç­–ç»“æœ
                'thinking_seed': thinking_seed,  # é˜¶æ®µä¸€ï¼šæ€ç»´ç§å­
                'seed_verification': seed_verification_result,  # é˜¶æ®µäºŒï¼šç§å­éªŒè¯
                'chosen_path': chosen_path,  # æœ€ç»ˆé€‰ä¸­çš„æ€ç»´è·¯å¾„
                'available_paths': all_reasoning_paths,  # é˜¶æ®µä¸‰ï¼šæ‰€æœ‰å€™é€‰è·¯å¾„
                'verified_paths': verified_paths,  # é˜¶æ®µå››ï¼šéªŒè¯ç»“æœ
                'mab_decision': mab_decision,  # é˜¶æ®µäº”ï¼šæœ€ç»ˆå†³ç­–è¯¦æƒ…
                
                # å‘åå…¼å®¹å­—æ®µ
                'selected_path': chosen_path,  # å…¼å®¹æ—§æ¥å£
                'task_confidence': task_confidence,
                'complexity_analysis': complexity_info,
                
                # å†³ç­–å…ƒä¿¡æ¯
                'reasoning': f"äº”é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–: {chosen_path.path_type} - {chosen_path.description}",
                'path_count': len(all_reasoning_paths),
                'feasible_path_count': feasible_count,
                'architecture_version': '5-stage-verification',  # æ–°å¢ï¼šæ¶æ„ç‰ˆæœ¬æ ‡è¯†
                'verification_enabled': True,  # æ ‡è¯†å¯ç”¨éªŒè¯
                'instant_learning_enabled': True,  # æ ‡è¯†å¯ç”¨å³æ—¶å­¦ä¹ 
                
                # ğŸ”¬ éªŒè¯ç»Ÿè®¡
                'verification_stats': {
                    'seed_feasibility': seed_feasibility,
                    'seed_reward': seed_reward,
                    'paths_verified': len(verified_paths),
                    'feasible_paths': feasible_count,
                    'infeasible_paths': len(verified_paths) - feasible_count,
                    'all_paths_infeasible': all_infeasible,
                    'average_path_feasibility': sum(vp['feasibility_score'] for vp in verified_paths) / len(verified_paths) if verified_paths else 0.0,
                    'total_verification_time': seed_verification_time + path_verification_time
                },
                
                # æ€§èƒ½æŒ‡æ ‡
                'performance_metrics': {
                    'total_time': total_decision_time,
                    'stage1_reasoner_time': reasoner_time,
                    'stage2_seed_verification_time': seed_verification_time,
                    'stage3_generator_time': generator_time,
                    'stage4_path_verification_time': path_verification_time,
                    'stage5_final_decision_time': final_decision_time,
                    'stages_breakdown': {
                        'thinking_seed_generation': reasoner_time,
                        'seed_verification': seed_verification_time,
                        'path_generation': generator_time,
                        'path_verification_learning': path_verification_time,
                        'intelligent_final_decision': final_decision_time
                    }
                }
            }
            
            # è®°å½•å†³ç­–å†å²
            self.decision_history.append(decision_result)
            
            # é™åˆ¶å†å²è®°å½•é•¿åº¦
            max_history = SYSTEM_LIMITS["max_decision_history"]
            if len(self.decision_history) > max_history:
                self.decision_history = self.decision_history[-max_history//2:]
            
            # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
            self.performance_stats['total_decisions'] += 1
            self._update_avg_decision_time(total_decision_time)
            
            logger.info(f"ğŸ‰ äº”é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–å®Œæˆ:")
            logger.info(f"   ğŸŒ± æ€ç»´ç§å­: {len(thinking_seed)}å­—ç¬¦ (å¯è¡Œæ€§: {seed_feasibility:.2f})")
            logger.info(f"   ğŸ›¤ï¸ ç”Ÿæˆè·¯å¾„: {len(all_reasoning_paths)}æ¡")
            logger.info(f"   ğŸ”¬ éªŒè¯ç»“æœ: {feasible_count}æ¡å¯è¡Œ/{len(verified_paths)}æ¡æ€»æ•°")
            logger.info(f"   ğŸ¯ æœ€ç»ˆé€‰æ‹©: {chosen_path.path_type}")
            logger.info(f"   ğŸ’¡ å³æ—¶å­¦ä¹ : MABæƒé‡å·²æ›´æ–°")
            logger.info(f"   â±ï¸ æ€»è€—æ—¶: {total_decision_time:.3f}s")
            logger.info(f"      - é˜¶æ®µä¸€(ç§å­ç”Ÿæˆ): {reasoner_time:.3f}s")
            logger.info(f"      - é˜¶æ®µäºŒ(ç§å­éªŒè¯): {seed_verification_time:.3f}s")
            logger.info(f"      - é˜¶æ®µä¸‰(è·¯å¾„ç”Ÿæˆ): {generator_time:.3f}s") 
            logger.info(f"      - é˜¶æ®µå››(è·¯å¾„éªŒè¯): {path_verification_time:.3f}s")
            logger.info(f"      - é˜¶æ®µäº”(æ™ºèƒ½å†³ç­–): {final_decision_time:.3f}s")
            
            return decision_result
            
        except Exception as e:
            logger.error(f"âŒ å†³ç­–è¿‡ç¨‹å¤±è´¥: {e}")
            # è¿”å›é”™è¯¯å†³ç­–ç»“æœ
            return self._create_error_decision_result(user_query, str(e), time.time() - start_time)
    
    def _update_component_performance(self, component_name: str, execution_time: float):
        """æ›´æ–°ç»„ä»¶æ€§èƒ½ç»Ÿè®¡"""
        component_stats = self.performance_stats['component_performance'][component_name]
        component_stats['calls'] += 1
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡
        current_avg = component_stats['avg_time']
        call_count = component_stats['calls']
        component_stats['avg_time'] = (current_avg * (call_count - 1) + execution_time) / call_count
    
    def _update_avg_decision_time(self, decision_time: float):
        """æ›´æ–°å¹³å‡å†³ç­–æ—¶é—´"""
        current_avg = self.performance_stats['avg_decision_time']
        total_decisions = self.performance_stats['total_decisions']
        
        if total_decisions == 1:
            self.performance_stats['avg_decision_time'] = decision_time
        else:
            self.performance_stats['avg_decision_time'] = (
                current_avg * (total_decisions - 1) + decision_time
            ) / total_decisions
    
    def _create_error_decision_result(self, user_query: str, error_msg: str, execution_time: float) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯å†³ç­–ç»“æœ"""
        return {
            'timestamp': time.time(),
            'round_number': self.total_rounds,
            'user_query': user_query,
            'selected_dimensions': {},
            'confidence_scores': {},
            'task_confidence': 0.0,
            'complexity_analysis': {'complexity_score': 0.5, 'estimated_domain': 'error'},
            'mab_decisions': {},
            'reasoning': f"å†³ç­–å¤±è´¥: {error_msg}",
            'fallback_used': True,
            'component_architecture': True,
            'error': error_msg,
            'performance_metrics': {
                'total_time': execution_time,
                'error_occurred': True
            }
        }
    
    def update_performance_feedback(self, decision_result: Dict[str, Any], 
                                  execution_success: bool, execution_time: float = 30.0,
                                  user_satisfaction: float = 0.5, rl_reward: float = 0.5):
        """
        æ›´æ–°ä¸‰é˜¶æ®µå†³ç­–æ€§èƒ½åé¦ˆ - å‡çº§ç‰ˆç»„ä»¶åŒ–æ¶æ„
        
        Args:
            decision_result: å†³ç­–ç»“æœ
            execution_success: æ‰§è¡Œæ˜¯å¦æˆåŠŸ
            execution_time: æ‰§è¡Œæ—¶é—´
            user_satisfaction: ç”¨æˆ·æ»¡æ„åº¦
            rl_reward: å¼ºåŒ–å­¦ä¹ å¥–åŠ±
        """
        try:
            # ğŸ¯ æ ¸å¿ƒæ›´æ–°ï¼šåŸºäºé€‰ä¸­çš„æ€ç»´è·¯å¾„æ›´æ–°MABæ€§èƒ½
            chosen_path = decision_result.get('chosen_path') or decision_result.get('selected_path')
            if chosen_path:
                # ä½¿ç”¨å‡çº§åçš„è·¯å¾„æ€§èƒ½æ›´æ–°æ–¹æ³•
                self.mab_converger.update_path_performance(
                    path_id=chosen_path.strategy_id,  # ğŸ¯ æ ¹æºä¿®å¤ï¼šä½¿ç”¨ç­–ç•¥IDè¿›è¡Œå­¦ä¹ 
                    success=execution_success,
                    reward=rl_reward
                )
                logger.debug(f"ğŸ° å·²æ›´æ–°è·¯å¾„æ€§èƒ½: {chosen_path.strategy_id} -> æˆåŠŸ={execution_success}, å¥–åŠ±={rl_reward:.3f}")
            else:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°é€‰ä¸­çš„æ€ç»´è·¯å¾„ï¼Œæ— æ³•æ›´æ–°MABæ€§èƒ½")
            
            # ğŸ“Š æ›´æ–°å…ˆéªŒæ¨ç†å™¨çš„ç½®ä¿¡åº¦å†å²
            task_confidence = decision_result.get('task_confidence', 0.5)
            if hasattr(self.prior_reasoner, 'update_confidence_feedback'):
                self.prior_reasoner.update_confidence_feedback(
                    task_confidence, execution_success, execution_time
                )
            
            # ğŸ§  æ–°å¢ï¼šæ›´æ–°æ€ç»´ç§å­çš„æ•ˆæœè·Ÿè¸ª
            thinking_seed = decision_result.get('thinking_seed')
            if thinking_seed and hasattr(self.prior_reasoner, 'update_seed_feedback'):
                self.prior_reasoner.update_seed_feedback(
                    thinking_seed, execution_success, rl_reward
                )
            
            # ğŸ“ˆ æ›´æ–°ç³»ç»Ÿçº§æ€§èƒ½ç»Ÿè®¡
            if execution_success:
                self.performance_stats['successful_decisions'] += 1
            
            # ğŸ’¡ æ›´æ–°Aha-Momentå†³ç­–åé¦ˆ
            self.update_aha_moment_feedback(execution_success)
            
            # ğŸ“ æ ‡è®°å†³ç­–å†å²ä¸­çš„æ‰§è¡Œç»“æœï¼ˆç”¨äºåç»­å¤±è´¥æ£€æµ‹ï¼‰
            if self.decision_history:
                self.decision_history[-1]['execution_success'] = execution_success
            
            # ğŸ•’ è®°å½•è¯¦ç»†åé¦ˆåˆ°å†³ç­–å†å²ä¸­
            if self.decision_history and self.decision_history[-1]['round_number'] == decision_result.get('round_number'):
                feedback_data = {
                    'execution_success': execution_success,
                    'execution_time': execution_time,
                    'user_satisfaction': user_satisfaction,
                    'rl_reward': rl_reward,
                    'feedback_timestamp': time.time(),
                    'architecture_version': '3-stage',  # æ ‡è¯†ä¸ºä¸‰é˜¶æ®µæ¶æ„åé¦ˆ
                    'strategy_id': chosen_path.strategy_id if chosen_path else None,  # ğŸ¯ æ ¹æºä¿®å¤ï¼šè®°å½•ç­–ç•¥ID
                    'instance_id': chosen_path.instance_id if chosen_path else None,  # ä¿ç•™å®ä¾‹IDç”¨äºè¿½è¸ª
                    'path_type': chosen_path.path_type if chosen_path else None
                }
                self.decision_history[-1]['feedback'] = feedback_data
            
            # ğŸ“Š è®¡ç®—å¹¶è®°å½•æ€§èƒ½æŒ‡æ ‡
            success_rate = self.performance_stats['successful_decisions'] / max(self.performance_stats['total_decisions'], 1)
            
            logger.info(f"ğŸ“ˆ ä¸‰é˜¶æ®µæ€§èƒ½åé¦ˆå·²æ›´æ–°:")
            logger.info(f"   ğŸ¯ è·¯å¾„: {chosen_path.path_type if chosen_path else 'Unknown'}")
            logger.info(f"   âœ… æ‰§è¡Œ: æˆåŠŸ={execution_success}, è€—æ—¶={execution_time:.2f}s")
            logger.info(f"   ğŸ å¥–åŠ±: RL={rl_reward:.3f}, æ»¡æ„åº¦={user_satisfaction:.3f}")
            logger.info(f"   ğŸ“Š æ•´ä½“æˆåŠŸç‡: {success_rate:.1%}")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ä¸‰é˜¶æ®µæ€§èƒ½åé¦ˆå¤±è´¥: {e}")
            logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ä¸‰é˜¶æ®µæ™ºèƒ½å†³ç­–ç³»ç»ŸçŠ¶æ€"""
        try:
            # è®¡ç®—æˆåŠŸç‡
            success_rate = 0.0
            if self.performance_stats['total_decisions'] > 0:
                success_rate = self.performance_stats['successful_decisions'] / self.performance_stats['total_decisions']
            
            # è·å–å„ç»„ä»¶ç»Ÿè®¡ï¼ˆå®‰å…¨è°ƒç”¨ï¼Œé¿å…æ–¹æ³•ä¸å­˜åœ¨çš„é”™è¯¯ï¼‰
            prior_reasoner_stats = {}
            if hasattr(self.prior_reasoner, 'get_confidence_statistics'):
                prior_reasoner_stats = self.prior_reasoner.get_confidence_statistics()
            else:
                prior_reasoner_stats = {'total_assessments': 0, 'avg_confidence': 0.5, 'confidence_trend': 'stable'}
            
            path_generator_stats = {}
            if hasattr(self.path_generator, 'get_generation_statistics'):
                path_generator_stats = self.path_generator.get_generation_statistics()
            else:
                path_generator_stats = {'total_generations': 0, 'fallback_usage_rate': 0.0, 'avg_dimensions_per_generation': 0}
            
            # ä½¿ç”¨å‡çº§åçš„MABçŠ¶æ€è·å–æ–¹æ³•
            mab_stats = self.mab_converger.get_system_status()
            
            # è·å–è·¯å¾„çº§ç»Ÿè®¡
            path_summary = {}
            if hasattr(self.mab_converger, 'get_system_path_summary'):
                path_summary = self.mab_converger.get_system_path_summary()
            
            return {
                # åŸºæœ¬ä¿¡æ¯
                'total_rounds': self.total_rounds,
                'architecture_version': '3-stage',  # æ ‡è¯†æ¶æ„ç‰ˆæœ¬
                'component_architecture': True,  # å‘åå…¼å®¹
                
                # ç³»ç»Ÿæ€§èƒ½
                'system_performance': {
                    'success_rate': success_rate,
                    'avg_decision_time': self.performance_stats['avg_decision_time'],
                    'total_decisions': self.performance_stats['total_decisions'],
                    'successful_decisions': self.performance_stats['successful_decisions']
                },
                
                # ä¸‰é˜¶æ®µç»„ä»¶çŠ¶æ€
                'component_status': {
                    'stage1_prior_reasoner': {
                        'assessments_count': prior_reasoner_stats.get('total_assessments', 0),
                        'avg_confidence': prior_reasoner_stats.get('avg_confidence', 0.5),
                        'confidence_trend': prior_reasoner_stats.get('confidence_trend', 'stable'),
                        'thinking_seeds_generated': self.total_rounds,  # è¿‘ä¼¼å€¼
                        'performance': self.performance_stats['component_performance']['prior_reasoner']
                    },
                    'stage2_path_generator': {
                        'generations_count': path_generator_stats.get('total_generations', 0),
                        'fallback_rate': path_generator_stats.get('fallback_usage_rate', 0.0),
                        'avg_paths_per_generation': path_generator_stats.get('avg_dimensions_per_generation', 0),
                        'performance': self.performance_stats['component_performance']['path_generator']
                    },
                    'stage3_mab_converger': {
                        'mode': mab_stats.get('mode', 'path_selection'),
                        'total_paths': mab_stats.get('total_paths', 0),
                        'active_paths': mab_stats.get('active_paths', 0),
                        'total_selections': mab_stats.get('total_selections', 0),
                        'convergence_level': mab_stats.get('convergence_level', 0.0),
                        'most_popular_path_type': mab_stats.get('most_popular_path_type'),
                        'performance': self.performance_stats['component_performance']['mab_converger']
                    }
                },
                
                # è·¯å¾„é€‰æ‹©çŠ¶æ€
                'path_selection_status': {
                    'total_paths_tracked': path_summary.get('total_paths', 0),
                    'is_converged': path_summary.get('is_converged', False),
                    'convergence_level': path_summary.get('convergence_level', 0.0),
                    'most_used_path': path_summary.get('most_used_path'),
                    'best_performing_path': path_summary.get('best_performing_path'),
                    'algorithm_performance': path_summary.get('algorithm_performance', {})
                },
                
                # ç³»ç»Ÿèµ„æºä½¿ç”¨
                'memory_usage': {
                    'decision_history_size': len(self.decision_history),
                    'path_arms_count': len(getattr(self.mab_converger, 'path_arms', {})),
                    'path_generation_cache_size': len(getattr(self.path_generator, 'path_generation_cache', {})),
                    'confidence_cache_size': len(getattr(self.prior_reasoner, 'assessment_cache', {}))
                },
                
                # ğŸš€ æ€§èƒ½ä¼˜åŒ–å™¨çŠ¶æ€
                'performance_optimization': self._get_performance_optimization_status(),
                
                # æ‰©å±•åŠŸèƒ½çŠ¶æ€
                'extended_features': {
                    'thinking_seed_tracking': True,  # æ–°åŠŸèƒ½æ ‡è¯†
                    'path_performance_tracking': True,
                    'multi_algorithm_mab': True,
                    'aha_moment_decision_enabled': True  # ğŸ’¡ æ–°å¢ï¼šAha-Momentå†³ç­–åŠŸèƒ½
                },
                
                # ğŸ’¡ Aha-Momentå†³ç­–ç³»ç»ŸçŠ¶æ€
                'aha_moment_system': self.get_aha_moment_stats(),
                
                # ğŸ’¡ è·¯å¾„ç½®ä¿¡åº¦åˆ†æ
                'confidence_analysis': self.mab_converger.get_confidence_analysis(),
                
                # ğŸ’¡ åˆ›é€ æ€§ç»•é“ç»Ÿè®¡
                'creative_bypass_stats': self.path_generator.get_creative_bypass_stats(),
                
                # ğŸ† é»„é‡‘æ¨¡æ¿ç³»ç»ŸçŠ¶æ€ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                'golden_template_system': mab_stats.get('golden_template_system', {}),
                
                # å‘åå…¼å®¹å­—æ®µ
                'recent_decisions': len(self.decision_history)
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
            return {
                'error': str(e),
                'total_rounds': self.total_rounds,
                'component_architecture': True
            }
    
    def get_decision_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–å†³ç­–å†å²è®°å½•
        
        Args:
            limit: è¿”å›è®°å½•æ•°é‡é™åˆ¶
            
        Returns:
            å†³ç­–å†å²è®°å½•åˆ—è¡¨
        """
        return self.decision_history[-limit:] if self.decision_history else []
    
    def _get_performance_optimization_status(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ä¼˜åŒ–å™¨çŠ¶æ€"""
        if not self.performance_optimizer:
            return {
                'enabled': False,
                'status': 'disabled',
                'message': 'æ€§èƒ½ä¼˜åŒ–å™¨æœªå¯ç”¨'
            }
        
        try:
            optimization_report = self.performance_optimizer.get_performance_report()
            
            return {
                'enabled': True,
                'status': 'active',
                'features': {
                    'parallel_verification': PERFORMANCE_CONFIG.get("enable_parallel_path_verification", False),
                    'intelligent_caching': PERFORMANCE_CONFIG.get("enable_intelligent_caching", False),
                    'adaptive_path_count': PERFORMANCE_CONFIG.get("enable_adaptive_path_count", False),
                    'early_termination': PERFORMANCE_CONFIG.get("enable_early_termination", False)
                },
                'cache_stats': optimization_report.get('cache_stats', {}),
                'performance_improvements': optimization_report.get('optimization_stats', {}),
                'config': {
                    'max_concurrent_verifications': PERFORMANCE_CONFIG.get("max_concurrent_verifications", 3),
                    'cache_ttl_seconds': PERFORMANCE_CONFIG.get("cache_ttl_seconds", 3600),
                    'path_consistency_threshold': PERFORMANCE_CONFIG.get("path_consistency_threshold", 0.8)
                },
                'uptime_hours': optimization_report.get('uptime_hours', 0)
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–æ€§èƒ½ä¼˜åŒ–å™¨çŠ¶æ€å¤±è´¥: {e}")
            return {
                'enabled': True,
                'status': 'error',
                'error': str(e)
            }
    
    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–è¯¦ç»†æ€§èƒ½æŠ¥å‘Š"""
        try:
            report = {
                'overview': {
                    'total_decisions': self.performance_stats['total_decisions'],
                    'successful_decisions': self.performance_stats['successful_decisions'],
                    'success_rate': 0.0,
                    'avg_decision_time': self.performance_stats['avg_decision_time']
                },
                'component_performance': self.performance_stats['component_performance'].copy(),
                'recent_trends': self._analyze_recent_trends(),
                'bottlenecks': self._identify_performance_bottlenecks(),
                'recommendations': self._generate_performance_recommendations()
            }
            
            # è®¡ç®—æˆåŠŸç‡
            if report['overview']['total_decisions'] > 0:
                report['overview']['success_rate'] = (
                    report['overview']['successful_decisions'] / report['overview']['total_decisions']
                )
            
            return report
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _analyze_recent_trends(self) -> Dict[str, Any]:
        """åˆ†ææœ€è¿‘çš„æ€§èƒ½è¶‹åŠ¿"""
        if len(self.decision_history) < 5:
            return {'status': 'insufficient_data'}
        
        recent_decisions = self.decision_history[-10:]
        
        # åˆ†ææˆåŠŸç‡è¶‹åŠ¿
        recent_successes = [
            1 if d.get('feedback', {}).get('execution_success', False) else 0 
            for d in recent_decisions if 'feedback' in d
        ]
        
        # åˆ†æå†³ç­–æ—¶é—´è¶‹åŠ¿
        recent_times = [
            d.get('performance_metrics', {}).get('total_time', 0) 
            for d in recent_decisions
        ]
        
        trends = {
            'success_rate_trend': 'stable',
            'decision_time_trend': 'stable',
            'recent_success_rate': 0.0,
            'recent_avg_time': 0.0
        }
        
        if recent_successes:
            trends['recent_success_rate'] = sum(recent_successes) / len(recent_successes)
            
        if recent_times:
            trends['recent_avg_time'] = sum(recent_times) / len(recent_times)
            
            # ç®€å•è¶‹åŠ¿åˆ†æ
            if len(recent_times) >= 5:
                first_half_avg = sum(recent_times[:len(recent_times)//2]) / (len(recent_times)//2)
                second_half_avg = sum(recent_times[len(recent_times)//2:]) / (len(recent_times) - len(recent_times)//2)
                
                if second_half_avg > first_half_avg * 1.2:
                    trends['decision_time_trend'] = 'increasing'
                elif second_half_avg < first_half_avg * 0.8:
                    trends['decision_time_trend'] = 'decreasing'
        
        return trends
    
    def _identify_performance_bottlenecks(self) -> List[str]:
        """è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ"""
        bottlenecks = []
        
        # åˆ†æç»„ä»¶æ€§èƒ½
        component_perfs = self.performance_stats['component_performance']
        
        # æ‰¾å‡ºæœ€æ…¢çš„ç»„ä»¶
        slowest_component = max(component_perfs.items(), key=lambda x: x[1]['avg_time'])
        if slowest_component[1]['avg_time'] > 2.0:  # è¶…è¿‡2ç§’
            bottlenecks.append(f"{slowest_component[0]}å“åº”æ—¶é—´è¿‡é•¿ ({slowest_component[1]['avg_time']:.2f}s)")
        
        # æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
        if hasattr(self.path_generator, 'generation_cache') and len(self.path_generator.generation_cache) > 20:
            bottlenecks.append("è·¯å¾„ç”Ÿæˆç¼“å­˜å¯èƒ½è¿‡å¤§ï¼Œå½±å“å†…å­˜ä½¿ç”¨")
        
        # æ£€æŸ¥å†³ç­–å†å²å¤§å°
        if len(self.decision_history) > SYSTEM_LIMITS["max_decision_history"] * 0.8:
            bottlenecks.append("å†³ç­–å†å²æ¥è¿‘ä¸Šé™ï¼Œå¯èƒ½å½±å“æ€§èƒ½")
        
        return bottlenecks
    
    def _generate_performance_recommendations(self) -> List[str]:
        """ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # åŸºäºæˆåŠŸç‡çš„å»ºè®®
        success_rate = 0.0
        if self.performance_stats['total_decisions'] > 0:
            success_rate = self.performance_stats['successful_decisions'] / self.performance_stats['total_decisions']
        
        if success_rate < 0.7:
            recommendations.append("æˆåŠŸç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥ç»´åº¦ç”Ÿæˆç­–ç•¥å’ŒMABç®—æ³•å‚æ•°")
        
        # åŸºäºå†³ç­–æ—¶é—´çš„å»ºè®®
        if self.performance_stats['avg_decision_time'] > 3.0:
            recommendations.append("å¹³å‡å†³ç­–æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–APIè°ƒç”¨æˆ–å¢åŠ ç¼“å­˜")
        
        # åŸºäºç»„ä»¶æ€§èƒ½çš„å»ºè®®
        component_perfs = self.performance_stats['component_performance']
        for component_name, perf in component_perfs.items():
            if perf['avg_time'] > 1.5:
                recommendations.append(f"ä¼˜åŒ–{component_name}ç»„ä»¶æ€§èƒ½ï¼Œå½“å‰å¹³å‡è€—æ—¶{perf['avg_time']:.2f}ç§’")
        
        if not recommendations:
            recommendations.append("ç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼Œæ— ç‰¹åˆ«ä¼˜åŒ–å»ºè®®")
        
        return recommendations
    
    # ==================== ğŸ’¡ Aha-Momentå†³ç­–ç³»ç»Ÿå®ç° ====================
    
    def _check_aha_moment_trigger(self, chosen_path) -> Tuple[bool, str]:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘Aha-Momentå†³ç­–ï¼ˆç»•é“æ€è€ƒï¼‰
        
        Args:
            chosen_path: MABé€‰æ‹©çš„æ€ç»´è·¯å¾„
            
        Returns:
            (æ˜¯å¦è§¦å‘, è§¦å‘åŸå› )
        """
        # è§¦å‘æ¡ä»¶1ï¼šè·¯å¾„ç½®ä¿¡åº¦è¿‡ä½
        if hasattr(chosen_path, 'strategy_id'):
            path_confidence = self.mab_converger.get_path_confidence(chosen_path.strategy_id)
            
            if path_confidence < self.aha_moment_stats['confidence_threshold']:
                return True, f"é€‰ä¸­è·¯å¾„ç½®ä¿¡åº¦è¿‡ä½ ({path_confidence:.3f} < {self.aha_moment_stats['confidence_threshold']})"
        
        # è§¦å‘æ¡ä»¶2ï¼šæ‰€æœ‰è·¯å¾„éƒ½è¡¨ç°å¾ˆå·®
        is_low_confidence_scenario = self.mab_converger.check_low_confidence_scenario(
            threshold=self.aha_moment_stats['confidence_threshold']
        )
        
        if is_low_confidence_scenario:
            return True, "æ‰€æœ‰å¯ç”¨è·¯å¾„çš„ç½®ä¿¡åº¦éƒ½åä½ï¼Œéœ€è¦åˆ›é€ æ€§çªç ´"
        
        # è§¦å‘æ¡ä»¶3ï¼šè¿ç»­å¤±è´¥æ¬¡æ•°è¿‡å¤š
        if self.aha_moment_stats['consecutive_failures'] >= self.aha_moment_stats['failure_threshold']:
            return True, f"è¿ç»­å¤±è´¥ {self.aha_moment_stats['consecutive_failures']} æ¬¡ï¼Œè¶…è¿‡é˜ˆå€¼ {self.aha_moment_stats['failure_threshold']}"
        
        # è§¦å‘æ¡ä»¶4ï¼šç‰¹å®šæ—¶é—´é—´éš”å†…çš„å¤±è´¥å¯†åº¦è¿‡é«˜
        recent_failures = self._count_recent_failures(time_window=300)  # 5åˆ†é’Ÿå†…
        if recent_failures >= 3:
            return True, f"æœ€è¿‘5åˆ†é’Ÿå†…å¤±è´¥ {recent_failures} æ¬¡ï¼Œé¢‘ç‡è¿‡é«˜"
        
        return False, "å¸¸è§„å†³ç­–è·¯å¾„è¡¨ç°æ­£å¸¸"
    
    def _execute_aha_moment_thinking(self, user_query: str, thinking_seed: str, 
                                   original_path, original_paths) -> Tuple[Any, List[Any]]:
        """
        æ‰§è¡ŒAha-Momentç»•é“æ€è€ƒ
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            thinking_seed: åŸå§‹æ€ç»´ç§å­
            original_path: åŸå§‹é€‰æ‹©çš„è·¯å¾„
            original_paths: åŸå§‹è·¯å¾„åˆ—è¡¨
            
        Returns:
            (æ–°é€‰æ‹©çš„è·¯å¾„, æ–°çš„è·¯å¾„åˆ—è¡¨)
        """
        aha_start_time = time.time()
        self.aha_moment_stats['total_aha_moments'] += 1
        
        logger.info("ğŸ’¡ å¼€å§‹æ‰§è¡ŒAha-Momentç»•é“æ€è€ƒ...")
        logger.info(f"   åŸå§‹è·¯å¾„: {original_path.path_type}")
        logger.info(f"   åŸå§‹è·¯å¾„æ•°é‡: {len(original_paths)}")
        
        try:
            # Step 1: ç”Ÿæˆåˆ›é€ æ€§ç»•é“è·¯å¾„
            logger.info("ğŸŒŸ ç”Ÿæˆåˆ›é€ æ€§æ€ç»´è·¯å¾„...")
            creative_paths = self.path_generator.generate_paths(
                thinking_seed=thinking_seed,
                task=user_query,
                max_paths=4,  # å‡å°‘æ•°é‡ï¼Œä¸“æ³¨è´¨é‡
                mode='creative_bypass'  # åˆ›é€ æ€§ç»•é“æ¨¡å¼
            )
            
            logger.info(f"ğŸŒŸ ç”Ÿæˆäº† {len(creative_paths)} æ¡åˆ›é€ æ€§è·¯å¾„")
            for i, path in enumerate(creative_paths, 1):
                logger.info(f"   åˆ›é€ æ€§è·¯å¾„{i}: {path.path_type}")
            
            # Step 2: åˆå¹¶åŸå§‹è·¯å¾„å’Œåˆ›é€ æ€§è·¯å¾„
            combined_paths = original_paths + creative_paths
            
            # Step 3: ä½¿ç”¨MABé‡æ–°é€‰æ‹©ï¼ˆç°åœ¨æœ‰æ›´å¤šé€‰æ‹©ï¼‰
            logger.info("ğŸ¯ åœ¨æ‰©å±•è·¯å¾„é›†åˆä¸­é‡æ–°é€‰æ‹©æœ€ä¼˜è·¯å¾„...")
            final_chosen_path = self.mab_converger.select_best_path(combined_paths)
            
            # Step 4: è®°å½•Aha-Momentå†³ç­–å†å²
            aha_record = {
                'timestamp': time.time(),
                'trigger_reason': 'low_confidence_scenario',
                'original_path': original_path.path_type,
                'creative_paths_generated': len(creative_paths),
                'final_chosen_path': final_chosen_path.path_type,
                'was_creative_path_chosen': final_chosen_path in creative_paths,
                'aha_thinking_time': time.time() - aha_start_time
            }
            
            self.aha_moment_stats['aha_decision_history'].append(aha_record)
            
            # é™åˆ¶å†å²è®°å½•é•¿åº¦
            if len(self.aha_moment_stats['aha_decision_history']) > 100:
                self.aha_moment_stats['aha_decision_history'] = self.aha_moment_stats['aha_decision_history'][-50:]
            
            logger.info(f"ğŸ’¡ Aha-Momentæ€è€ƒå®Œæˆ:")
            logger.info(f"   æœ€ç»ˆè·¯å¾„: {final_chosen_path.path_type}")
            logger.info(f"   æ˜¯å¦é€‰æ‹©åˆ›é€ æ€§è·¯å¾„: {'æ˜¯' if final_chosen_path in creative_paths else 'å¦'}")
            logger.info(f"   ç»•é“æ€è€ƒè€—æ—¶: {time.time() - aha_start_time:.3f}s")
            
            return final_chosen_path, combined_paths
            
        except Exception as e:
            logger.error(f"âŒ Aha-Momentæ€è€ƒè¿‡ç¨‹å¤±è´¥: {e}")
            logger.warning("ğŸ”„ å›é€€åˆ°åŸå§‹è·¯å¾„é€‰æ‹©")
            return original_path, original_paths
    
    def _count_recent_failures(self, time_window: int = 300) -> int:
        """
        ç»Ÿè®¡æœ€è¿‘æ—¶é—´çª—å£å†…çš„å¤±è´¥æ¬¡æ•°
        
        Args:
            time_window: æ—¶é—´çª—å£ï¼ˆç§’ï¼‰
            
        Returns:
            å¤±è´¥æ¬¡æ•°
        """
        if not self.decision_history:
            return 0
        
        current_time = time.time()
        failure_count = 0
        
        for decision in reversed(self.decision_history):
            if current_time - decision.get('timestamp', 0) > time_window:
                break  # è¶…å‡ºæ—¶é—´çª—å£
            
            # æ£€æŸ¥è¿™ä¸ªå†³ç­–æ˜¯å¦è¢«æ ‡è®°ä¸ºå¤±è´¥
            # è¿™éœ€è¦åœ¨update_performance_feedbackä¸­è®¾ç½®
            if decision.get('execution_success', True) is False:
                failure_count += 1
        
        return failure_count
    
    def update_aha_moment_feedback(self, success: bool):
        """
        æ›´æ–°Aha-Momentå†³ç­–çš„åé¦ˆ
        
        Args:
            success: å†³ç­–æ˜¯å¦æˆåŠŸ
        """
        if success:
            self.aha_moment_stats['consecutive_failures'] = 0
            self.aha_moment_stats['last_decision_success'] = True
            logger.debug("âœ… å†³ç­–æˆåŠŸï¼Œé‡ç½®è¿ç»­å¤±è´¥è®¡æ•°")
        else:
            self.aha_moment_stats['consecutive_failures'] += 1
            self.aha_moment_stats['last_decision_success'] = False
            self.aha_moment_stats['last_failure_timestamp'] = time.time()
            logger.debug(f"âŒ å†³ç­–å¤±è´¥ï¼Œè¿ç»­å¤±è´¥æ¬¡æ•°: {self.aha_moment_stats['consecutive_failures']}")
        
        # æ›´æ–°Aha-MomentæˆåŠŸç‡ç»Ÿè®¡
        if self.aha_moment_stats['aha_decision_history']:
            aha_successes = sum(1 for record in self.aha_moment_stats['aha_decision_history'] 
                              if record.get('success', False))
            total_aha = len(self.aha_moment_stats['aha_decision_history'])
            self.aha_moment_stats['aha_success_rate'] = aha_successes / total_aha
    
    def get_aha_moment_stats(self) -> Dict[str, any]:
        """
        è·å–Aha-Momentå†³ç­–ç³»ç»Ÿçš„ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        recent_aha_count = sum(1 for record in self.aha_moment_stats['aha_decision_history']
                              if time.time() - record['timestamp'] < 3600)  # æœ€è¿‘1å°æ—¶
        
        return {
            'total_aha_moments': self.aha_moment_stats['total_aha_moments'],
            'consecutive_failures': self.aha_moment_stats['consecutive_failures'],
            'aha_success_rate': self.aha_moment_stats['aha_success_rate'],
            'recent_aha_count': recent_aha_count,
            'failure_threshold': self.aha_moment_stats['failure_threshold'],
            'confidence_threshold': self.aha_moment_stats['confidence_threshold'],
            'last_failure_timestamp': self.aha_moment_stats['last_failure_timestamp'],
            'last_decision_success': self.aha_moment_stats['last_decision_success'],
            'history_count': len(self.aha_moment_stats['aha_decision_history'])
        }
    
    def reset_system(self, preserve_learnings: bool = True):
        """
        é‡ç½®ç³»ç»ŸçŠ¶æ€
        
        Args:
            preserve_learnings: æ˜¯å¦ä¿ç•™å­¦ä¹ åˆ°çš„çŸ¥è¯†
        """
        logger.info("ğŸ”„ å¼€å§‹é‡ç½®ç³»ç»Ÿ...")
        
        # é‡ç½®è®¡æ•°å™¨
        self.total_rounds = 0
        self.decision_history.clear()
        
        # é‡ç½®æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            'total_decisions': 0,
            'successful_decisions': 0,
            'avg_decision_time': 0.0,
            'component_performance': {
                'prior_reasoner': {'calls': 0, 'avg_time': 0.0},
                'path_generator': {'calls': 0, 'avg_time': 0.0},
                'mab_converger': {'calls': 0, 'avg_time': 0.0},
                'idea_verification': {'calls': 0, 'avg_time': 0.0, 'success_rate': 0.0}  # åŒ…å«æ–°çš„éªŒè¯ç»Ÿè®¡
            }
        }
        
        if not preserve_learnings:
            # æ¸…é™¤æ‰€æœ‰å­¦ä¹ æ•°æ®
            self.prior_reasoner.reset_cache()
            self.path_generator.clear_cache()
            # MABæ•°æ®ä¸æ¸…é™¤ï¼Œå› ä¸ºå®ƒæ˜¯æ ¸å¿ƒå­¦ä¹ æœºåˆ¶
            logger.info("ğŸ§¹ å·²æ¸…é™¤ç¼“å­˜å’Œä¸´æ—¶æ•°æ®")
        
        logger.info("âœ… ç³»ç»Ÿé‡ç½®å®Œæˆ")
        
        # é‡ç½®éªŒè¯ç›¸å…³ç¼“å­˜
        if hasattr(self, 'idea_verification_client') and self.idea_verification_client:
            self.idea_verification_client.verification_cache.clear()
            logger.info("ğŸ§¹ å·²æ¸…é™¤éªŒè¯ç¼“å­˜")
    
    # ================================
    # ğŸ”¬ æ–°å¢ï¼šæƒ³æ³•éªŒè¯ç ”ç©¶å‘˜èƒ½åŠ›
    # ================================
    
    def verify_idea_feasibility(self, idea_text: str, context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        æƒ³æ³•éªŒè¯æµç¨‹ - MainControllerçš„æ–°"ç ”ç©¶å‘˜"èƒ½åŠ›
        
        è¿™ä¸ªæ–¹æ³•å®ç°äº†å®Œæ•´çš„"æœç´¢å¹¶åˆ¤æ–­å¯è¡Œæ€§"å·¥ä½œæµï¼š
        1. æ¥æ”¶æƒ³æ³•ï¼šæ¥æ”¶éœ€è¦éªŒè¯çš„æƒ³æ³•æ–‡æœ¬
        2. æ„æ€é—®é¢˜ï¼šè½¬æ¢æˆæœç´¢æŸ¥è¯¢
        3. æ‰§è¡Œæœç´¢ï¼šè·å–ç›¸å…³èµ„æ–™
        4. è¯·æ±‚åˆ†æï¼šLLMåˆ†æå¯è¡Œæ€§
        5. é‡åŒ–ç»“æœï¼šè®¡ç®—å¥–æƒ©åˆ†æ•°
        
        Args:
            idea_text: éœ€è¦éªŒè¯çš„æƒ³æ³•æ–‡æœ¬ï¼ˆæ€ç»´ç§å­æˆ–æ€ç»´è·¯å¾„æè¿°ï¼‰
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        start_time = time.time()
        logger.info(f"ğŸ”¬ å¼€å§‹æƒ³æ³•éªŒè¯ç ”ç©¶: {idea_text[:50]}...")
        
        try:
            # ç¬¬1æ­¥ï¼šæ¥æ”¶æƒ³æ³• - é¢„å¤„ç†å’Œæ¸…ç†
            cleaned_idea = self._preprocess_idea_text(idea_text)
            logger.debug(f"ğŸ“ æƒ³æ³•æ¸…ç†å®Œæˆ: {len(cleaned_idea)}å­—ç¬¦")
            
            # ç¬¬2æ­¥ï¼šæ„æ€é—®é¢˜ - è½¬æ¢æˆæœç´¢æŸ¥è¯¢
            search_query = self._generate_verification_query(cleaned_idea, context)
            logger.info(f"ğŸ¤” æ„æ€æœç´¢é—®é¢˜: {search_query}")
            
            # ç¬¬3æ­¥ï¼šæ‰§è¡Œæœç´¢ - è·å–å¤–éƒ¨èµ„æ–™
            search_start = time.time()
            search_response = self.idea_verification_client.search_for_idea_verification(
                cleaned_idea, context
            )
            search_time = time.time() - search_start
            
            if not search_response.success:
                logger.warning(f"âš ï¸ æœç´¢å¤±è´¥: {search_response.error_message}")
                return self._create_fallback_verification_result(idea_text, "æœç´¢å¤±è´¥")
            
            logger.info(f"ğŸ” æœç´¢å®Œæˆ: æ‰¾åˆ°{len(search_response.results)}ä¸ªç»“æœï¼Œè€—æ—¶{search_time:.2f}ç§’")
            
            # ç¬¬4æ­¥ï¼šè¯·æ±‚åˆ†æ - LLMåˆ†æå¯è¡Œæ€§
            analysis_start = time.time()
            feasibility_analysis = self._analyze_idea_feasibility(
                cleaned_idea, search_response, context
            )
            analysis_time = time.time() - analysis_start
            
            logger.info(f"ğŸ§  LLMåˆ†æå®Œæˆ: è€—æ—¶{analysis_time:.2f}ç§’")
            
            # ç¬¬5æ­¥ï¼šé‡åŒ–ç»“æœ - è®¡ç®—å¥–æƒ©åˆ†æ•°
            reward_score = self._calculate_verification_reward(feasibility_analysis)
            
            # æ„å»ºå®Œæ•´ç»“æœ
            verification_result = {
                'idea_text': idea_text,
                'cleaned_idea': cleaned_idea,
                'search_query': search_query,
                'search_results': search_response.results,
                'search_stats': {
                    'total_results': search_response.total_results,
                    'search_time': search_time,
                    'success': search_response.success
                },
                'feasibility_analysis': feasibility_analysis,
                'reward_score': reward_score,
                'verification_time': time.time() - start_time,
                'timestamp': time.time()
            }
            
            # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
            self._update_verification_performance(verification_result)
            
            logger.info(f"âœ… æƒ³æ³•éªŒè¯å®Œæˆ: å¥–åŠ±åˆ†æ•°={reward_score:.3f}")
            return verification_result
            
        except Exception as e:
            error_time = time.time() - start_time
            logger.error(f"âŒ æƒ³æ³•éªŒè¯å¤±è´¥: {e}")
            
            return self._create_fallback_verification_result(
                idea_text, f"éªŒè¯è¿‡ç¨‹å¼‚å¸¸: {str(e)}", error_time
            )
    
    def _preprocess_idea_text(self, idea_text: str) -> str:
        """é¢„å¤„ç†æƒ³æ³•æ–‡æœ¬"""
        # æ¸…ç†å’Œæ ‡å‡†åŒ–æ–‡æœ¬
        cleaned = idea_text.strip()
        
        # é™åˆ¶é•¿åº¦ï¼ˆé¿å…è¿‡é•¿çš„æœç´¢æŸ¥è¯¢ï¼‰
        if len(cleaned) > 200:
            cleaned = cleaned[:200] + "..."
            
        return cleaned
    
    def _generate_verification_query(self, idea_text: str, context: Optional[Dict] = None) -> str:
        """
        ç”ŸæˆéªŒè¯æŸ¥è¯¢ - å°†æƒ³æ³•è½¬æ¢æˆé€‚åˆæœç´¢çš„é—®é¢˜
        
        Args:
            idea_text: æƒ³æ³•æ–‡æœ¬
            context: ä¸Šä¸‹æ–‡
            
        Returns:
            æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
        """
        # æå–æ ¸å¿ƒæŠ€æœ¯æ¦‚å¿µ
        tech_concepts = self._extract_technical_concepts(idea_text)
        
        # æ„å»ºæŸ¥è¯¢æ¨¡æ¿
        if tech_concepts:
            query_template = f"'{' '.join(tech_concepts[:2])}' æŠ€æœ¯å¯è¡Œæ€§ å®ç°æ–¹æ³• æ½œåœ¨é£é™© æœ€ä½³å®è·µ"
        else:
            query_template = f"'{idea_text[:50]}' è§£å†³æ–¹æ¡ˆ æŠ€æœ¯å®ç° æŒ‘æˆ˜åˆ†æ"
        
        # æ·»åŠ é¢†åŸŸä¸Šä¸‹æ–‡
        if context and 'domain' in context:
            query_template += f" {context['domain']}"
        
        return query_template
    
    def _extract_technical_concepts(self, text: str) -> List[str]:
        """æå–æŠ€æœ¯æ¦‚å¿µ"""
        tech_terms = [
            'API', 'api', 'ç®—æ³•', 'æ•°æ®åº“', 'ç³»ç»Ÿ', 'æ¶æ„', 'ä¼˜åŒ–',
            'æœºå™¨å­¦ä¹ ', 'ML', 'AI', 'äººå·¥æ™ºèƒ½', 'æ·±åº¦å­¦ä¹ ',
            'ç½‘ç»œ', 'çˆ¬è™«', 'æ•°æ®åˆ†æ', 'å®æ—¶', 'æ€§èƒ½', 'å®‰å…¨',
            'å¹¶å‘', 'åˆ†å¸ƒå¼', 'å¾®æœåŠ¡', 'å®¹å™¨', 'äº‘è®¡ç®—', 'åŒºå—é“¾',
            'Python', 'Java', 'JavaScript', 'React', 'Node.js'
        ]
        
        found_concepts = []
        text_lower = text.lower()
        
        for term in tech_terms:
            if term.lower() in text_lower:
                found_concepts.append(term)
        
        return found_concepts[:3]  # è¿”å›å‰3ä¸ªæ¦‚å¿µ
    
    def _analyze_idea_feasibility(self, idea_text: str, search_response: SearchResponse, 
                                context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        LLMåˆ†ææƒ³æ³•å¯è¡Œæ€§
        
        Args:
            idea_text: æƒ³æ³•æ–‡æœ¬
            search_response: æœç´¢å“åº”
            context: ä¸Šä¸‹æ–‡
            
        Returns:
            å¯è¡Œæ€§åˆ†æç»“æœ
        """
        if not self.llm_client:
            logger.warning("âš ï¸ LLMå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œä½¿ç”¨å¯å‘å¼åˆ†æ")
            logger.warning(f"   å®¢æˆ·ç«¯çŠ¶æ€: {self.llm_client}")
            logger.warning(f"   APIå¯†é’¥çŠ¶æ€: {'å·²è®¾ç½®' if self.api_key else 'æœªè®¾ç½®'}")
            logger.warning(f"   å»ºè®®: æ£€æŸ¥APIå¯†é’¥é…ç½®å’Œç½‘ç»œè¿æ¥")
            return self._heuristic_feasibility_analysis(idea_text, search_response)
        
        # æ„å»ºåˆ†ææç¤º
        analysis_prompt = self._build_feasibility_analysis_prompt(
            idea_text, search_response, context
        )
        
        try:
            # è°ƒç”¨LLMè¿›è¡Œåˆ†æ
            llm_response = self.llm_client.call_api(analysis_prompt, temperature=0.3)
            
            # è§£æLLMå“åº”
            analysis_result = self._parse_feasibility_analysis(llm_response)
            
            logger.debug(f"ğŸ§  LLMå¯è¡Œæ€§åˆ†æ: {analysis_result.get('feasibility_score', 0.5):.2f}")
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ LLMåˆ†æå¤±è´¥: {e}")
            return self._heuristic_feasibility_analysis(idea_text, search_response)
    
    def _build_feasibility_analysis_prompt(self, idea_text: str, search_response: SearchResponse,
                                         context: Optional[Dict] = None) -> str:
        """æ„å»ºå¯è¡Œæ€§åˆ†ææç¤º"""
        
        # æ•´ç†æœç´¢ç»“æœ
        search_summary = ""
        for i, result in enumerate(search_response.results[:3], 1):
            search_summary += f"{i}. {result.title}\n   {result.snippet}\n\n"
        
        # ä½¿ç”¨ä¸“é—¨çš„æç¤ºæ¨¡æ¿
        analysis_prompt = f"""
ä½œä¸ºä¸€ä½ä¸¥è°¨çš„æŠ€æœ¯åˆ†æå¸ˆï¼Œè¯·æ ¹æ®æä¾›çš„æœç´¢èµ„æ–™ï¼Œåˆ¤æ–­ä»¥ä¸‹æƒ³æ³•çš„å¯è¡Œæ€§ã€‚

ğŸ¯ **å¾…åˆ†ææƒ³æ³•**:
{idea_text}

ğŸ” **æœç´¢åˆ°çš„ç›¸å…³èµ„æ–™**:
{search_summary}

ğŸ“Š **ä¸Šä¸‹æ–‡ä¿¡æ¯**:
{context if context else 'æ— ç‰¹å®šä¸Šä¸‹æ–‡'}

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œæ·±åº¦åˆ†æï¼š

1. **æŠ€æœ¯å¯è¡Œæ€§**: ä»æŠ€æœ¯å®ç°è§’åº¦è¯„ä¼°è¿™ä¸ªæƒ³æ³•æ˜¯å¦å¯è¡Œ
2. **å®æ–½å¤æ‚åº¦**: åˆ†æå®æ–½è¿‡ç¨‹ä¸­å¯èƒ½é‡åˆ°çš„æŠ€æœ¯å¤æ‚åº¦
3. **é£é™©è¯„ä¼°**: è¯†åˆ«æ½œåœ¨çš„æŠ€æœ¯é£é™©å’ŒæŒ‘æˆ˜
4. **æˆåŠŸæ¦‚ç‡**: åŸºäºå½“å‰æŠ€æœ¯æ°´å¹³è¯„ä¼°æˆåŠŸæ¦‚ç‡
5. **æ”¹è¿›å»ºè®®**: æå‡ºä¼˜åŒ–å’Œæ”¹è¿›çš„å»ºè®®

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼ä¸¥æ ¼è¿”å›åˆ†æç»“æœï¼š
{{
    "feasibility_score": 0.0-1.0çš„å¯è¡Œæ€§è¯„åˆ†,
    "confidence_level": 0.0-1.0çš„åˆ†æç½®ä¿¡åº¦,
    "technical_feasibility": {{
        "score": 0.0-1.0,
        "reasoning": "æŠ€æœ¯å¯è¡Œæ€§åˆ†æç†ç”±"
    }},
    "complexity_assessment": {{
        "score": 0.0-1.0,
        "level": "low|medium|high",
        "reasoning": "å¤æ‚åº¦è¯„ä¼°ç†ç”±"
    }},
    "risk_analysis": {{
        "risk_level": 0.0-1.0,
        "key_risks": ["é£é™©1", "é£é™©2", "é£é™©3"],
        "mitigation_strategies": ["åº”å¯¹ç­–ç•¥1", "åº”å¯¹ç­–ç•¥2"]
    }},
    "implementation_recommendations": [
        "å»ºè®®1", "å»ºè®®2", "å»ºè®®3"
    ],
    "evidence_support": {{
        "supporting_evidence": ["æ”¯æŒè¯æ®1", "æ”¯æŒè¯æ®2"],
        "contradicting_evidence": ["åå¯¹è¯æ®1", "åå¯¹è¯æ®2"]
    }},
    "overall_assessment": "ç»¼åˆè¯„ä¼°æ€»ç»“"
}}

è¯·åŸºäºä¸“ä¸šçŸ¥è¯†å’Œæœç´¢èµ„æ–™ï¼Œç»™å‡ºå®¢è§‚ã€å‡†ç¡®çš„åˆ†æã€‚
"""
        
        return analysis_prompt
    
    def _parse_feasibility_analysis(self, llm_response: str) -> Dict[str, Any]:
        """è§£æLLMçš„å¯è¡Œæ€§åˆ†æå“åº”"""
        try:
            # å°è¯•è§£æJSONå“åº”
            import json
            import re
            
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', llm_response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                analysis_result = json.loads(json_str)
                
                # éªŒè¯å¿…è¦å­—æ®µ
                if 'feasibility_score' in analysis_result and 'confidence_level' in analysis_result:
                    return analysis_result
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æ„
            logger.warning("âš ï¸ LLMå“åº”è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åˆ†æç»“æ„")
            return self._create_default_analysis_result(llm_response)
            
        except Exception as e:
            logger.error(f"âŒ å¯è¡Œæ€§åˆ†æè§£æå¤±è´¥: {e}")
            return self._create_default_analysis_result(llm_response)
    
    def _create_default_analysis_result(self, raw_response: str) -> Dict[str, Any]:
        """åˆ›å»ºé»˜è®¤çš„åˆ†æç»“æœ"""
        return {
            "feasibility_score": 0.5,
            "confidence_level": 0.3,
            "technical_feasibility": {
                "score": 0.5,
                "reasoning": "LLMå“åº”è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è¯„ä¼°"
            },
            "complexity_assessment": {
                "score": 0.5,
                "level": "medium",
                "reasoning": "æ— æ³•ç¡®å®šå¤æ‚åº¦ï¼Œä½¿ç”¨ä¸­ç­‰è¯„ä¼°"
            },
            "risk_analysis": {
                "risk_level": 0.5,
                "key_risks": ["å“åº”è§£æå¤±è´¥", "åˆ†æä¸ç¡®å®š"],
                "mitigation_strategies": ["äººå·¥å¤æ ¸", "è¡¥å……ä¿¡æ¯"]
            },
            "implementation_recommendations": [
                "éœ€è¦æ›´è¯¦ç»†çš„åˆ†æ",
                "å»ºè®®äººå·¥éªŒè¯",
                "è¡¥å……æŠ€æœ¯ç»†èŠ‚"
            ],
            "evidence_support": {
                "supporting_evidence": [],
                "contradicting_evidence": []
            },
            "overall_assessment": f"åˆ†æå“åº”è§£æå¤±è´¥ï¼ŒåŸå§‹å“åº”é•¿åº¦: {len(raw_response)}å­—ç¬¦",
            "raw_response": raw_response[:500]  # ä¿ç•™éƒ¨åˆ†åŸå§‹å“åº”ç”¨äºè°ƒè¯•
        }
    
    def _heuristic_feasibility_analysis(self, idea_text: str, search_response: SearchResponse) -> Dict[str, Any]:
        """å¯å‘å¼å¯è¡Œæ€§åˆ†æï¼ˆå½“LLMä¸å¯ç”¨æ—¶çš„å¤‡ç”¨æ–¹æ³•ï¼‰"""
        
        # åŸºäºæœç´¢ç»“æœæ•°é‡å’Œç›¸å…³æ€§çš„ç®€å•è¯„ä¼°
        result_count = len(search_response.results)
        avg_relevance = sum(r.relevance_score for r in search_response.results) / max(result_count, 1)
        
        # åŸºäºæ–‡æœ¬ç‰¹å¾çš„å¤æ‚åº¦è¯„ä¼°
        complexity_indicators = ['å¤æ‚', 'å›°éš¾', 'æŒ‘æˆ˜', 'é«˜çº§', 'åˆ†å¸ƒå¼', 'å¹¶å‘']
        complexity_score = sum(1 for indicator in complexity_indicators if indicator in idea_text) / len(complexity_indicators)
        
        feasibility_score = min(1.0, avg_relevance * 0.7 + (1 - complexity_score) * 0.3)
        
        return {
            "feasibility_score": feasibility_score,
            "confidence_level": 0.4,  # å¯å‘å¼åˆ†æç½®ä¿¡åº¦è¾ƒä½
            "technical_feasibility": {
                "score": feasibility_score,
                "reasoning": "åŸºäºæœç´¢ç»“æœç›¸å…³æ€§å’Œæ–‡æœ¬å¤æ‚åº¦çš„å¯å‘å¼è¯„ä¼°"
            },
            "complexity_assessment": {
                "score": complexity_score,
                "level": "high" if complexity_score > 0.6 else "medium" if complexity_score > 0.3 else "low",
                "reasoning": f"æ£€æµ‹åˆ°{complexity_score:.1%}çš„å¤æ‚åº¦æŒ‡æ ‡"
            },
            "risk_analysis": {
                "risk_level": complexity_score,
                "key_risks": ["æŠ€æœ¯å¤æ‚åº¦", "å®æ–½éš¾åº¦"],
                "mitigation_strategies": ["åˆ†æ­¥å®æ–½", "æŠ€æœ¯è°ƒç ”"]
            },
            "implementation_recommendations": [
                "è¿›è¡Œæ›´è¯¦ç»†çš„æŠ€æœ¯è°ƒç ”",
                "è€ƒè™‘åˆ†é˜¶æ®µå®æ–½",
                "å¯»æ±‚ä¸“å®¶å»ºè®®"
            ],
            "evidence_support": {
                "supporting_evidence": [f"æ‰¾åˆ°{result_count}ä¸ªç›¸å…³æœç´¢ç»“æœ"],
                "contradicting_evidence": []
            },
            "overall_assessment": f"å¯å‘å¼åˆ†æ: å¯è¡Œæ€§{feasibility_score:.1%}ï¼Œå¤æ‚åº¦{complexity_score:.1%}",
            "analysis_method": "heuristic"
        }
    
    def _calculate_verification_reward(self, feasibility_analysis: Dict[str, Any]) -> float:
        """
        è®¡ç®—éªŒè¯å¥–æƒ©åˆ†æ•°
        
        Args:
            feasibility_analysis: å¯è¡Œæ€§åˆ†æç»“æœ
            
        Returns:
            å¥–æƒ©åˆ†æ•° (-1.0 åˆ° +1.0)
        """
        feasibility_score = feasibility_analysis.get('feasibility_score', 0.5)
        confidence_level = feasibility_analysis.get('confidence_level', 0.5)
        risk_level = feasibility_analysis.get('risk_analysis', {}).get('risk_level', 0.5)
        
        # åŸºç¡€å¥–åŠ±è®¡ç®—
        if feasibility_score >= 0.7:
            # é«˜å¯è¡Œæ€§ -> æ­£å¥–åŠ±
            base_reward = (feasibility_score - 0.5) * 2  # 0.4 åˆ° 1.0
        elif feasibility_score <= 0.3:
            # ä½å¯è¡Œæ€§ -> è´Ÿå¥–åŠ±  
            base_reward = (feasibility_score - 0.5) * 2  # -1.0 åˆ° -0.4
        else:
            # ä¸­ç­‰å¯è¡Œæ€§ -> å°å¹…å¥–åŠ±/æƒ©ç½š
            base_reward = (feasibility_score - 0.5) * 0.5  # -0.1 åˆ° 0.1
        
        # ç½®ä¿¡åº¦è°ƒæ•´
        confidence_multiplier = 0.5 + confidence_level * 0.5  # 0.5 åˆ° 1.0
        
        # é£é™©è°ƒæ•´
        risk_penalty = risk_level * 0.2  # æœ€å¤šæ‰£é™¤0.2åˆ†
        
        # æœ€ç»ˆå¥–åŠ±è®¡ç®—
        final_reward = (base_reward * confidence_multiplier) - risk_penalty
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        final_reward = max(-1.0, min(1.0, final_reward))
        
        logger.debug(f"ğŸ† å¥–åŠ±è®¡ç®—: åŸºç¡€={base_reward:.3f}, ç½®ä¿¡åº¦Ã—{confidence_multiplier:.3f}, é£é™©-{risk_penalty:.3f} = {final_reward:.3f}")
        
        return final_reward
    
    def _create_fallback_verification_result(self, idea_text: str, error_reason: str, 
                                           processing_time: float = 0.0) -> Dict[str, Any]:
        """åˆ›å»ºå¤‡ç”¨éªŒè¯ç»“æœï¼ˆå½“éªŒè¯è¿‡ç¨‹å¤±è´¥æ—¶ï¼‰"""
        return {
            'idea_text': idea_text,
            'cleaned_idea': idea_text,
            'search_query': "éªŒè¯å¤±è´¥",
            'search_results': [],
            'search_stats': {
                'total_results': 0,
                'search_time': 0.0,
                'success': False
            },
            'feasibility_analysis': {
                "feasibility_score": 0.3,  # å¤±è´¥æ—¶ç»™äºˆè¾ƒä½åˆ†æ•°
                "confidence_level": 0.1,
                "overall_assessment": f"éªŒè¯å¤±è´¥: {error_reason}"
            },
            'reward_score': -0.5,  # å¤±è´¥æƒ©ç½š
            'verification_time': processing_time,
            'timestamp': time.time(),
            'error': error_reason,
            'fallback': True
        }
    
    def _update_verification_performance(self, verification_result: Dict[str, Any]):
        """æ›´æ–°éªŒè¯æ€§èƒ½ç»Ÿè®¡"""
        perf_stats = self.performance_stats['component_performance']['idea_verification']
        
        # æ›´æ–°è°ƒç”¨æ¬¡æ•°
        perf_stats['calls'] += 1
        
        # æ›´æ–°å¹³å‡æ—¶é—´
        if perf_stats['calls'] == 1:
            perf_stats['avg_time'] = verification_result['verification_time']
        else:
            perf_stats['avg_time'] = (
                (perf_stats['avg_time'] * (perf_stats['calls'] - 1) + verification_result['verification_time'])
                / perf_stats['calls']
            )
        
        # æ›´æ–°æˆåŠŸç‡
        success = not verification_result.get('fallback', False)
        if perf_stats['calls'] == 1:
            perf_stats['success_rate'] = 1.0 if success else 0.0
        else:
            current_success_count = perf_stats['success_rate'] * (perf_stats['calls'] - 1)
            if success:
                current_success_count += 1
            perf_stats['success_rate'] = current_success_count / perf_stats['calls']
    
    # ================================
    # ğŸš€ æ™ºèƒ½ç»•é“æ€è€ƒç³»ç»Ÿï¼ˆå…¨æ–°Aha-Momentï¼‰
    # ================================
    
    def _execute_intelligent_detour_thinking(self, user_query: str, thinking_seed: str, 
                                           original_paths: List, verified_paths: List) -> Tuple[Any, Dict]:
        """
        æ™ºèƒ½ç»•é“æ€è€ƒ - å½“æ‰€æœ‰å¸¸è§„è·¯å¾„éƒ½è¢«éªŒè¯ä¸ºä¸å¯è¡Œæ—¶çš„åˆ›æ–°å†³ç­–
        
        è¿™æ˜¯åŸºäºéªŒè¯ç»“æœçš„æ–°å‹Aha-Momentè§¦å‘å™¨ï¼Œæ¯”ä¼ ç»Ÿæ–¹æ³•æ›´æ™ºèƒ½
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            thinking_seed: æ€ç»´ç§å­
            original_paths: åŸå§‹è·¯å¾„åˆ—è¡¨
            verified_paths: éªŒè¯ç»“æœåˆ—è¡¨
            
        Returns:
            Tuple[chosen_path, mab_decision]
        """
        logger.info("ğŸš€ å¼€å§‹æ™ºèƒ½ç»•é“æ€è€ƒ - å¯»æ‰¾åˆ›æ–°è§£å†³æ–¹æ¡ˆ")
        
        try:
            # åˆ†æå¤±è´¥æ¨¡å¼ - ä»éªŒè¯ç»“æœä¸­å­¦ä¹ 
            failure_patterns = self._analyze_verification_failures(verified_paths)
            logger.debug(f"ğŸ“Š å¤±è´¥æ¨¡å¼åˆ†æ: {failure_patterns}")
            
            # åŸºäºå¤±è´¥åˆ†æç”Ÿæˆåˆ›æ–°ç§å­
            innovative_seed = self._generate_innovative_thinking_seed(
                user_query, thinking_seed, failure_patterns
            )
            
            # ç”Ÿæˆåˆ›æ–°è·¯å¾„
            if innovative_seed:
                logger.info("ğŸ’¡ åŸºäºå¤±è´¥åˆ†æç”Ÿæˆåˆ›æ–°æ€ç»´ç§å­")
                innovative_paths = self.path_generator.generate_paths(
                    thinking_seed=innovative_seed,
                    task=user_query,
                    max_paths=3  # ä¸“æ³¨äºå°‘æ•°åˆ›æ–°è·¯å¾„
                )
            else:
                innovative_paths = []
            
            # å¦‚æœåˆ›æ–°è·¯å¾„ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨åº”æ€¥åˆ›æ–°è·¯å¾„
            if not innovative_paths:
                logger.warning("âš ï¸ åˆ›æ–°è·¯å¾„ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨åº”æ€¥åˆ›æ–°è·¯å¾„")
                innovative_paths = self._create_emergency_innovative_paths(user_query, failure_patterns)
            
            # éªŒè¯åˆ›æ–°è·¯å¾„
            best_innovative_path = None
            best_feasibility = 0.0
            
            for path in innovative_paths:
                path_verification = self.verify_idea_feasibility(
                    idea_text=f"åˆ›æ–°æ–¹æ¡ˆ: {path.path_type}: {path.description}",
                    context={
                        'stage': 'innovative_detour',
                        'original_failure': True,
                        'query': user_query
                    }
                )
                
                feasibility = path_verification.get('feasibility_analysis', {}).get('feasibility_score', 0.0)
                
                if feasibility > best_feasibility:
                    best_feasibility = feasibility
                    best_innovative_path = path
                
                # æ›´æ–°MABå­¦ä¹ ï¼ˆå³ä½¿æ˜¯åˆ›æ–°è·¯å¾„ä¹Ÿè¦å­¦ä¹ ï¼‰
                self.mab_converger.update_path_performance(
                    path_id=path.path_id,
                    success=feasibility > 0.4,  # åˆ›æ–°è·¯å¾„çš„æˆåŠŸé˜ˆå€¼ç¨ä½
                    reward=path_verification.get('reward_score', 0.0)
                )
            
            # é€‰æ‹©æœ€ä½³åˆ›æ–°è·¯å¾„
            if best_innovative_path and best_feasibility > 0.2:
                chosen_path = best_innovative_path
                logger.info(f"âœ… é€‰æ‹©åˆ›æ–°è·¯å¾„: {chosen_path.path_type} (å¯è¡Œæ€§: {best_feasibility:.2f})")
            else:
                # æœ€åçš„åº”æ€¥æ–¹æ¡ˆ
                logger.warning("ğŸ†˜ æ‰€æœ‰åˆ›æ–°å°è¯•å¤±è´¥ï¼Œä½¿ç”¨ä¿å®ˆåº”æ€¥æ–¹æ¡ˆ")
                chosen_path = self._create_conservative_emergency_path(user_query)
            
            # æ„å»ºå†³ç­–ç»“æœ
            mab_decision = {
                'chosen_path': chosen_path,
                'available_paths': original_paths + innovative_paths,
                'innovative_paths': innovative_paths,
                'failure_patterns': failure_patterns,
                'innovative_seed': innovative_seed if 'innovative_seed' in locals() else None,
                'best_innovative_feasibility': best_feasibility,
                'detour_success': best_feasibility > 0.2
            }
            
            # è®°å½•æ™ºèƒ½ç»•é“ç»Ÿè®¡
            self.aha_moment_stats['total_aha_moments'] += 1
            self.aha_moment_stats['aha_decision_history'].append({
                'timestamp': time.time(),
                'type': 'intelligent_detour',
                'trigger_reason': 'all_paths_verification_failed',
                'innovative_paths_count': len(innovative_paths),
                'best_feasibility': best_feasibility,
                'success': best_feasibility > 0.2
            })
            
            return chosen_path, mab_decision
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½ç»•é“æ€è€ƒå¤±è´¥: {e}")
            # è¿”å›æœ€ä¿å®ˆçš„åº”æ€¥æ–¹æ¡ˆ
            emergency_path = self._create_conservative_emergency_path(user_query)
            emergency_decision = {
                'chosen_path': emergency_path,
                'available_paths': original_paths,
                'detour_error': str(e),
                'emergency_fallback': True
            }
            return emergency_path, emergency_decision
    
    def _analyze_verification_failures(self, verified_paths: List[Dict]) -> Dict[str, Any]:
        """åˆ†æéªŒè¯å¤±è´¥çš„æ¨¡å¼"""
        if not verified_paths:
            return {'error': 'no_paths_to_analyze'}
        
        # æ”¶é›†å¤±è´¥åŸå› 
        low_feasibility_paths = [vp for vp in verified_paths if vp['feasibility_score'] < 0.3]
        common_issues = []
        
        # åˆ†æå…±åŒçš„å¤±è´¥æ¨¡å¼
        for vp in low_feasibility_paths:
            verification_result = vp.get('verification_result', {})
            risk_analysis = verification_result.get('feasibility_analysis', {}).get('risk_analysis', {})
            key_risks = risk_analysis.get('key_risks', [])
            common_issues.extend(key_risks)
        
        # ç»Ÿè®¡æœ€å¸¸è§çš„é—®é¢˜
        from collections import Counter
        issue_counts = Counter(common_issues)
        
        return {
            'total_failed_paths': len(low_feasibility_paths),
            'average_feasibility': sum(vp['feasibility_score'] for vp in verified_paths) / len(verified_paths),
            'common_failure_reasons': dict(issue_counts.most_common(3)),
            'risk_patterns': [issue for issue, count in issue_counts.most_common(3)]
        }
    
    def _generate_innovative_thinking_seed(self, user_query: str, original_seed: str, 
                                         failure_patterns: Dict) -> str:
        """åŸºäºå¤±è´¥åˆ†æç”Ÿæˆåˆ›æ–°æ€ç»´ç§å­"""
        if not self.llm_client:
            return self._heuristic_innovative_seed(user_query, failure_patterns)
        
        try:
            innovation_prompt = f"""
åŸºäºå¤±è´¥åˆ†æï¼Œé‡æ–°æ€è€ƒé—®é¢˜çš„è§£å†³æ–¹æ¡ˆï¼š

ğŸ¯ **åŸå§‹é—®é¢˜**: {user_query}

ğŸŒ± **åŸå§‹æ€ç»´ç§å­**: {original_seed[:200]}...

âŒ **éªŒè¯å¤±è´¥æ¨¡å¼**:
- å¤±è´¥è·¯å¾„æ•°: {failure_patterns.get('total_failed_paths', 0)}
- å¹³å‡å¯è¡Œæ€§: {failure_patterns.get('average_feasibility', 0):.2f}
- ä¸»è¦é£é™©: {failure_patterns.get('risk_patterns', [])}

ğŸ’¡ **åˆ›æ–°æ€è€ƒè¦æ±‚**:
1. é¿å¼€å·²éªŒè¯çš„å¤±è´¥æ¨¡å¼
2. ä»ä¸åŒè§’åº¦é‡æ–°å®šä¹‰é—®é¢˜
3. è€ƒè™‘éå¸¸è§„ã€åˆ›æ–°æ€§çš„è§£å†³è·¯å¾„
4. é™ä½å·²è¯†åˆ«çš„é£é™©å› ç´ 

è¯·ç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„åˆ›æ–°æ€ç»´ç§å­ï¼Œé¿å¼€å¤±è´¥æ¨¡å¼ï¼Œæä¾›åˆ›æ–°è§†è§’ï¼š
"""
            
            innovative_response = self.llm_client.call_api(innovation_prompt, temperature=0.8)
            
            # ç®€å•æå–å“åº”å†…å®¹
            if len(innovative_response) > 50:
                return innovative_response
            else:
                return self._heuristic_innovative_seed(user_query, failure_patterns)
                
        except Exception as e:
            logger.warning(f"âš ï¸ LLMåˆ›æ–°ç§å­ç”Ÿæˆå¤±è´¥: {e}")
            return self._heuristic_innovative_seed(user_query, failure_patterns)
    
    def _heuristic_innovative_seed(self, user_query: str, failure_patterns: Dict) -> str:
        """å¯å‘å¼åˆ›æ–°ç§å­ç”Ÿæˆ"""
        innovation_approaches = [
            f"é‡æ–°å®šä¹‰é—®é¢˜è§’åº¦: {user_query}",
            f"é€†å‘æ€ç»´è§£å†³: {user_query}",
            f"è·¨é¢†åŸŸå€Ÿé‰´æ–¹æ³•: {user_query}",
            f"ç®€åŒ–åˆ°æ ¸å¿ƒéœ€æ±‚: {user_query}",
            f"åˆ†é˜¶æ®µæ¸è¿›è§£å†³: {user_query}"
        ]
        
        import random
        return random.choice(innovation_approaches)
    
    def _create_emergency_innovative_paths(self, user_query: str, failure_patterns: Dict) -> List:
        """åˆ›å»ºåº”æ€¥åˆ›æ–°è·¯å¾„"""
        from .data_structures import ReasoningPath
        
        emergency_paths = [
            ReasoningPath(
                path_id="emergency_innovative_1",
                path_type="é—®é¢˜é‡å®šä¹‰å‹",
                description="é‡æ–°å®šä¹‰é—®é¢˜çš„æ ¸å¿ƒéœ€æ±‚ï¼Œå¯»æ‰¾æ›´ç®€å•çš„è§£å†³æ–¹æ¡ˆ",
                prompt_template="è®©æˆ‘ä»¬é‡æ–°å®¡è§†è¿™ä¸ªé—®é¢˜çš„æœ¬è´¨éœ€æ±‚ï¼š{task}"
            ),
            ReasoningPath(
                path_id="emergency_innovative_2", 
                path_type="åˆ†æ­¥ç®€åŒ–å‹",
                description="å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºå¤šä¸ªç®€å•æ­¥éª¤",
                prompt_template="å°†å¤æ‚ä»»åŠ¡æ‹†åˆ†ä¸ºå¯ç®¡ç†çš„å­ä»»åŠ¡ï¼š{task}"
            ),
            ReasoningPath(
                path_id="emergency_innovative_3",
                path_type="æ›¿ä»£æ–¹æ¡ˆå‹", 
                description="å¯»æ‰¾å®ç°ç›¸åŒç›®æ ‡çš„æ›¿ä»£æ–¹æ³•",
                prompt_template="æ¢ç´¢è¾¾æˆç›®æ ‡çš„ä¸åŒè·¯å¾„ï¼š{task}"
            )
        ]
        
        return emergency_paths
    
    # ==================== å¤šLLMç®¡ç†æ–¹æ³• ====================
    
    def switch_llm_provider(self, provider_name: str) -> bool:
        """
        åˆ‡æ¢LLMæä¾›å•†
        
        Args:
            provider_name: æä¾›å•†åç§°
            
        Returns:
            bool: æ˜¯å¦åˆ‡æ¢æˆåŠŸ
        """
        if not self.llm_manager:
            logger.warning("âš ï¸ LLMç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•åˆ‡æ¢æä¾›å•†")
            return False
        
        success = self.llm_manager.switch_primary_provider(provider_name)
        if success:
            logger.info(f"ğŸ”„ å·²åˆ‡æ¢åˆ°LLMæä¾›å•†: {provider_name}")
        else:
            logger.error(f"âŒ åˆ‡æ¢LLMæä¾›å•†å¤±è´¥: {provider_name}")
        
        return success
    
    def get_llm_provider_status(self) -> Dict[str, Any]:
        """
        è·å–LLMæä¾›å•†çŠ¶æ€
        
        Returns:
            Dict[str, Any]: æä¾›å•†çŠ¶æ€ä¿¡æ¯
        """
        if not self.llm_manager:
            return {
                'initialized': False,
                'error': 'LLMç®¡ç†å™¨æœªåˆå§‹åŒ–',
                'fallback_mode': True,
                'available_providers': []
            }
        
        return self.llm_manager.get_provider_status()
    
    def get_available_llm_models(self, provider_name: Optional[str] = None) -> Dict[str, List[str]]:
        """
        è·å–å¯ç”¨çš„LLMæ¨¡å‹
        
        Args:
            provider_name: æä¾›å•†åç§°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Dict[str, List[str]]: æä¾›å•†å’Œå¯¹åº”çš„æ¨¡å‹åˆ—è¡¨
        """
        if not self.llm_manager:
            return {"error": "LLMç®¡ç†å™¨æœªåˆå§‹åŒ–"}
        
        return self.llm_manager.get_available_models(provider_name)
    
    def run_llm_health_check(self, force: bool = False) -> Dict[str, bool]:
        """
        è¿è¡ŒLLMæä¾›å•†å¥åº·æ£€æŸ¥
        
        Args:
            force: æ˜¯å¦å¼ºåˆ¶æ£€æŸ¥
            
        Returns:
            Dict[str, bool]: å„æä¾›å•†çš„å¥åº·çŠ¶æ€
        """
        if not self.llm_manager:
            return {"error": "LLMç®¡ç†å™¨æœªåˆå§‹åŒ–"}
        
        return self.llm_manager.health_check(force)
    
    def get_llm_cost_summary(self) -> Dict[str, Any]:
        """
        è·å–LLMä½¿ç”¨æˆæœ¬æ€»ç»“
        
        Returns:
            Dict[str, Any]: æˆæœ¬æ€»ç»“ä¿¡æ¯
        """
        if not self.llm_manager:
            return {"error": "LLMç®¡ç†å™¨æœªåˆå§‹åŒ–"}
        
        status = self.llm_manager.get_provider_status()
        cost_data = status.get('stats', {}).get('cost_tracking', {})
        
        total_cost = sum(cost_data.values())
        
        return {
            'total_cost_usd': total_cost,
            'cost_by_provider': dict(cost_data),
            'total_requests': status.get('stats', {}).get('total_requests', 0),
            'successful_requests': status.get('stats', {}).get('successful_requests', 0),
            'fallback_count': status.get('stats', {}).get('fallback_count', 0)
        }
    
    def _create_conservative_emergency_path(self, user_query: str):
        """åˆ›å»ºä¿å®ˆçš„åº”æ€¥è·¯å¾„"""
        from .data_structures import ReasoningPath
        
        return ReasoningPath(
            path_id="conservative_emergency",
            path_type="ä¿å®ˆåº”æ€¥å‹",
            description="ä½¿ç”¨æœ€åŸºç¡€ã€æœ€å¯é çš„æ–¹æ³•å¤„ç†é—®é¢˜",
            prompt_template="ä½¿ç”¨æœ€ç›´æ¥ã€æœ€åŸºç¡€çš„æ–¹æ³•å¤„ç†ï¼š{task}"
        )
