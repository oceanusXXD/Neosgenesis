#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä¸»æ§åˆ¶å™¨ - åè°ƒå„ä¸ªç»„ä»¶çš„å·¥ä½œ
Main Controller - coordinates the work of all components
"""

import time
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass

from .reasoner import PriorReasoner
from .path_generator import PathGenerator
from .mab_converger import MABConverger
from .data_structures import DecisionResult, SystemStatus
# ğŸ—‘ï¸ å·²ç§»é™¤ï¼šä¸å†ç›´æ¥å¯¼å…¥æœç´¢å®¢æˆ·ç«¯ï¼Œæ‰€æœ‰æœç´¢åŠŸèƒ½é€šè¿‡ToolRegistryè¿›è¡Œ
# from .utils.search_client import WebSearchClient, IdeaVerificationSearchClient, SearchResponse
from .utils.performance_optimizer import PerformanceOptimizer
from .utils.shutdown_manager import shutdown_neogenesis_system, register_for_shutdown

# ğŸ”§ æ–°å¢ï¼šå¯¼å…¥ç»Ÿä¸€å·¥å…·æŠ½è±¡æ¥å£
from .utils.tool_abstraction import (
    ToolRegistry, 
    global_tool_registry,
    register_tool,
    get_tool,
    execute_tool,
    search_tools,
    ToolCategory,
    ToolResult
)
from .utils.search_tools import (
    WebSearchTool,
    IdeaVerificationTool,
    create_and_register_search_tools
)

from config import SYSTEM_LIMITS, FEATURE_FLAGS, PROMPT_TEMPLATES, PERFORMANCE_CONFIG

logger = logging.getLogger(__name__)




@dataclass
class MainController:
    """ä¸»æ§åˆ¶å™¨ - åè°ƒå„ä¸ªç»„ä»¶çš„å·¥ä½œ"""
    
    def __init__(self, api_key: str = "", config=None):
        self.api_key = api_key
        self.config = config
        
        # ğŸ—ï¸ å¤šLLMæ”¯æŒï¼šä½¿ç”¨ç»Ÿä¸€çš„LLMç®¡ç†å™¨
        from .llm_manager import LLMManager
        
        logger.info(f"ğŸ”§ æ­£åœ¨åˆå§‹åŒ–LLMç®¡ç†å™¨...")
        
        # å¦‚æœæä¾›äº†APIå¯†é’¥ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå‘åå…¼å®¹ï¼‰
        if api_key and api_key.strip():
            import os
            os.environ.setdefault("DEEPSEEK_API_KEY", api_key.strip())
            logger.info(f"ğŸ”‘ APIå¯†é’¥å·²è®¾ç½®ä¸ºDEEPSEEK_API_KEYç¯å¢ƒå˜é‡")
        
        # åˆ›å»ºLLMç®¡ç†å™¨
        try:
            self.llm_manager = LLMManager()
            self.llm_client = self.llm_manager  # å‘åå…¼å®¹
            
            status = self.llm_manager.get_provider_status()
            logger.info("ğŸ§  LLMç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            logger.info(f"   æ€»æä¾›å•†: {status['total_providers']}")
            logger.info(f"   å¥åº·æä¾›å•†: {status['healthy_providers']}")
            logger.info(f"   åˆå§‹åŒ–çŠ¶æ€: {'âœ…' if status['initialized'] else 'âŒ'}")
            
        except Exception as e:
            logger.error(f"âŒ LLMç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            logger.error(f"   è¯¦ç»†å †æ ˆ: {traceback.format_exc()}")
            
            # å›é€€åˆ°å•ä¸€å®¢æˆ·ç«¯æ¨¡å¼
            logger.warning("ğŸ”„ å›é€€åˆ°å•ä¸€DeepSeekå®¢æˆ·ç«¯æ¨¡å¼")
            self.llm_manager = None
            self.llm_client = self._create_fallback_client(api_key)
        
        # ğŸ”§ åˆå§‹åŒ–å·¥å…·æ³¨å†Œè¡¨ç³»ç»Ÿ
        self._initialize_tool_registry()
        
        # ğŸ—‘ï¸ å·²ç§»é™¤ï¼šä¸å†éœ€è¦ç›´æ¥çš„æœç´¢å®¢æˆ·ç«¯ï¼Œæ‰€æœ‰æœç´¢åŠŸèƒ½é€šè¿‡ToolRegistryè¿›è¡Œ
        
        # å®Œæˆå‰©ä½™çš„åˆå§‹åŒ–å·¥ä½œ
        self._complete_initialization()
    
    def _create_fallback_client(self, api_key: str):
        """åˆ›å»ºå›é€€å®¢æˆ·ç«¯"""
        if api_key and api_key.strip():
            try:
                from .utils.client_adapter import DeepSeekClientAdapter
                return DeepSeekClientAdapter(api_key.strip())
            except Exception as e:
                logger.error(f"âŒ å›é€€å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {e}")
                return None
        return None
    
    def _initialize_tool_registry(self):
        """åˆå§‹åŒ–å·¥å…·æ³¨å†Œè¡¨ç³»ç»Ÿ"""
        try:
            # ä½¿ç”¨å…¨å±€å·¥å…·æ³¨å†Œè¡¨
            self.tool_registry = global_tool_registry
            
            # åˆ›å»ºå¹¶æ³¨å†Œæœç´¢å·¥å…·
            tools = create_and_register_search_tools()
            
            logger.info(f"ğŸ”§ å·¥å…·æ³¨å†Œè¡¨åˆå§‹åŒ–å®Œæˆï¼Œå·²æ³¨å†Œ {len(tools)} ä¸ªå·¥å…·")
            for tool_name in tools:
                logger.debug(f"   - {tool_name}")
                
        except Exception as e:
            logger.error(f"âŒ å·¥å…·æ³¨å†Œè¡¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.tool_registry = None
    
    def _execute_llm_with_tools(self, prompt: str, context: Optional[Dict] = None, 
                               available_tools: Optional[List[str]] = None,
                               max_tool_calls: int = 3) -> Dict[str, Any]:
        """
        å¢å¼ºçš„LLMæ‰§è¡Œæ–¹æ³• - æ”¯æŒå·¥å…·è°ƒç”¨
        
        è¿™ä¸ªæ–¹æ³•å…è®¸LLMåœ¨æ¨ç†è¿‡ç¨‹ä¸­æ™ºèƒ½åœ°è°ƒç”¨å·¥å…·æ¥è·å–ä¿¡æ¯æˆ–æ‰§è¡Œæ“ä½œã€‚
        å·¥å…·è°ƒç”¨ç»“æœä¼šè¢«èå…¥åˆ°LLMçš„æ€è€ƒè¿‡ç¨‹ä¸­ï¼Œå®ç°çœŸæ­£çš„å·¥å…·å¢å¼ºæ¨ç†ã€‚
        
        Args:
            prompt: LLMæç¤ºè¯
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ 
            available_tools: å¯ç”¨å·¥å…·åˆ—è¡¨ï¼ˆå¦‚æœä¸ºNoneï¼Œåˆ™ä½¿ç”¨æ‰€æœ‰å·²æ³¨å†Œå·¥å…·ï¼‰
            max_tool_calls: æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°
            
        Returns:
            åŒ…å«LLMå“åº”å’Œå·¥å…·è°ƒç”¨ç»“æœçš„å­—å…¸
        """
        start_time = time.time()
        
        # å‡†å¤‡å·¥å…·ä¿¡æ¯
        tool_descriptions = self._prepare_tool_descriptions(available_tools)
        
        # æ„å»ºå¢å¼ºçš„æç¤ºè¯
        enhanced_prompt = self._build_tool_enhanced_prompt(prompt, tool_descriptions, context)
        
        # æ‰§è¡Œç»“æœ
        result = {
            'llm_response': '',
            'tool_calls': [],
            'tool_results': {},
            'execution_time': 0.0,
            'success': True,
            'error_message': '',
            'context_updates': {}
        }
        
        try:
            # åˆå§‹LLMè°ƒç”¨
            logger.debug(f"ğŸ§  æ‰§è¡Œå·¥å…·å¢å¼ºLLMæ¨ç†ï¼Œæœ€å¤§å·¥å…·è°ƒç”¨: {max_tool_calls}")
            
            if self.llm_manager:
                llm_result = self.llm_manager.chat_completion(enhanced_prompt)
                if llm_result.success:
                    llm_response = llm_result.content
                else:
                    raise Exception(f"LLMè°ƒç”¨å¤±è´¥: {llm_result.error_message}")
            elif self.llm_client:
                llm_response = self.llm_client.call_api(enhanced_prompt)
            else:
                raise Exception("æ²¡æœ‰å¯ç”¨çš„LLMå®¢æˆ·ç«¯")
            
            result['llm_response'] = llm_response
            
            # è§£æå¹¶æ‰§è¡Œå·¥å…·è°ƒç”¨
            tool_calls_made = 0
            current_response = llm_response
            
            while tool_calls_made < max_tool_calls:
                # æ£€æµ‹å·¥å…·è°ƒç”¨æ„å›¾
                tool_call_request = self._detect_tool_call_intent(current_response)
                
                if not tool_call_request:
                    break
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                tool_result = self._execute_detected_tool_call(tool_call_request)
                
                if tool_result:
                    result['tool_calls'].append(tool_call_request)
                    result['tool_results'][tool_call_request['tool_name']] = tool_result
                    
                    # å°†å·¥å…·ç»“æœèå…¥åˆ°ä¸‹ä¸€æ¬¡LLMè°ƒç”¨ä¸­
                    followup_prompt = self._build_tool_followup_prompt(
                        original_prompt=prompt,
                        previous_response=current_response,
                        tool_call=tool_call_request,
                        tool_result=tool_result
                    )
                    
                    # ä¸‹ä¸€æ¬¡LLMè°ƒç”¨
                    if self.llm_manager:
                        llm_result = self.llm_manager.chat_completion(followup_prompt)
                        if llm_result.success:
                            current_response = llm_result.content
                        else:
                            raise Exception(f"LLMè°ƒç”¨å¤±è´¥: {llm_result.error_message}")
                    elif self.llm_client:
                        current_response = self.llm_client.call_api(followup_prompt)
                    
                    result['llm_response'] = current_response  # æ›´æ–°æœ€ç»ˆå“åº”
                    tool_calls_made += 1
                    
                    logger.debug(f"ğŸ”§ å·¥å…·è°ƒç”¨ {tool_calls_made}: {tool_call_request['tool_name']}")
                else:
                    break
            
            result['execution_time'] = time.time() - start_time
            logger.debug(f"âœ… å·¥å…·å¢å¼ºLLMæ‰§è¡Œå®Œæˆï¼Œè°ƒç”¨äº† {tool_calls_made} ä¸ªå·¥å…·")
            
        except Exception as e:
            result['success'] = False
            result['error_message'] = str(e)
            result['execution_time'] = time.time() - start_time
            logger.error(f"âŒ å·¥å…·å¢å¼ºLLMæ‰§è¡Œå¤±è´¥: {e}")
        
        return result
    
    def _prepare_tool_descriptions(self, available_tools: Optional[List[str]] = None) -> str:
        """å‡†å¤‡å·¥å…·æè¿°ä¿¡æ¯"""
        if not self.tool_registry:
            return "å½“å‰æ²¡æœ‰å¯ç”¨å·¥å…·ã€‚"
        
        if available_tools:
            # ä½¿ç”¨æŒ‡å®šçš„å·¥å…·åˆ—è¡¨
            tool_list = []
            for tool_name in available_tools:
                tool = get_tool(tool_name)
                if tool:
                    tool_list.append(f"- {tool.name}: {tool.description}")
        else:
            # ä½¿ç”¨æ‰€æœ‰å·²æ³¨å†Œå·¥å…·
            all_tools = [tool for tool in self.tool_registry]
            tool_list = [f"- {tool.name}: {tool.description}" for tool in all_tools]
        
        if not tool_list:
            return "å½“å‰æ²¡æœ‰å¯ç”¨å·¥å…·ã€‚"
        
        return "å¯ç”¨å·¥å…·:\n" + "\n".join(tool_list)
    
    def _build_tool_enhanced_prompt(self, original_prompt: str, tool_descriptions: str, 
                                   context: Optional[Dict] = None) -> str:
        """æ„å»ºå·¥å…·å¢å¼ºçš„æç¤ºè¯"""
        enhanced_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½AIåŠ©æ‰‹ï¼Œå…·æœ‰ä½¿ç”¨å·¥å…·çš„èƒ½åŠ›ã€‚åœ¨å›ç­”é—®é¢˜æ—¶ï¼Œä½ å¯ä»¥è°ƒç”¨ä»¥ä¸‹å·¥å…·æ¥è·å–ä¿¡æ¯æˆ–æ‰§è¡Œæ“ä½œï¼š

{tool_descriptions}

è°ƒç”¨å·¥å…·çš„æ ¼å¼ï¼š
**TOOL_CALL**: [å·¥å…·åç§°] | [è°ƒç”¨å‚æ•°]

ä¾‹å¦‚ï¼š
**TOOL_CALL**: web_search | Pythonç¼–ç¨‹æœ€ä½³å®è·µ

è¯·æ ¹æ®ä»¥ä¸‹ä»»åŠ¡æ€è€ƒæ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·ï¼Œå¦‚æœéœ€è¦ï¼Œè¯·æŒ‰ç…§ä¸Šè¿°æ ¼å¼è°ƒç”¨å·¥å…·ï¼š

{original_prompt}

å¦‚æœä½ éœ€è¦è°ƒç”¨å·¥å…·ï¼Œè¯·åœ¨å›ç­”ä¸­æ˜ç¡®è¡¨æ˜ï¼Œå¹¶ä½¿ç”¨æ­£ç¡®çš„æ ¼å¼ã€‚å¦‚æœä¸éœ€è¦å·¥å…·ï¼Œè¯·ç›´æ¥å›ç­”é—®é¢˜ã€‚
"""
        
        if context:
            enhanced_prompt += f"\n\nä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š{context}"
        
        return enhanced_prompt
    
    def _detect_tool_call_intent(self, response: str) -> Optional[Dict[str, Any]]:
        """æ£€æµ‹LLMå“åº”ä¸­çš„å·¥å…·è°ƒç”¨æ„å›¾"""
        import re
        
        # æŸ¥æ‰¾å·¥å…·è°ƒç”¨æ¨¡å¼
        pattern = r'\*\*TOOL_CALL\*\*:\s*([^\|]+)\|\s*(.+)'
        match = re.search(pattern, response)
        
        if match:
            tool_name = match.group(1).strip()
            tool_params = match.group(2).strip()
            
            return {
                'tool_name': tool_name,
                'tool_params': tool_params,
                'raw_call': match.group(0)
            }
        
        return None
    
    def _execute_detected_tool_call(self, tool_call_request: Dict[str, Any]) -> Optional[ToolResult]:
        """æ‰§è¡Œæ£€æµ‹åˆ°çš„å·¥å…·è°ƒç”¨"""
        try:
            tool_name = tool_call_request['tool_name']
            tool_params = tool_call_request['tool_params']
            
            # é€šè¿‡å·¥å…·æ³¨å†Œè¡¨æ‰§è¡Œå·¥å…·
            result = execute_tool(tool_name, tool_params)
            
            if result and result.success:
                logger.debug(f"âœ… å·¥å…· {tool_name} æ‰§è¡ŒæˆåŠŸ")
                return result
            else:
                logger.warning(f"âš ï¸ å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {result.error_message if result else 'æœªçŸ¥é”™è¯¯'}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ å·¥å…·è°ƒç”¨å¼‚å¸¸: {e}")
            return None
    
    def _build_tool_followup_prompt(self, original_prompt: str, previous_response: str,
                                   tool_call: Dict[str, Any], tool_result: ToolResult) -> str:
        """æ„å»ºå·¥å…·è°ƒç”¨åçš„è·Ÿè¿›æç¤ºè¯"""
        
        tool_result_summary = ""
        if tool_result.success and tool_result.data:
            # æ ¹æ®å·¥å…·ç±»å‹æ ¼å¼åŒ–ç»“æœ
            if isinstance(tool_result.data, dict) and 'results' in tool_result.data:
                # æœç´¢ç»“æœæ ¼å¼åŒ–
                results = tool_result.data['results'][:3]  # åªå–å‰3ä¸ªç»“æœ
                tool_result_summary = f"æœç´¢åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœï¼š\n"
                for i, item in enumerate(results, 1):
                    tool_result_summary += f"{i}. {item.get('title', 'æ— æ ‡é¢˜')}\n   {item.get('snippet', 'æ— æ‘˜è¦')[:100]}...\n"
            else:
                tool_result_summary = str(tool_result.data)[:500] + "..."
        else:
            tool_result_summary = f"å·¥å…·è°ƒç”¨å¤±è´¥: {tool_result.error_message}"
        
        followup_prompt = f"""
åŸå§‹ä»»åŠ¡: {original_prompt}

ä½ åˆšæ‰è°ƒç”¨äº†å·¥å…·: {tool_call['tool_name']}
å·¥å…·è°ƒç”¨å‚æ•°: {tool_call['tool_params']}

å·¥å…·è¿”å›çš„ç»“æœ:
{tool_result_summary}

è¯·åŸºäºè¿™äº›å·¥å…·è·å–çš„ä¿¡æ¯ï¼Œç»§ç»­å®ŒæˆåŸå§‹ä»»åŠ¡ã€‚å¦‚æœè¿˜éœ€è¦è°ƒç”¨å…¶ä»–å·¥å…·ï¼Œè¯·ç»§ç»­ä½¿ç”¨ **TOOL_CALL** æ ¼å¼ã€‚å¦åˆ™ï¼Œè¯·æä¾›æœ€ç»ˆç­”æ¡ˆã€‚
"""
        
        return followup_prompt
    
    def _complete_initialization(self):
        """å®Œæˆå‰©ä½™çš„åˆå§‹åŒ–å·¥ä½œ"""
        # ğŸ”§ åˆå§‹åŒ–å„ä¸ªç»„ä»¶ - æ³¨å…¥å…±äº«ä¾èµ–
        self.prior_reasoner = PriorReasoner(self.api_key)  # è½»é‡çº§ï¼Œä¸éœ€è¦LLMå®¢æˆ·ç«¯
        self.path_generator = PathGenerator(self.api_key, llm_client=self.llm_client)  # æ³¨å…¥LLMå®¢æˆ·ç«¯
        self.mab_converger = MABConverger()
        
        # ğŸš€ æ–°å¢ï¼šæ€§èƒ½ä¼˜åŒ–å™¨
        if FEATURE_FLAGS.get("enable_performance_optimization", False):
            self.performance_optimizer = PerformanceOptimizer(PERFORMANCE_CONFIG)
            logger.info("ğŸš€ æ€§èƒ½ä¼˜åŒ–å™¨å·²å¯ç”¨")
        else:
            self.performance_optimizer = None
            logger.info("ğŸ“Š æ€§èƒ½ä¼˜åŒ–å™¨å·²ç¦ç”¨")
        
        # æ³¨å†Œç³»ç»Ÿå…³é—­å›è°ƒ - æš‚æ—¶ç¦ç”¨é¿å…é€’å½’é—®é¢˜
        # register_for_shutdown(lambda: shutdown_neogenesis_system(self), "MainController")
        logger.debug("âš ï¸ å…³é—­å›è°ƒå·²ç¦ç”¨ï¼Œé¿å…é€’å½’é—®é¢˜")
        
        # ç³»ç»ŸçŠ¶æ€
        self.total_rounds = 0
        self.decision_history = []
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            'total_decisions': 0,
            'successful_decisions': 0,
            'avg_decision_time': 0.0,
            'component_performance': {
                'prior_reasoner': {'calls': 0, 'avg_time': 0.0},
                'path_generator': {'calls': 0, 'avg_time': 0.0},
                'mab_converger': {'calls': 0, 'avg_time': 0.0},
                'idea_verification': {'calls': 0, 'avg_time': 0.0, 'success_rate': 0.0}  # æ–°å¢éªŒè¯ç»Ÿè®¡
            }
        }
        
        # ğŸ’¡ Aha-Momentå†³ç­–ç³»ç»Ÿ
        self.aha_moment_stats = {
            'consecutive_failures': 0,         # è¿ç»­å¤±è´¥æ¬¡æ•°
            'last_failure_timestamp': None,    # æœ€åå¤±è´¥æ—¶é—´
            'total_aha_moments': 0,            # æ€»Aha-Momentæ¬¡æ•°
            'aha_success_rate': 0.0,           # Aha-MomentæˆåŠŸç‡
            'last_decision_success': True,     # ä¸Šæ¬¡å†³ç­–æ˜¯å¦æˆåŠŸ
            'failure_threshold': 3,            # è¿ç»­å¤±è´¥é˜ˆå€¼
            'confidence_threshold': 0.3,       # ç½®ä¿¡åº¦é˜ˆå€¼
            'aha_decision_history': []         # Aha-Momentå†³ç­–å†å²
        }
        
        logger.info("ğŸš€ MainControlleråˆå§‹åŒ–å®Œæˆ - ä½¿ç”¨å·¥å…·å¢å¼ºçš„äº”é˜¶æ®µå†³ç­–ç³»ç»Ÿ")
        logger.info(f"ğŸ”§ å·¥å…·æ³¨å†Œè¡¨å·²è£…å¤‡: {'âœ…' if self.tool_registry else 'âŒ'} ç»Ÿä¸€å·¥å…·æ¥å£")
        
        # æ˜¾ç¤ºå·²æ³¨å†Œå·¥å…·
        if self.tool_registry:
            from .utils.tool_abstraction import list_available_tools
            tools = list_available_tools()
            logger.info(f"ğŸ” å·²æ³¨å†Œå·¥å…·: {len(tools)} ä¸ª ({', '.join(tools)})")
        
        # æ˜¾ç¤ºLLMç³»ç»ŸçŠ¶æ€
        if self.llm_manager:
            status = self.llm_manager.get_provider_status()
            logger.info(f"ğŸ§  LLMç³»ç»Ÿå·²è£…å¤‡: âœ… ç®¡ç†å™¨æ¨¡å¼")
            logger.info(f"   å¯ç”¨æä¾›å•†: {status['healthy_providers']}/{status['total_providers']}")
            
            # æ˜¾ç¤ºä¸»è¦æä¾›å•†
            if status['providers']:
                healthy_providers = [name for name, info in status['providers'].items() if info['healthy']]
                if healthy_providers:
                    logger.info(f"   æ´»è·ƒæä¾›å•†: {', '.join(healthy_providers)}")
        else:
            logger.info(f"ğŸ§  LLMç³»ç»Ÿå·²è£…å¤‡: {'âœ…' if self.llm_client else 'âŒ'} å›é€€æ¨¡å¼")
    
    def make_decision(self, user_query: str, deepseek_confidence: float = 0.5, 
                     execution_context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        ğŸš€ äº”é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–æµç¨‹ - å†…ç½®æœç´¢éªŒè¯ç³»ç»Ÿ
        
        é˜¶æ®µä¸€ï¼šæ€ç»´ç§å­ç”Ÿæˆ (PriorReasoner) - ç†è§£é—®é¢˜ï¼Œç”Ÿæˆæ€ç»´ç§å­
        é˜¶æ®µäºŒï¼šç§å­éªŒè¯æ£€æŸ¥ (æ–°å¢) - éªŒè¯æ€ç»´ç§å­çš„å®è§‚æ–¹å‘
        é˜¶æ®µä¸‰ï¼šæ€ç»´è·¯å¾„ç”Ÿæˆ (PathGenerator) - åŸºäºç§å­ç”Ÿæˆå¤šæ¡è·¯å¾„
        é˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯å­¦ä¹  (æ ¸å¿ƒåˆ›æ–°) - é€ä¸€éªŒè¯è·¯å¾„å¹¶å³æ—¶å­¦ä¹ 
        é˜¶æ®µäº”ï¼šæ™ºèƒ½æœ€ç»ˆå†³ç­– (å‡çº§) - åŸºäºéªŒè¯ç»“æœæ™ºèƒ½å†³ç­–
        
        æ ¸å¿ƒåˆ›æ–°ï¼šAIåœ¨æ€è€ƒé˜¶æ®µå°±è·å¾—å³æ—¶åé¦ˆï¼Œä¸å†ç­‰å¾…æœ€ç»ˆæ‰§è¡Œç»“æœ
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            deepseek_confidence: DeepSeekå¯¹è¯¥ä»»åŠ¡çš„ç½®ä¿¡åº¦
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            å†³ç­–ç»“æœ
        """
        start_time = time.time()
        self.total_rounds += 1
        
        logger.info(f"ğŸš€ å¼€å§‹ç¬¬ {self.total_rounds} è½®äº”é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–")
        logger.info(f"   æŸ¥è¯¢: {user_query[:50]}...")
        logger.info(f"   DeepSeekç½®ä¿¡åº¦: {deepseek_confidence:.2f}")
        
        try:
            # ğŸ§  é˜¶æ®µä¸€ï¼šå…ˆéªŒæ¨ç† - ç”Ÿæˆæ€ç»´ç§å­ï¼ˆä¸å˜ï¼‰
            reasoner_start = time.time()
            thinking_seed = self.prior_reasoner.get_thinking_seed(user_query, execution_context)
            
            # å…¼å®¹æ€§ï¼šåŒæ—¶è·å–æ—§æ ¼å¼çš„æ•°æ®ç”¨äºå‘åå…¼å®¹
            task_confidence = self.prior_reasoner.assess_task_confidence(user_query, execution_context)
            complexity_info = self.prior_reasoner.analyze_task_complexity(user_query)
            
            reasoner_time = time.time() - reasoner_start
            self._update_component_performance('prior_reasoner', reasoner_time)
            
            logger.info(f"ğŸ§  é˜¶æ®µä¸€å®Œæˆ: æ€ç»´ç§å­ç”Ÿæˆ (é•¿åº¦: {len(thinking_seed)} å­—ç¬¦)")
            logger.debug(f"ğŸŒ± æ€ç»´ç§å­é¢„è§ˆ: {thinking_seed[:100]}...")
            
            # ğŸ” é˜¶æ®µäºŒï¼šéªŒè¯æ€ç»´ç§å­ï¼ˆæ–°å¢ï¼‰- å¯¹å®è§‚æ–¹å‘è¿›è¡Œå¿«é€ŸéªŒè¯
            seed_verification_start = time.time()
            seed_verification_result = self.verify_idea_feasibility(
                idea_text=thinking_seed,
                context={
                    'stage': 'thinking_seed',
                    'domain': 'strategic_planning',
                    'query': user_query,
                    **(execution_context if execution_context else {})
                }
            )
            seed_verification_time = time.time() - seed_verification_start
            
            # åˆ†æç§å­éªŒè¯ç»“æœ
            seed_feasibility = seed_verification_result.get('feasibility_analysis', {}).get('feasibility_score', 0.5)
            seed_reward = seed_verification_result.get('reward_score', 0.0)
            
            logger.info(f"ğŸ” é˜¶æ®µäºŒå®Œæˆ: æ€ç»´ç§å­éªŒè¯ (å¯è¡Œæ€§: {seed_feasibility:.2f}, å¥–åŠ±: {seed_reward:+.3f})")
            
            if seed_feasibility < 0.3:
                logger.warning(f"âš ï¸ æ€ç»´ç§å­æ–¹å‘å­˜åœ¨é—®é¢˜ (å¯è¡Œæ€§: {seed_feasibility:.2f})ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
            
            # ğŸ›¤ï¸ é˜¶æ®µä¸‰ï¼šè·¯å¾„ç”Ÿæˆ - åŸºäºï¼ˆå·²éªŒè¯çš„ï¼‰æ€ç»´ç§å­ç”Ÿæˆæ€ç»´è·¯å¾„åˆ—è¡¨ï¼ˆä¸å˜ï¼‰
            generator_start = time.time()
            all_reasoning_paths = self.path_generator.generate_paths(
                thinking_seed=thinking_seed, 
                task=user_query,
                max_paths=6  # é™åˆ¶è·¯å¾„æ•°é‡ä»¥æé«˜æ€§èƒ½
            )
            generator_time = time.time() - generator_start
            self._update_component_performance('path_generator', generator_time)
            
            logger.info(f"ğŸ›¤ï¸ é˜¶æ®µä¸‰å®Œæˆ: ç”Ÿæˆäº† {len(all_reasoning_paths)} æ¡æ€ç»´è·¯å¾„")
            for i, path in enumerate(all_reasoning_paths[:3], 1):  # è®°å½•å‰3ä¸ªè·¯å¾„
                logger.debug(f"   è·¯å¾„{i}: {path.path_type} (ID: {path.path_id})")
            
            # ğŸš€ é˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯å­¦ä¹ ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰- é€ä¸€éªŒè¯è·¯å¾„å¹¶å³æ—¶å­¦ä¹ 
            path_verification_start = time.time()
            # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šæ™ºèƒ½è·¯å¾„éªŒè¯ï¼ˆæ”¯æŒå¹¶è¡ŒåŒ–å’Œè‡ªé€‚åº”ï¼‰
            verified_paths = []
            all_infeasible = True  # æ ‡è®°æ˜¯å¦æ‰€æœ‰è·¯å¾„éƒ½ä¸å¯è¡Œ
            
            # ç¡®å®šè¦éªŒè¯çš„è·¯å¾„æ•°é‡ï¼ˆè‡ªé€‚åº”ä¼˜åŒ–ï¼‰
            original_path_count = len(all_reasoning_paths)
            if self.performance_optimizer and PERFORMANCE_CONFIG.get("enable_adaptive_path_count", False):
                # æå–å¤æ‚åº¦åˆ†æ•°
                complexity_score = complexity_info.get('overall_score', 0.5) if isinstance(complexity_info, dict) else 0.5
                optimal_count = self.performance_optimizer.adaptive_selector.get_optimal_path_count(
                    confidence=deepseek_confidence,
                    complexity=complexity_score
                )
                # åªéªŒè¯å‰Næ¡æœ€æœ‰æ½œåŠ›çš„è·¯å¾„
                paths_to_verify = all_reasoning_paths[:optimal_count]
                logger.info(f"ğŸ¯ è‡ªé€‚åº”ä¼˜åŒ–: ä»{original_path_count}æ¡è·¯å¾„ä¸­é€‰æ‹©{optimal_count}æ¡è¿›è¡ŒéªŒè¯")
            else:
                paths_to_verify = all_reasoning_paths
            
            logger.info(f"ğŸ”¬ é˜¶æ®µå››å¼€å§‹: éªŒè¯ {len(paths_to_verify)} æ¡æ€ç»´è·¯å¾„")
            
            # ğŸš€ å¹¶è¡ŒéªŒè¯è·¯å¾„ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
            if (self.performance_optimizer and 
                PERFORMANCE_CONFIG.get("enable_parallel_path_verification", False) and 
                len(paths_to_verify) > 1):
                
                logger.info(f"âš¡ å¯ç”¨å¹¶è¡ŒéªŒè¯æ¨¡å¼ - æœ€å¤§å¹¶å‘æ•°: {PERFORMANCE_CONFIG.get('max_concurrent_verifications', 3)}")
                
                # åˆ›å»ºéªŒè¯ä»»åŠ¡
                def create_verification_task(path):
                    def verify_single_path(p):
                        return self.verify_idea_feasibility(
                            idea_text=f"{p.path_type}: {p.description}",
                            context={
                                'stage': 'reasoning_path',
                                'path_id': p.path_id,
                                'path_type': p.path_type,
                                'query': user_query,
                                **(execution_context if execution_context else {})
                            }
                        )
                    return (path, verify_single_path)
                
                verification_tasks = [create_verification_task(path) for path in paths_to_verify]
                
                # å¹¶è¡Œæ‰§è¡ŒéªŒè¯
                parallel_results = self.performance_optimizer.parallel_verifier.verify_paths_parallel(verification_tasks)
                
                # å¤„ç†å¹¶è¡ŒéªŒè¯ç»“æœ
                for i, (path, result) in enumerate(zip(paths_to_verify, parallel_results)):
                    if result is None:
                        logger.warning(f"âš ï¸ è·¯å¾„ {path.path_type} å¹¶è¡ŒéªŒè¯å¤±è´¥ï¼Œè·³è¿‡")
                        continue
                    
                    # æå–éªŒè¯ç»“æœ
                    path_feasibility = result.get('feasibility_analysis', {}).get('feasibility_score', 0.5)
                    path_reward = result.get('reward_score', 0.0)
                    verification_success = not result.get('fallback', False)
                    
                    # ğŸ’¡ å³æ—¶å­¦ä¹ ï¼šç«‹å³å°†éªŒè¯ç»“æœåé¦ˆç»™MABç³»ç»Ÿ
                    if verification_success and path_feasibility > 0.3:
                        # å¯è¡Œçš„è·¯å¾„ - æ­£é¢å­¦ä¹ ä¿¡å·
                        self.mab_converger.update_path_performance(
                            path_id=path.strategy_id,  # ğŸ¯ æ ¹æºä¿®å¤ï¼šä½¿ç”¨ç­–ç•¥IDè¿›è¡Œå­¦ä¹ 
                            success=True,
                            reward=path_reward
                        )
                        all_infeasible = False  # è‡³å°‘æœ‰ä¸€ä¸ªè·¯å¾„å¯è¡Œ
                        logger.debug(f"âœ… è·¯å¾„ {path.path_type} éªŒè¯é€šè¿‡: å¯è¡Œæ€§={path_feasibility:.2f}, å¥–åŠ±={path_reward:+.3f}")
                    else:
                        # ä¸å¯è¡Œçš„è·¯å¾„ - è´Ÿé¢å­¦ä¹ ä¿¡å·
                        self.mab_converger.update_path_performance(
                            path_id=path.strategy_id,  # ğŸ¯ æ ¹æºä¿®å¤ï¼šä½¿ç”¨ç­–ç•¥IDè¿›è¡Œå­¦ä¹ 
                            success=False,
                            reward=path_reward  # å¯èƒ½æ˜¯è´Ÿå€¼
                        )
                        logger.debug(f"âŒ è·¯å¾„ {path.path_type} éªŒè¯å¤±è´¥: å¯è¡Œæ€§={path_feasibility:.2f}, å¥–åŠ±={path_reward:+.3f}")
                    
                    # è®°å½•éªŒè¯ç»“æœ
                    verified_paths.append({
                        'path': path,
                        'verification_result': result,
                        'feasibility_score': path_feasibility,
                        'reward_score': path_reward,
                        'is_feasible': path_feasibility > 0.3
                    })
                    
                    # ğŸ”„ æ—©æœŸç»ˆæ­¢æ£€æŸ¥ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
                    if (PERFORMANCE_CONFIG.get("enable_early_termination", False) and 
                        len(verified_paths) >= 3 and
                        self.performance_optimizer.adaptive_selector.should_early_terminate(verified_paths)):
                        logger.info(f"ğŸ”„ æ—©æœŸç»ˆæ­¢: å·²éªŒè¯{len(verified_paths)}æ¡è·¯å¾„ï¼Œç»“æœä¸€è‡´æ€§è¶³å¤Ÿ")
                        break
                
            else:
                # ğŸ”„ ä¼ ç»Ÿä¸²è¡ŒéªŒè¯ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
                logger.info("ğŸ“Š ä½¿ç”¨ä¼ ç»Ÿä¸²è¡ŒéªŒè¯æ¨¡å¼")
                
                for i, path in enumerate(paths_to_verify, 1):
                    logger.debug(f"ğŸ”¬ éªŒè¯è·¯å¾„ {i}/{len(paths_to_verify)}: {path.path_type}")
                    
                    # ğŸ§  æ™ºèƒ½ç¼“å­˜æ£€æŸ¥
                    cache_key = f"{path.path_type}_{path.description[:50]}"
                    cached_result = None
                    if (self.performance_optimizer and 
                        PERFORMANCE_CONFIG.get("enable_intelligent_caching", False)):
                        cached_result = self.performance_optimizer.cache.get(cache_key, execution_context)
                    
                    if cached_result:
                        logger.debug(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜ç»“æœ: {path.path_type}")
                        path_verification_result = cached_result
                    else:
                        # éªŒè¯å•ä¸ªè·¯å¾„
                        path_verification_result = self.verify_idea_feasibility(
                            idea_text=f"{path.path_type}: {path.description}",
                            context={
                                'stage': 'reasoning_path',
                                'path_id': path.path_id,
                                'path_type': path.path_type,
                                'query': user_query,
                                **(execution_context if execution_context else {})
                            }
                        )
                        
                        # ğŸ’¾ ç¼“å­˜ç»“æœ
                        if (self.performance_optimizer and 
                            PERFORMANCE_CONFIG.get("enable_intelligent_caching", False)):
                            self.performance_optimizer.cache.set(cache_key, path_verification_result, execution_context)
                    
                    # æå–éªŒè¯ç»“æœ
                    path_feasibility = path_verification_result.get('feasibility_analysis', {}).get('feasibility_score', 0.5)
                    path_reward = path_verification_result.get('reward_score', 0.0)
                    verification_success = not path_verification_result.get('fallback', False)
                    
                    # ğŸ’¡ å³æ—¶å­¦ä¹ ï¼šç«‹å³å°†éªŒè¯ç»“æœåé¦ˆç»™MABç³»ç»Ÿ
                    if verification_success and path_feasibility > 0.3:
                        # å¯è¡Œçš„è·¯å¾„ - æ­£é¢å­¦ä¹ ä¿¡å·
                        self.mab_converger.update_path_performance(
                            path_id=path.strategy_id,  # ğŸ¯ æ ¹æºä¿®å¤ï¼šä½¿ç”¨ç­–ç•¥IDè¿›è¡Œå­¦ä¹ 
                            success=True,
                            reward=path_reward
                        )
                        all_infeasible = False  # è‡³å°‘æœ‰ä¸€ä¸ªè·¯å¾„å¯è¡Œ
                        logger.debug(f"âœ… è·¯å¾„ {path.path_type} éªŒè¯é€šè¿‡: å¯è¡Œæ€§={path_feasibility:.2f}, å¥–åŠ±={path_reward:+.3f}")
                    else:
                        # ä¸å¯è¡Œçš„è·¯å¾„ - è´Ÿé¢å­¦ä¹ ä¿¡å·
                        self.mab_converger.update_path_performance(
                            path_id=path.strategy_id,  # ğŸ¯ æ ¹æºä¿®å¤ï¼šä½¿ç”¨ç­–ç•¥IDè¿›è¡Œå­¦ä¹ 
                            success=False,
                            reward=path_reward  # å¯èƒ½æ˜¯è´Ÿå€¼
                        )
                        logger.debug(f"âŒ è·¯å¾„ {path.path_type} éªŒè¯å¤±è´¥: å¯è¡Œæ€§={path_feasibility:.2f}, å¥–åŠ±={path_reward:+.3f}")
                    
                    # è®°å½•éªŒè¯ç»“æœ
                    verified_paths.append({
                        'path': path,
                        'verification_result': path_verification_result,
                        'feasibility_score': path_feasibility,
                        'reward_score': path_reward,
                        'is_feasible': path_feasibility > 0.3
                    })
                    
                    # ğŸ”„ æ—©æœŸç»ˆæ­¢æ£€æŸ¥ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
                    if (self.performance_optimizer and 
                        PERFORMANCE_CONFIG.get("enable_early_termination", False) and 
                        len(verified_paths) >= 3 and
                        self.performance_optimizer.adaptive_selector.should_early_terminate(verified_paths)):
                        logger.info(f"ğŸ”„ æ—©æœŸç»ˆæ­¢: å·²éªŒè¯{len(verified_paths)}æ¡è·¯å¾„ï¼Œç»“æœä¸€è‡´æ€§è¶³å¤Ÿ")
                        break
            
            path_verification_time = time.time() - path_verification_start
            feasible_count = sum(1 for vp in verified_paths if vp['is_feasible'])
            
            logger.info(f"ğŸ”¬ é˜¶æ®µå››å®Œæˆ: {feasible_count}/{len(all_reasoning_paths)} æ¡è·¯å¾„å¯è¡Œ")
            logger.info(f"   ğŸ’¡ å³æ—¶å­¦ä¹ : MABç³»ç»Ÿå·²æ›´æ–°æ‰€æœ‰è·¯å¾„æƒé‡")
            
            # ğŸ¯ é˜¶æ®µäº”ï¼šæ™ºèƒ½æœ€ç»ˆå†³ç­–ï¼ˆå‡çº§ï¼‰- åŸºäºéªŒè¯ç»“æœæ™ºèƒ½å†³ç­–
            final_decision_start = time.time()
            
            if all_infeasible:
                # ğŸš¨ æ‰€æœ‰è·¯å¾„éƒ½ä¸å¯è¡Œ - è§¦å‘æ™ºèƒ½ç»•é“æ€è€ƒ
                logger.warning("ğŸš¨ æ‰€æœ‰æ€ç»´è·¯å¾„éƒ½è¢«éªŒè¯ä¸ºä¸å¯è¡Œï¼Œè§¦å‘æ™ºèƒ½ç»•é“æ€è€ƒ")
                
                # è¿™æ˜¯æ›´æ™ºèƒ½çš„Aha-Momentè§¦å‘å™¨
                chosen_path, mab_decision = self._execute_intelligent_detour_thinking(
                    user_query, thinking_seed, all_reasoning_paths, verified_paths
                )
                
                mab_decision.update({
                    'selection_algorithm': 'intelligent_detour',
                    'all_paths_infeasible': True,
                    'detour_triggered': True,
                    'verification_triggered_detour': True
                })
                
                logger.info(f"ğŸš€ æ™ºèƒ½ç»•é“å®Œæˆ: é€‰æ‹©åˆ›æ–°è·¯å¾„ '{chosen_path.path_type}'")
                
            else:
                # âœ… è‡³å°‘æœ‰å¯è¡Œè·¯å¾„ - ä½¿ç”¨å¢å¼ºçš„MABé€‰æ‹©
                logger.info("âœ… å‘ç°å¯è¡Œè·¯å¾„ï¼Œä½¿ç”¨éªŒè¯å¢å¼ºçš„MABå†³ç­–")
                
                # MABç°åœ¨å·²ç»æœ‰äº†å³æ—¶å­¦ä¹ çš„æƒé‡ï¼Œä¼šè‡ªç„¶å€¾å‘äºå¯è¡Œè·¯å¾„
                chosen_path = self.mab_converger.select_best_path(all_reasoning_paths)
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼ ç»Ÿçš„Aha-Momentï¼ˆä½œä¸ºé¢å¤–ä¿é™©ï¼‰
                aha_triggered, aha_reason = self._check_aha_moment_trigger(chosen_path)
                
                if aha_triggered:
                    logger.info(f"ğŸ’¡ é¢å¤–è§¦å‘ä¼ ç»ŸAha-Moment: {aha_reason}")
                    chosen_path, _ = self._execute_aha_moment_thinking(
                        user_query, thinking_seed, chosen_path, all_reasoning_paths
                    )
                
                mab_decision = {
                    'chosen_path': chosen_path,
                    'available_paths': all_reasoning_paths,
                    'verified_paths': verified_paths,
                    'selection_algorithm': 'verification_enhanced_mab',
                    'converged': self.mab_converger.check_path_convergence(),
                    'all_paths_infeasible': False,
                    'feasible_paths_count': feasible_count,
                    'total_paths_count': len(all_reasoning_paths),
                    'verification_triggered_detour': False,
                    'traditional_aha_triggered': aha_triggered
                }
                
                logger.info(f"ğŸ¯ æ™ºèƒ½å†³ç­–å®Œæˆ: é€‰æ‹©éªŒè¯ä¼˜åŒ–è·¯å¾„ '{chosen_path.path_type}'")
            
            final_decision_time = time.time() - final_decision_start
            total_mab_time = path_verification_time + final_decision_time
            self._update_component_performance('mab_converger', total_mab_time)
            
            # è®¡ç®—æ€»ä½“å†³ç­–æ—¶é—´
            total_decision_time = time.time() - start_time
            
            # æ„å»ºå‡çº§ç‰ˆäº”é˜¶æ®µå†³ç­–ç»“æœ
            decision_result = {
                # åŸºæœ¬ä¿¡æ¯
                'timestamp': time.time(),
                'round_number': self.total_rounds,
                'user_query': user_query,
                'deepseek_confidence': deepseek_confidence,
                'execution_context': execution_context,
                
                # ğŸš€ äº”é˜¶æ®µå†³ç­–ç»“æœ
                'thinking_seed': thinking_seed,  # é˜¶æ®µä¸€ï¼šæ€ç»´ç§å­
                'seed_verification': seed_verification_result,  # é˜¶æ®µäºŒï¼šç§å­éªŒè¯
                'chosen_path': chosen_path,  # æœ€ç»ˆé€‰ä¸­çš„æ€ç»´è·¯å¾„
                'available_paths': all_reasoning_paths,  # é˜¶æ®µä¸‰ï¼šæ‰€æœ‰å€™é€‰è·¯å¾„
                'verified_paths': verified_paths,  # é˜¶æ®µå››ï¼šéªŒè¯ç»“æœ
                'mab_decision': mab_decision,  # é˜¶æ®µäº”ï¼šæœ€ç»ˆå†³ç­–è¯¦æƒ…
                
                # å‘åå…¼å®¹å­—æ®µ
                'selected_path': chosen_path,  # å…¼å®¹æ—§æ¥å£
                'task_confidence': task_confidence,
                'complexity_analysis': complexity_info,
                
                # å†³ç­–å…ƒä¿¡æ¯
                'reasoning': f"äº”é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–: {chosen_path.path_type} - {chosen_path.description}",
                'path_count': len(all_reasoning_paths),
                'feasible_path_count': feasible_count,
                'architecture_version': '5-stage-verification',  # æ–°å¢ï¼šæ¶æ„ç‰ˆæœ¬æ ‡è¯†
                'verification_enabled': True,  # æ ‡è¯†å¯ç”¨éªŒè¯
                'instant_learning_enabled': True,  # æ ‡è¯†å¯ç”¨å³æ—¶å­¦ä¹ 
                
                # ğŸ”¬ éªŒè¯ç»Ÿè®¡
                'verification_stats': {
                    'seed_feasibility': seed_feasibility,
                    'seed_reward': seed_reward,
                    'paths_verified': len(verified_paths),
                    'feasible_paths': feasible_count,
                    'infeasible_paths': len(verified_paths) - feasible_count,
                    'all_paths_infeasible': all_infeasible,
                    'average_path_feasibility': sum(vp['feasibility_score'] for vp in verified_paths) / len(verified_paths) if verified_paths else 0.0,
                    'total_verification_time': seed_verification_time + path_verification_time
                },
                
                # æ€§èƒ½æŒ‡æ ‡
                'performance_metrics': {
                    'total_time': total_decision_time,
                    'stage1_reasoner_time': reasoner_time,
                    'stage2_seed_verification_time': seed_verification_time,
                    'stage3_generator_time': generator_time,
                    'stage4_path_verification_time': path_verification_time,
                    'stage5_final_decision_time': final_decision_time,
                    'stages_breakdown': {
                        'thinking_seed_generation': reasoner_time,
                        'seed_verification': seed_verification_time,
                        'path_generation': generator_time,
                        'path_verification_learning': path_verification_time,
                        'intelligent_final_decision': final_decision_time
                    }
                }
            }
            
            # è®°å½•å†³ç­–å†å²
            self.decision_history.append(decision_result)
            
            # é™åˆ¶å†å²è®°å½•é•¿åº¦
            max_history = SYSTEM_LIMITS["max_decision_history"]
            if len(self.decision_history) > max_history:
                self.decision_history = self.decision_history[-max_history//2:]
            
            # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
            self.performance_stats['total_decisions'] += 1
            self._update_avg_decision_time(total_decision_time)
            
            logger.info(f"ğŸ‰ äº”é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–å®Œæˆ:")
            logger.info(f"   ğŸŒ± æ€ç»´ç§å­: {len(thinking_seed)}å­—ç¬¦ (å¯è¡Œæ€§: {seed_feasibility:.2f})")
            logger.info(f"   ğŸ›¤ï¸ ç”Ÿæˆè·¯å¾„: {len(all_reasoning_paths)}æ¡")
            logger.info(f"   ğŸ”¬ éªŒè¯ç»“æœ: {feasible_count}æ¡å¯è¡Œ/{len(verified_paths)}æ¡æ€»æ•°")
            logger.info(f"   ğŸ¯ æœ€ç»ˆé€‰æ‹©: {chosen_path.path_type}")
            logger.info(f"   ğŸ’¡ å³æ—¶å­¦ä¹ : MABæƒé‡å·²æ›´æ–°")
            logger.info(f"   â±ï¸ æ€»è€—æ—¶: {total_decision_time:.3f}s")
            logger.info(f"      - é˜¶æ®µä¸€(ç§å­ç”Ÿæˆ): {reasoner_time:.3f}s")
            logger.info(f"      - é˜¶æ®µäºŒ(ç§å­éªŒè¯): {seed_verification_time:.3f}s")
            logger.info(f"      - é˜¶æ®µä¸‰(è·¯å¾„ç”Ÿæˆ): {generator_time:.3f}s") 
            logger.info(f"      - é˜¶æ®µå››(è·¯å¾„éªŒè¯): {path_verification_time:.3f}s")
            logger.info(f"      - é˜¶æ®µäº”(æ™ºèƒ½å†³ç­–): {final_decision_time:.3f}s")
            
            return decision_result
            
        except Exception as e:
            logger.error(f"âŒ å†³ç­–è¿‡ç¨‹å¤±è´¥: {e}")
            # è¿”å›é”™è¯¯å†³ç­–ç»“æœ
            return self._create_error_decision_result(user_query, str(e), time.time() - start_time)
    
    def _update_component_performance(self, component_name: str, execution_time: float):
        """æ›´æ–°ç»„ä»¶æ€§èƒ½ç»Ÿè®¡"""
        component_stats = self.performance_stats['component_performance'][component_name]
        component_stats['calls'] += 1
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡
        current_avg = component_stats['avg_time']
        call_count = component_stats['calls']
        component_stats['avg_time'] = (current_avg * (call_count - 1) + execution_time) / call_count
    
    def _update_avg_decision_time(self, decision_time: float):
        """æ›´æ–°å¹³å‡å†³ç­–æ—¶é—´"""
        current_avg = self.performance_stats['avg_decision_time']
        total_decisions = self.performance_stats['total_decisions']
        
        if total_decisions == 1:
            self.performance_stats['avg_decision_time'] = decision_time
        else:
            self.performance_stats['avg_decision_time'] = (
                current_avg * (total_decisions - 1) + decision_time
            ) / total_decisions
    
    def _create_error_decision_result(self, user_query: str, error_msg: str, execution_time: float) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯å†³ç­–ç»“æœ"""
        return {
            'timestamp': time.time(),
            'round_number': self.total_rounds,
            'user_query': user_query,
            'selected_dimensions': {},
            'confidence_scores': {},
            'task_confidence': 0.0,
            'complexity_analysis': {'complexity_score': 0.5, 'estimated_domain': 'error'},
            'mab_decisions': {},
            'reasoning': f"å†³ç­–å¤±è´¥: {error_msg}",
            'fallback_used': True,
            'component_architecture': True,
            'error': error_msg,
            'performance_metrics': {
                'total_time': execution_time,
                'error_occurred': True
            }
        }
    
    def update_performance_feedback(self, decision_result: Dict[str, Any], 
                                  execution_success: bool, execution_time: float = 30.0,
                                  user_satisfaction: float = 0.5, rl_reward: float = 0.5):
        """
        æ›´æ–°ä¸‰é˜¶æ®µå†³ç­–æ€§èƒ½åé¦ˆ - å‡çº§ç‰ˆç»„ä»¶åŒ–æ¶æ„
        
        Args:
            decision_result: å†³ç­–ç»“æœ
            execution_success: æ‰§è¡Œæ˜¯å¦æˆåŠŸ
            execution_time: æ‰§è¡Œæ—¶é—´
            user_satisfaction: ç”¨æˆ·æ»¡æ„åº¦
            rl_reward: å¼ºåŒ–å­¦ä¹ å¥–åŠ±
        """
        try:
            # ğŸ¯ æ ¸å¿ƒæ›´æ–°ï¼šåŸºäºé€‰ä¸­çš„æ€ç»´è·¯å¾„æ›´æ–°MABæ€§èƒ½
            chosen_path = decision_result.get('chosen_path') or decision_result.get('selected_path')
            if chosen_path:
                # ä½¿ç”¨å‡çº§åçš„è·¯å¾„æ€§èƒ½æ›´æ–°æ–¹æ³•
                self.mab_converger.update_path_performance(
                    path_id=chosen_path.strategy_id,  # ğŸ¯ æ ¹æºä¿®å¤ï¼šä½¿ç”¨ç­–ç•¥IDè¿›è¡Œå­¦ä¹ 
                    success=execution_success,
                    reward=rl_reward
                )
                logger.debug(f"ğŸ° å·²æ›´æ–°è·¯å¾„æ€§èƒ½: {chosen_path.strategy_id} -> æˆåŠŸ={execution_success}, å¥–åŠ±={rl_reward:.3f}")
            else:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°é€‰ä¸­çš„æ€ç»´è·¯å¾„ï¼Œæ— æ³•æ›´æ–°MABæ€§èƒ½")
            
            # ğŸ“Š æ›´æ–°å…ˆéªŒæ¨ç†å™¨çš„ç½®ä¿¡åº¦å†å²
            task_confidence = decision_result.get('task_confidence', 0.5)
            if hasattr(self.prior_reasoner, 'update_confidence_feedback'):
                self.prior_reasoner.update_confidence_feedback(
                    task_confidence, execution_success, execution_time
                )
            
            # ğŸ§  æ–°å¢ï¼šæ›´æ–°æ€ç»´ç§å­çš„æ•ˆæœè·Ÿè¸ª
            thinking_seed = decision_result.get('thinking_seed')
            if thinking_seed and hasattr(self.prior_reasoner, 'update_seed_feedback'):
                self.prior_reasoner.update_seed_feedback(
                    thinking_seed, execution_success, rl_reward
                )
            
            # ğŸ“ˆ æ›´æ–°ç³»ç»Ÿçº§æ€§èƒ½ç»Ÿè®¡
            if execution_success:
                self.performance_stats['successful_decisions'] += 1
            
            # ğŸ’¡ æ›´æ–°Aha-Momentå†³ç­–åé¦ˆ
            self.update_aha_moment_feedback(execution_success)
            
            # ğŸ“ æ ‡è®°å†³ç­–å†å²ä¸­çš„æ‰§è¡Œç»“æœï¼ˆç”¨äºåç»­å¤±è´¥æ£€æµ‹ï¼‰
            if self.decision_history:
                self.decision_history[-1]['execution_success'] = execution_success
            
            # ğŸ•’ è®°å½•è¯¦ç»†åé¦ˆåˆ°å†³ç­–å†å²ä¸­
            if self.decision_history and self.decision_history[-1]['round_number'] == decision_result.get('round_number'):
                feedback_data = {
                    'execution_success': execution_success,
                    'execution_time': execution_time,
                    'user_satisfaction': user_satisfaction,
                    'rl_reward': rl_reward,
                    'feedback_timestamp': time.time(),
                    'architecture_version': '3-stage',  # æ ‡è¯†ä¸ºä¸‰é˜¶æ®µæ¶æ„åé¦ˆ
                    'strategy_id': chosen_path.strategy_id if chosen_path else None,  # ğŸ¯ æ ¹æºä¿®å¤ï¼šè®°å½•ç­–ç•¥ID
                    'instance_id': chosen_path.instance_id if chosen_path else None,  # ä¿ç•™å®ä¾‹IDç”¨äºè¿½è¸ª
                    'path_type': chosen_path.path_type if chosen_path else None
                }
                self.decision_history[-1]['feedback'] = feedback_data
            
            # ğŸ“Š è®¡ç®—å¹¶è®°å½•æ€§èƒ½æŒ‡æ ‡
            success_rate = self.performance_stats['successful_decisions'] / max(self.performance_stats['total_decisions'], 1)
            
            logger.info(f"ğŸ“ˆ ä¸‰é˜¶æ®µæ€§èƒ½åé¦ˆå·²æ›´æ–°:")
            logger.info(f"   ğŸ¯ è·¯å¾„: {chosen_path.path_type if chosen_path else 'Unknown'}")
            logger.info(f"   âœ… æ‰§è¡Œ: æˆåŠŸ={execution_success}, è€—æ—¶={execution_time:.2f}s")
            logger.info(f"   ğŸ å¥–åŠ±: RL={rl_reward:.3f}, æ»¡æ„åº¦={user_satisfaction:.3f}")
            logger.info(f"   ğŸ“Š æ•´ä½“æˆåŠŸç‡: {success_rate:.1%}")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ä¸‰é˜¶æ®µæ€§èƒ½åé¦ˆå¤±è´¥: {e}")
            logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ä¸‰é˜¶æ®µæ™ºèƒ½å†³ç­–ç³»ç»ŸçŠ¶æ€"""
        try:
            # è®¡ç®—æˆåŠŸç‡
            success_rate = 0.0
            if self.performance_stats['total_decisions'] > 0:
                success_rate = self.performance_stats['successful_decisions'] / self.performance_stats['total_decisions']
            
            # è·å–å„ç»„ä»¶ç»Ÿè®¡ï¼ˆå®‰å…¨è°ƒç”¨ï¼Œé¿å…æ–¹æ³•ä¸å­˜åœ¨çš„é”™è¯¯ï¼‰
            prior_reasoner_stats = {}
            if hasattr(self.prior_reasoner, 'get_confidence_statistics'):
                prior_reasoner_stats = self.prior_reasoner.get_confidence_statistics()
            else:
                prior_reasoner_stats = {'total_assessments': 0, 'avg_confidence': 0.5, 'confidence_trend': 'stable'}
            
            path_generator_stats = {}
            if hasattr(self.path_generator, 'get_generation_statistics'):
                path_generator_stats = self.path_generator.get_generation_statistics()
            else:
                path_generator_stats = {'total_generations': 0, 'fallback_usage_rate': 0.0, 'avg_dimensions_per_generation': 0}
            
            # ä½¿ç”¨å‡çº§åçš„MABçŠ¶æ€è·å–æ–¹æ³•
            mab_stats = self.mab_converger.get_system_status()
            
            # è·å–è·¯å¾„çº§ç»Ÿè®¡
            path_summary = {}
            if hasattr(self.mab_converger, 'get_system_path_summary'):
                path_summary = self.mab_converger.get_system_path_summary()
            
            return {
                # åŸºæœ¬ä¿¡æ¯
                'total_rounds': self.total_rounds,
                'architecture_version': '3-stage',  # æ ‡è¯†æ¶æ„ç‰ˆæœ¬
                'component_architecture': True,  # å‘åå…¼å®¹
                
                # ç³»ç»Ÿæ€§èƒ½
                'system_performance': {
                    'success_rate': success_rate,
                    'avg_decision_time': self.performance_stats['avg_decision_time'],
                    'total_decisions': self.performance_stats['total_decisions'],
                    'successful_decisions': self.performance_stats['successful_decisions']
                },
                
                # ä¸‰é˜¶æ®µç»„ä»¶çŠ¶æ€
                'component_status': {
                    'stage1_prior_reasoner': {
                        'assessments_count': prior_reasoner_stats.get('total_assessments', 0),
                        'avg_confidence': prior_reasoner_stats.get('avg_confidence', 0.5),
                        'confidence_trend': prior_reasoner_stats.get('confidence_trend', 'stable'),
                        'thinking_seeds_generated': self.total_rounds,  # è¿‘ä¼¼å€¼
                        'performance': self.performance_stats['component_performance']['prior_reasoner']
                    },
                    'stage2_path_generator': {
                        'generations_count': path_generator_stats.get('total_generations', 0),
                        'fallback_rate': path_generator_stats.get('fallback_usage_rate', 0.0),
                        'avg_paths_per_generation': path_generator_stats.get('avg_dimensions_per_generation', 0),
                        'performance': self.performance_stats['component_performance']['path_generator']
                    },
                    'stage3_mab_converger': {
                        'mode': mab_stats.get('mode', 'path_selection'),
                        'total_paths': mab_stats.get('total_paths', 0),
                        'active_paths': mab_stats.get('active_paths', 0),
                        'total_selections': mab_stats.get('total_selections', 0),
                        'convergence_level': mab_stats.get('convergence_level', 0.0),
                        'most_popular_path_type': mab_stats.get('most_popular_path_type'),
                        'performance': self.performance_stats['component_performance']['mab_converger']
                    }
                },
                
                # è·¯å¾„é€‰æ‹©çŠ¶æ€
                'path_selection_status': {
                    'total_paths_tracked': path_summary.get('total_paths', 0),
                    'is_converged': path_summary.get('is_converged', False),
                    'convergence_level': path_summary.get('convergence_level', 0.0),
                    'most_used_path': path_summary.get('most_used_path'),
                    'best_performing_path': path_summary.get('best_performing_path'),
                    'algorithm_performance': path_summary.get('algorithm_performance', {})
                },
                
                # ç³»ç»Ÿèµ„æºä½¿ç”¨
                'memory_usage': {
                    'decision_history_size': len(self.decision_history),
                    'path_arms_count': len(getattr(self.mab_converger, 'path_arms', {})),
                    'path_generation_cache_size': len(getattr(self.path_generator, 'path_generation_cache', {})),
                    'confidence_cache_size': len(getattr(self.prior_reasoner, 'assessment_cache', {}))
                },
                
                # ğŸš€ æ€§èƒ½ä¼˜åŒ–å™¨çŠ¶æ€
                'performance_optimization': self._get_performance_optimization_status(),
                
                # æ‰©å±•åŠŸèƒ½çŠ¶æ€
                'extended_features': {
                    'thinking_seed_tracking': True,  # æ–°åŠŸèƒ½æ ‡è¯†
                    'path_performance_tracking': True,
                    'multi_algorithm_mab': True,
                    'aha_moment_decision_enabled': True  # ğŸ’¡ æ–°å¢ï¼šAha-Momentå†³ç­–åŠŸèƒ½
                },
                
                # ğŸ’¡ Aha-Momentå†³ç­–ç³»ç»ŸçŠ¶æ€
                'aha_moment_system': self.get_aha_moment_stats(),
                
                # ğŸ’¡ è·¯å¾„ç½®ä¿¡åº¦åˆ†æ
                'confidence_analysis': self.mab_converger.get_confidence_analysis(),
                
                # ğŸ’¡ åˆ›é€ æ€§ç»•é“ç»Ÿè®¡
                'creative_bypass_stats': self.path_generator.get_creative_bypass_stats(),
                
                # ğŸ† é»„é‡‘æ¨¡æ¿ç³»ç»ŸçŠ¶æ€ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                'golden_template_system': mab_stats.get('golden_template_system', {}),
                
                # å‘åå…¼å®¹å­—æ®µ
                'recent_decisions': len(self.decision_history)
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
            return {
                'error': str(e),
                'total_rounds': self.total_rounds,
                'component_architecture': True
            }
    
    def get_decision_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–å†³ç­–å†å²è®°å½•
        
        Args:
            limit: è¿”å›è®°å½•æ•°é‡é™åˆ¶
            
        Returns:
            å†³ç­–å†å²è®°å½•åˆ—è¡¨
        """
        return self.decision_history[-limit:] if self.decision_history else []
    
    def _get_performance_optimization_status(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ä¼˜åŒ–å™¨çŠ¶æ€"""
        if not self.performance_optimizer:
            return {
                'enabled': False,
                'status': 'disabled',
                'message': 'æ€§èƒ½ä¼˜åŒ–å™¨æœªå¯ç”¨'
            }
        
        try:
            optimization_report = self.performance_optimizer.get_performance_report()
            
            return {
                'enabled': True,
                'status': 'active',
                'features': {
                    'parallel_verification': PERFORMANCE_CONFIG.get("enable_parallel_path_verification", False),
                    'intelligent_caching': PERFORMANCE_CONFIG.get("enable_intelligent_caching", False),
                    'adaptive_path_count': PERFORMANCE_CONFIG.get("enable_adaptive_path_count", False),
                    'early_termination': PERFORMANCE_CONFIG.get("enable_early_termination", False)
                },
                'cache_stats': optimization_report.get('cache_stats', {}),
                'performance_improvements': optimization_report.get('optimization_stats', {}),
                'config': {
                    'max_concurrent_verifications': PERFORMANCE_CONFIG.get("max_concurrent_verifications", 3),
                    'cache_ttl_seconds': PERFORMANCE_CONFIG.get("cache_ttl_seconds", 3600),
                    'path_consistency_threshold': PERFORMANCE_CONFIG.get("path_consistency_threshold", 0.8)
                },
                'uptime_hours': optimization_report.get('uptime_hours', 0)
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–æ€§èƒ½ä¼˜åŒ–å™¨çŠ¶æ€å¤±è´¥: {e}")
            return {
                'enabled': True,
                'status': 'error',
                'error': str(e)
            }
    
    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–è¯¦ç»†æ€§èƒ½æŠ¥å‘Š"""
        try:
            report = {
                'overview': {
                    'total_decisions': self.performance_stats['total_decisions'],
                    'successful_decisions': self.performance_stats['successful_decisions'],
                    'success_rate': 0.0,
                    'avg_decision_time': self.performance_stats['avg_decision_time']
                },
                'component_performance': self.performance_stats['component_performance'].copy(),
                'recent_trends': self._analyze_recent_trends(),
                'bottlenecks': self._identify_performance_bottlenecks(),
                'recommendations': self._generate_performance_recommendations()
            }
            
            # è®¡ç®—æˆåŠŸç‡
            if report['overview']['total_decisions'] > 0:
                report['overview']['success_rate'] = (
                    report['overview']['successful_decisions'] / report['overview']['total_decisions']
                )
            
            return report
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _analyze_recent_trends(self) -> Dict[str, Any]:
        """åˆ†ææœ€è¿‘çš„æ€§èƒ½è¶‹åŠ¿"""
        if len(self.decision_history) < 5:
            return {'status': 'insufficient_data'}
        
        recent_decisions = self.decision_history[-10:]
        
        # åˆ†ææˆåŠŸç‡è¶‹åŠ¿
        recent_successes = [
            1 if d.get('feedback', {}).get('execution_success', False) else 0 
            for d in recent_decisions if 'feedback' in d
        ]
        
        # åˆ†æå†³ç­–æ—¶é—´è¶‹åŠ¿
        recent_times = [
            d.get('performance_metrics', {}).get('total_time', 0) 
            for d in recent_decisions
        ]
        
        trends = {
            'success_rate_trend': 'stable',
            'decision_time_trend': 'stable',
            'recent_success_rate': 0.0,
            'recent_avg_time': 0.0
        }
        
        if recent_successes:
            trends['recent_success_rate'] = sum(recent_successes) / len(recent_successes)
            
        if recent_times:
            trends['recent_avg_time'] = sum(recent_times) / len(recent_times)
            
            # ç®€å•è¶‹åŠ¿åˆ†æ
            if len(recent_times) >= 5:
                first_half_avg = sum(recent_times[:len(recent_times)//2]) / (len(recent_times)//2)
                second_half_avg = sum(recent_times[len(recent_times)//2:]) / (len(recent_times) - len(recent_times)//2)
                
                if second_half_avg > first_half_avg * 1.2:
                    trends['decision_time_trend'] = 'increasing'
                elif second_half_avg < first_half_avg * 0.8:
                    trends['decision_time_trend'] = 'decreasing'
        
        return trends
    
    def _identify_performance_bottlenecks(self) -> List[str]:
        """è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ"""
        bottlenecks = []
        
        # åˆ†æç»„ä»¶æ€§èƒ½
        component_perfs = self.performance_stats['component_performance']
        
        # æ‰¾å‡ºæœ€æ…¢çš„ç»„ä»¶
        slowest_component = max(component_perfs.items(), key=lambda x: x[1]['avg_time'])
        if slowest_component[1]['avg_time'] > 2.0:  # è¶…è¿‡2ç§’
            bottlenecks.append(f"{slowest_component[0]}å“åº”æ—¶é—´è¿‡é•¿ ({slowest_component[1]['avg_time']:.2f}s)")
        
        # æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
        if hasattr(self.path_generator, 'generation_cache') and len(self.path_generator.generation_cache) > 20:
            bottlenecks.append("è·¯å¾„ç”Ÿæˆç¼“å­˜å¯èƒ½è¿‡å¤§ï¼Œå½±å“å†…å­˜ä½¿ç”¨")
        
        # æ£€æŸ¥å†³ç­–å†å²å¤§å°
        if len(self.decision_history) > SYSTEM_LIMITS["max_decision_history"] * 0.8:
            bottlenecks.append("å†³ç­–å†å²æ¥è¿‘ä¸Šé™ï¼Œå¯èƒ½å½±å“æ€§èƒ½")
        
        return bottlenecks
    
    def _generate_performance_recommendations(self) -> List[str]:
        """ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # åŸºäºæˆåŠŸç‡çš„å»ºè®®
        success_rate = 0.0
        if self.performance_stats['total_decisions'] > 0:
            success_rate = self.performance_stats['successful_decisions'] / self.performance_stats['total_decisions']
        
        if success_rate < 0.7:
            recommendations.append("æˆåŠŸç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥ç»´åº¦ç”Ÿæˆç­–ç•¥å’ŒMABç®—æ³•å‚æ•°")
        
        # åŸºäºå†³ç­–æ—¶é—´çš„å»ºè®®
        if self.performance_stats['avg_decision_time'] > 3.0:
            recommendations.append("å¹³å‡å†³ç­–æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–APIè°ƒç”¨æˆ–å¢åŠ ç¼“å­˜")
        
        # åŸºäºç»„ä»¶æ€§èƒ½çš„å»ºè®®
        component_perfs = self.performance_stats['component_performance']
        for component_name, perf in component_perfs.items():
            if perf['avg_time'] > 1.5:
                recommendations.append(f"ä¼˜åŒ–{component_name}ç»„ä»¶æ€§èƒ½ï¼Œå½“å‰å¹³å‡è€—æ—¶{perf['avg_time']:.2f}ç§’")
        
        if not recommendations:
            recommendations.append("ç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼Œæ— ç‰¹åˆ«ä¼˜åŒ–å»ºè®®")
        
        return recommendations
    
    # ==================== ğŸ’¡ Aha-Momentå†³ç­–ç³»ç»Ÿå®ç° ====================
    
    def _check_aha_moment_trigger(self, chosen_path) -> Tuple[bool, str]:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘Aha-Momentå†³ç­–ï¼ˆç»•é“æ€è€ƒï¼‰
        
        Args:
            chosen_path: MABé€‰æ‹©çš„æ€ç»´è·¯å¾„
            
        Returns:
            (æ˜¯å¦è§¦å‘, è§¦å‘åŸå› )
        """
        # è§¦å‘æ¡ä»¶1ï¼šè·¯å¾„ç½®ä¿¡åº¦è¿‡ä½
        if hasattr(chosen_path, 'strategy_id'):
            path_confidence = self.mab_converger.get_path_confidence(chosen_path.strategy_id)
            
            if path_confidence < self.aha_moment_stats['confidence_threshold']:
                return True, f"é€‰ä¸­è·¯å¾„ç½®ä¿¡åº¦è¿‡ä½ ({path_confidence:.3f} < {self.aha_moment_stats['confidence_threshold']})"
        
        # è§¦å‘æ¡ä»¶2ï¼šæ‰€æœ‰è·¯å¾„éƒ½è¡¨ç°å¾ˆå·®
        is_low_confidence_scenario = self.mab_converger.check_low_confidence_scenario(
            threshold=self.aha_moment_stats['confidence_threshold']
        )
        
        if is_low_confidence_scenario:
            return True, "æ‰€æœ‰å¯ç”¨è·¯å¾„çš„ç½®ä¿¡åº¦éƒ½åä½ï¼Œéœ€è¦åˆ›é€ æ€§çªç ´"
        
        # è§¦å‘æ¡ä»¶3ï¼šè¿ç»­å¤±è´¥æ¬¡æ•°è¿‡å¤š
        if self.aha_moment_stats['consecutive_failures'] >= self.aha_moment_stats['failure_threshold']:
            return True, f"è¿ç»­å¤±è´¥ {self.aha_moment_stats['consecutive_failures']} æ¬¡ï¼Œè¶…è¿‡é˜ˆå€¼ {self.aha_moment_stats['failure_threshold']}"
        
        # è§¦å‘æ¡ä»¶4ï¼šç‰¹å®šæ—¶é—´é—´éš”å†…çš„å¤±è´¥å¯†åº¦è¿‡é«˜
        recent_failures = self._count_recent_failures(time_window=300)  # 5åˆ†é’Ÿå†…
        if recent_failures >= 3:
            return True, f"æœ€è¿‘5åˆ†é’Ÿå†…å¤±è´¥ {recent_failures} æ¬¡ï¼Œé¢‘ç‡è¿‡é«˜"
        
        return False, "å¸¸è§„å†³ç­–è·¯å¾„è¡¨ç°æ­£å¸¸"
    
    def _execute_aha_moment_thinking(self, user_query: str, thinking_seed: str, 
                                   original_path, original_paths) -> Tuple[Any, List[Any]]:
        """
        æ‰§è¡ŒAha-Momentç»•é“æ€è€ƒ
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            thinking_seed: åŸå§‹æ€ç»´ç§å­
            original_path: åŸå§‹é€‰æ‹©çš„è·¯å¾„
            original_paths: åŸå§‹è·¯å¾„åˆ—è¡¨
            
        Returns:
            (æ–°é€‰æ‹©çš„è·¯å¾„, æ–°çš„è·¯å¾„åˆ—è¡¨)
        """
        aha_start_time = time.time()
        self.aha_moment_stats['total_aha_moments'] += 1
        
        logger.info("ğŸ’¡ å¼€å§‹æ‰§è¡ŒAha-Momentç»•é“æ€è€ƒ...")
        logger.info(f"   åŸå§‹è·¯å¾„: {original_path.path_type}")
        logger.info(f"   åŸå§‹è·¯å¾„æ•°é‡: {len(original_paths)}")
        
        try:
            # Step 1: ç”Ÿæˆåˆ›é€ æ€§ç»•é“è·¯å¾„
            logger.info("ğŸŒŸ ç”Ÿæˆåˆ›é€ æ€§æ€ç»´è·¯å¾„...")
            creative_paths = self.path_generator.generate_paths(
                thinking_seed=thinking_seed,
                task=user_query,
                max_paths=4,  # å‡å°‘æ•°é‡ï¼Œä¸“æ³¨è´¨é‡
                mode='creative_bypass'  # åˆ›é€ æ€§ç»•é“æ¨¡å¼
            )
            
            logger.info(f"ğŸŒŸ ç”Ÿæˆäº† {len(creative_paths)} æ¡åˆ›é€ æ€§è·¯å¾„")
            for i, path in enumerate(creative_paths, 1):
                logger.info(f"   åˆ›é€ æ€§è·¯å¾„{i}: {path.path_type}")
            
            # Step 2: åˆå¹¶åŸå§‹è·¯å¾„å’Œåˆ›é€ æ€§è·¯å¾„
            combined_paths = original_paths + creative_paths
            
            # Step 3: ä½¿ç”¨MABé‡æ–°é€‰æ‹©ï¼ˆç°åœ¨æœ‰æ›´å¤šé€‰æ‹©ï¼‰
            logger.info("ğŸ¯ åœ¨æ‰©å±•è·¯å¾„é›†åˆä¸­é‡æ–°é€‰æ‹©æœ€ä¼˜è·¯å¾„...")
            final_chosen_path = self.mab_converger.select_best_path(combined_paths)
            
            # Step 4: è®°å½•Aha-Momentå†³ç­–å†å²
            aha_record = {
                'timestamp': time.time(),
                'trigger_reason': 'low_confidence_scenario',
                'original_path': original_path.path_type,
                'creative_paths_generated': len(creative_paths),
                'final_chosen_path': final_chosen_path.path_type,
                'was_creative_path_chosen': final_chosen_path in creative_paths,
                'aha_thinking_time': time.time() - aha_start_time
            }
            
            self.aha_moment_stats['aha_decision_history'].append(aha_record)
            
            # é™åˆ¶å†å²è®°å½•é•¿åº¦
            if len(self.aha_moment_stats['aha_decision_history']) > 100:
                self.aha_moment_stats['aha_decision_history'] = self.aha_moment_stats['aha_decision_history'][-50:]
            
            logger.info(f"ğŸ’¡ Aha-Momentæ€è€ƒå®Œæˆ:")
            logger.info(f"   æœ€ç»ˆè·¯å¾„: {final_chosen_path.path_type}")
            logger.info(f"   æ˜¯å¦é€‰æ‹©åˆ›é€ æ€§è·¯å¾„: {'æ˜¯' if final_chosen_path in creative_paths else 'å¦'}")
            logger.info(f"   ç»•é“æ€è€ƒè€—æ—¶: {time.time() - aha_start_time:.3f}s")
            
            return final_chosen_path, combined_paths
            
        except Exception as e:
            logger.error(f"âŒ Aha-Momentæ€è€ƒè¿‡ç¨‹å¤±è´¥: {e}")
            logger.warning("ğŸ”„ å›é€€åˆ°åŸå§‹è·¯å¾„é€‰æ‹©")
            return original_path, original_paths
    
    def _count_recent_failures(self, time_window: int = 300) -> int:
        """
        ç»Ÿè®¡æœ€è¿‘æ—¶é—´çª—å£å†…çš„å¤±è´¥æ¬¡æ•°
        
        Args:
            time_window: æ—¶é—´çª—å£ï¼ˆç§’ï¼‰
            
        Returns:
            å¤±è´¥æ¬¡æ•°
        """
        if not self.decision_history:
            return 0
        
        current_time = time.time()
        failure_count = 0
        
        for decision in reversed(self.decision_history):
            if current_time - decision.get('timestamp', 0) > time_window:
                break  # è¶…å‡ºæ—¶é—´çª—å£
            
            # æ£€æŸ¥è¿™ä¸ªå†³ç­–æ˜¯å¦è¢«æ ‡è®°ä¸ºå¤±è´¥
            # è¿™éœ€è¦åœ¨update_performance_feedbackä¸­è®¾ç½®
            if decision.get('execution_success', True) is False:
                failure_count += 1
        
        return failure_count
    
    def update_aha_moment_feedback(self, success: bool):
        """
        æ›´æ–°Aha-Momentå†³ç­–çš„åé¦ˆ
        
        Args:
            success: å†³ç­–æ˜¯å¦æˆåŠŸ
        """
        if success:
            self.aha_moment_stats['consecutive_failures'] = 0
            self.aha_moment_stats['last_decision_success'] = True
            logger.debug("âœ… å†³ç­–æˆåŠŸï¼Œé‡ç½®è¿ç»­å¤±è´¥è®¡æ•°")
        else:
            self.aha_moment_stats['consecutive_failures'] += 1
            self.aha_moment_stats['last_decision_success'] = False
            self.aha_moment_stats['last_failure_timestamp'] = time.time()
            logger.debug(f"âŒ å†³ç­–å¤±è´¥ï¼Œè¿ç»­å¤±è´¥æ¬¡æ•°: {self.aha_moment_stats['consecutive_failures']}")
        
        # æ›´æ–°Aha-MomentæˆåŠŸç‡ç»Ÿè®¡
        if self.aha_moment_stats['aha_decision_history']:
            aha_successes = sum(1 for record in self.aha_moment_stats['aha_decision_history'] 
                              if record.get('success', False))
            total_aha = len(self.aha_moment_stats['aha_decision_history'])
            self.aha_moment_stats['aha_success_rate'] = aha_successes / total_aha
    
    def get_aha_moment_stats(self) -> Dict[str, any]:
        """
        è·å–Aha-Momentå†³ç­–ç³»ç»Ÿçš„ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        recent_aha_count = sum(1 for record in self.aha_moment_stats['aha_decision_history']
                              if time.time() - record['timestamp'] < 3600)  # æœ€è¿‘1å°æ—¶
        
        return {
            'total_aha_moments': self.aha_moment_stats['total_aha_moments'],
            'consecutive_failures': self.aha_moment_stats['consecutive_failures'],
            'aha_success_rate': self.aha_moment_stats['aha_success_rate'],
            'recent_aha_count': recent_aha_count,
            'failure_threshold': self.aha_moment_stats['failure_threshold'],
            'confidence_threshold': self.aha_moment_stats['confidence_threshold'],
            'last_failure_timestamp': self.aha_moment_stats['last_failure_timestamp'],
            'last_decision_success': self.aha_moment_stats['last_decision_success'],
            'history_count': len(self.aha_moment_stats['aha_decision_history'])
        }
    
    def reset_system(self, preserve_learnings: bool = True):
        """
        é‡ç½®ç³»ç»ŸçŠ¶æ€
        
        Args:
            preserve_learnings: æ˜¯å¦ä¿ç•™å­¦ä¹ åˆ°çš„çŸ¥è¯†
        """
        logger.info("ğŸ”„ å¼€å§‹é‡ç½®ç³»ç»Ÿ...")
        
        # é‡ç½®è®¡æ•°å™¨
        self.total_rounds = 0
        self.decision_history.clear()
        
        # é‡ç½®æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            'total_decisions': 0,
            'successful_decisions': 0,
            'avg_decision_time': 0.0,
            'component_performance': {
                'prior_reasoner': {'calls': 0, 'avg_time': 0.0},
                'path_generator': {'calls': 0, 'avg_time': 0.0},
                'mab_converger': {'calls': 0, 'avg_time': 0.0},
                'idea_verification': {'calls': 0, 'avg_time': 0.0, 'success_rate': 0.0}  # åŒ…å«æ–°çš„éªŒè¯ç»Ÿè®¡
            }
        }
        
        if not preserve_learnings:
            # æ¸…é™¤æ‰€æœ‰å­¦ä¹ æ•°æ®
            self.prior_reasoner.reset_cache()
            self.path_generator.clear_cache()
            # MABæ•°æ®ä¸æ¸…é™¤ï¼Œå› ä¸ºå®ƒæ˜¯æ ¸å¿ƒå­¦ä¹ æœºåˆ¶
            logger.info("ğŸ§¹ å·²æ¸…é™¤ç¼“å­˜å’Œä¸´æ—¶æ•°æ®")
        
        logger.info("âœ… ç³»ç»Ÿé‡ç½®å®Œæˆ")
        
        # ğŸ—‘ï¸ å·²ç§»é™¤ï¼šä¸å†éœ€è¦æ¸…ç†éªŒè¯å®¢æˆ·ç«¯ç¼“å­˜ï¼Œå·¥å…·ç¼“å­˜ç”±ToolRegistryç®¡ç†
    
    # ================================
    # ğŸ”¬ æ–°å¢ï¼šæƒ³æ³•éªŒè¯ç ”ç©¶å‘˜èƒ½åŠ›
    # ================================
    
    def verify_idea_feasibility(self, idea_text: str, context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        ğŸ”§ å·¥å…·å¢å¼ºçš„æƒ³æ³•éªŒè¯æµç¨‹ - ä»ç¡¬ç¼–ç æœç´¢å‡çº§ä¸ºçµæ´»å·¥å…·è°ƒç”¨
        
        åŸæœ‰æ–¹æ³•æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªç¡¬ç¼–ç çš„"æœç´¢å·¥å…·"è°ƒç”¨ã€‚ç°åœ¨å‡çº§ä¸ºï¼š
        1. æ™ºèƒ½å·¥å…·é€‰æ‹©ï¼šæ ¹æ®éªŒè¯éœ€æ±‚é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·
        2. å·¥å…·å¢å¼ºæ¨ç†ï¼šLLMå¯ä»¥è°ƒç”¨å¤šä¸ªå·¥å…·è·å–ä¿¡æ¯
        3. åŠ¨æ€éªŒè¯ç­–ç•¥ï¼šæ ¹æ®æƒ³æ³•ç±»å‹é‡‡ç”¨ä¸åŒéªŒè¯æ–¹æ³•
        4. å­¦ä¹ åé¦ˆæœºåˆ¶ï¼šå·¥å…·ä½¿ç”¨ç»“æœå½±å“MABå­¦ä¹ 
        
        Args:
            idea_text: éœ€è¦éªŒè¯çš„æƒ³æ³•æ–‡æœ¬ï¼ˆæ€ç»´ç§å­æˆ–æ€ç»´è·¯å¾„æè¿°ï¼‰
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            å¢å¼ºçš„éªŒè¯ç»“æœå­—å…¸
        """
        start_time = time.time()
        logger.info(f"ğŸ”¬ å¼€å§‹æƒ³æ³•éªŒè¯ç ”ç©¶: {idea_text[:50]}...")
        
        try:
            # ğŸ”§ ä½¿ç”¨å·¥å…·å¢å¼ºçš„éªŒè¯æµç¨‹ï¼ˆæ— å›é€€æœºåˆ¶ï¼‰
            verification_result = self._enhanced_verification_with_tools(idea_text, context)
            
            # å¦‚æœå·¥å…·å¢å¼ºéªŒè¯å¤±è´¥ï¼Œç›´æ¥è¿”å›å¤±è´¥ç»“æœ
            if not verification_result.get('success', False):
                logger.error("âŒ å·¥å…·å¢å¼ºéªŒè¯å¤±è´¥ï¼Œæ— å›é€€æœºåˆ¶")
                execution_time = time.time() - start_time
                return self._create_direct_failure_result(
                    idea_text, 
                    verification_result.get('error_message', 'å·¥å…·å¢å¼ºéªŒè¯å¤±è´¥'), 
                    execution_time
                )
            
            # ç»Ÿè®¡å’Œå­¦ä¹ åé¦ˆ
            execution_time = time.time() - start_time
            self._update_verification_stats(verification_result, execution_time)
            
            logger.info(f"âœ… æƒ³æ³•éªŒè¯å®Œæˆ: å¯è¡Œæ€§={verification_result.get('feasibility_analysis', {}).get('feasibility_score', 0):.2f}")
            return verification_result
            
        except Exception as e:
            logger.error(f"âŒ æƒ³æ³•éªŒè¯å¼‚å¸¸: {e}")
            execution_time = time.time() - start_time
            return self._create_direct_failure_result(
                idea_text, f"éªŒè¯å¼‚å¸¸: {e}", execution_time
            )
    
    def _enhanced_verification_with_tools(self, idea_text: str, context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        ğŸ”§ å·¥å…·å¢å¼ºçš„éªŒè¯æ–¹æ³• - æ ¸å¿ƒå‡çº§
        
        è¿™ä¸ªæ–¹æ³•å±•ç¤ºäº†å¦‚ä½•å°†åŸæœ‰çš„ç¡¬ç¼–ç æœç´¢æ”¹é€ ä¸ºçµæ´»çš„å·¥å…·è°ƒç”¨ï¼š
        1. æ™ºèƒ½å·¥å…·é€‰æ‹©ï¼šæ ¹æ®æƒ³æ³•ç±»å‹é€‰æ‹©æœ€åˆé€‚çš„éªŒè¯å·¥å…·
        2. å¤šæ­¥éª¤éªŒè¯ï¼šå¯ä»¥è¿ç»­ä½¿ç”¨å¤šä¸ªå·¥å…·
        3. ä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼šæ ¹æ®éªŒè¯é˜¶æ®µè°ƒæ•´å·¥å…·ä½¿ç”¨ç­–ç•¥
        """
        try:
            # æ„å»ºéªŒè¯æç¤ºè¯
            verification_prompt = self._build_verification_prompt(idea_text, context)
            
            # é€‰æ‹©é€‚åˆéªŒè¯çš„å·¥å…·
            available_tools = self._select_verification_tools(idea_text, context)
            
            # ä½¿ç”¨å·¥å…·å¢å¼ºçš„LLMæ¨ç†
            llm_result = self._execute_llm_with_tools(
                prompt=verification_prompt,
                context=context,
                available_tools=available_tools,
                max_tool_calls=2  # éªŒè¯é˜¶æ®µé™åˆ¶å·¥å…·è°ƒç”¨æ¬¡æ•°
            )
            
            if not llm_result['success']:
                return {'success': False, 'error_message': llm_result['error_message']}
            
            # è§£æLLMçš„éªŒè¯ç»“æœ
            verification_analysis = self._parse_verification_response(llm_result['llm_response'])
            
            # è®¡ç®—å¥–åŠ±åˆ†æ•°ï¼ˆè€ƒè™‘å·¥å…·ä½¿ç”¨æ•ˆæœï¼‰
            reward_score = self._calculate_enhanced_reward(verification_analysis, llm_result['tool_calls'])
            
            return {
                'success': True,
                'idea_text': idea_text,
                'feasibility_analysis': verification_analysis,
                'reward_score': reward_score,
                'tool_calls_made': len(llm_result['tool_calls']),
                'tool_results': llm_result['tool_results'],
                'execution_time': llm_result['execution_time'],
                'verification_method': 'tool_enhanced'
            }
            
        except Exception as e:
            logger.error(f"âŒ å·¥å…·å¢å¼ºéªŒè¯å¤±è´¥: {e}")
            return {'success': False, 'error_message': str(e)}
    
    def _build_verification_prompt(self, idea_text: str, context: Optional[Dict] = None) -> str:
        """æ„å»ºéªŒè¯æç¤ºè¯"""
        stage = context.get('stage', 'unknown') if context else 'unknown'
        
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹æƒ³æ³•çš„å¯è¡Œæ€§ï¼Œå¹¶æä¾›è¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Šã€‚ä½ å¯ä»¥ä½¿ç”¨æœç´¢å·¥å…·æ¥è·å–ç›¸å…³ä¿¡æ¯ï¼š

æƒ³æ³•å†…å®¹ï¼š{idea_text}

åˆ†æé˜¶æ®µï¼š{stage}
"""
        
        if context:
            if 'query' in context:
                prompt += f"\nåŸå§‹æŸ¥è¯¢ï¼š{context['query']}"
            if 'domain' in context:
                prompt += f"\nåº”ç”¨é¢†åŸŸï¼š{context['domain']}"
        
        prompt += """

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼š
1. æŠ€æœ¯å¯è¡Œæ€§ - ä»æŠ€æœ¯è§’åº¦è¯„ä¼°å®ç°éš¾åº¦
2. å¸‚åœºéœ€æ±‚ - åˆ†ææ˜¯å¦æœ‰å®é™…éœ€æ±‚
3. èµ„æºè¦æ±‚ - è¯„ä¼°æ‰€éœ€èµ„æºå’Œæˆæœ¬
4. é£é™©è¯„ä¼° - è¯†åˆ«æ½œåœ¨é£é™©å’ŒæŒ‘æˆ˜
5. åˆ›æ–°ç¨‹åº¦ - è¯„ä¼°æƒ³æ³•çš„æ–°é¢–æ€§

å¦‚æœéœ€è¦è·å–æœ€æ–°ä¿¡æ¯ï¼Œè¯·ä½¿ç”¨æœç´¢å·¥å…·ã€‚

æœ€åï¼Œè¯·ç»™å‡ºä¸€ä¸ª0-1ä¹‹é—´çš„å¯è¡Œæ€§è¯„åˆ†ï¼Œå¹¶ç®€è¦è¯´æ˜ç†ç”±ã€‚
"""
        
        return prompt
    
    def _select_verification_tools(self, idea_text: str, context: Optional[Dict] = None) -> List[str]:
        """æ ¹æ®éªŒè¯éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥å…·"""
        available_tools = ["web_search"]  # åŸºç¡€æœç´¢å·¥å…·
        
        # æ ¹æ®æƒ³æ³•ç±»å‹å’Œä¸Šä¸‹æ–‡é€‰æ‹©é¢å¤–å·¥å…·
        if context:
            stage = context.get('stage', '')
            if stage == 'thinking_seed':
                # æ€ç»´ç§å­é˜¶æ®µï¼šéœ€è¦å¹¿æ³›çš„ä¿¡æ¯æ”¶é›†
                available_tools.extend(["idea_verification"])
            elif stage == 'reasoning_path':
                # æ¨ç†è·¯å¾„é˜¶æ®µï¼šéœ€è¦æ·±åº¦éªŒè¯
                available_tools.extend(["idea_verification"])
        
        # æ ¹æ®æƒ³æ³•å†…å®¹æ¨æ–­éœ€è¦çš„å·¥å…·
        idea_lower = idea_text.lower()
        if any(keyword in idea_lower for keyword in ['æŠ€æœ¯', 'technology', 'ç¼–ç¨‹', 'programming']):
            # æŠ€æœ¯ç±»æƒ³æ³•å¯èƒ½éœ€è¦æ›´å¤šæŠ€æœ¯èµ„æº
            pass  # æœªæ¥å¯ä»¥æ·»åŠ æŠ€æœ¯ç±»éªŒè¯å·¥å…·
        
        return available_tools
    
    def _parse_verification_response(self, llm_response: str) -> Dict[str, Any]:
        """è§£æLLMçš„éªŒè¯å“åº”"""
        # å°è¯•ä»å“åº”ä¸­æå–å¯è¡Œæ€§è¯„åˆ†
        import re
        
        # æŸ¥æ‰¾è¯„åˆ†
        score_patterns = [
            r'å¯è¡Œæ€§è¯„åˆ†[ï¼š:]\s*([0-9]*\.?[0-9]+)',
            r'è¯„åˆ†[ï¼š:]\s*([0-9]*\.?[0-9]+)',
            r'score[ï¼š:]?\s*([0-9]*\.?[0-9]+)',
            r'([0-9]*\.?[0-9]+)\s*/\s*1',
            r'([0-9]*\.?[0-9]+)\s*åˆ†'
        ]
        
        feasibility_score = 0.5  # é»˜è®¤å€¼
        for pattern in score_patterns:
            match = re.search(pattern, llm_response, re.IGNORECASE)
            if match:
                try:
                    score = float(match.group(1))
                    if score > 1:  # å¯èƒ½æ˜¯ç™¾åˆ†åˆ¶
                        score = score / 100
                    feasibility_score = max(0, min(1, score))  # é™åˆ¶åœ¨0-1èŒƒå›´
                    break
                except ValueError:
                    continue
        
        # æå–å…³é”®åˆ†æè¦ç‚¹
        analysis_summary = llm_response[:500] + "..." if len(llm_response) > 500 else llm_response
        
        return {
            'feasibility_score': feasibility_score,
            'analysis_summary': analysis_summary,
            'full_response': llm_response
        }
    
    def _calculate_enhanced_reward(self, verification_analysis: Dict[str, Any], tool_calls: List[Dict]) -> float:
        """è®¡ç®—å¢å¼ºçš„å¥–åŠ±åˆ†æ•°ï¼ˆè€ƒè™‘å·¥å…·ä½¿ç”¨æ•ˆæœï¼‰"""
        base_score = verification_analysis.get('feasibility_score', 0.5)
        
        # å·¥å…·ä½¿ç”¨å¥–åŠ±
        tool_bonus = 0.0
        if tool_calls:
            # æˆåŠŸä½¿ç”¨å·¥å…·è·å¾—å°å¹…å¥–åŠ±
            tool_bonus = min(0.1, len(tool_calls) * 0.05)
        
        # æœ€ç»ˆå¥–åŠ±åˆ†æ•°
        reward = base_score + tool_bonus - 0.5  # è½¬æ¢ä¸º[-0.5, 0.6]èŒƒå›´
        
        return reward
    

    def _update_verification_stats(self, verification_result: Dict[str, Any], execution_time: float):
        """æ›´æ–°éªŒè¯ç»Ÿè®¡ä¿¡æ¯"""
        success = verification_result.get('success', False)
        
        # æ›´æ–°ç»„ä»¶æ€§èƒ½ç»Ÿè®¡
        current_stats = self.performance_stats['component_performance']['idea_verification']
        current_stats['calls'] += 1
        
        # æ›´æ–°å¹³å‡æ—¶é—´
        if current_stats['calls'] == 1:
            current_stats['avg_time'] = execution_time
        else:
            current_stats['avg_time'] = (current_stats['avg_time'] * (current_stats['calls'] - 1) + execution_time) / current_stats['calls']
        
        # æ›´æ–°æˆåŠŸç‡
        if 'total_success' not in current_stats:
            current_stats['total_success'] = 0
        
        if success:
            current_stats['total_success'] += 1
        
        current_stats['success_rate'] = current_stats['total_success'] / current_stats['calls']
        
        # è®°å½•å·¥å…·ä½¿ç”¨ç»Ÿè®¡
        verification_method = verification_result.get('verification_method', 'unknown')
        tool_calls_made = verification_result.get('tool_calls_made', 0)
        
        if 'verification_methods' not in current_stats:
            current_stats['verification_methods'] = {}
        
        if verification_method not in current_stats['verification_methods']:
            current_stats['verification_methods'][verification_method] = 0
        current_stats['verification_methods'][verification_method] += 1
        
        if 'tool_usage' not in current_stats:
            current_stats['tool_usage'] = {'total_calls': 0, 'calls_per_verification': 0}
        
        current_stats['tool_usage']['total_calls'] += tool_calls_made
        current_stats['tool_usage']['calls_per_verification'] = current_stats['tool_usage']['total_calls'] / current_stats['calls']
        
        logger.debug(f"ğŸ“Š éªŒè¯ç»Ÿè®¡æ›´æ–°: æˆåŠŸç‡={current_stats['success_rate']:.1%}, æ–¹æ³•={verification_method}, å·¥å…·è°ƒç”¨={tool_calls_made}")
    
    def _create_direct_failure_result(self, idea_text: str, error_message: str, execution_time: float = 0.0) -> Dict[str, Any]:
        """åˆ›å»ºç›´æ¥å¤±è´¥ç»“æœï¼ˆæ— å›é€€æœºåˆ¶ï¼‰"""
        return {
            'success': False,
            'idea_text': idea_text,
            'feasibility_analysis': {
                'feasibility_score': 0.0,  # å¤±è´¥æ—¶ç»™äºˆæœ€ä½è¯„åˆ†
                'analysis_summary': f"å·¥å…·å¢å¼ºéªŒè¯å¤±è´¥: {error_message}ã€‚ç³»ç»Ÿå°†ä¾èµ–MABå­¦ä¹ é¿å…æ­¤ç±»è·¯å¾„ã€‚"
            },
            'reward_score': -0.5,  # å¼ºè´Ÿå¥–åŠ±ï¼Œè®©MABç³»ç»Ÿå­¦ä¼šé¿å…å¯¼è‡´å¤±è´¥çš„è·¯å¾„
            'error_message': error_message,
            'execution_time': execution_time,
            'verification_method': 'tool_enhanced_failed',
            'tool_calls_made': 0,
            'tool_results': {}
        }
    
    def _preprocess_idea_text(self, idea_text: str) -> str:
        """é¢„å¤„ç†æƒ³æ³•æ–‡æœ¬"""
        # æ¸…ç†å’Œæ ‡å‡†åŒ–æ–‡æœ¬
        cleaned = idea_text.strip()
        
        # é™åˆ¶é•¿åº¦ï¼ˆé¿å…è¿‡é•¿çš„æœç´¢æŸ¥è¯¢ï¼‰
        if len(cleaned) > 200:
            cleaned = cleaned[:200] + "..."
            
        return cleaned
    
    def _generate_verification_query(self, idea_text: str, context: Optional[Dict] = None) -> str:
        """
        ç”ŸæˆéªŒè¯æŸ¥è¯¢ - å°†æƒ³æ³•è½¬æ¢æˆé€‚åˆæœç´¢çš„é—®é¢˜
        
        Args:
            idea_text: æƒ³æ³•æ–‡æœ¬
            context: ä¸Šä¸‹æ–‡
            
        Returns:
            æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
        """
        # æå–æ ¸å¿ƒæŠ€æœ¯æ¦‚å¿µ
        tech_concepts = self._extract_technical_concepts(idea_text)
        
        # æ„å»ºæŸ¥è¯¢æ¨¡æ¿
        if tech_concepts:
            query_template = f"'{' '.join(tech_concepts[:2])}' æŠ€æœ¯å¯è¡Œæ€§ å®ç°æ–¹æ³• æ½œåœ¨é£é™© æœ€ä½³å®è·µ"
        else:
            query_template = f"'{idea_text[:50]}' è§£å†³æ–¹æ¡ˆ æŠ€æœ¯å®ç° æŒ‘æˆ˜åˆ†æ"
        
        # æ·»åŠ é¢†åŸŸä¸Šä¸‹æ–‡
        if context and 'domain' in context:
            query_template += f" {context['domain']}"
        
        return query_template
    
    def _extract_technical_concepts(self, text: str) -> List[str]:
        """æå–æŠ€æœ¯æ¦‚å¿µ"""
        tech_terms = [
            'API', 'api', 'ç®—æ³•', 'æ•°æ®åº“', 'ç³»ç»Ÿ', 'æ¶æ„', 'ä¼˜åŒ–',
            'æœºå™¨å­¦ä¹ ', 'ML', 'AI', 'äººå·¥æ™ºèƒ½', 'æ·±åº¦å­¦ä¹ ',
            'ç½‘ç»œ', 'çˆ¬è™«', 'æ•°æ®åˆ†æ', 'å®æ—¶', 'æ€§èƒ½', 'å®‰å…¨',
            'å¹¶å‘', 'åˆ†å¸ƒå¼', 'å¾®æœåŠ¡', 'å®¹å™¨', 'äº‘è®¡ç®—', 'åŒºå—é“¾',
            'Python', 'Java', 'JavaScript', 'React', 'Node.js'
        ]
        
        found_concepts = []
        text_lower = text.lower()
        
        for term in tech_terms:
            if term.lower() in text_lower:
                found_concepts.append(term)
        
        return found_concepts[:3]  # è¿”å›å‰3ä¸ªæ¦‚å¿µ
    
    # ğŸ—‘ï¸ å·²ç§»é™¤ _analyze_idea_feasibility - ä¼ ç»ŸéªŒè¯ç³»ç»Ÿçš„ä¸€éƒ¨åˆ†
    
    # ğŸ—‘ï¸ å·²ç§»é™¤ _build_feasibility_analysis_prompt - ä¼ ç»ŸéªŒè¯ç³»ç»Ÿçš„ä¸€éƒ¨åˆ†
    
    # ğŸ—‘ï¸ å·²ç§»é™¤ _parse_feasibility_analysis - ä¼ ç»ŸéªŒè¯ç³»ç»Ÿçš„ä¸€éƒ¨åˆ†
    
    # ğŸ—‘ï¸ å·²ç§»é™¤ _create_default_analysis_result - ä¼ ç»ŸéªŒè¯ç³»ç»Ÿçš„ä¸€éƒ¨åˆ†
    
    # ğŸ—‘ï¸ å·²ç§»é™¤ _heuristic_feasibility_analysis - ä¼ ç»ŸéªŒè¯ç³»ç»Ÿçš„ä¸€éƒ¨åˆ†
    
    # ğŸ—‘ï¸ å·²ç§»é™¤ _calculate_verification_reward - ä¼ ç»ŸéªŒè¯ç³»ç»Ÿçš„ä¸€éƒ¨åˆ†
    

    def _update_verification_performance(self, verification_result: Dict[str, Any]):
        """æ›´æ–°éªŒè¯æ€§èƒ½ç»Ÿè®¡"""
        perf_stats = self.performance_stats['component_performance']['idea_verification']
        
        # æ›´æ–°è°ƒç”¨æ¬¡æ•°
        perf_stats['calls'] += 1
        
        # æ›´æ–°å¹³å‡æ—¶é—´
        if perf_stats['calls'] == 1:
            perf_stats['avg_time'] = verification_result['verification_time']
        else:
            perf_stats['avg_time'] = (
                (perf_stats['avg_time'] * (perf_stats['calls'] - 1) + verification_result['verification_time'])
                / perf_stats['calls']
            )
        
        # æ›´æ–°æˆåŠŸç‡
        success = not verification_result.get('fallback', False)
        if perf_stats['calls'] == 1:
            perf_stats['success_rate'] = 1.0 if success else 0.0
        else:
            current_success_count = perf_stats['success_rate'] * (perf_stats['calls'] - 1)
            if success:
                current_success_count += 1
            perf_stats['success_rate'] = current_success_count / perf_stats['calls']
    
    # ================================
    # ğŸš€ æ™ºèƒ½ç»•é“æ€è€ƒç³»ç»Ÿï¼ˆå…¨æ–°Aha-Momentï¼‰
    # ================================
    
    def _execute_intelligent_detour_thinking(self, user_query: str, thinking_seed: str, 
                                           original_paths: List, verified_paths: List) -> Tuple[Any, Dict]:
        """
        æ™ºèƒ½ç»•é“æ€è€ƒ - å½“æ‰€æœ‰å¸¸è§„è·¯å¾„éƒ½è¢«éªŒè¯ä¸ºä¸å¯è¡Œæ—¶çš„åˆ›æ–°å†³ç­–
        
        è¿™æ˜¯åŸºäºéªŒè¯ç»“æœçš„æ–°å‹Aha-Momentè§¦å‘å™¨ï¼Œæ¯”ä¼ ç»Ÿæ–¹æ³•æ›´æ™ºèƒ½
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            thinking_seed: æ€ç»´ç§å­
            original_paths: åŸå§‹è·¯å¾„åˆ—è¡¨
            verified_paths: éªŒè¯ç»“æœåˆ—è¡¨
            
        Returns:
            Tuple[chosen_path, mab_decision]
        """
        logger.info("ğŸš€ å¼€å§‹æ™ºèƒ½ç»•é“æ€è€ƒ - å¯»æ‰¾åˆ›æ–°è§£å†³æ–¹æ¡ˆ")
        
        try:
            # åˆ†æå¤±è´¥æ¨¡å¼ - ä»éªŒè¯ç»“æœä¸­å­¦ä¹ 
            failure_patterns = self._analyze_verification_failures(verified_paths)
            logger.debug(f"ğŸ“Š å¤±è´¥æ¨¡å¼åˆ†æ: {failure_patterns}")
            
            # åŸºäºå¤±è´¥åˆ†æç”Ÿæˆåˆ›æ–°ç§å­
            innovative_seed = self._generate_innovative_thinking_seed(
                user_query, thinking_seed, failure_patterns
            )
            
            # ç”Ÿæˆåˆ›æ–°è·¯å¾„
            if innovative_seed:
                logger.info("ğŸ’¡ åŸºäºå¤±è´¥åˆ†æç”Ÿæˆåˆ›æ–°æ€ç»´ç§å­")
                innovative_paths = self.path_generator.generate_paths(
                    thinking_seed=innovative_seed,
                    task=user_query,
                    max_paths=3  # ä¸“æ³¨äºå°‘æ•°åˆ›æ–°è·¯å¾„
                )
            else:
                innovative_paths = []
            
            # å¦‚æœåˆ›æ–°è·¯å¾„ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨åº”æ€¥åˆ›æ–°è·¯å¾„
            if not innovative_paths:
                logger.warning("âš ï¸ åˆ›æ–°è·¯å¾„ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨åº”æ€¥åˆ›æ–°è·¯å¾„")
                innovative_paths = self._create_emergency_innovative_paths(user_query, failure_patterns)
            
            # éªŒè¯åˆ›æ–°è·¯å¾„
            best_innovative_path = None
            best_feasibility = 0.0
            
            for path in innovative_paths:
                path_verification = self.verify_idea_feasibility(
                    idea_text=f"åˆ›æ–°æ–¹æ¡ˆ: {path.path_type}: {path.description}",
                    context={
                        'stage': 'innovative_detour',
                        'original_failure': True,
                        'query': user_query
                    }
                )
                
                feasibility = path_verification.get('feasibility_analysis', {}).get('feasibility_score', 0.0)
                
                if feasibility > best_feasibility:
                    best_feasibility = feasibility
                    best_innovative_path = path
                
                # æ›´æ–°MABå­¦ä¹ ï¼ˆå³ä½¿æ˜¯åˆ›æ–°è·¯å¾„ä¹Ÿè¦å­¦ä¹ ï¼‰
                self.mab_converger.update_path_performance(
                    path_id=path.path_id,
                    success=feasibility > 0.4,  # åˆ›æ–°è·¯å¾„çš„æˆåŠŸé˜ˆå€¼ç¨ä½
                    reward=path_verification.get('reward_score', 0.0)
                )
            
            # é€‰æ‹©æœ€ä½³åˆ›æ–°è·¯å¾„
            if best_innovative_path and best_feasibility > 0.2:
                chosen_path = best_innovative_path
                logger.info(f"âœ… é€‰æ‹©åˆ›æ–°è·¯å¾„: {chosen_path.path_type} (å¯è¡Œæ€§: {best_feasibility:.2f})")
            else:
                # æœ€åçš„åº”æ€¥æ–¹æ¡ˆ
                logger.warning("ğŸ†˜ æ‰€æœ‰åˆ›æ–°å°è¯•å¤±è´¥ï¼Œä½¿ç”¨ä¿å®ˆåº”æ€¥æ–¹æ¡ˆ")
                chosen_path = self._create_conservative_emergency_path(user_query)
            
            # æ„å»ºå†³ç­–ç»“æœ
            mab_decision = {
                'chosen_path': chosen_path,
                'available_paths': original_paths + innovative_paths,
                'innovative_paths': innovative_paths,
                'failure_patterns': failure_patterns,
                'innovative_seed': innovative_seed if 'innovative_seed' in locals() else None,
                'best_innovative_feasibility': best_feasibility,
                'detour_success': best_feasibility > 0.2
            }
            
            # è®°å½•æ™ºèƒ½ç»•é“ç»Ÿè®¡
            self.aha_moment_stats['total_aha_moments'] += 1
            self.aha_moment_stats['aha_decision_history'].append({
                'timestamp': time.time(),
                'type': 'intelligent_detour',
                'trigger_reason': 'all_paths_verification_failed',
                'innovative_paths_count': len(innovative_paths),
                'best_feasibility': best_feasibility,
                'success': best_feasibility > 0.2
            })
            
            return chosen_path, mab_decision
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½ç»•é“æ€è€ƒå¤±è´¥: {e}")
            # è¿”å›æœ€ä¿å®ˆçš„åº”æ€¥æ–¹æ¡ˆ
            emergency_path = self._create_conservative_emergency_path(user_query)
            emergency_decision = {
                'chosen_path': emergency_path,
                'available_paths': original_paths,
                'detour_error': str(e),
                'emergency_fallback': True
            }
            return emergency_path, emergency_decision
    
    def _analyze_verification_failures(self, verified_paths: List[Dict]) -> Dict[str, Any]:
        """åˆ†æéªŒè¯å¤±è´¥çš„æ¨¡å¼"""
        if not verified_paths:
            return {'error': 'no_paths_to_analyze'}
        
        # æ”¶é›†å¤±è´¥åŸå› 
        low_feasibility_paths = [vp for vp in verified_paths if vp['feasibility_score'] < 0.3]
        common_issues = []
        
        # åˆ†æå…±åŒçš„å¤±è´¥æ¨¡å¼
        for vp in low_feasibility_paths:
            verification_result = vp.get('verification_result', {})
            risk_analysis = verification_result.get('feasibility_analysis', {}).get('risk_analysis', {})
            key_risks = risk_analysis.get('key_risks', [])
            common_issues.extend(key_risks)
        
        # ç»Ÿè®¡æœ€å¸¸è§çš„é—®é¢˜
        from collections import Counter
        issue_counts = Counter(common_issues)
        
        return {
            'total_failed_paths': len(low_feasibility_paths),
            'average_feasibility': sum(vp['feasibility_score'] for vp in verified_paths) / len(verified_paths),
            'common_failure_reasons': dict(issue_counts.most_common(3)),
            'risk_patterns': [issue for issue, count in issue_counts.most_common(3)]
        }
    
    def _generate_innovative_thinking_seed(self, user_query: str, original_seed: str, 
                                         failure_patterns: Dict) -> str:
        """åŸºäºå¤±è´¥åˆ†æç”Ÿæˆåˆ›æ–°æ€ç»´ç§å­"""
        if not self.llm_client:
            return self._heuristic_innovative_seed(user_query, failure_patterns)
        
        try:
            innovation_prompt = f"""
åŸºäºå¤±è´¥åˆ†æï¼Œé‡æ–°æ€è€ƒé—®é¢˜çš„è§£å†³æ–¹æ¡ˆï¼š

ğŸ¯ **åŸå§‹é—®é¢˜**: {user_query}

ğŸŒ± **åŸå§‹æ€ç»´ç§å­**: {original_seed[:200]}...

âŒ **éªŒè¯å¤±è´¥æ¨¡å¼**:
- å¤±è´¥è·¯å¾„æ•°: {failure_patterns.get('total_failed_paths', 0)}
- å¹³å‡å¯è¡Œæ€§: {failure_patterns.get('average_feasibility', 0):.2f}
- ä¸»è¦é£é™©: {failure_patterns.get('risk_patterns', [])}

ğŸ’¡ **åˆ›æ–°æ€è€ƒè¦æ±‚**:
1. é¿å¼€å·²éªŒè¯çš„å¤±è´¥æ¨¡å¼
2. ä»ä¸åŒè§’åº¦é‡æ–°å®šä¹‰é—®é¢˜
3. è€ƒè™‘éå¸¸è§„ã€åˆ›æ–°æ€§çš„è§£å†³è·¯å¾„
4. é™ä½å·²è¯†åˆ«çš„é£é™©å› ç´ 

è¯·ç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„åˆ›æ–°æ€ç»´ç§å­ï¼Œé¿å¼€å¤±è´¥æ¨¡å¼ï¼Œæä¾›åˆ›æ–°è§†è§’ï¼š
"""
            
            # ä½¿ç”¨æ­£ç¡®çš„LLMè°ƒç”¨æ¥å£
            if self.llm_manager:
                llm_result = self.llm_manager.chat_completion(innovation_prompt, temperature=0.8)
                if llm_result.success:
                    innovative_response = llm_result.content
                else:
                    raise Exception(f"LLMè°ƒç”¨å¤±è´¥: {llm_result.error_message}")
            elif self.llm_client:
                innovative_response = self.llm_client.call_api(innovation_prompt, temperature=0.8)
            else:
                raise Exception("æ²¡æœ‰å¯ç”¨çš„LLMå®¢æˆ·ç«¯")
            
            # ç®€å•æå–å“åº”å†…å®¹
            if len(innovative_response) > 50:
                return innovative_response
            else:
                return self._heuristic_innovative_seed(user_query, failure_patterns)
                
        except Exception as e:
            logger.warning(f"âš ï¸ LLMåˆ›æ–°ç§å­ç”Ÿæˆå¤±è´¥: {e}")
            return self._heuristic_innovative_seed(user_query, failure_patterns)
    
    def _heuristic_innovative_seed(self, user_query: str, failure_patterns: Dict) -> str:
        """å¯å‘å¼åˆ›æ–°ç§å­ç”Ÿæˆ"""
        innovation_approaches = [
            f"é‡æ–°å®šä¹‰é—®é¢˜è§’åº¦: {user_query}",
            f"é€†å‘æ€ç»´è§£å†³: {user_query}",
            f"è·¨é¢†åŸŸå€Ÿé‰´æ–¹æ³•: {user_query}",
            f"ç®€åŒ–åˆ°æ ¸å¿ƒéœ€æ±‚: {user_query}",
            f"åˆ†é˜¶æ®µæ¸è¿›è§£å†³: {user_query}"
        ]
        
        import random
        return random.choice(innovation_approaches)
    
    def _create_emergency_innovative_paths(self, user_query: str, failure_patterns: Dict) -> List:
        """åˆ›å»ºåº”æ€¥åˆ›æ–°è·¯å¾„"""
        from .data_structures import ReasoningPath
        
        emergency_paths = [
            ReasoningPath(
                path_id="emergency_innovative_1",
                path_type="é—®é¢˜é‡å®šä¹‰å‹",
                description="é‡æ–°å®šä¹‰é—®é¢˜çš„æ ¸å¿ƒéœ€æ±‚ï¼Œå¯»æ‰¾æ›´ç®€å•çš„è§£å†³æ–¹æ¡ˆ",
                prompt_template="è®©æˆ‘ä»¬é‡æ–°å®¡è§†è¿™ä¸ªé—®é¢˜çš„æœ¬è´¨éœ€æ±‚ï¼š{task}"
            ),
            ReasoningPath(
                path_id="emergency_innovative_2", 
                path_type="åˆ†æ­¥ç®€åŒ–å‹",
                description="å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºå¤šä¸ªç®€å•æ­¥éª¤",
                prompt_template="å°†å¤æ‚ä»»åŠ¡æ‹†åˆ†ä¸ºå¯ç®¡ç†çš„å­ä»»åŠ¡ï¼š{task}"
            ),
            ReasoningPath(
                path_id="emergency_innovative_3",
                path_type="æ›¿ä»£æ–¹æ¡ˆå‹", 
                description="å¯»æ‰¾å®ç°ç›¸åŒç›®æ ‡çš„æ›¿ä»£æ–¹æ³•",
                prompt_template="æ¢ç´¢è¾¾æˆç›®æ ‡çš„ä¸åŒè·¯å¾„ï¼š{task}"
            )
        ]
        
        return emergency_paths
    
    # ==================== å¤šLLMç®¡ç†æ–¹æ³• ====================
    
    def switch_llm_provider(self, provider_name: str) -> bool:
        """
        åˆ‡æ¢LLMæä¾›å•†
        
        Args:
            provider_name: æä¾›å•†åç§°
            
        Returns:
            bool: æ˜¯å¦åˆ‡æ¢æˆåŠŸ
        """
        if not self.llm_manager:
            logger.warning("âš ï¸ LLMç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•åˆ‡æ¢æä¾›å•†")
            return False
        
        success = self.llm_manager.switch_primary_provider(provider_name)
        if success:
            logger.info(f"ğŸ”„ å·²åˆ‡æ¢åˆ°LLMæä¾›å•†: {provider_name}")
        else:
            logger.error(f"âŒ åˆ‡æ¢LLMæä¾›å•†å¤±è´¥: {provider_name}")
        
        return success
    
    def get_llm_provider_status(self) -> Dict[str, Any]:
        """
        è·å–LLMæä¾›å•†çŠ¶æ€
        
        Returns:
            Dict[str, Any]: æä¾›å•†çŠ¶æ€ä¿¡æ¯
        """
        if not self.llm_manager:
            return {
                'initialized': False,
                'error': 'LLMç®¡ç†å™¨æœªåˆå§‹åŒ–',
                'fallback_mode': True,
                'available_providers': []
            }
        
        return self.llm_manager.get_provider_status()
    
    def get_available_llm_models(self, provider_name: Optional[str] = None) -> Dict[str, List[str]]:
        """
        è·å–å¯ç”¨çš„LLMæ¨¡å‹
        
        Args:
            provider_name: æä¾›å•†åç§°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Dict[str, List[str]]: æä¾›å•†å’Œå¯¹åº”çš„æ¨¡å‹åˆ—è¡¨
        """
        if not self.llm_manager:
            return {"error": "LLMç®¡ç†å™¨æœªåˆå§‹åŒ–"}
        
        return self.llm_manager.get_available_models(provider_name)
    
    def run_llm_health_check(self, force: bool = False) -> Dict[str, bool]:
        """
        è¿è¡ŒLLMæä¾›å•†å¥åº·æ£€æŸ¥
        
        Args:
            force: æ˜¯å¦å¼ºåˆ¶æ£€æŸ¥
            
        Returns:
            Dict[str, bool]: å„æä¾›å•†çš„å¥åº·çŠ¶æ€
        """
        if not self.llm_manager:
            return {"error": "LLMç®¡ç†å™¨æœªåˆå§‹åŒ–"}
        
        return self.llm_manager.health_check(force)
    
    def get_llm_cost_summary(self) -> Dict[str, Any]:
        """
        è·å–LLMä½¿ç”¨æˆæœ¬æ€»ç»“
        
        Returns:
            Dict[str, Any]: æˆæœ¬æ€»ç»“ä¿¡æ¯
        """
        if not self.llm_manager:
            return {"error": "LLMç®¡ç†å™¨æœªåˆå§‹åŒ–"}
        
        status = self.llm_manager.get_provider_status()
        cost_data = status.get('stats', {}).get('cost_tracking', {})
        
        total_cost = sum(cost_data.values())
        
        return {
            'total_cost_usd': total_cost,
            'cost_by_provider': dict(cost_data),
            'total_requests': status.get('stats', {}).get('total_requests', 0),
            'successful_requests': status.get('stats', {}).get('successful_requests', 0),
            'fallback_count': status.get('stats', {}).get('fallback_count', 0)
        }
    
    def _create_conservative_emergency_path(self, user_query: str):
        """åˆ›å»ºä¿å®ˆçš„åº”æ€¥è·¯å¾„"""
        from .data_structures import ReasoningPath
        
        return ReasoningPath(
            path_id="conservative_emergency",
            path_type="ä¿å®ˆåº”æ€¥å‹",
            description="ä½¿ç”¨æœ€åŸºç¡€ã€æœ€å¯é çš„æ–¹æ³•å¤„ç†é—®é¢˜",
            prompt_template="ä½¿ç”¨æœ€ç›´æ¥ã€æœ€åŸºç¡€çš„æ–¹æ³•å¤„ç†ï¼š{task}"
        )
