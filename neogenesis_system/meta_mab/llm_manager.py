#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
LLMÁÆ°ÁêÜÂô® - Áªü‰∏ÄÁÆ°ÁêÜÂ§ö‰∏™LLMÊèê‰æõÂïÜ
LLM Manager - Unified management for multiple LLM providers
"""

import os
import time
import logging
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass
from collections import defaultdict

from .llm_base import BaseLLMClient, LLMConfig, LLMProvider, LLMResponse, LLMMessage
from .providers import create_llm_client, get_available_providers, is_provider_available
from config import (
    LLM_PROVIDERS_CONFIG, DEFAULT_LLM_CONFIG, LLM_MANAGER_CONFIG, 
    COST_CONTROL_CONFIG, FEATURE_FLAGS
)

logger = logging.getLogger(__name__)


@dataclass
class ProviderStatus:
    """Êèê‰æõÂïÜÁä∂ÊÄÅ"""
    name: str
    enabled: bool
    healthy: bool
    last_check: float
    error_count: int
    success_count: int
    avg_response_time: float
    last_error: Optional[str] = None


class LLMManager:
    """
    LLMÁÆ°ÁêÜÂô® - Áªü‰∏ÄÁÆ°ÁêÜÂ§ö‰∏™LLMÊèê‰æõÂïÜ
    
    ÂäüËÉΩÔºö
    - Ëá™Âä®ÂèëÁé∞ÂíåÂàùÂßãÂåñÂèØÁî®ÁöÑLLMÊèê‰æõÂïÜ
    - Êô∫ËÉΩË∑ØÁî±ÂíåË¥üËΩΩÂùáË°°
    - Ëá™Âä®ÂõûÈÄÄÊú∫Âà∂
    - ÊàêÊú¨Ë∑üË∏™ÂíåÊéßÂà∂
    - ÂÅ•Â∫∑Ê£ÄÊü•ÂíåÁõëÊéß
    """
    
    def __init__(self):
        """ÂàùÂßãÂåñLLMÁÆ°ÁêÜÂô®"""
        self.providers: Dict[str, BaseLLMClient] = {}
        self.provider_status: Dict[str, ProviderStatus] = {}
        self.config = DEFAULT_LLM_CONFIG.copy()
        
        # ÊÄßËÉΩÁªüËÆ°
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'fallback_count': 0,
            'provider_usage': defaultdict(int),
            'cost_tracking': defaultdict(float),
            'request_history': []
        }
        
        # ÂàùÂßãÂåñÁä∂ÊÄÅ
        self.initialized = False
        self.last_health_check = 0
        
        logger.info("üöÄ LLMÁÆ°ÁêÜÂô®ÂàùÂßãÂåñÂºÄÂßã")
        self._initialize_providers()
        
    def _initialize_providers(self):
        """ÂàùÂßãÂåñÂèØÁî®ÁöÑÊèê‰æõÂïÜ"""
        if not FEATURE_FLAGS.get("enable_multi_llm_support", False):
            logger.info("üìã Â§öLLMÊîØÊåÅÂ∑≤Á¶ÅÁî®Ôºå‰ªÖ‰ΩøÁî®DeepSeek")
            self._initialize_single_provider()
            return
        
        initialized_count = 0
        
        for provider_name, provider_config in LLM_PROVIDERS_CONFIG.items():
            try:
                if not provider_config.get("enabled", False):
                    logger.debug(f"‚è≠Ô∏è Ë∑≥ËøáÁ¶ÅÁî®ÁöÑÊèê‰æõÂïÜ: {provider_name}")
                    continue
                
                # Ê£ÄÊü•APIÂØÜÈí•
                api_key_env = provider_config.get("api_key_env")
                api_key = ""
                
                if api_key_env:
                    api_key = os.getenv(api_key_env, "")
                    if not api_key:
                        logger.warning(f"‚ö†Ô∏è Êú™ÊâæÂà∞{provider_name}ÁöÑAPIÂØÜÈí•: {api_key_env}")
                        continue
                
                # ÂàõÂª∫LLMÈÖçÁΩÆ
                llm_config = self._create_llm_config(provider_name, provider_config, api_key)
                
                # ÂàõÂª∫ÂÆ¢Êà∑Á´Ø
                client = create_llm_client(llm_config.provider, llm_config)
                
                # Âø´ÈÄüÂÅ•Â∫∑Ê£ÄÊü•
                if self._quick_health_check(client, provider_name):
                    self.providers[provider_name] = client
                    self.provider_status[provider_name] = ProviderStatus(
                        name=provider_name,
                        enabled=True,
                        healthy=True,
                        last_check=time.time(),
                        error_count=0,
                        success_count=1,
                        avg_response_time=0.0
                    )
                    initialized_count += 1
                    logger.info(f"‚úÖ {provider_name}Êèê‰æõÂïÜÂàùÂßãÂåñÊàêÂäü")
                else:
                    logger.warning(f"‚ùå {provider_name}Êèê‰æõÂïÜÂÅ•Â∫∑Ê£ÄÊü•Â§±Ë¥•")
                    
            except Exception as e:
                logger.error(f"‚ùå ÂàùÂßãÂåñ{provider_name}Êèê‰æõÂïÜÂ§±Ë¥•: {e}")
                continue
        
        if initialized_count == 0:
            logger.warning("‚ö†Ô∏è Ê≤°ÊúâÂèØÁî®ÁöÑLLMÊèê‰æõÂïÜÔºåÂõûÈÄÄÂà∞Âçï‰∏ÄÊèê‰æõÂïÜÊ®°Âºè")
            self._initialize_single_provider()
        else:
            logger.info(f"üéâ LLMÁÆ°ÁêÜÂô®ÂàùÂßãÂåñÂÆåÊàêÔºåÂèØÁî®Êèê‰æõÂïÜ: {initialized_count}‰∏™")
            self.initialized = True
    
    def _initialize_single_provider(self):
        """ÂàùÂßãÂåñÂçï‰∏ÄÊèê‰æõÂïÜÔºàDeepSeekÔºâ"""
        try:
            from .utils.client_adapter import get_or_create_unified_client
            
            api_key = os.getenv("DEEPSEEK_API_KEY", "")
            if not api_key:
                logger.error("‚ùå Êú™ÊâæÂà∞DEEPSEEK_API_KEYÁéØÂ¢ÉÂèòÈáè")
                return
            
            client = get_or_create_unified_client(api_key)
            self.providers["deepseek"] = client
            self.provider_status["deepseek"] = ProviderStatus(
                name="deepseek",
                enabled=True,
                healthy=True,
                last_check=time.time(),
                error_count=0,
                success_count=1,
                avg_response_time=0.0
            )
            
            logger.info("‚úÖ Âçï‰∏ÄÊèê‰æõÂïÜÊ®°ÂºèÂàùÂßãÂåñÊàêÂäü (DeepSeek)")
            self.initialized = True
            
        except Exception as e:
            logger.error(f"‚ùå Âçï‰∏ÄÊèê‰æõÂïÜÂàùÂßãÂåñÂ§±Ë¥•: {e}")
    
    def _create_llm_config(self, provider_name: str, provider_config: Dict, api_key: str) -> LLMConfig:
        """ÂàõÂª∫LLMÈÖçÁΩÆ"""
        provider_type = provider_config["provider_type"]
        provider_enum = LLMProvider(provider_type)
        
        # ÁâπÊÆäÂ§ÑÁêÜAzure OpenAI
        extra_params = {}
        base_url = provider_config.get("base_url")
        
        if provider_type == "azure_openai":
            azure_endpoint = os.getenv(provider_config.get("azure_endpoint_env", ""), "")
            if azure_endpoint:
                base_url = azure_endpoint
                extra_params["api_version"] = provider_config.get("api_version", "2024-02-15-preview")
        
        return LLMConfig(
            provider=provider_enum,
            api_key=api_key,
            model_name=provider_config["default_model"],
            temperature=provider_config.get("temperature", 0.7),
            max_tokens=provider_config.get("max_tokens", 2000),
            base_url=base_url,
            timeout=tuple(provider_config.get("timeout", (30, 120))),
            max_retries=provider_config.get("max_retries", 3),
            retry_delay_base=provider_config.get("retry_delay_base", 2.0),
            request_interval=provider_config.get("request_interval", 1.0),
            extra_params=extra_params
        )
    
    def _quick_health_check(self, client: BaseLLMClient, provider_name: str) -> bool:
        """Âø´ÈÄüÂÅ•Â∫∑Ê£ÄÊü•"""
        try:
            # ÁÆÄÂçïÁöÑÈÖçÁΩÆÈ™åËØÅ
            return client.validate_config()
        except Exception as e:
            logger.debug(f"üîç {provider_name}ÂÅ•Â∫∑Ê£ÄÊü•Â§±Ë¥•: {e}")
            return False
    
    def call_api(self, prompt: str, 
                 system_message: Optional[str] = None,
                 temperature: Optional[float] = None,
                 **kwargs) -> str:
        """
        ÁÆÄÂåñÁöÑAPIË∞ÉÁî®Êé•Âè£ - ÂÖºÂÆπÁé∞Êúâ‰ª£Á†Å
        
        Args:
            prompt: Áî®Êà∑ÊèêÁ§∫
            system_message: Á≥ªÁªüÊ∂àÊÅØ
            temperature: Ê∏©Â∫¶ÂèÇÊï∞
            **kwargs: ÂÖ∂‰ªñÂèÇÊï∞
            
        Returns:
            str: LLMÂìçÂ∫îÂÜÖÂÆπ
            
        Raises:
            Exception: Ë∞ÉÁî®Â§±Ë¥•Êó∂ÊäõÂá∫ÂºÇÂ∏∏
        """
        try:
            # ÊûÑÂª∫Ê∂àÊÅØÊ†ºÂºè
            messages = []
            if system_message:
                messages.append(LLMMessage(role="system", content=system_message))
            messages.append(LLMMessage(role="user", content=prompt))
            
            # Ë∞ÉÁî®chat_completion
            response = self.chat_completion(
                messages=messages,
                temperature=temperature,
                **kwargs
            )
            
            if response.success:
                return response.content
            else:
                raise Exception(f"LLMË∞ÉÁî®Â§±Ë¥•: {response.error_message}")
                
        except Exception as e:
            logger.error(f"‚ùå LLM APIË∞ÉÁî®Â§±Ë¥•: {e}")
            raise
    
    def chat_completion(self, 
                       messages: Union[str, List[LLMMessage]], 
                       provider_name: Optional[str] = None,
                       temperature: Optional[float] = None,
                       **kwargs) -> LLMResponse:
        """
        ËÅäÂ§©ÂÆåÊàê - Êô∫ËÉΩË∑ØÁî±Âà∞ÊúÄ‰Ω≥Êèê‰æõÂïÜ
        
        Args:
            messages: Ê∂àÊÅØÂÜÖÂÆπ
            provider_name: ÊåáÂÆöÊèê‰æõÂïÜÔºàÂèØÈÄâÔºâ
            **kwargs: ÂÖ∂‰ªñÂèÇÊï∞
            
        Returns:
            LLMResponse: Áªü‰∏ÄÂìçÂ∫î
        """
        self.stats['total_requests'] += 1
        
        if not self.initialized or not self.providers:
            return self._create_error_response("Ê≤°ÊúâÂèØÁî®ÁöÑLLMÊèê‰æõÂïÜ")
        
        # Â§ÑÁêÜÁõ¥Êé•‰º†ÂÖ•Â≠óÁ¨¶‰∏≤ÁöÑÊÉÖÂÜµ
        if isinstance(messages, str):
            messages = [LLMMessage(role="user", content=messages)]
        
        # ÈÄâÊã©Êèê‰æõÂïÜ
        selected_provider = self._select_provider(provider_name)
        if not selected_provider:
            return self._create_error_response("Êó†Ê≥ïÈÄâÊã©ÂêàÈÄÇÁöÑÊèê‰æõÂïÜ")
        
        # Ê∑ªÂä†temperatureÂà∞kwargs‰∏≠
        if temperature is not None:
            kwargs['temperature'] = temperature
        
        # ÊâßË°åËØ∑Ê±ÇÔºàÂ∏¶ÂõûÈÄÄÊú∫Âà∂Ôºâ
        return self._execute_with_fallback(selected_provider, messages, **kwargs)
    
    def _select_provider(self, preferred_provider: Optional[str] = None) -> Optional[str]:
        """ÈÄâÊã©Êèê‰æõÂïÜ"""
        # Â¶ÇÊûúÊåáÂÆö‰∫ÜÊèê‰æõÂïÜ‰∏îÂèØÁî®ÔºåÁõ¥Êé•‰ΩøÁî®
        if preferred_provider and preferred_provider in self.providers:
            if self.provider_status[preferred_provider].healthy:
                return preferred_provider
        
        # Ê£ÄÊü•‰∏ªË¶ÅÊèê‰æõÂïÜËÆæÁΩÆ
        primary = self.config.get("primary_provider", "auto")
        
        if primary == "auto":
            # Ëá™Âä®ÈÄâÊã©ÔºöÊåâÈ¶ñÈÄâÈ°∫Â∫èÈÄâÊã©Á¨¨‰∏Ä‰∏™ÂèØÁî®ÁöÑÊèê‰æõÂïÜ
            preferred_order = self.config.get("preferred_providers", ["deepseek", "openai", "anthropic"])
            for provider_name in preferred_order:
                if provider_name in self.providers and self.provider_status[provider_name].healthy:
                    return provider_name
        else:
            # ‰ΩøÁî®ÊåáÂÆöÁöÑ‰∏ªË¶ÅÊèê‰æõÂïÜ
            if primary in self.providers and self.provider_status[primary].healthy:
                return primary
        
        # ‰ΩøÁî®Á¨¨‰∏Ä‰∏™ÂÅ•Â∫∑ÁöÑÊèê‰æõÂïÜ
        for name, status in self.provider_status.items():
            if status.healthy and name in self.providers:
                return name
        
        return None
    
    def _execute_with_fallback(self, provider_name: str, messages: Union[str, List[LLMMessage]], **kwargs) -> LLMResponse:
        """ÊâßË°åËØ∑Ê±ÇÔºàÂ∏¶ÂõûÈÄÄÊú∫Âà∂Ôºâ"""
        providers_to_try = [provider_name]
        
        # Ê∑ªÂä†ÂõûÈÄÄÊèê‰æõÂïÜ
        if self.config.get("auto_fallback", True):
            fallback_providers = self.config.get("fallback_providers", [])
            for fallback in fallback_providers:
                if fallback != provider_name and fallback in self.providers:
                    providers_to_try.append(fallback)
        
        last_error = None
        
        for current_provider in providers_to_try:
            try:
                if not self.provider_status[current_provider].healthy:
                    continue
                
                start_time = time.time()
                client = self.providers[current_provider]
                
                logger.info(f"ü§ñ ‰ΩøÁî®Êèê‰æõÂïÜ: {current_provider}")
                response = client.chat_completion(messages, **kwargs)
                
                response_time = time.time() - start_time
                
                if response.success:
                    # Êõ¥Êñ∞ÁªüËÆ°
                    self._update_provider_stats(current_provider, True, response_time)
                    self.stats['successful_requests'] += 1
                    self.stats['provider_usage'][current_provider] += 1
                    
                    # ÊàêÊú¨Ë∑üË∏™
                    if response.usage and COST_CONTROL_CONFIG.get("token_usage_tracking", True):
                        self._track_cost(current_provider, response.usage)
                    
                    return response
                else:
                    # ËÆ∞ÂΩïÂ§±Ë¥•‰ΩÜÁªßÁª≠Â∞ùËØï‰∏ã‰∏Ä‰∏™Êèê‰æõÂïÜ
                    self._update_provider_stats(current_provider, False, response_time)
                    last_error = response.error_message
                    logger.warning(f"‚ö†Ô∏è {current_provider}ËØ∑Ê±ÇÂ§±Ë¥•: {last_error}")
                    
                    if len(providers_to_try) > 1:
                        self.stats['fallback_count'] += 1
                        continue
                    else:
                        return response
                        
            except Exception as e:
                self._update_provider_stats(current_provider, False, 0)
                last_error = str(e)
                logger.error(f"‚ùå {current_provider}ÊâßË°åÂºÇÂ∏∏: {e}")
                continue
        
        # ÊâÄÊúâÊèê‰æõÂïÜÈÉΩÂ§±Ë¥•
        self.stats['failed_requests'] += 1
        return self._create_error_response(f"ÊâÄÊúâÊèê‰æõÂïÜÈÉΩ‰∏çÂèØÁî®: {last_error}")
    
    def _update_provider_stats(self, provider_name: str, success: bool, response_time: float):
        """Êõ¥Êñ∞Êèê‰æõÂïÜÁªüËÆ°"""
        if provider_name not in self.provider_status:
            return
        
        status = self.provider_status[provider_name]
        status.last_check = time.time()
        
        if success:
            status.success_count += 1
            status.error_count = 0  # ÈáçÁΩÆÈîôËØØËÆ°Êï∞
            status.healthy = True
            
            # Êõ¥Êñ∞Âπ≥ÂùáÂìçÂ∫îÊó∂Èó¥
            if status.avg_response_time == 0:
                status.avg_response_time = response_time
            else:
                status.avg_response_time = (status.avg_response_time + response_time) / 2
        else:
            status.error_count += 1
            
            # ËøûÁª≠ÈîôËØØËøáÂ§öÊó∂Ê†áËÆ∞‰∏∫‰∏çÂÅ•Â∫∑
            if status.error_count >= 3:
                status.healthy = False
                logger.warning(f"‚ö†Ô∏è {provider_name}Ë¢´Ê†áËÆ∞‰∏∫‰∏çÂÅ•Â∫∑")
    
    def _track_cost(self, provider_name: str, usage):
        """Ë∑üË∏™ÊàêÊú¨"""
        try:
            provider_config = LLM_PROVIDERS_CONFIG.get(provider_name, {})
            cost_per_1k = provider_config.get("cost_per_1k_tokens", {})
            
            input_cost = (usage.prompt_tokens / 1000) * cost_per_1k.get("input", 0)
            output_cost = (usage.completion_tokens / 1000) * cost_per_1k.get("output", 0)
            total_cost = input_cost + output_cost
            
            self.stats['cost_tracking'][provider_name] += total_cost
            
            logger.debug(f"üí∞ {provider_name}ÊàêÊú¨: ${total_cost:.6f}")
            
        except Exception as e:
            logger.debug(f"‚ùå ÊàêÊú¨Ë∑üË∏™Â§±Ë¥•: {e}")
    
    def _create_error_response(self, error_message: str) -> LLMResponse:
        """ÂàõÂª∫ÈîôËØØÂìçÂ∫î"""
        from .llm_base import LLMErrorType, create_error_response
        return create_error_response(
            provider="llm_manager",
            error_type=LLMErrorType.UNKNOWN_ERROR,
            error_message=error_message
        )
    
    def get_provider_status(self) -> Dict[str, Any]:
        """Ëé∑ÂèñÊèê‰æõÂïÜÁä∂ÊÄÅ"""
        return {
            'initialized': self.initialized,
            'total_providers': len(self.providers),
            'healthy_providers': sum(1 for s in self.provider_status.values() if s.healthy),
            'providers': {name: {
                'enabled': status.enabled,
                'healthy': status.healthy,
                'success_count': status.success_count,
                'error_count': status.error_count,
                'avg_response_time': status.avg_response_time,
                'last_error': status.last_error
            } for name, status in self.provider_status.items()},
            'stats': self.stats.copy()
        }
    
    def get_available_models(self, provider_name: Optional[str] = None) -> Dict[str, List[str]]:
        """Ëé∑ÂèñÂèØÁî®Ê®°Âûã"""
        if provider_name:
            if provider_name in self.providers:
                return {provider_name: self.providers[provider_name].get_available_models()}
            else:
                return {}
        
        return {
            name: client.get_available_models() 
            for name, client in self.providers.items()
        }
    
    def switch_primary_provider(self, provider_name: str) -> bool:
        """ÂàáÊç¢‰∏ªË¶ÅÊèê‰æõÂïÜ"""
        if provider_name in self.providers and self.provider_status[provider_name].healthy:
            self.config["primary_provider"] = provider_name
            logger.info(f"üîÑ ‰∏ªË¶ÅÊèê‰æõÂïÜÂ∑≤ÂàáÊç¢Âà∞: {provider_name}")
            return True
        return False
    
    def health_check(self, force: bool = False) -> Dict[str, bool]:
        """ÂÅ•Â∫∑Ê£ÄÊü•"""
        current_time = time.time()
        check_interval = LLM_MANAGER_CONFIG.get("health_check_interval", 300)
        
        if not force and (current_time - self.last_health_check) < check_interval:
            return {name: status.healthy for name, status in self.provider_status.items()}
        
        logger.info("üîç ÊâßË°åLLMÊèê‰æõÂïÜÂÅ•Â∫∑Ê£ÄÊü•")
        results = {}
        
        for name, client in self.providers.items():
            try:
                healthy = self._quick_health_check(client, name)
                self.provider_status[name].healthy = healthy
                results[name] = healthy
                logger.debug(f"üîç {name}: {'‚úÖ' if healthy else '‚ùå'}")
            except Exception as e:
                self.provider_status[name].healthy = False
                results[name] = False
                logger.error(f"üîç {name}ÂÅ•Â∫∑Ê£ÄÊü•ÂºÇÂ∏∏: {e}")
        
        self.last_health_check = current_time
        return results
