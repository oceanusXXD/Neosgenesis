#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Neogenesis System - Advanced Chains
é«˜çº§å†³ç­–é“¾ï¼šæ™ºèƒ½åè°ƒçš„äº”é˜¶æ®µå†³ç­–æµç¨‹
"""

import asyncio
import json
import logging
import time
from typing import Any, Dict, List, Optional, Union

try:
    from langchain.chains.base import Chain
    from langchain.callbacks.manager import CallbackManagerForChainRun
    from pydantic import BaseModel, Field
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    
    class BaseModel:
        pass
    
    class Chain:
        input_keys: List[str] = []
        output_keys: List[str] = []
        
        def _call(self, inputs: Dict[str, Any], run_manager=None) -> Dict[str, Any]:
            raise NotImplementedError

from .coordinators import (
    NeogenesisToolCoordinator,
    ExecutionContext,
    ExecutionMode,
    PerformanceOptimizer
)
from .state_management import NeogenesisStateManager, DecisionStage

logger = logging.getLogger(__name__)

# =============================================================================
# é«˜çº§è¾“å…¥æ¨¡å‹
# =============================================================================

class AdvancedDecisionInput(BaseModel):
    """é«˜çº§å†³ç­–é“¾è¾“å…¥æ¨¡å‹"""
    user_query: str = Field(description="ç”¨æˆ·æŸ¥è¯¢")
    execution_context: Optional[Dict[str, Any]] = Field(
        default=None,
        description="æ‰§è¡Œä¸Šä¸‹æ–‡"
    )
    execution_mode: str = Field(
        default="adaptive",
        description="æ‰§è¡Œæ¨¡å¼ï¼šsequential, parallel, adaptive, pipeline"
    )
    enable_verification: bool = Field(
        default=True,
        description="æ˜¯å¦å¯ç”¨éªŒè¯"
    )
    enable_caching: bool = Field(
        default=True,
        description="æ˜¯å¦å¯ç”¨ç¼“å­˜"
    )
    max_paths: int = Field(
        default=4,
        description="æœ€å¤§æ€ç»´è·¯å¾„æ•°"
    )
    timeout: float = Field(
        default=120.0,
        description="æ€»è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰"
    )
    priority_mode: str = Field(
        default="balanced",
        description="ä¼˜å…ˆçº§æ¨¡å¼ï¼šspeed, quality, balanced"
    )
    fallback_enabled: bool = Field(
        default=True,
        description="æ˜¯å¦å¯ç”¨å›é€€æœºåˆ¶"
    )

# =============================================================================
# æ™ºèƒ½åè°ƒå†³ç­–é“¾
# =============================================================================

class SmartCoordinatedChain(Chain):
    """
    æ™ºèƒ½åè°ƒå†³ç­–é“¾
    
    ç‰¹æ€§ï¼š
    - æ™ºèƒ½å·¥å…·åè°ƒå’Œæ‰§è¡Œç­–ç•¥é€‰æ‹©
    - è‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–
    - é«˜çº§é”™è¯¯å¤„ç†å’Œæ¢å¤
    - å®æ—¶çŠ¶æ€ç›‘æ§
    - çµæ´»çš„æ‰§è¡Œæ¨¡å¼åˆ‡æ¢
    """
    
    coordinator: NeogenesisToolCoordinator
    state_manager: Optional[NeogenesisStateManager] = None
    performance_optimizer: PerformanceOptimizer
    enable_async: bool = True
    
    # Chainæ¥å£è¦æ±‚
    input_keys: List[str] = ["user_query"]
    output_keys: List[str] = ["smart_decision_result"]
    
    def __init__(self,
                 api_key: str = "",
                 search_engine: str = "duckduckgo",
                 llm_client=None,
                 web_search_client=None,
                 enable_state_management: bool = True,
                 storage_path: str = "./smart_chain_state",
                 max_workers: int = 4,
                 **kwargs):
        """
        åˆå§‹åŒ–æ™ºèƒ½åè°ƒå†³ç­–é“¾
        
        Args:
            api_key: APIå¯†é’¥
            search_engine: æœç´¢å¼•æ“ç±»å‹
            llm_client: LLMå®¢æˆ·ç«¯
            web_search_client: ç½‘ç»œæœç´¢å®¢æˆ·ç«¯
            enable_state_management: æ˜¯å¦å¯ç”¨çŠ¶æ€ç®¡ç†
            storage_path: çŠ¶æ€å­˜å‚¨è·¯å¾„
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
            **kwargs: å…¶ä»–å‚æ•°
        """
        # åˆå§‹åŒ–çŠ¶æ€ç®¡ç†å™¨
        state_manager = None
        if enable_state_management:
            try:
                state_manager = NeogenesisStateManager(storage_path=storage_path)
            except Exception as e:
                logger.warning(f"âš ï¸ çŠ¶æ€ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆå§‹åŒ–åè°ƒå™¨
        coordinator = NeogenesisToolCoordinator(
            api_key=api_key,
            search_engine=search_engine,
            llm_client=llm_client,
            web_search_client=web_search_client,
            state_manager=state_manager,
            max_workers=max_workers
        )
        
        # åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–å™¨
        performance_optimizer = PerformanceOptimizer()
        
        super().__init__(
            coordinator=coordinator,
            state_manager=state_manager,
            performance_optimizer=performance_optimizer,
            **kwargs
        )
        
        logger.info("ğŸ¯ SmartCoordinatedChain åˆå§‹åŒ–å®Œæˆ")
    
    def _call(self,
              inputs: Dict[str, Any],
              run_manager: Optional[CallbackManagerForChainRun] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ™ºèƒ½åè°ƒå†³ç­–é“¾
        
        Args:
            inputs: è¾“å…¥å­—å…¸
            run_manager: LangChainå›è°ƒç®¡ç†å™¨
            
        Returns:
            å†³ç­–ç»“æœå­—å…¸
        """
        # è§£æè¾“å…¥
        user_query = inputs["user_query"]
        execution_context_raw = inputs.get("execution_context", {})
        execution_mode = inputs.get("execution_mode", "adaptive")
        enable_verification = inputs.get("enable_verification", True)
        enable_caching = inputs.get("enable_caching", True)
        max_paths = inputs.get("max_paths", 4)
        timeout = inputs.get("timeout", 120.0)
        priority_mode = inputs.get("priority_mode", "balanced")
        fallback_enabled = inputs.get("fallback_enabled", True)
        
        session_id = f"smart_chain_{int(time.time() * 1000)}"
        
        logger.info(f"ğŸš€ å¼€å§‹æ™ºèƒ½åè°ƒå†³ç­–: {user_query[:50]}...")
        logger.info(f"   æ¨¡å¼: {execution_mode}, éªŒè¯: {enable_verification}, ç¼“å­˜: {enable_caching}")
        
        try:
            # åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
            context = ExecutionContext(
                session_id=session_id,
                user_query=user_query,
                execution_mode=ExecutionMode(execution_mode),
                timeout=timeout,
                enable_caching=enable_caching,
                enable_verification=enable_verification,
                fallback_enabled=fallback_enabled,
                custom_config={
                    "max_paths": max_paths,
                    "priority_mode": priority_mode,
                    **execution_context_raw
                }
            )
            
            # æ ¹æ®ä¼˜å…ˆçº§æ¨¡å¼è°ƒæ•´ç­–ç•¥
            context = self._apply_priority_mode(context, priority_mode)
            
            # åˆ›å»ºæ‰§è¡Œè®¡åˆ’
            execution_plan = self.coordinator.create_execution_plan(context)
            
            # æ‰§è¡Œè®¡åˆ’
            if self.enable_async:
                # å¼‚æ­¥æ‰§è¡Œ
                results = asyncio.run(
                    self.coordinator.execute_plan_async(execution_plan, context)
                )
            else:
                # åŒæ­¥æ‰§è¡Œï¼ˆç®€åŒ–ç‰ˆï¼‰
                results = self._execute_plan_sync(execution_plan, context)
            
            # åˆ†ææ‰§è¡Œç»“æœ
            decision_analysis = self._analyze_execution_results(results, context)
            
            # ç”Ÿæˆæœ€ç»ˆå†³ç­–
            final_decision = self._generate_final_decision(results, decision_analysis, context)
            
            # æ€§èƒ½åˆ†æ
            performance_analysis = self.performance_optimizer.analyze_performance(self.coordinator)
            
            # æ„å»ºè¿”å›ç»“æœ
            smart_result = {
                "decision_success": decision_analysis["overall_success"],
                "session_id": session_id,
                "user_query": user_query,
                "execution_mode": execution_mode,
                "execution_context": context.custom_config,
                
                # æ ¸å¿ƒå†³ç­–ç»“æœ
                "final_decision": final_decision,
                "thinking_seed": decision_analysis.get("thinking_seed"),
                "reasoning_paths": decision_analysis.get("reasoning_paths", []),
                "verification_results": decision_analysis.get("verification_results", {}),
                
                # æ‰§è¡Œè¯¦æƒ…
                "execution_details": {
                    "total_tools_executed": len(results),
                    "successful_tools": sum(1 for r in results.values() if r.success),
                    "failed_tools": sum(1 for r in results.values() if not r.success),
                    "total_execution_time": sum(r.execution_time for r in results.values()),
                    "cache_hits": sum(1 for r in results.values() if r.cache_hit),
                    "execution_plan_steps": len(execution_plan)
                },
                
                # æ€§èƒ½å’Œä¼˜åŒ–
                "performance_analysis": performance_analysis,
                "optimization_recommendations": performance_analysis.get("recommendations", []),
                
                # å…ƒæ•°æ®
                "chain_metadata": {
                    "chain_type": "SmartCoordinatedChain",
                    "execution_timestamp": time.time(),
                    "langchain_integration": True,
                    "async_execution": self.enable_async,
                    "state_management_enabled": self.state_manager is not None
                }
            }
            
            # å®Œæˆä¼šè¯çŠ¶æ€
            if self.state_manager:
                self.state_manager.complete_session(session_id, smart_result)
            
            logger.info("âœ… æ™ºèƒ½åè°ƒå†³ç­–é“¾æ‰§è¡Œå®Œæˆ")
            return {"smart_decision_result": smart_result}
            
        except Exception as e:
            error_msg = f"æ™ºèƒ½åè°ƒå†³ç­–é“¾æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            
            # é”™è¯¯å¤„ç†
            error_result = {
                "decision_success": False,
                "error": error_msg,
                "session_id": session_id,
                "user_query": user_query,
                "execution_mode": execution_mode,
                "chain_metadata": {
                    "chain_type": "SmartCoordinatedChain",
                    "error_timestamp": time.time(),
                    "error_details": str(e)
                }
            }
            
            return {"smart_decision_result": error_result}
    
    def _apply_priority_mode(self, context: ExecutionContext, priority_mode: str) -> ExecutionContext:
        """æ ¹æ®ä¼˜å…ˆçº§æ¨¡å¼è°ƒæ•´æ‰§è¡Œç­–ç•¥"""
        if priority_mode == "speed":
            # é€Ÿåº¦ä¼˜å…ˆï¼šå¹¶è¡Œæ‰§è¡Œï¼Œå‡å°‘éªŒè¯ï¼Œshorter timeout
            context.execution_mode = ExecutionMode.PARALLEL
            context.enable_verification = False
            context.timeout = min(context.timeout, 60.0)
            context.max_parallel_tools = 4
            
        elif priority_mode == "quality":
            # è´¨é‡ä¼˜å…ˆï¼šå®Œæ•´éªŒè¯ï¼Œlonger timeoutï¼Œæ›´å¤šè·¯å¾„
            context.execution_mode = ExecutionMode.SEQUENTIAL
            context.enable_verification = True
            context.timeout = max(context.timeout, 180.0)
            context.custom_config["max_paths"] = max(context.custom_config.get("max_paths", 4), 6)
            
        elif priority_mode == "balanced":
            # å¹³è¡¡æ¨¡å¼ï¼šè‡ªé€‚åº”æ‰§è¡Œ
            context.execution_mode = ExecutionMode.ADAPTIVE
            context.enable_verification = True
            
        return context
    
    def _execute_plan_sync(self, 
                          execution_plan: List,
                          context: ExecutionContext) -> Dict[str, Any]:
        """åŒæ­¥æ‰§è¡Œè®¡åˆ’ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        results = {}
        
        for tool_plan in execution_plan:
            try:
                # æ£€æŸ¥ä¾èµ–
                dependencies_met = all(
                    dep in results and results[dep].success
                    for dep in tool_plan.dependencies
                )
                
                if not dependencies_met and tool_plan.dependencies:
                    logger.warning(f"âš ï¸ è·³è¿‡å·¥å…· {tool_plan.tool_name}ï¼šä¾èµ–æœªæ»¡è¶³")
                    continue
                
                # å‡†å¤‡è¾“å…¥
                tool_input = self.coordinator._prepare_tool_input(tool_plan, context, results)
                
                # æ‰§è¡Œå·¥å…·
                start_time = time.time()
                result_data = tool_plan.tool_instance.run(**tool_input)
                execution_time = time.time() - start_time
                
                # åˆ›å»ºç»“æœ
                from .coordinators import ExecutionResult
                result = ExecutionResult(
                    tool_name=tool_plan.tool_name,
                    stage=tool_plan.stage,
                    success=True,
                    data=result_data,
                    execution_time=execution_time
                )
                
                results[tool_plan.tool_name] = result
                logger.info(f"âœ… åŒæ­¥æ‰§è¡Œå·¥å…·: {tool_plan.tool_name}")
                
            except Exception as e:
                logger.error(f"âŒ åŒæ­¥æ‰§è¡Œå·¥å…·å¤±è´¥: {tool_plan.tool_name} - {e}")
                from .coordinators import ExecutionResult
                result = ExecutionResult(
                    tool_name=tool_plan.tool_name,
                    stage=tool_plan.stage,
                    success=False,
                    error_message=str(e),
                    execution_time=0.0
                )
                results[tool_plan.tool_name] = result
        
        return results
    
    def _analyze_execution_results(self, 
                                 results: Dict[str, Any],
                                 context: ExecutionContext) -> Dict[str, Any]:
        """åˆ†ææ‰§è¡Œç»“æœ"""
        analysis = {
            "overall_success": True,
            "successful_stages": [],
            "failed_stages": [],
            "thinking_seed": None,
            "reasoning_paths": [],
            "verification_results": {},
            "performance_metrics": {}
        }
        
        # åˆ†æå„å·¥å…·ç»“æœ
        for tool_name, result in results.items():
            if result.success:
                analysis["successful_stages"].append(tool_name)
                
                # æå–å…³é”®æ•°æ®
                if tool_name in ["thinking_seed", "rag_seed"]:
                    try:
                        data = json.loads(result.data) if isinstance(result.data, str) else result.data
                        analysis["thinking_seed"] = data.get("thinking_seed") or data.get("rag_enhanced_seed")
                    except:
                        analysis["thinking_seed"] = str(result.data)
                        
                elif tool_name == "path_generator":
                    try:
                        data = json.loads(result.data) if isinstance(result.data, str) else result.data
                        analysis["reasoning_paths"] = data.get("reasoning_paths", [])
                    except:
                        pass
                        
                elif tool_name == "idea_verification":
                    try:
                        data = json.loads(result.data) if isinstance(result.data, str) else result.data
                        analysis["verification_results"][result.stage.value] = data
                    except:
                        pass
            else:
                analysis["failed_stages"].append(tool_name)
                analysis["overall_success"] = False
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        total_time = sum(r.execution_time for r in results.values())
        cache_hits = sum(1 for r in results.values() if getattr(r, 'cache_hit', False))
        
        analysis["performance_metrics"] = {
            "total_execution_time": total_time,
            "average_tool_time": total_time / len(results) if results else 0,
            "cache_hit_rate": cache_hits / len(results) if results else 0,
            "success_rate": len(analysis["successful_stages"]) / len(results) if results else 0
        }
        
        return analysis
    
    def _generate_final_decision(self,
                               results: Dict[str, Any],
                               analysis: Dict[str, Any],
                               context: ExecutionContext) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆå†³ç­–"""
        # æ£€æŸ¥MABå†³ç­–ç»“æœ
        mab_result = results.get("mab_decision")
        if mab_result and mab_result.success:
            try:
                mab_data = json.loads(mab_result.data) if isinstance(mab_result.data, str) else mab_result.data
                selected_path = mab_data.get("selected_path", {})
                mab_statistics = mab_data.get("mab_statistics", {})
                
                return {
                    "decision_type": "mab_optimized",
                    "selected_strategy": selected_path,
                    "confidence_score": mab_statistics.get("confidence_score", 0.8),
                    "decision_reasoning": "åŸºäºå¤šè‡‚è€è™æœºç®—æ³•çš„æ™ºèƒ½é€‰æ‹©",
                    "alternative_paths": analysis.get("reasoning_paths", []),
                    "verification_support": analysis.get("verification_results", {}),
                    "optimization_level": "high"
                }
            except:
                pass
        
        # å›é€€åˆ°è·¯å¾„é€‰æ‹©
        reasoning_paths = analysis.get("reasoning_paths", [])
        if reasoning_paths:
            # é€‰æ‹©ç¬¬ä¸€ä¸ªè·¯å¾„ä½œä¸ºé»˜è®¤å†³ç­–
            selected_path = reasoning_paths[0]
            
            return {
                "decision_type": "path_based",
                "selected_strategy": selected_path,
                "confidence_score": 0.6,
                "decision_reasoning": "åŸºäºè·¯å¾„ç”Ÿæˆçš„é»˜è®¤é€‰æ‹©",
                "alternative_paths": reasoning_paths[1:],
                "verification_support": analysis.get("verification_results", {}),
                "optimization_level": "medium"
            }
        
        # æœ€ç»ˆå›é€€
        return {
            "decision_type": "fallback",
            "selected_strategy": {
                "path_type": "é€šç”¨åˆ†æå‹",
                "description": f"é’ˆå¯¹'{context.user_query}'é‡‡ç”¨ç³»ç»Ÿæ€§åˆ†ææ–¹æ³•",
                "approach": "åŸºç¡€é—®é¢˜åˆ†æå’Œè§£å†³æ–¹æ¡ˆåˆ¶å®š"
            },
            "confidence_score": 0.4,
            "decision_reasoning": "ç³»ç»Ÿå›é€€åˆ°åŸºç¡€åˆ†ææ–¹æ³•",
            "alternative_paths": [],
            "verification_support": {},
            "optimization_level": "basic"
        }

# =============================================================================
# ä¸“ç”¨é«˜çº§é“¾
# =============================================================================

class HighPerformanceDecisionChain(SmartCoordinatedChain):
    """
    é«˜æ€§èƒ½å†³ç­–é“¾
    ä¸“ä¸ºæ€§èƒ½æ•æ„Ÿåœºæ™¯ä¼˜åŒ–
    """
    
    def __init__(self, **kwargs):
        kwargs.setdefault("max_workers", 8)
        super().__init__(**kwargs)
        
        # æ€§èƒ½ä¼˜åŒ–é…ç½®
        self.enable_async = True
        self.coordinator.result_cache = {}  # é‡ç½®ç¼“å­˜
        
        logger.info("âš¡ HighPerformanceDecisionChain åˆå§‹åŒ–å®Œæˆ")
    
    def _apply_priority_mode(self, context: ExecutionContext, priority_mode: str) -> ExecutionContext:
        """å¼ºåˆ¶æ€§èƒ½ä¼˜åŒ–"""
        context = super()._apply_priority_mode(context, priority_mode)
        
        # å¼ºåˆ¶å¹¶è¡Œæ‰§è¡Œ
        context.execution_mode = ExecutionMode.PARALLEL
        context.max_parallel_tools = 6
        context.timeout = min(context.timeout, 45.0)
        
        # å¯ç”¨æ¿€è¿›ç¼“å­˜
        context.enable_caching = True
        
        return context

class QualityAssuredDecisionChain(SmartCoordinatedChain):
    """
    è´¨é‡ä¿è¯å†³ç­–é“¾
    ä¸“ä¸ºé«˜è´¨é‡å†³ç­–ä¼˜åŒ–
    """
    
    def __init__(self, **kwargs):
        kwargs.setdefault("enable_state_management", True)
        super().__init__(**kwargs)
        
        logger.info("ğŸ¯ QualityAssuredDecisionChain åˆå§‹åŒ–å®Œæˆ")
    
    def _apply_priority_mode(self, context: ExecutionContext, priority_mode: str) -> ExecutionContext:
        """å¼ºåˆ¶è´¨é‡ä¿è¯"""
        context = super()._apply_priority_mode(context, priority_mode)
        
        # å¼ºåˆ¶è´¨é‡ä¼˜å…ˆè®¾ç½®
        context.execution_mode = ExecutionMode.SEQUENTIAL
        context.enable_verification = True
        context.timeout = max(context.timeout, 200.0)
        context.fallback_enabled = True
        
        # å¢åŠ è·¯å¾„æ•°é‡
        context.custom_config["max_paths"] = max(context.custom_config.get("max_paths", 4), 8)
        
        return context

# =============================================================================
# é“¾å·¥å‚å‡½æ•°
# =============================================================================

def create_smart_coordinated_chain(
    api_key: str = "",
    search_engine: str = "duckduckgo",
    llm_client=None,
    web_search_client=None,
    chain_type: str = "smart",
    **kwargs
) -> SmartCoordinatedChain:
    """
    åˆ›å»ºæ™ºèƒ½åè°ƒå†³ç­–é“¾
    
    Args:
        api_key: APIå¯†é’¥
        search_engine: æœç´¢å¼•æ“ç±»å‹
        llm_client: LLMå®¢æˆ·ç«¯
        web_search_client: ç½‘ç»œæœç´¢å®¢æˆ·ç«¯
        chain_type: é“¾ç±»å‹ï¼ˆ"smart", "high_performance", "quality_assured"ï¼‰
        **kwargs: å…¶ä»–å‚æ•°
        
    Returns:
        æ™ºèƒ½åè°ƒå†³ç­–é“¾å®ä¾‹
    """
    chain_classes = {
        "smart": SmartCoordinatedChain,
        "high_performance": HighPerformanceDecisionChain,
        "quality_assured": QualityAssuredDecisionChain
    }
    
    chain_class = chain_classes.get(chain_type, SmartCoordinatedChain)
    
    return chain_class(
        api_key=api_key,
        search_engine=search_engine,
        llm_client=llm_client,
        web_search_client=web_search_client,
        **kwargs
    )

def create_adaptive_chain_pipeline(
    queries: List[str],
    api_key: str = "",
    **kwargs
) -> List[Dict[str, Any]]:
    """
    åˆ›å»ºè‡ªé€‚åº”é“¾ç®¡é“ï¼Œå¤„ç†å¤šä¸ªæŸ¥è¯¢
    
    Args:
        queries: æŸ¥è¯¢åˆ—è¡¨
        api_key: APIå¯†é’¥
        **kwargs: å…¶ä»–å‚æ•°
        
    Returns:
        å¤„ç†ç»“æœåˆ—è¡¨
    """
    chain = create_smart_coordinated_chain(api_key=api_key, **kwargs)
    results = []
    
    for i, query in enumerate(queries):
        logger.info(f"ğŸ”„ å¤„ç†æŸ¥è¯¢ {i+1}/{len(queries)}: {query[:50]}...")
        
        # æ ¹æ®æŸ¥è¯¢å¤æ‚åº¦é€‰æ‹©æ‰§è¡Œæ¨¡å¼
        if len(query) > 200 or "å¤æ‚" in query or "åˆ†æ" in query:
            execution_mode = "quality"
        elif "å¿«é€Ÿ" in query or "ç®€å•" in query:
            execution_mode = "speed"
        else:
            execution_mode = "balanced"
        
        result = chain({
            "user_query": query,
            "priority_mode": execution_mode,
            "execution_context": {"pipeline_index": i}
        })
        
        results.append(result)
    
    return results

# =============================================================================
# å…¼å®¹æ€§å’Œæµ‹è¯•
# =============================================================================

def test_smart_coordinated_chain():
    """æµ‹è¯•æ™ºèƒ½åè°ƒå†³ç­–é“¾"""
    print("ğŸ§ª æµ‹è¯•æ™ºèƒ½åè°ƒå†³ç­–é“¾...")
    
    try:
        # åˆ›å»ºé“¾
        chain = create_smart_coordinated_chain(
            api_key="test_key",
            chain_type="smart"
        )
        print("âœ… æ™ºèƒ½åè°ƒé“¾åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ‰§è¡Œ
        test_input = {
            "user_query": "è®¾è®¡ä¸€ä¸ªé«˜æ€§èƒ½çš„åˆ†å¸ƒå¼ç¼“å­˜ç³»ç»Ÿ",
            "execution_mode": "adaptive",
            "priority_mode": "balanced",
            "max_paths": 3
        }
        
        result = chain(test_input)
        
        if result.get("smart_decision_result", {}).get("decision_success", False):
            print("âœ… æµ‹è¯•æ‰§è¡ŒæˆåŠŸ")
            
            decision_result = result["smart_decision_result"]
            print(f"   æ‰§è¡Œæ¨¡å¼: {decision_result.get('execution_mode')}")
            print(f"   å·¥å…·æ‰§è¡Œæ•°: {decision_result.get('execution_details', {}).get('total_tools_executed', 0)}")
            print(f"   æ€»æ‰§è¡Œæ—¶é—´: {decision_result.get('execution_details', {}).get('total_execution_time', 0):.2f}s")
            
        else:
            print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {result}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    success = test_smart_coordinated_chain()
    
    if success:
        print("âœ… æ™ºèƒ½åè°ƒå†³ç­–é“¾æµ‹è¯•å®Œæˆ")
    else:
        print("âŒ æµ‹è¯•æœªé€šè¿‡ï¼Œéœ€è¦æ£€æŸ¥é…ç½®")
