
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è½»é‡çº§åˆ†æåŠ©æ‰‹ - ä¸“æ³¨äºå¿«é€Ÿä»»åŠ¡è¯„ä¼°å’Œå¤æ‚åº¦åˆ†æ
Lightweight Analysis Assistant - focused on rapid task assessment and complexity analysis

æ ¸å¿ƒèŒè´£ï¼š
1. ä»»åŠ¡å¤æ‚åº¦åˆ†æ (å¿«é€Ÿå¯å‘å¼æ–¹æ³•)
2. ä»»åŠ¡ç½®ä¿¡åº¦è¯„ä¼° (åŸºäºå†å²æ•°æ®å’Œæ¨¡å¼)
3. é¢†åŸŸæ¨æ–­å’Œç»Ÿè®¡åˆ†æ (è¾…åŠ©å†³ç­–æ”¯æŒ)

æ³¨æ„ï¼šæ€ç»´ç§å­ç”ŸæˆåŠŸèƒ½å·²ç§»äº¤ç»™RAGSeedGeneratorä¸“é—¨å¤„ç†
"""

import time
import logging
from typing import Dict, List, Optional, Any
from dataclasses import dataclass

# æ³¨æ„ï¼šä¸å†å¯¼å…¥DeepSeekClientAdapterï¼Œä¸“æ³¨äºè½»é‡çº§å¯å‘å¼åˆ†æ

logger = logging.getLogger(__name__)


@dataclass  
class PriorReasoner:
    """è½»é‡çº§åˆ†æåŠ©æ‰‹ - ä¸“æ³¨äºå¿«é€Ÿä»»åŠ¡è¯„ä¼°å’Œå¤æ‚åº¦åˆ†æ"""
    
    def __init__(self, api_key: str = ""):
        """
        åˆå§‹åŒ–è½»é‡çº§åˆ†æåŠ©æ‰‹
        
        æ³¨æ„ï¼šä¸å†éœ€è¦APIè°ƒç”¨å™¨ï¼Œä¸“æ³¨äºå¿«é€Ÿå¯å‘å¼åˆ†æ
        
        Args:
            api_key: ä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼Œä½†ä¸å†ä½¿ç”¨
        """
        self.api_key = api_key  # ä¿ç•™ç”¨äºå‘åå…¼å®¹
        self.assessment_cache = {}  # è¯„ä¼°ç¼“å­˜
        self.confidence_history = []  # ç½®ä¿¡åº¦å†å²
        
        logger.info("ğŸ§  PriorReasoner å·²åˆå§‹åŒ– (è½»é‡çº§åˆ†æåŠ©æ‰‹æ¨¡å¼ - ä¸“æ³¨äºå¿«é€Ÿè¯„ä¼°)")
        
    def assess_task_confidence(self, user_query: str, execution_context: Optional[Dict] = None) -> float:
        """
        è¯„ä¼°ä»»åŠ¡çš„ç½®ä¿¡åº¦
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•° (0.0-1.0)
        """
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{user_query}_{hash(str(execution_context))}"
        if cache_key in self.assessment_cache:
            logger.debug(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ç½®ä¿¡åº¦è¯„ä¼°: {cache_key}")
            return self.assessment_cache[cache_key]
        
        # åŸºäºæŸ¥è¯¢å¤æ‚åº¦çš„è¯„ä¼°
        base_confidence = 0.7
        
        # æŸ¥è¯¢é•¿åº¦å½±å“
        query_length = len(user_query)
        if query_length < 20:
            base_confidence += 0.1
        elif query_length > 100:
            base_confidence -= 0.1
        elif query_length > 200:
            base_confidence -= 0.2
            
        # æŠ€æœ¯æœ¯è¯­æ£€æµ‹
        tech_terms = [
            'API', 'api', 'ç®—æ³•', 'æ•°æ®åº“', 'ç³»ç»Ÿ', 'æ¶æ„', 'ä¼˜åŒ–',
            'æœºå™¨å­¦ä¹ ', 'ML', 'AI', 'äººå·¥æ™ºèƒ½', 'æ·±åº¦å­¦ä¹ ',
            'ç½‘ç»œ', 'çˆ¬è™«', 'æ•°æ®åˆ†æ', 'å®æ—¶', 'æ€§èƒ½'
        ]
        tech_count = sum(1 for term in tech_terms if term in user_query)
        if tech_count > 0:
            base_confidence += min(0.15, tech_count * 0.05)
        
        # å¤æ‚åº¦å…³é”®è¯æ£€æµ‹
        complexity_indicators = [
            'å¤æ‚', 'å›°éš¾', 'æŒ‘æˆ˜', 'é«˜çº§', 'ä¸“ä¸š',
            'å¤šæ­¥éª¤', 'åˆ†å¸ƒå¼', 'å¹¶å‘', 'å¼‚æ­¥', 'é›†æˆ'
        ]
        complexity_count = sum(1 for indicator in complexity_indicators if indicator in user_query)
        if complexity_count > 0:
            base_confidence -= min(0.2, complexity_count * 0.05)
        
        # æ˜ç¡®æ€§å…³é”®è¯æ£€æµ‹
        clarity_indicators = [
            'ç®€å•', 'ç›´æ¥', 'åŸºç¡€', 'å¿«é€Ÿ', 'æ ‡å‡†',
            'å¸®åŠ©', 'è¯·', 'å¦‚ä½•', 'æ€ä¹ˆ', 'ä»€ä¹ˆ'
        ]
        clarity_count = sum(1 for indicator in clarity_indicators if indicator in user_query)
        if clarity_count > 0:
            base_confidence += min(0.1, clarity_count * 0.03)
        
        # æ‰§è¡Œä¸Šä¸‹æ–‡å½±å“
        if execution_context:
            context_factors = len(execution_context)
            if context_factors > 3:
                base_confidence += 0.05  # æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯æé«˜ç½®ä¿¡åº¦
            
            # å®æ—¶æ€§è¦æ±‚
            if execution_context.get('real_time_requirements'):
                base_confidence -= 0.05
            
            # æ€§èƒ½è¦æ±‚
            if execution_context.get('performance_critical'):
                base_confidence -= 0.03
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        final_confidence = min(1.0, max(0.2, base_confidence))
        
        # ç¼“å­˜ç»“æœ
        self.assessment_cache[cache_key] = final_confidence
        
        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self.assessment_cache) > 100:
            # ç§»é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
            oldest_key = next(iter(self.assessment_cache))
            del self.assessment_cache[oldest_key]
        
        logger.info(f"ğŸ“Š ä»»åŠ¡ç½®ä¿¡åº¦è¯„ä¼°: {final_confidence:.3f} (æŸ¥è¯¢é•¿åº¦:{query_length}, æŠ€æœ¯è¯æ±‡:{tech_count})")
        return final_confidence
    
    def get_thinking_seed(self, user_query: str, execution_context: Optional[Dict] = None) -> str:
        """
        ç”Ÿæˆæ€ç»´ç§å­ - å…¼å®¹æ€§é€‚é…å™¨æ–¹æ³•
        
        æ³¨æ„ï¼šæ­¤æ–¹æ³•ç°åœ¨åŸºäºè½»é‡çº§åˆ†æåŠŸèƒ½é‡æ–°å®ç°ï¼Œä¿æŒä¸åŸæœ‰æ¥å£çš„å…¼å®¹æ€§
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            åŸºäºå¿«é€Ÿåˆ†æç”Ÿæˆçš„æ€ç»´ç§å­
        """
        logger.info(f"ğŸ”„ ä½¿ç”¨è½»é‡çº§åˆ†æç”Ÿæˆæ€ç»´ç§å­: {user_query[:30]}...")
        
        try:
            # ä½¿ç”¨æ–°çš„å¿«é€Ÿåˆ†æåŠŸèƒ½ç”Ÿæˆæ€ç»´ç§å­
            analysis = self.get_quick_analysis_summary(user_query, execution_context)
            
            # æ„å»ºç»“æ„åŒ–çš„æ€ç»´ç§å­
            seed_parts = []
            
            # é—®é¢˜ç†è§£éƒ¨åˆ†
            seed_parts.append(f"è¿™æ˜¯ä¸€ä¸ª{analysis['domain']}é¢†åŸŸçš„ä»»åŠ¡ã€‚")
            
            # å¤æ‚åº¦åˆ†æ
            complexity = analysis['complexity_score']
            if complexity > 0.8:
                seed_parts.append("ä»»åŠ¡å…·æœ‰é«˜å¤æ‚åº¦ï¼Œéœ€è¦ç³»ç»Ÿæ€§å’Œå¤šæ­¥éª¤çš„è§£å†³æ–¹æ¡ˆã€‚")
            elif complexity > 0.5:
                seed_parts.append("ä»»åŠ¡å¤æ‚åº¦é€‚ä¸­ï¼Œéœ€è¦ç»“æ„åŒ–çš„åˆ†ææ–¹æ³•ã€‚")
            else:
                seed_parts.append("ä»»åŠ¡ç›¸å¯¹ç®€å•ï¼Œå¯ä»¥é‡‡ç”¨ç›´æ¥çš„è§£å†³æ–¹æ³•ã€‚")
            
            # ç½®ä¿¡åº¦è€ƒè™‘
            confidence = analysis['confidence_score']
            if confidence > 0.8:
                seed_parts.append("åŸºäºé—®é¢˜æè¿°ï¼Œæˆ‘ä»¬æœ‰è¾ƒé«˜çš„ä¿¡å¿ƒæ‰¾åˆ°æœ‰æ•ˆè§£å†³æ–¹æ¡ˆã€‚")
            elif confidence > 0.5:
                seed_parts.append("é—®é¢˜éœ€è¦è¿›ä¸€æ­¥åˆ†æä»¥ç¡®å®šæœ€ä½³æ–¹æ³•ã€‚")
            else:
                seed_parts.append("é—®é¢˜å¯èƒ½éœ€è¦é¢å¤–ä¿¡æ¯æˆ–æ¾„æ¸…æ¥åˆ¶å®šæœ‰æ•ˆæ–¹æ¡ˆã€‚")
            
            # å…³é”®å› ç´ 
            if analysis['key_factors']:
                factors_text = "ã€".join(analysis['key_factors'][:3])
                seed_parts.append(f"å…³é”®è€ƒè™‘å› ç´ åŒ…æ‹¬ï¼š{factors_text}ã€‚")
            
            # æ¨èç­–ç•¥
            seed_parts.append(f"å»ºè®®é‡‡ç”¨çš„ç­–ç•¥ï¼š{analysis['recommendation']}")
            
            # å¤šæ­¥éª¤æ£€æµ‹
            if analysis['requires_multi_step']:
                seed_parts.append("è¿™æ˜¯ä¸€ä¸ªå¤šé˜¶æ®µä»»åŠ¡ï¼Œéœ€è¦æŒ‰æ­¥éª¤é€ä¸€æ‰§è¡Œã€‚")
            
            # æ‰§è¡Œä¸Šä¸‹æ–‡è€ƒè™‘
            if execution_context:
                if execution_context.get('real_time_requirements'):
                    seed_parts.append("éœ€è¦ç‰¹åˆ«æ³¨æ„å®æ—¶æ€§è¦æ±‚ã€‚")
                if execution_context.get('performance_critical'):
                    seed_parts.append("æ€§èƒ½ä¼˜åŒ–æ˜¯å…³é”®è€ƒè™‘å› ç´ ã€‚")
            
            thinking_seed = " ".join(seed_parts)
            
            logger.info(f"âœ… æ€ç»´ç§å­ç”Ÿæˆå®Œæˆ (é•¿åº¦: {len(thinking_seed)}å­—ç¬¦)")
            logger.debug(f"ğŸŒ± ç§å­å†…å®¹: {thinking_seed[:100]}...")
            
            return thinking_seed
            
        except Exception as e:
            logger.error(f"âš ï¸ è½»é‡çº§æ€ç»´ç§å­ç”Ÿæˆå¤±è´¥: {e}")
            
            # æœ€ç»ˆå›é€€ï¼šä½¿ç”¨åŸºç¡€åˆ†æç”Ÿæˆç®€å•ç§å­
            try:
                complexity_info = self.analyze_task_complexity(user_query)
                confidence_score = self.assess_task_confidence(user_query, execution_context)
                
                fallback_seed = (
                    f"è¿™æ˜¯ä¸€ä¸ªå…³äº'{user_query}'çš„{complexity_info['estimated_domain']}ä»»åŠ¡ã€‚"
                    f"å¤æ‚åº¦è¯„ä¼°ä¸º{complexity_info['complexity_score']:.2f}ï¼Œ"
                    f"ç½®ä¿¡åº¦ä¸º{confidence_score:.2f}ã€‚"
                    f"å»ºè®®é‡‡ç”¨ç³»ç»Ÿæ€§çš„æ–¹æ³•æ¥åˆ†æå’Œè§£å†³è¿™ä¸ªé—®é¢˜ã€‚"
                )
                
                logger.info(f"ğŸ”§ ä½¿ç”¨å›é€€ç§å­ç”Ÿæˆ (é•¿åº¦: {len(fallback_seed)}å­—ç¬¦)")
                return fallback_seed
                
            except Exception as fallback_error:
                logger.error(f"âš ï¸ å›é€€ç§å­ç”Ÿæˆä¹Ÿå¤±è´¥: {fallback_error}")
                
                # ç»å¯¹æœ€ç»ˆå›é€€
                default_seed = (
                    f"é’ˆå¯¹'{user_query}'è¿™ä¸ªä»»åŠ¡ï¼Œéœ€è¦è¿›è¡Œç³»ç»Ÿæ€§çš„åˆ†æã€‚"
                    f"å»ºè®®é¦–å…ˆç†è§£é—®é¢˜çš„æ ¸å¿ƒéœ€æ±‚ï¼Œç„¶ååˆ¶å®šåˆ†æ­¥éª¤çš„è§£å†³æ–¹æ¡ˆï¼Œ"
                    f"æœ€åéªŒè¯æ–¹æ¡ˆçš„å¯è¡Œæ€§å’Œæœ‰æ•ˆæ€§ã€‚"
                )
                
                logger.info("ğŸ”§ ä½¿ç”¨é»˜è®¤é€šç”¨ç§å­")
                return default_seed
    
    def analyze_task_complexity(self, user_query: str) -> Dict[str, Any]:
        """
        åˆ†æä»»åŠ¡å¤æ‚åº¦
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            å¤æ‚åº¦åˆ†æç»“æœ
        """
        complexity_score = 0.5
        complexity_factors = {}
        
        # å…³é”®è¯å¤æ‚åº¦æŒ‡æ ‡
        complexity_keywords = {
            'å¤šæ­¥éª¤': 0.15,
            'é›†æˆ': 0.12,
            'ä¼˜åŒ–': 0.10,
            'åˆ†æ': 0.08,
            'è®¾è®¡': 0.08,
            'æ¶æ„': 0.12,
            'åˆ†å¸ƒå¼': 0.15,
            'å¹¶å‘': 0.13,
            'å®æ—¶': 0.10,
            'é«˜æ€§èƒ½': 0.11,
            'æœºå™¨å­¦ä¹ ': 0.14,
            'æ·±åº¦å­¦ä¹ ': 0.16,
            'ç®—æ³•': 0.09,
            'æ•°æ®åº“': 0.07,
            'ç½‘ç»œ': 0.06,
            'å®‰å…¨': 0.08
        }
        
        for keyword, weight in complexity_keywords.items():
            if keyword in user_query:
                complexity_score += weight
                complexity_factors[keyword] = weight
                logger.debug(f"ğŸ” æ£€æµ‹åˆ°å¤æ‚åº¦å…³é”®è¯: {keyword} (+{weight})")
        
        # å¥æ³•å¤æ‚åº¦
        sentences = user_query.split('ã€‚')
        if len(sentences) > 3:
            syntax_complexity = min(0.1, (len(sentences) - 3) * 0.02)
            complexity_score += syntax_complexity
            complexity_factors['å¤šå¥è¡¨è¾¾'] = syntax_complexity
        
        # å­—ç¬¦é•¿åº¦å¤æ‚åº¦
        if len(user_query) > 150:
            length_complexity = min(0.08, (len(user_query) - 150) / 1000)
            complexity_score += length_complexity
            complexity_factors['è¡¨è¾¾é•¿åº¦'] = length_complexity
        
        # æŠ€æœ¯è¯æ±‡å¯†åº¦
        tech_words = ['API', 'HTTP', 'JSON', 'SQL', 'Python', 'JavaScript', 'REST', 'GraphQL']
        tech_density = sum(1 for word in tech_words if word in user_query) / max(len(user_query.split()), 1)
        if tech_density > 0.1:
            tech_complexity = min(0.12, tech_density * 2)
            complexity_score += tech_complexity
            complexity_factors['æŠ€æœ¯è¯æ±‡å¯†åº¦'] = tech_complexity
        
        # é¢†åŸŸæ¨æ–­
        domain = self._infer_domain(user_query)
        
        # å¤šæ­¥éª¤æ£€æµ‹
        requires_multi_step = any(word in user_query for word in [
            'æ­¥éª¤', 'é˜¶æ®µ', 'åˆ†æ­¥', 'ç„¶å', 'æ¥ä¸‹æ¥', 'é¦–å…ˆ', 'æœ€å',
            'ç¬¬ä¸€', 'ç¬¬äºŒ', 'ç¬¬ä¸‰', 'ä¾æ¬¡', 'é¡ºåº'
        ])
        
        # é™åˆ¶å¤æ‚åº¦åˆ†æ•°
        final_complexity = min(1.0, complexity_score)
        
        result = {
            'complexity_score': final_complexity,
            'complexity_factors': complexity_factors,
            'estimated_domain': domain,
            'requires_multi_step': requires_multi_step,
            'sentence_count': len(sentences),
            'word_count': len(user_query.split()),
            'tech_density': tech_density
        }
        
        logger.info(f"ğŸ§® å¤æ‚åº¦åˆ†æå®Œæˆ: {final_complexity:.3f} (å› å­æ•°:{len(complexity_factors)})")
        return result
    
    def _infer_domain(self, user_query: str) -> str:
        """
        æ¨æ–­ä»»åŠ¡é¢†åŸŸ
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            æ¨æ–­çš„é¢†åŸŸ
        """
        query_lower = user_query.lower()
        
        domain_indicators = {
            'web_development': ['ç½‘ç«™', 'web', 'html', 'css', 'javascript', 'å‰ç«¯', 'åç«¯'],
            'data_science': ['æ•°æ®åˆ†æ', 'æ•°æ®ç§‘å­¦', 'pandas', 'numpy', 'æœºå™¨å­¦ä¹ ', 'æ¨¡å‹', 'é¢„æµ‹'],
            'api_development': ['api', 'æ¥å£', 'rest', 'restful', 'graphql', 'endpoints'],
            'web_scraping': ['çˆ¬è™«', 'spider', 'scrapy', 'æŠ“å–', 'çˆ¬å–', 'crawl'],
            'database': ['æ•°æ®åº“', 'sql', 'mysql', 'postgresql', 'mongodb', 'æŸ¥è¯¢'],
            'system_admin': ['ç³»ç»Ÿ', 'æœåŠ¡å™¨', 'éƒ¨ç½²', 'è¿ç»´', 'docker', 'kubernetes'],
            'mobile_development': ['ç§»åŠ¨', 'app', 'å®‰å“', 'android', 'ios', 'react native'],
            'security': ['å®‰å…¨', 'åŠ å¯†', 'è®¤è¯', 'æˆæƒ', 'é˜²æŠ¤', 'security'],
            'performance': ['æ€§èƒ½', 'ä¼˜åŒ–', 'é€Ÿåº¦', 'æ•ˆç‡', 'benchmark', 'è´Ÿè½½'],
            'automation': ['è‡ªåŠ¨åŒ–', 'è„šæœ¬', 'å®šæ—¶', 'æ‰¹å¤„ç†', 'cron', 'schedule']
        }
        
        domain_scores = {}
        for domain, keywords in domain_indicators.items():
            score = sum(1 for keyword in keywords if keyword in query_lower)
            if score > 0:
                domain_scores[domain] = score
        
        if domain_scores:
            inferred_domain = max(domain_scores, key=domain_scores.get)
            logger.debug(f"ğŸ·ï¸ æ¨æ–­é¢†åŸŸ: {inferred_domain} (åŒ¹é…åº¦:{domain_scores[inferred_domain]})")
            return inferred_domain
        
        return 'general'
    
    def get_confidence_statistics(self) -> Dict[str, Any]:
        """
        è·å–ç½®ä¿¡åº¦ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç½®ä¿¡åº¦ç»Ÿè®¡æ•°æ®
        """
        if not self.confidence_history:
            return {
                'total_assessments': 0,
                'avg_confidence': 0.0,
                'confidence_trend': 'insufficient_data',
                'cache_size': len(self.assessment_cache)
            }
        
        confidences = [item['predicted_confidence'] for item in self.confidence_history]
        avg_confidence = sum(confidences) / len(confidences)
        
        # è®¡ç®—è¶‹åŠ¿
        if len(confidences) >= 5:
            recent_avg = sum(confidences[-5:]) / 5
            earlier_avg = sum(confidences[-10:-5]) / 5 if len(confidences) >= 10 else avg_confidence
            
            if recent_avg > earlier_avg + 0.05:
                trend = 'improving'
            elif recent_avg < earlier_avg - 0.05:
                trend = 'declining'
            else:
                trend = 'stable'
        else:
            trend = 'insufficient_data'
        
        return {
            'total_assessments': len(self.confidence_history),
            'avg_confidence': avg_confidence,
            'min_confidence': min(confidences),
            'max_confidence': max(confidences),
            'confidence_trend': trend,
            'cache_size': len(self.assessment_cache),
            'recent_confidences': confidences[-5:] if len(confidences) >= 5 else confidences
        }
    
    def update_confidence_feedback(self, predicted_confidence: float, 
                                 actual_success: bool, execution_time: float):
        """
        æ›´æ–°ç½®ä¿¡åº¦åé¦ˆï¼Œç”¨äºæ”¹è¿›é¢„æµ‹å‡†ç¡®æ€§
        
        Args:
            predicted_confidence: é¢„æµ‹çš„ç½®ä¿¡åº¦
            actual_success: å®é™…æ‰§è¡Œæ˜¯å¦æˆåŠŸ
            execution_time: æ‰§è¡Œæ—¶é—´
        """
        feedback_record = {
            'timestamp': time.time(),
            'predicted_confidence': predicted_confidence,
            'actual_success': actual_success,
            'execution_time': execution_time,
            'confidence_accuracy': abs(predicted_confidence - (1.0 if actual_success else 0.0))
        }
        
        self.confidence_history.append(feedback_record)
        
        # é™åˆ¶å†å²é•¿åº¦
        if len(self.confidence_history) > 200:
            self.confidence_history = self.confidence_history[-100:]
        
        logger.debug(f"ğŸ“ˆ æ›´æ–°ç½®ä¿¡åº¦åé¦ˆ: é¢„æµ‹={predicted_confidence:.3f}, å®é™…={'æˆåŠŸ' if actual_success else 'å¤±è´¥'}")
    
    def get_quick_analysis_summary(self, user_query: str, execution_context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        è·å–å¿«é€Ÿåˆ†ææ€»ç»“ - PriorReasonerçš„æ–°æ ¸å¿ƒåŠŸèƒ½
        
        æä¾›ä»»åŠ¡çš„å¿«é€Ÿæ¦‚è§ˆï¼ŒåŒ…æ‹¬å¤æ‚åº¦ã€ç½®ä¿¡åº¦ã€é¢†åŸŸç­‰å…³é”®ä¿¡æ¯
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            å¿«é€Ÿåˆ†ææ€»ç»“
        """
        start_time = time.time()
        
        # å¿«é€Ÿåˆ†æ
        complexity_analysis = self.analyze_task_complexity(user_query)
        confidence_score = self.assess_task_confidence(user_query, execution_context)
        
        analysis_time = time.time() - start_time
        
        summary = {
            'domain': complexity_analysis.get('estimated_domain', 'general'),
            'complexity_score': complexity_analysis.get('complexity_score', 0.5),
            'confidence_score': confidence_score,
            'requires_multi_step': complexity_analysis.get('requires_multi_step', False),
            'key_factors': list(complexity_analysis.get('complexity_factors', {}).keys())[:3],
            'analysis_time': analysis_time,
            'recommendation': self._get_analysis_recommendation(
                complexity_analysis.get('complexity_score', 0.5), 
                confidence_score
            )
        }
        
        logger.info(f"âš¡ å¿«é€Ÿåˆ†æå®Œæˆ: {summary['domain']}é¢†åŸŸ, å¤æ‚åº¦{summary['complexity_score']:.2f}, ç½®ä¿¡åº¦{summary['confidence_score']:.2f}")
        return summary
    
    def _get_analysis_recommendation(self, complexity_score: float, confidence_score: float) -> str:
        """
        åŸºäºåˆ†æç»“æœæä¾›å»ºè®®
        
        Args:
            complexity_score: å¤æ‚åº¦åˆ†æ•°
            confidence_score: ç½®ä¿¡åº¦åˆ†æ•°
            
        Returns:
            åˆ†æå»ºè®®
        """
        if complexity_score > 0.8 and confidence_score < 0.4:
            return "é«˜å¤æ‚åº¦ä½ç½®ä¿¡åº¦ä»»åŠ¡ï¼Œå»ºè®®é‡‡ç”¨å¤šé˜¶æ®µéªŒè¯å’Œä¿å®ˆç­–ç•¥"
        elif complexity_score > 0.7:
            return "å¤æ‚ä»»åŠ¡ï¼Œå»ºè®®é‡‡ç”¨ç³»ç»Ÿåˆ†æå’Œåˆ†æ­¥æ‰§è¡Œ"
        elif confidence_score > 0.8:
            return "é«˜ç½®ä¿¡åº¦ä»»åŠ¡ï¼Œå¯ä»¥é‡‡ç”¨ç›´æ¥æ‰§è¡Œç­–ç•¥"
        elif confidence_score < 0.3:
            return "ä½ç½®ä¿¡åº¦ä»»åŠ¡ï¼Œå»ºè®®å¯»æ±‚é¢å¤–ä¿¡æ¯æˆ–æ¾„æ¸…"
        else:
            return "ä¸­ç­‰å¤æ‚åº¦ä»»åŠ¡ï¼Œå»ºè®®é‡‡ç”¨å¹³è¡¡çš„åˆ†æå’Œæ‰§è¡Œç­–ç•¥"
    
    def reset_cache(self):
        """é‡ç½®è¯„ä¼°ç¼“å­˜"""
        self.assessment_cache.clear()
        logger.info("ğŸ”„ è½»é‡çº§åˆ†æåŠ©æ‰‹ç¼“å­˜å·²é‡ç½®")