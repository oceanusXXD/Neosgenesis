
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è½»é‡çº§åˆ†æåŠ©æ‰‹ - ä¸“æ³¨äºå¿«é€Ÿä»»åŠ¡è¯„ä¼°å’Œå¤æ‚åº¦åˆ†æ
Lightweight Analysis Assistant - focused on rapid task assessment and complexity analysis

æ ¸å¿ƒèŒè´£ï¼š
1. ä»»åŠ¡å¤æ‚åº¦åˆ†æ (å¿«é€Ÿå¯å‘å¼æ–¹æ³•)
2. ä»»åŠ¡ç½®ä¿¡åº¦è¯„ä¼° (åŸºäºå†å²æ•°æ®å’Œæ¨¡å¼)
3. é¢†åŸŸæ¨æ–­å’Œç»Ÿè®¡åˆ†æ (è¾…åŠ©å†³ç­–æ”¯æŒ)

æ³¨æ„ï¼šæ€ç»´ç§å­ç”ŸæˆåŠŸèƒ½å·²ç§»äº¤ç»™RAGSeedGeneratorä¸“é—¨å¤„ç†
"""

import time
import logging
import json
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum

# LLM ç›¸å…³å¯¼å…¥
try:
    from ..providers.llm_manager import LLMManager
    from ..providers.impl.ollama_client import create_ollama_client, OllamaClient
    from ..providers.llm_base import LLMConfig, LLMProvider, LLMMessage
    LLM_AVAILABLE = True
except ImportError as e:
    logger.warning(f"LLMç»„ä»¶å¯¼å…¥å¤±è´¥ï¼Œå°†ä½¿ç”¨çº¯å¯å‘å¼æ¨¡å¼: {e}")
    LLM_AVAILABLE = False

logger = logging.getLogger(__name__)


# ==================== è·¯ç”±åˆ†ç±»æ•°æ®ç»“æ„å®šä¹‰ ====================

class TaskComplexity(Enum):
    """ä»»åŠ¡å¤æ‚åº¦æšä¸¾"""
    SIMPLE = "simple"         # ç®€å•ä»»åŠ¡ï¼šç›´æ¥å›ç­”æˆ–å•æ­¥æ“ä½œ
    MODERATE = "moderate"     # ä¸­ç­‰ä»»åŠ¡ï¼šéœ€è¦ä¸€å®šåˆ†æå’Œå¤šæ­¥éª¤
    COMPLEX = "complex"       # å¤æ‚ä»»åŠ¡ï¼šéœ€è¦æ·±å…¥åˆ†æå’Œç³»ç»Ÿæ€§æ–¹æ³•
    EXPERT = "expert"         # ä¸“å®¶çº§ä»»åŠ¡ï¼šéœ€è¦ä¸“ä¸šçŸ¥è¯†å’Œå¤æ‚æ¨ç†

class TaskDomain(Enum):
    """ä»»åŠ¡é¢†åŸŸæšä¸¾"""
    WEB_DEV = "web_development"          # Webå¼€å‘
    DATA_SCIENCE = "data_science"        # æ•°æ®ç§‘å­¦
    API_DEV = "api_development"          # APIå¼€å‘  
    SYSTEM_ADMIN = "system_admin"        # ç³»ç»Ÿç®¡ç†
    DATABASE = "database"                # æ•°æ®åº“
    SECURITY = "security"                # å®‰å…¨
    MOBILE_DEV = "mobile_development"    # ç§»åŠ¨å¼€å‘
    ML_AI = "machine_learning"           # æœºå™¨å­¦ä¹ /AI
    GENERAL = "general"                  # é€šç”¨ä»»åŠ¡

class TaskIntent(Enum):
    """ä»»åŠ¡æ„å›¾æšä¸¾"""
    QUESTION = "question"                # å’¨è¯¢é—®é¢˜
    TASK_EXECUTION = "task_execution"    # ä»»åŠ¡æ‰§è¡Œ
    ANALYSIS = "analysis"                # åˆ†æè¯·æ±‚
    CREATION = "creation"                # åˆ›å»ºå†…å®¹
    DEBUGGING = "debugging"              # è°ƒè¯•é—®é¢˜
    OPTIMIZATION = "optimization"        # ä¼˜åŒ–æ”¹è¿›

class TaskUrgency(Enum):
    """ä»»åŠ¡ç´§æ€¥åº¦æšä¸¾"""
    LOW = "low"                         # ä½ä¼˜å…ˆçº§
    MEDIUM = "medium"                   # ä¸­ç­‰ä¼˜å…ˆçº§  
    HIGH = "high"                       # é«˜ä¼˜å…ˆçº§
    CRITICAL = "critical"               # ç´§æ€¥å…³é”®

class RouteStrategy(Enum):
    """è·¯ç”±ç­–ç•¥æšä¸¾"""
    DIRECT_RESPONSE = "direct_response"              # ç›´æ¥å›ç­”
    MULTI_STAGE_PROCESSING = "multi_stage_processing" # å¤šé˜¶æ®µå¤„ç†
    WORKFLOW_PLANNING = "workflow_planning"          # å·¥ä½œæµè§„åˆ’
    IDEATION_MODE = "ideation_mode"                 # åˆ›æ„æ¨¡å¼
    DIAGNOSTIC_MODE = "diagnostic_mode"             # è¯Šæ–­æ¨¡å¼
    EXPERT_CONSULTATION = "expert_consultation"      # ä¸“å®¶å’¨è¯¢

@dataclass
class TriageClassification:
    """ä»»åŠ¡åˆ†è¯Šåˆ†ç±»ç»“æœ"""
    complexity: TaskComplexity
    domain: TaskDomain
    intent: TaskIntent
    urgency: TaskUrgency
    route_strategy: RouteStrategy
    confidence: float                    # åˆ†ç±»ç½®ä¿¡åº¦ (0.0-1.0)
    reasoning: str                       # åˆ†ç±»ç†ç”±
    key_factors: List[str]              # å…³é”®å› ç´ 
    estimated_time: Optional[int] = None # é¢„ä¼°å¤„ç†æ—¶é—´(åˆ†é’Ÿ)
    required_resources: Optional[List[str]] = None  # æ‰€éœ€èµ„æº


@dataclass  
class PriorReasoner:
    """
    æ™ºèƒ½è·¯ç”±ç½‘å…³ - å‡çº§ç‰ˆä»»åŠ¡åˆ†æå™¨
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å¿«é€Ÿä»»åŠ¡å¤æ‚åº¦åˆ†æ (å¯å‘å¼ + LLMåŒé‡åˆ†æ)
    2. æ™ºèƒ½ç½®ä¿¡åº¦è¯„ä¼° (åŸºäºè¯­ä¹‰ç†è§£)
    3. è¾“å…¥åˆ†ç±»å’Œè·¯ç”±å†³ç­– (LLMé©±åŠ¨)
    4. å‘åå…¼å®¹çš„æ¥å£è®¾è®¡
    """
    
    def __init__(self, 
                 api_key: str = "",
                 llm_manager: Optional[LLMManager] = None,
                 ollama_config: Optional[Dict[str, Any]] = None,
                 enable_llm: bool = True):
        """
        åˆå§‹åŒ–æ™ºèƒ½è·¯ç”±ç½‘å…³
        
        Args:
            api_key: ä¿ç•™ç”¨äºå‘åå…¼å®¹
            llm_manager: å¯é€‰çš„LLMç®¡ç†å™¨å®ä¾‹
            ollama_config: Ollamaé…ç½®å‚æ•°
            enable_llm: æ˜¯å¦å¯ç”¨LLMåŠŸèƒ½
        """
        # ä¿æŒå‘åå…¼å®¹
        self.api_key = api_key
        self.assessment_cache = {}  # è¯„ä¼°ç¼“å­˜
        self.confidence_history = []  # ç½®ä¿¡åº¦å†å²
        
        # LLM èƒ½åŠ›é›†æˆ
        self.enable_llm = enable_llm and LLM_AVAILABLE
        self.llm_manager = None
        self.ollama_client = None
        
        if self.enable_llm:
            try:
                # å°è¯•åˆå§‹åŒ–LLMèƒ½åŠ›
                self._init_llm_capabilities(llm_manager, ollama_config)
            except Exception as e:
                logger.warning(f"âš ï¸ LLMèƒ½åŠ›åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨å¯å‘å¼æ¨¡å¼: {e}")
                self.enable_llm = False
        
        # æ—¥å¿—ä¿¡æ¯
        mode = "LLMå¢å¼ºæ™ºèƒ½åˆ†æ" if self.enable_llm else "è½»é‡çº§å¯å‘å¼åˆ†æ"
        logger.info(f"ğŸ§  PriorReasoner å·²åˆå§‹åŒ– ({mode}æ¨¡å¼)")
        
        if self.enable_llm and self.llm_manager:
            logger.info("âœ… LLMç®¡ç†å™¨å·²é›†æˆï¼Œæ”¯æŒæ™ºèƒ½è·¯ç”±åŠŸèƒ½")
        if self.enable_llm and self.ollama_client:
            logger.info("âœ… Ollamaå®¢æˆ·ç«¯å·²è¿æ¥ï¼Œæ”¯æŒæœ¬åœ°å¿«é€Ÿæ¨ç†")
    
    def _init_llm_capabilities(self, llm_manager: Optional[LLMManager], ollama_config: Optional[Dict[str, Any]]):
        """
        åˆå§‹åŒ–LLMèƒ½åŠ›
        
        Args:
            llm_manager: å¤–éƒ¨æä¾›çš„LLMç®¡ç†å™¨
            ollama_config: Ollamaé…ç½®å‚æ•°
        """
        # æ–¹å¼1ï¼šä½¿ç”¨å¤–éƒ¨æä¾›çš„LLMç®¡ç†å™¨
        if llm_manager:
            self.llm_manager = llm_manager
            logger.debug("ğŸ”— ä½¿ç”¨å¤–éƒ¨æä¾›çš„LLMç®¡ç†å™¨")
            return
        
        # æ–¹å¼2ï¼šåˆ›å»ºä¸“ç”¨çš„Ollamaå®¢æˆ·ç«¯
        default_ollama_config = {
            "model_name": "deepseek-r1:7b",  # ä½¿ç”¨å·²å®‰è£…çš„deepseek-r1:7bæ¨¡å‹è¿›è¡Œå¿«é€Ÿåˆ†ç±»
            "base_url": "http://localhost:11434",
            "temperature": 0.1,             # åˆ†ç±»ä»»åŠ¡éœ€è¦ç¡®å®šæ€§
            "max_tokens": 500,              # å¿«é€Ÿå“åº”
            "timeout": (5, 30)              # å¿«é€Ÿè¶…æ—¶
        }
        
        # åˆå¹¶ç”¨æˆ·é…ç½®
        if ollama_config:
            default_ollama_config.update(ollama_config)
        
        try:
            # åˆ›å»ºOllamaå®¢æˆ·ç«¯
            self.ollama_client = create_ollama_client(**default_ollama_config)
            logger.debug(f"ğŸ¤– Ollamaå®¢æˆ·ç«¯å·²åˆ›å»º: {default_ollama_config['model_name']}")
            
            # å¿«é€Ÿå¥åº·æ£€æŸ¥
            if hasattr(self.ollama_client, 'validate_config'):
                is_healthy = self.ollama_client.validate_config()
                if not is_healthy:
                    logger.warning("âš ï¸ Ollamaå®¢æˆ·ç«¯å¥åº·æ£€æŸ¥å¤±è´¥")
                    self.ollama_client = None
                else:
                    logger.debug("âœ… Ollamaå®¢æˆ·ç«¯å¥åº·æ£€æŸ¥é€šè¿‡")
                    
        except Exception as e:
            logger.warning(f"âš ï¸ åˆ›å»ºOllamaå®¢æˆ·ç«¯å¤±è´¥: {e}")
            self.ollama_client = None
            
        # æ–¹å¼3ï¼šå¦‚æœOllamaä¸å¯ç”¨ï¼Œåˆ›å»ºåŸºç¡€çš„LLMManager
        if not self.ollama_client and not self.llm_manager:
            try:
                self.llm_manager = LLMManager()
                logger.debug("ğŸ”§ åˆ›å»ºé»˜è®¤LLMç®¡ç†å™¨ä½œä¸ºå›é€€")
            except Exception as e:
                logger.warning(f"âš ï¸ åˆ›å»ºLLMç®¡ç†å™¨å¤±è´¥: {e}")
                raise Exception("æ— æ³•åˆå§‹åŒ–ä»»ä½•LLMèƒ½åŠ›")
    
    def _call_llm(self, prompt: str, temperature: float = 0.1, max_tokens: int = 500) -> Optional[str]:
        """
        é€šç”¨LLMè°ƒç”¨æ¥å£
        
        Args:
            prompt: è¾“å…¥æç¤º
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            
        Returns:
            LLMå“åº”å†…å®¹ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        if not self.enable_llm:
            return None
            
        try:
            # æ–¹å¼1ï¼šä¼˜å…ˆä½¿ç”¨Ollamaå®¢æˆ·ç«¯ï¼ˆæ›´å¿«é€Ÿï¼‰
            if self.ollama_client:
                messages = [LLMMessage(role="user", content=prompt)]
                response = self.ollama_client.chat_completion(
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
                
                if response.success:
                    logger.debug(f"âœ… Ollamaè°ƒç”¨æˆåŠŸ: {response.content[:50]}...")
                    return response.content
                else:
                    logger.warning(f"âš ï¸ Ollamaè°ƒç”¨å¤±è´¥: {response.error_message}")
                    
            # æ–¹å¼2ï¼šä½¿ç”¨LLMç®¡ç†å™¨ä½œä¸ºå›é€€
            if self.llm_manager:
                response_content = self.llm_manager.call_api(
                    prompt=prompt,
                    temperature=temperature
                )
                
                if response_content:
                    logger.debug(f"âœ… LLMç®¡ç†å™¨è°ƒç”¨æˆåŠŸ: {response_content[:50]}...")
                    return response_content
                    
        except Exception as e:
            logger.warning(f"âš ï¸ LLMè°ƒç”¨å¼‚å¸¸: {e}")
            
        return None
    
    def _call_llm_with_fallback(self, prompt: str, fallback_result: Any, **kwargs) -> Any:
        """
        å¸¦å›é€€æœºåˆ¶çš„LLMè°ƒç”¨
        
        Args:
            prompt: LLMæç¤º
            fallback_result: LLMè°ƒç”¨å¤±è´¥æ—¶çš„å›é€€ç»“æœ
            **kwargs: LLMè°ƒç”¨å‚æ•°
            
        Returns:
            LLMç»“æœæˆ–å›é€€ç»“æœ
        """
        llm_result = self._call_llm(prompt, **kwargs)
        
        if llm_result is not None:
            return llm_result
        else:
            logger.debug("ğŸ”§ LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¯å‘å¼å›é€€ç»“æœ")
            return fallback_result
        
    def assess_task_confidence(self, user_query: str, execution_context: Optional[Dict] = None) -> float:
        """
        è¯„ä¼°ä»»åŠ¡çš„ç½®ä¿¡åº¦ - å‡çº§ç‰ˆï¼šæ”¯æŒLLMå¢å¼ºåˆ†æ
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•° (0.0-1.0)
        """
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"confidence_{user_query}_{hash(str(execution_context))}"
        if cache_key in self.assessment_cache:
            logger.debug(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ç½®ä¿¡åº¦è¯„ä¼°")
            return self.assessment_cache[cache_key]
        
        # è·å–å¯å‘å¼åˆ†æç»“æœï¼ˆä½œä¸ºåŸºçº¿å’Œå›é€€ï¼‰
        heuristic_confidence = self._heuristic_confidence_assessment(user_query, execution_context)
        
        # å°è¯•LLMå¢å¼ºåˆ†æ
        if self.enable_llm:
            try:
                llm_confidence = self._llm_confidence_assessment(user_query, execution_context)
                if llm_confidence is not None:
                    # æ™ºèƒ½åˆå¹¶ï¼šLLMåˆ†æä¸ºä¸»ï¼Œå¯å‘å¼åˆ†æä½œä¸ºæ ¡å‡†
                    final_confidence = self._merge_confidence_scores(heuristic_confidence, llm_confidence)
                    logger.debug(f"ğŸ§  ç½®ä¿¡åº¦è¯„ä¼° - å¯å‘å¼:{heuristic_confidence:.3f}, LLM:{llm_confidence:.3f}, åˆå¹¶:{final_confidence:.3f}")
                else:
                    final_confidence = heuristic_confidence
                    logger.debug(f"ğŸ”§ LLMç½®ä¿¡åº¦è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨å¯å‘å¼ç»“æœ:{final_confidence:.3f}")
            except Exception as e:
                logger.warning(f"âš ï¸ LLMç½®ä¿¡åº¦è¯„ä¼°å¼‚å¸¸: {e}")
                final_confidence = heuristic_confidence
        else:
            final_confidence = heuristic_confidence
            logger.debug(f"ğŸ“Š å¯å‘å¼ç½®ä¿¡åº¦è¯„ä¼°:{final_confidence:.3f}")
        
        # ç¼“å­˜ç»“æœ
        self.assessment_cache[cache_key] = final_confidence
        
        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self.assessment_cache) > 100:
            oldest_key = next(iter(self.assessment_cache))
            del self.assessment_cache[oldest_key]
        
        logger.info(f"ğŸ“Š ä»»åŠ¡ç½®ä¿¡åº¦è¯„ä¼°å®Œæˆ: {final_confidence:.3f}")
        return final_confidence
    
    def _heuristic_confidence_assessment(self, user_query: str, execution_context: Optional[Dict] = None) -> float:
        """
        å¯å‘å¼ç½®ä¿¡åº¦è¯„ä¼°ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            å¯å‘å¼ç½®ä¿¡åº¦åˆ†æ•°
        """
        # åŸºäºæŸ¥è¯¢å¤æ‚åº¦çš„è¯„ä¼°
        base_confidence = 0.7
        
        # æŸ¥è¯¢é•¿åº¦å½±å“
        query_length = len(user_query)
        if query_length < 20:
            base_confidence += 0.1
        elif query_length > 100:
            base_confidence -= 0.1
        elif query_length > 200:
            base_confidence -= 0.2
            
        # æŠ€æœ¯æœ¯è¯­æ£€æµ‹
        tech_terms = [
            'API', 'api', 'ç®—æ³•', 'æ•°æ®åº“', 'ç³»ç»Ÿ', 'æ¶æ„', 'ä¼˜åŒ–',
            'æœºå™¨å­¦ä¹ ', 'ML', 'AI', 'äººå·¥æ™ºèƒ½', 'æ·±åº¦å­¦ä¹ ',
            'ç½‘ç»œ', 'çˆ¬è™«', 'æ•°æ®åˆ†æ', 'å®æ—¶', 'æ€§èƒ½'
        ]
        tech_count = sum(1 for term in tech_terms if term in user_query)
        if tech_count > 0:
            base_confidence += min(0.15, tech_count * 0.05)
        
        # å¤æ‚åº¦å…³é”®è¯æ£€æµ‹
        complexity_indicators = [
            'å¤æ‚', 'å›°éš¾', 'æŒ‘æˆ˜', 'é«˜çº§', 'ä¸“ä¸š',
            'å¤šæ­¥éª¤', 'åˆ†å¸ƒå¼', 'å¹¶å‘', 'å¼‚æ­¥', 'é›†æˆ'
        ]
        complexity_count = sum(1 for indicator in complexity_indicators if indicator in user_query)
        if complexity_count > 0:
            base_confidence -= min(0.2, complexity_count * 0.05)
        
        # æ˜ç¡®æ€§å…³é”®è¯æ£€æµ‹
        clarity_indicators = [
            'ç®€å•', 'ç›´æ¥', 'åŸºç¡€', 'å¿«é€Ÿ', 'æ ‡å‡†',
            'å¸®åŠ©', 'è¯·', 'å¦‚ä½•', 'æ€ä¹ˆ', 'ä»€ä¹ˆ'
        ]
        clarity_count = sum(1 for indicator in clarity_indicators if indicator in user_query)
        if clarity_count > 0:
            base_confidence += min(0.1, clarity_count * 0.03)
        
        # æ‰§è¡Œä¸Šä¸‹æ–‡å½±å“
        if execution_context:
            context_factors = len(execution_context)
            if context_factors > 3:
                base_confidence += 0.05  # æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯æé«˜ç½®ä¿¡åº¦
            
            # å®æ—¶æ€§è¦æ±‚
            if execution_context.get('real_time_requirements'):
                base_confidence -= 0.05
            
            # æ€§èƒ½è¦æ±‚
            if execution_context.get('performance_critical'):
                base_confidence -= 0.03
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        return min(1.0, max(0.2, base_confidence))
    
    def _llm_confidence_assessment(self, user_query: str, execution_context: Optional[Dict] = None) -> Optional[float]:
        """
        LLMå¢å¼ºçš„ç½®ä¿¡åº¦è¯„ä¼°
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            LLMè¯„ä¼°çš„ç½®ä¿¡åº¦åˆ†æ•°ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        context_info = ""
        if execution_context:
            context_info = f"\n\nä¸Šä¸‹æ–‡ä¿¡æ¯:\n{json.dumps(execution_context, ensure_ascii=False, indent=2)}"
            
        prompt = f"""
è¯·åˆ†æä¸‹é¢çš„ç”¨æˆ·æŸ¥è¯¢ï¼Œè¯„ä¼°æˆ‘ä»¬èƒ½æˆåŠŸå®Œæˆè¿™ä¸ªä»»åŠ¡çš„ç½®ä¿¡åº¦ã€‚

ç”¨æˆ·æŸ¥è¯¢: "{user_query}"{context_info}

è¯·ä»ä»¥ä¸‹ç»´åº¦åˆ†æ:
1. ä»»åŠ¡æ¸…æ™°åº¦ - éœ€æ±‚æ˜¯å¦æ˜ç¡®
2. æŠ€æœ¯å¯è¡Œæ€§ - æŠ€æœ¯å®ç°éš¾åº¦
3. èµ„æºéœ€æ±‚ - æ‰€éœ€èµ„æºæ˜¯å¦åˆç†
4. å¤æ‚åº¦è¯„ä¼° - ä»»åŠ¡å¤æ‚ç¨‹åº¦
5. é£é™©å› ç´  - æ½œåœ¨çš„å¤±è´¥é£é™©

è¯·è¿”å›ä¸€ä¸ª0.0-1.0ä¹‹é—´çš„ç½®ä¿¡åº¦åˆ†æ•°ï¼Œå¹¶ç®€è¦è¯´æ˜ç†ç”±ã€‚

æ ¼å¼:
ç½®ä¿¡åº¦: 0.85
ç†ç”±: ä»»åŠ¡éœ€æ±‚æ˜ç¡®ï¼ŒæŠ€æœ¯å¯è¡Œæ€§é«˜ï¼Œå¤æ‚åº¦é€‚ä¸­
"""
        
        llm_response = self._call_llm(prompt, temperature=0.1, max_tokens=300)
        if llm_response is None:
            return None
            
        # è§£æLLMå“åº”ï¼Œæå–ç½®ä¿¡åº¦åˆ†æ•°
        try:
            # ç®€å•çš„æ­£åˆ™è§£æ
            import re
            confidence_match = re.search(r'ç½®ä¿¡åº¦[ï¼š:]\s*([0-9.]+)', llm_response)
            if confidence_match:
                confidence_score = float(confidence_match.group(1))
                # ç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´å†…
                confidence_score = min(1.0, max(0.0, confidence_score))
                
                logger.debug(f"ğŸ¤– LLMç½®ä¿¡åº¦åˆ†æ: {confidence_score} - {llm_response[:50]}...")
                return confidence_score
            else:
                logger.warning(f"âš ï¸ æ— æ³•ä»LLMå“åº”ä¸­è§£æç½®ä¿¡åº¦: {llm_response[:100]}")
                return None
                
        except Exception as e:
            logger.warning(f"âš ï¸ LLMç½®ä¿¡åº¦å“åº”è§£æå¤±è´¥: {e}")
            return None
    
    def _merge_confidence_scores(self, heuristic_score: float, llm_score: float) -> float:
        """
        æ™ºèƒ½åˆå¹¶å¯å‘å¼å’ŒLLMç½®ä¿¡åº¦åˆ†æ•°
        
        Args:
            heuristic_score: å¯å‘å¼åˆ†æåˆ†æ•°
            llm_score: LLMåˆ†æåˆ†æ•°
            
        Returns:
            åˆå¹¶åçš„ç½®ä¿¡åº¦åˆ†æ•°
        """
        # åŠ æƒå¹³å‡ï¼šLLMæƒé‡æ›´é«˜ï¼ˆ0.7ï¼‰ï¼Œå¯å‘å¼ä½œä¸ºæ ¡å‡†ï¼ˆ0.3ï¼‰
        merged_score = llm_score * 0.7 + heuristic_score * 0.3
        
        # å¦‚æœä¸¤ä¸ªåˆ†æ•°å·®å¼‚å¾ˆå¤§ï¼Œé™ä½ç½®ä¿¡åº¦ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
        score_diff = abs(llm_score - heuristic_score)
        if score_diff > 0.3:
            # å·®å¼‚æƒ©ç½š
            penalty = min(0.15, score_diff * 0.2)
            merged_score -= penalty
            logger.debug(f"ğŸ” ç½®ä¿¡åº¦åˆ†æ•°å·®å¼‚è¾ƒå¤§({score_diff:.3f})ï¼Œåº”ç”¨æƒ©ç½š:{penalty:.3f}")
        
        return min(1.0, max(0.1, merged_score))

    # ==================== æ ¸å¿ƒ LLM è·¯ç”±åˆ†æå¼•æ“ ====================

    def _llm_route_analysis(self, user_query: str, execution_context: Optional[Dict] = None) -> Optional[TriageClassification]:
        """
        æ ¸å¿ƒ LLM è·¯ç”±åˆ†ææ–¹æ³• - å–ä»£ä¼ ç»Ÿå…³é”®è¯åŒ¹é…
        
        ä½¿ç”¨æœ¬åœ° LLM è¿›è¡Œæ·±åº¦è¯­ä¹‰åˆ†æï¼Œæä¾›ç²¾ç¡®çš„ä»»åŠ¡åˆ†ç±»å’Œè·¯ç”±å†³ç­–
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            LLM åˆ†æç»“æœï¼Œå¤±è´¥æ—¶è¿”å› None
        """
        if not self.enable_llm:
            logger.debug("ğŸ”§ LLM æœªå¯ç”¨ï¼Œè·³è¿‡ LLM è·¯ç”±åˆ†æ")
            return None
            
        logger.info(f"ğŸ§  å¯åŠ¨æ ¸å¿ƒ LLM è·¯ç”±åˆ†æ: {user_query[:50]}...")
        
        try:
            # æ„å»ºä¸“é—¨çš„è·¯ç”±åˆ†ææç¤º
            route_prompt = self._build_route_analysis_prompt(user_query, execution_context)
            
            # è°ƒç”¨æœ¬åœ° LLM è¿›è¡Œåˆ†æ
            llm_response = self._call_llm(route_prompt, temperature=0.1, max_tokens=1000)
            
            if llm_response is None:
                logger.warning("âš ï¸ LLM è·¯ç”±åˆ†æè°ƒç”¨å¤±è´¥")
                return None
            
            # è§£æ LLM çš„å†³ç­–ç»“æœ
            classification = self._parse_llm_route_decision(llm_response, user_query)
            
            if classification:
                logger.info(f"âœ… LLM è·¯ç”±åˆ†ææˆåŠŸ: {classification.domain.value} -> {classification.route_strategy.value}")
                return classification
            else:
                logger.warning("âš ï¸ LLM è·¯ç”±å†³ç­–è§£æå¤±è´¥")
                return None
                
        except Exception as e:
            logger.error(f"âŒ LLM è·¯ç”±åˆ†æå¼‚å¸¸: {e}")
            return None

    def _build_route_analysis_prompt(self, user_query: str, execution_context: Optional[Dict] = None) -> str:
        """
        æ„å»ºä¸“é—¨çš„ LLM è·¯ç”±åˆ†ææç¤º
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            ä¼˜åŒ–çš„è·¯ç”±åˆ†ææç¤º
        """
        # ä¸Šä¸‹æ–‡ä¿¡æ¯å¤„ç†
        context_section = ""
        if execution_context:
            context_section = f"\n\n**æ‰§è¡Œä¸Šä¸‹æ–‡:**\n{json.dumps(execution_context, ensure_ascii=False, indent=2)}"
        
        # æ„å»ºä¸“é—¨çš„è·¯ç”±åˆ†ææç¤º
        route_prompt = f"""# ğŸš¦ ä»»åŠ¡è·¯ç”±åˆ†è¯Šç³»ç»Ÿ

## âš ï¸ è§’è‰²çº¦æŸ - æå…¶é‡è¦ï¼

**ä½ æ˜¯ä¸€ä¸ªçº¯ç²¹çš„"ä»»åŠ¡åˆ†è¯Šå‘˜"ï¼Œåªè´Ÿè´£ä»»åŠ¡åˆ†ç±»å’Œè·¯ç”±å†³ç­–ã€‚**

ğŸš« **ä¸¥ç¦è¡Œä¸ºï¼š**
- ç»å¯¹ä¸èƒ½å›ç­”ç”¨æˆ·çš„é—®é¢˜å†…å®¹
- ä¸èƒ½æä¾›ä»»ä½•æŠ€æœ¯è§£å†³æ–¹æ¡ˆ
- ä¸èƒ½ç»™å‡ºä»»ä½•å»ºè®®æˆ–æŒ‡å¯¼  
- ä¸èƒ½è§£é‡Šæ¦‚å¿µæˆ–æŠ€æœ¯åŸç†
- ä¸èƒ½è¿›è¡Œä»»ä½•å½¢å¼çš„é—®ç­”

âœ… **å”¯ä¸€èŒè´£ï¼š**
- ä»…å¯¹ç”¨æˆ·æŸ¥è¯¢è¿›è¡ŒæŠ€æœ¯ç»´åº¦åˆ†ç±»
- ä»…åˆ¤æ–­ä»»åŠ¡å¤æ‚åº¦å’Œå¤„ç†ç­–ç•¥
- ä»…è¾“å‡ºæ ‡å‡†åŒ–çš„è·¯ç”±å†³ç­–JSON

## ğŸ“‹ å¾…åˆ†ææŸ¥è¯¢

**ç”¨æˆ·è¾“å…¥:** "{user_query}"{context_section}

## ğŸ¯ åˆ†è¯Šç»´åº¦ï¼ˆä»…åˆ†ç±»ï¼Œä¸è§£ç­”ï¼‰

### å¤æ‚åº¦åˆ†è¯Š
- **simple**: é—®å€™è¯­ã€å•ä¸€æ¦‚å¿µæŸ¥è¯¢ï¼ˆå¦‚"ä½ å¥½"ã€"ä»€ä¹ˆæ˜¯HTTP"ï¼‰
- **moderate**: éœ€è¦å¤šæ­¥éª¤åˆ†æçš„æŠ€æœ¯é—®é¢˜
- **complex**: ç³»ç»Ÿè®¾è®¡æˆ–æ¶æ„çº§é—®é¢˜
- **expert**: éœ€è¦æ·±åº¦ä¸“ä¸šçŸ¥è¯†çš„é«˜éš¾åº¦é—®é¢˜

### æŠ€æœ¯é¢†åŸŸåˆ†è¯Š
- **web_development**: Webç›¸å…³æŠ€æœ¯
- **data_science**: æ•°æ®åˆ†æ/MLç›¸å…³
- **system_admin**: ç³»ç»Ÿè¿ç»´ç›¸å…³
- **database**: æ•°æ®åº“ç›¸å…³
- **general**: é€šç”¨æˆ–è·¨é¢†åŸŸ

### æ„å›¾åˆ†è¯Š
- **question**: çŸ¥è¯†æŸ¥è¯¢ç±»ï¼ˆå¦‚"ä»€ä¹ˆæ˜¯..."ã€"å¦‚ä½•..."ï¼‰
- **task_execution**: å…·ä½“ä»»åŠ¡æ‰§è¡Œ
- **debugging**: é—®é¢˜æ’æŸ¥ä¿®å¤

### ç´§æ€¥åº¦åˆ†è¯Š
- **low**: å­¦ä¹ æ€§æŸ¥è¯¢
- **medium**: å¸¸è§„å·¥ä½œä»»åŠ¡
- **high**: é‡è¦é¡¹ç›®éœ€æ±‚
- **critical**: ç”Ÿäº§ç¯å¢ƒç´§æ€¥æƒ…å†µ

### å¤„ç†ç­–ç•¥åˆ†è¯Š
- **direct_response**: ç®€å•é—®é¢˜ï¼Œå¿«é€Ÿé€šé“å¤„ç†
- **multi_stage_processing**: ä¸­ç­‰å¤æ‚åº¦ï¼Œæ ‡å‡†æµç¨‹å¤„ç†
- **workflow_planning**: å¤æ‚ä»»åŠ¡ï¼Œéœ€è¦è¯¦ç»†è§„åˆ’
- **expert_consultation**: é«˜éš¾åº¦ï¼Œéœ€è¦ä¸“å®¶çº§å¤„ç†

## ğŸ“„ è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼JSONï¼Œæ— å…¶ä»–å†…å®¹ï¼‰

```json
{{
  "complexity": "simple|moderate|complex|expert",
  "domain": "é¢†åŸŸä»£ç ",
  "intent": "æ„å›¾ä»£ç ", 
  "urgency": "ç´§æ€¥åº¦ä»£ç ",
  "route_strategy": "å¤„ç†ç­–ç•¥ä»£ç ",
  "confidence": 0.85,
  "reasoning": "åˆ†è¯Šç†ç”±ï¼ˆ50å­—å†…ï¼Œä»…è¯´æ˜åˆ†ç±»ä¾æ®ï¼‰",
  "key_factors": ["æŠ€æœ¯ç»´åº¦1", "æŠ€æœ¯ç»´åº¦2"],
  "estimated_time": é¢„ä¼°åˆ†é’Ÿæ•°,
  "required_resources": ["èµ„æºç±»å‹1", "èµ„æºç±»å‹2"]
}}
```

âš ï¸ **å†æ¬¡å¼ºè°ƒï¼šä½ åªæ˜¯ä¸€ä¸ªåˆ†è¯Šå‘˜ï¼Œç»å¯¹ä¸èƒ½å›ç­”é—®é¢˜å†…å®¹ï¼**"""
        
        return route_prompt

    def _parse_llm_route_decision(self, llm_response: str, user_query: str) -> Optional[TriageClassification]:
        """
        è§£æ LLM çš„è·¯ç”±å†³ç­–ç»“æœ
        
        Args:
            llm_response: LLM çš„åŸå§‹å“åº”
            user_query: åŸå§‹ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            è§£æåçš„åˆ†ç±»ç»“æœï¼Œå¤±è´¥æ—¶è¿”å› None
        """
        try:
            # å¤šç§æ–¹å¼æå–JSON
            import re
            
            # æ–¹å¼1ï¼šæå–```jsonå—ä¸­çš„å†…å®¹
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', llm_response, re.DOTALL)
            
            if not json_match:
                # æ–¹å¼2ï¼šæå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
                json_match = re.search(r'(\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\})', llm_response, re.DOTALL)
            
            if not json_match:
                # æ–¹å¼3ï¼šå°è¯•æ›´å®½æ¾çš„åŒ¹é…
                json_match = re.search(r'(\{.*\})', llm_response, re.DOTALL)
            
            if not json_match:
                logger.warning(f"âš ï¸ æ— æ³•ä» LLM å“åº”ä¸­æå– JSON å†³ç­–ç»“æœ")
                return None
            
            # è§£æJSONå†³ç­–æ•°æ®
            decision_data = json.loads(json_match.group(1))
            
            # éªŒè¯å¿…è¦å­—æ®µ
            required_fields = ['complexity', 'domain', 'intent', 'urgency', 'route_strategy']
            missing_fields = [field for field in required_fields if field not in decision_data]
            
            if missing_fields:
                logger.warning(f"âš ï¸ LLM å†³ç­–ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
                return None
            
            # æ„å»ºåˆ†ç±»ç»“æœ
            classification = TriageClassification(
                complexity=TaskComplexity(decision_data['complexity']),
                domain=TaskDomain(decision_data['domain']),
                intent=TaskIntent(decision_data['intent']),
                urgency=TaskUrgency(decision_data['urgency']),
                route_strategy=RouteStrategy(decision_data['route_strategy']),
                confidence=float(decision_data.get('confidence', 0.8)),
                reasoning=decision_data.get('reasoning', 'LLM è·¯ç”±åˆ†æç»“æœ'),
                key_factors=decision_data.get('key_factors', []),
                estimated_time=decision_data.get('estimated_time'),
                required_resources=decision_data.get('required_resources', [])
            )
            
            logger.debug(f"âœ… LLM è·¯ç”±å†³ç­–è§£ææˆåŠŸ: {classification.complexity.value}/{classification.domain.value}")
            return classification
            
        except json.JSONDecodeError as e:
            logger.warning(f"âš ï¸ LLM è·¯ç”±å†³ç­– JSON è§£æå¤±è´¥: {e}")
            return None
        except (ValueError, KeyError) as e:
            logger.warning(f"âš ï¸ LLM è·¯ç”±å†³ç­–æ•°æ®éªŒè¯å¤±è´¥: {e}")
            return None
        except Exception as e:
            logger.error(f"âŒ LLM è·¯ç”±å†³ç­–å¤„ç†å¼‚å¸¸: {e}")
            return None

    def _fallback_keyword_analysis(self, user_query: str, execution_context: Optional[Dict] = None) -> TriageClassification:
        """
        å›é€€å…³é”®è¯åˆ†ææ–¹æ³• - å°è£…ä¼ ç»Ÿçš„å…³é”®è¯åŒ¹é…é€»è¾‘
        
        å½“ LLM åˆ†æå¤±è´¥æ—¶ä½¿ç”¨æ­¤æ–¹æ³•ä½œä¸ºå¯é å›é€€
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            åŸºäºå…³é”®è¯åŒ¹é…çš„åˆ†ç±»ç»“æœ
        """
        logger.info(f"ğŸ”§ å¯åŠ¨å›é€€å…³é”®è¯åˆ†æ: {user_query[:50]}...")
        
        # ä½¿ç”¨ä¼ ç»Ÿçš„å¤æ‚åº¦åˆ†æ
        complexity_analysis = self.analyze_task_complexity(user_query)
        confidence_score = self._heuristic_confidence_assessment(user_query, execution_context)
        
        # å¤æ‚åº¦åˆ°åˆ†ç±»çš„æ˜ å°„
        complexity_score = complexity_analysis.get('complexity_score', 0.5)
        
        if complexity_score < 0.3:
            complexity = TaskComplexity.SIMPLE
            route_strategy = RouteStrategy.DIRECT_RESPONSE
        elif complexity_score < 0.6:
            complexity = TaskComplexity.MODERATE
            route_strategy = RouteStrategy.MULTI_STAGE_PROCESSING
        elif complexity_score < 0.8:
            complexity = TaskComplexity.COMPLEX
            route_strategy = RouteStrategy.WORKFLOW_PLANNING
        else:
            complexity = TaskComplexity.EXPERT
            route_strategy = RouteStrategy.EXPERT_CONSULTATION
        
        # ä¼ ç»Ÿé¢†åŸŸæ¨æ–­
        estimated_domain = complexity_analysis.get('estimated_domain', 'general')
        domain_mapping = {
            'web_development': TaskDomain.WEB_DEV,
            'data_science': TaskDomain.DATA_SCIENCE,
            'api_development': TaskDomain.API_DEV,
            'database': TaskDomain.DATABASE,
            'system_admin': TaskDomain.SYSTEM_ADMIN,
            'security': TaskDomain.SECURITY,
            'mobile_development': TaskDomain.MOBILE_DEV,
            'performance': TaskDomain.SYSTEM_ADMIN,
            'automation': TaskDomain.SYSTEM_ADMIN,
        }
        domain = domain_mapping.get(estimated_domain, TaskDomain.GENERAL)
        
        # ä¼ ç»Ÿæ„å›¾åˆ†æï¼ˆåŸºäºå…³é”®è¯ï¼‰
        intent = self._keyword_intent_analysis(user_query)
        
        # ä¼ ç»Ÿç´§æ€¥åº¦è¯„ä¼°ï¼ˆåŸºäºå…³é”®è¯ï¼‰
        urgency = self._keyword_urgency_analysis(user_query)
        
        # æ„å»ºå›é€€åˆ†ç±»ç»“æœ
        fallback_classification = TriageClassification(
            complexity=complexity,
            domain=domain,
            intent=intent,
            urgency=urgency,
            route_strategy=route_strategy,
            confidence=confidence_score * 0.8,  # å…³é”®è¯åˆ†æç½®ä¿¡åº¦ç•¥ä½
            reasoning=f"å…³é”®è¯åˆ†æï¼šå¤æ‚åº¦{complexity_score:.2f}ï¼Œé¢†åŸŸ{estimated_domain}",
            key_factors=list(complexity_analysis.get('complexity_factors', {}).keys())[:3],
            estimated_time=self._estimate_processing_time(complexity, domain),
            required_resources=self._estimate_required_resources(domain, complexity)
        )
        
        logger.info(f"âœ… å…³é”®è¯åˆ†æå®Œæˆ: {domain.value} -> {route_strategy.value}")
        return fallback_classification

    def _keyword_intent_analysis(self, user_query: str) -> TaskIntent:
        """åŸºäºå…³é”®è¯çš„æ„å›¾åˆ†æ"""
        query_lower = user_query.lower()
        
        # é—®é¢˜å’¨è¯¢å…³é”®è¯
        if any(word in query_lower for word in ['å¦‚ä½•', 'æ€ä¹ˆ', 'ä»€ä¹ˆæ˜¯', 'è¯·æ•™', 'å­¦ä¹ ', 'è§£é‡Š', 'ä»‹ç»']):
            return TaskIntent.QUESTION
        
        # åˆ›å»ºå¼€å‘å…³é”®è¯
        elif any(word in query_lower for word in ['åˆ›å»º', 'ç”Ÿæˆ', 'è®¾è®¡', 'å¼€å‘', 'å†™', 'æ„å»º', 'å®ç°']):
            return TaskIntent.CREATION
        
        # åˆ†æè¯„ä¼°å…³é”®è¯
        elif any(word in query_lower for word in ['åˆ†æ', 'è¯„ä¼°', 'æ¯”è¾ƒ', 'æ£€æŸ¥', 'å®¡æŸ¥', 'æµ‹è¯•']):
            return TaskIntent.ANALYSIS
        
        # è°ƒè¯•ä¿®å¤å…³é”®è¯
        elif any(word in query_lower for word in ['ä¿®å¤', 'è§£å†³', 'è°ƒè¯•', 'é”™è¯¯', 'é—®é¢˜', 'æ•…éšœ', 'å¼‚å¸¸']):
            return TaskIntent.DEBUGGING
        
        # ä¼˜åŒ–æ”¹è¿›å…³é”®è¯
        elif any(word in query_lower for word in ['ä¼˜åŒ–', 'æå‡', 'æ”¹è¿›', 'åŠ é€Ÿ', 'æ€§èƒ½', 'æ•ˆç‡']):
            return TaskIntent.OPTIMIZATION
        
        # é»˜è®¤ä¸ºä»»åŠ¡æ‰§è¡Œ
        else:
            return TaskIntent.TASK_EXECUTION

    def _keyword_urgency_analysis(self, user_query: str) -> TaskUrgency:
        """åŸºäºå…³é”®è¯çš„ç´§æ€¥åº¦åˆ†æ"""
        query_lower = user_query.lower()
        
        # ç´§æ€¥å…³é”®è¯
        if any(word in query_lower for word in ['ç´§æ€¥', 'æ€¥', 'é©¬ä¸Š', 'ç«‹å³', 'ç°åœ¨', 'critical', 'urgent', 'asap']):
            return TaskUrgency.CRITICAL
        
        # é‡è¦å…³é”®è¯
        elif any(word in query_lower for word in ['é‡è¦', 'å°½å¿«', 'ä¼˜å…ˆ', 'important', 'priority', 'high']):
            return TaskUrgency.HIGH
        
        # å­¦ä¹ æ¢ç´¢å…³é”®è¯
        elif any(word in query_lower for word in ['å­¦ä¹ ', 'äº†è§£', 'æ¢ç´¢', 'ç ”ç©¶', 'è¯•è¯•', 'çœ‹çœ‹']):
            return TaskUrgency.LOW
        
        # é»˜è®¤ä¸ºä¸­ç­‰ä¼˜å…ˆçº§
        else:
            return TaskUrgency.MEDIUM

    # ==================== è·¯ç”±ä¸“å®¶åŠŸèƒ½å®ç° ====================

    def classify_and_route(self, user_query: str, execution_context: Optional[Dict] = None) -> TriageClassification:
        """
        æ ¸å¿ƒè·¯ç”±åŠŸèƒ½ - å‡çº§ç‰ˆæ™ºèƒ½ä»»åŠ¡åˆ†è¯Š
        
        æ–°æ¶æ„ï¼šLLM æ ¸å¿ƒåˆ†æ + å…³é”®è¯å›é€€æœºåˆ¶
        - ä¸»è¦ï¼šä½¿ç”¨æœ¬åœ° LLM è¿›è¡Œæ·±åº¦è¯­ä¹‰ç†è§£å’Œè·¯ç”±å†³ç­–
        - å›é€€ï¼šå½“ LLM åˆ†æå¤±è´¥æ—¶ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…ä½œä¸ºå¯é å›é€€
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            TriageClassification: å®Œæ•´çš„æ™ºèƒ½åˆ†ç±»ç»“æœ
        """
        logger.info(f"ğŸš€ å¯åŠ¨æ™ºèƒ½è·¯ç”±åˆ†æ: {user_query[:50]}...")
        
        # ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šLLM æ ¸å¿ƒè·¯ç”±åˆ†æ
        llm_result = self._llm_route_analysis(user_query, execution_context)
        if llm_result:
            logger.info(f"âœ… LLM è·¯ç”±æˆåŠŸ: {llm_result.domain.value} -> {llm_result.route_strategy.value} (ç½®ä¿¡åº¦: {llm_result.confidence:.2f})")
            return llm_result
        
        # ç¬¬äºŒä¼˜å…ˆçº§ï¼šå…³é”®è¯å›é€€åˆ†æ
        logger.info("ğŸ”§ LLM åˆ†æä¸å¯ç”¨ï¼Œå¯åŠ¨å…³é”®è¯å›é€€åˆ†æ")
        fallback_result = self._fallback_keyword_analysis(user_query, execution_context)
        
        logger.info(f"ğŸ“Š å›é€€åˆ†æå®Œæˆ: {fallback_result.domain.value} -> {fallback_result.route_strategy.value} (ç½®ä¿¡åº¦: {fallback_result.confidence:.2f})")
        return fallback_result





    def _estimate_processing_time(self, complexity: TaskComplexity, domain: TaskDomain) -> int:
        """ä¼°ç®—å¤„ç†æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"""
        base_time = {
            TaskComplexity.SIMPLE: 5,
            TaskComplexity.MODERATE: 15,
            TaskComplexity.COMPLEX: 45,
            TaskComplexity.EXPERT: 120
        }
        
        domain_multiplier = {
            TaskDomain.GENERAL: 1.0,
            TaskDomain.WEB_DEV: 1.2,
            TaskDomain.DATA_SCIENCE: 1.5,
            TaskDomain.ML_AI: 1.8,
            TaskDomain.SYSTEM_ADMIN: 1.3,
            TaskDomain.SECURITY: 1.4
        }
        
        base = base_time.get(complexity, 30)
        multiplier = domain_multiplier.get(domain, 1.0)
        return int(base * multiplier)

    def _estimate_required_resources(self, domain: TaskDomain, complexity: TaskComplexity) -> List[str]:
        """ä¼°ç®—æ‰€éœ€èµ„æº"""
        resources = []
        
        # åŸºç¡€èµ„æº
        if complexity in [TaskComplexity.COMPLEX, TaskComplexity.EXPERT]:
            resources.extend(["ä¸“ä¸šçŸ¥è¯†åº“", "æŠ€æœ¯æ–‡æ¡£"])
        
        # é¢†åŸŸç‰¹å®šèµ„æº
        domain_resources = {
            TaskDomain.WEB_DEV: ["å‰ç«¯æ¡†æ¶", "åç«¯æŠ€æœ¯æ ˆ"],
            TaskDomain.DATA_SCIENCE: ["æ•°æ®é›†", "åˆ†æå·¥å…·"],
            TaskDomain.ML_AI: ["è®¡ç®—èµ„æº", "æ¨¡å‹åº“"],
            TaskDomain.DATABASE: ["æ•°æ®åº“å®ä¾‹", "æŸ¥è¯¢å·¥å…·"],
            TaskDomain.SYSTEM_ADMIN: ["ç³»ç»Ÿæƒé™", "ç›‘æ§å·¥å…·"],
            TaskDomain.SECURITY: ["å®‰å…¨å·¥å…·", "å¨èƒæƒ…æŠ¥"]
        }
        
        resources.extend(domain_resources.get(domain, []))
        return resources[:4]  # é™åˆ¶æœ€å¤š4ä¸ªèµ„æº
    
    def get_thinking_seed(self, user_query: str, execution_context: Optional[Dict] = None) -> str:
        """
        ç”Ÿæˆæ€ç»´ç§å­ - å…¼å®¹æ€§é€‚é…å™¨æ–¹æ³•
        
        æ³¨æ„ï¼šæ­¤æ–¹æ³•ç°åœ¨åŸºäºè½»é‡çº§åˆ†æåŠŸèƒ½é‡æ–°å®ç°ï¼Œä¿æŒä¸åŸæœ‰æ¥å£çš„å…¼å®¹æ€§
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            åŸºäºå¿«é€Ÿåˆ†æç”Ÿæˆçš„æ€ç»´ç§å­
        """
        logger.info(f"ğŸ”„ ä½¿ç”¨è½»é‡çº§åˆ†æç”Ÿæˆæ€ç»´ç§å­: {user_query[:30]}...")
        
        try:
            # ä½¿ç”¨æ–°çš„å¿«é€Ÿåˆ†æåŠŸèƒ½ç”Ÿæˆæ€ç»´ç§å­
            analysis = self.get_quick_analysis_summary(user_query, execution_context)
            
            # æ„å»ºç»“æ„åŒ–çš„æ€ç»´ç§å­
            seed_parts = []
            
            # é—®é¢˜ç†è§£éƒ¨åˆ†
            seed_parts.append(f"è¿™æ˜¯ä¸€ä¸ª{analysis['domain']}é¢†åŸŸçš„ä»»åŠ¡ã€‚")
            
            # å¤æ‚åº¦åˆ†æ
            complexity = analysis['complexity_score']
            if complexity > 0.8:
                seed_parts.append("ä»»åŠ¡å…·æœ‰é«˜å¤æ‚åº¦ï¼Œéœ€è¦ç³»ç»Ÿæ€§å’Œå¤šæ­¥éª¤çš„è§£å†³æ–¹æ¡ˆã€‚")
            elif complexity > 0.5:
                seed_parts.append("ä»»åŠ¡å¤æ‚åº¦é€‚ä¸­ï¼Œéœ€è¦ç»“æ„åŒ–çš„åˆ†ææ–¹æ³•ã€‚")
            else:
                seed_parts.append("ä»»åŠ¡ç›¸å¯¹ç®€å•ï¼Œå¯ä»¥é‡‡ç”¨ç›´æ¥çš„è§£å†³æ–¹æ³•ã€‚")
            
            # ç½®ä¿¡åº¦è€ƒè™‘
            confidence = analysis['confidence_score']
            if confidence > 0.8:
                seed_parts.append("åŸºäºé—®é¢˜æè¿°ï¼Œæˆ‘ä»¬æœ‰è¾ƒé«˜çš„ä¿¡å¿ƒæ‰¾åˆ°æœ‰æ•ˆè§£å†³æ–¹æ¡ˆã€‚")
            elif confidence > 0.5:
                seed_parts.append("é—®é¢˜éœ€è¦è¿›ä¸€æ­¥åˆ†æä»¥ç¡®å®šæœ€ä½³æ–¹æ³•ã€‚")
            else:
                seed_parts.append("é—®é¢˜å¯èƒ½éœ€è¦é¢å¤–ä¿¡æ¯æˆ–æ¾„æ¸…æ¥åˆ¶å®šæœ‰æ•ˆæ–¹æ¡ˆã€‚")
            
            # å…³é”®å› ç´ 
            if analysis['key_factors']:
                factors_text = "ã€".join(analysis['key_factors'][:3])
                seed_parts.append(f"å…³é”®è€ƒè™‘å› ç´ åŒ…æ‹¬ï¼š{factors_text}ã€‚")
            
            # æ¨èç­–ç•¥
            seed_parts.append(f"å»ºè®®é‡‡ç”¨çš„ç­–ç•¥ï¼š{analysis['recommendation']}")
            
            # å¤šæ­¥éª¤æ£€æµ‹
            if analysis['requires_multi_step']:
                seed_parts.append("è¿™æ˜¯ä¸€ä¸ªå¤šé˜¶æ®µä»»åŠ¡ï¼Œéœ€è¦æŒ‰æ­¥éª¤é€ä¸€æ‰§è¡Œã€‚")
            
            # æ‰§è¡Œä¸Šä¸‹æ–‡è€ƒè™‘
            if execution_context:
                if execution_context.get('real_time_requirements'):
                    seed_parts.append("éœ€è¦ç‰¹åˆ«æ³¨æ„å®æ—¶æ€§è¦æ±‚ã€‚")
                if execution_context.get('performance_critical'):
                    seed_parts.append("æ€§èƒ½ä¼˜åŒ–æ˜¯å…³é”®è€ƒè™‘å› ç´ ã€‚")
            
            thinking_seed = " ".join(seed_parts)
            
            logger.info(f"âœ… æ€ç»´ç§å­ç”Ÿæˆå®Œæˆ (é•¿åº¦: {len(thinking_seed)}å­—ç¬¦)")
            logger.debug(f"ğŸŒ± ç§å­å†…å®¹: {thinking_seed[:100]}...")
            
            return thinking_seed
            
        except Exception as e:
            logger.error(f"âš ï¸ è½»é‡çº§æ€ç»´ç§å­ç”Ÿæˆå¤±è´¥: {e}")
            
            # æœ€ç»ˆå›é€€ï¼šä½¿ç”¨åŸºç¡€åˆ†æç”Ÿæˆç®€å•ç§å­
            try:
                complexity_info = self.analyze_task_complexity(user_query)
                confidence_score = self.assess_task_confidence(user_query, execution_context)
                
                fallback_seed = (
                    f"è¿™æ˜¯ä¸€ä¸ªå…³äº'{user_query}'çš„{complexity_info['estimated_domain']}ä»»åŠ¡ã€‚"
                    f"å¤æ‚åº¦è¯„ä¼°ä¸º{complexity_info['complexity_score']:.2f}ï¼Œ"
                    f"ç½®ä¿¡åº¦ä¸º{confidence_score:.2f}ã€‚"
                    f"å»ºè®®é‡‡ç”¨ç³»ç»Ÿæ€§çš„æ–¹æ³•æ¥åˆ†æå’Œè§£å†³è¿™ä¸ªé—®é¢˜ã€‚"
                )
                
                logger.info(f"ğŸ”§ ä½¿ç”¨å›é€€ç§å­ç”Ÿæˆ (é•¿åº¦: {len(fallback_seed)}å­—ç¬¦)")
                return fallback_seed
                
            except Exception as fallback_error:
                logger.error(f"âš ï¸ å›é€€ç§å­ç”Ÿæˆä¹Ÿå¤±è´¥: {fallback_error}")
                
                # ç»å¯¹æœ€ç»ˆå›é€€
                default_seed = (
                    f"é’ˆå¯¹'{user_query}'è¿™ä¸ªä»»åŠ¡ï¼Œéœ€è¦è¿›è¡Œç³»ç»Ÿæ€§çš„åˆ†æã€‚"
                    f"å»ºè®®é¦–å…ˆç†è§£é—®é¢˜çš„æ ¸å¿ƒéœ€æ±‚ï¼Œç„¶ååˆ¶å®šåˆ†æ­¥éª¤çš„è§£å†³æ–¹æ¡ˆï¼Œ"
                    f"æœ€åéªŒè¯æ–¹æ¡ˆçš„å¯è¡Œæ€§å’Œæœ‰æ•ˆæ€§ã€‚"
                )
                
                logger.info("ğŸ”§ ä½¿ç”¨é»˜è®¤é€šç”¨ç§å­")
                return default_seed
    
    def analyze_task_complexity(self, user_query: str) -> Dict[str, Any]:
        """
        åˆ†æä»»åŠ¡å¤æ‚åº¦
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            å¤æ‚åº¦åˆ†æç»“æœ
        """
        complexity_score = 0.5
        complexity_factors = {}
        
        # å…³é”®è¯å¤æ‚åº¦æŒ‡æ ‡
        complexity_keywords = {
            'å¤šæ­¥éª¤': 0.15,
            'é›†æˆ': 0.12,
            'ä¼˜åŒ–': 0.10,
            'åˆ†æ': 0.08,
            'è®¾è®¡': 0.08,
            'æ¶æ„': 0.12,
            'åˆ†å¸ƒå¼': 0.15,
            'å¹¶å‘': 0.13,
            'å®æ—¶': 0.10,
            'é«˜æ€§èƒ½': 0.11,
            'æœºå™¨å­¦ä¹ ': 0.14,
            'æ·±åº¦å­¦ä¹ ': 0.16,
            'ç®—æ³•': 0.09,
            'æ•°æ®åº“': 0.07,
            'ç½‘ç»œ': 0.06,
            'å®‰å…¨': 0.08
        }
        
        for keyword, weight in complexity_keywords.items():
            if keyword in user_query:
                complexity_score += weight
                complexity_factors[keyword] = weight
                logger.debug(f"ğŸ” æ£€æµ‹åˆ°å¤æ‚åº¦å…³é”®è¯: {keyword} (+{weight})")
        
        # å¥æ³•å¤æ‚åº¦
        sentences = user_query.split('ã€‚')
        if len(sentences) > 3:
            syntax_complexity = min(0.1, (len(sentences) - 3) * 0.02)
            complexity_score += syntax_complexity
            complexity_factors['å¤šå¥è¡¨è¾¾'] = syntax_complexity
        
        # å­—ç¬¦é•¿åº¦å¤æ‚åº¦
        if len(user_query) > 150:
            length_complexity = min(0.08, (len(user_query) - 150) / 1000)
            complexity_score += length_complexity
            complexity_factors['è¡¨è¾¾é•¿åº¦'] = length_complexity
        
        # æŠ€æœ¯è¯æ±‡å¯†åº¦
        tech_words = ['API', 'HTTP', 'JSON', 'SQL', 'Python', 'JavaScript', 'REST', 'GraphQL']
        tech_density = sum(1 for word in tech_words if word in user_query) / max(len(user_query.split()), 1)
        if tech_density > 0.1:
            tech_complexity = min(0.12, tech_density * 2)
            complexity_score += tech_complexity
            complexity_factors['æŠ€æœ¯è¯æ±‡å¯†åº¦'] = tech_complexity
        
        # é¢†åŸŸæ¨æ–­
        domain = self._infer_domain(user_query)
        
        # å¤šæ­¥éª¤æ£€æµ‹
        requires_multi_step = any(word in user_query for word in [
            'æ­¥éª¤', 'é˜¶æ®µ', 'åˆ†æ­¥', 'ç„¶å', 'æ¥ä¸‹æ¥', 'é¦–å…ˆ', 'æœ€å',
            'ç¬¬ä¸€', 'ç¬¬äºŒ', 'ç¬¬ä¸‰', 'ä¾æ¬¡', 'é¡ºåº'
        ])
        
        # é™åˆ¶å¤æ‚åº¦åˆ†æ•°
        final_complexity = min(1.0, complexity_score)
        
        result = {
            'complexity_score': final_complexity,
            'complexity_factors': complexity_factors,
            'estimated_domain': domain,
            'requires_multi_step': requires_multi_step,
            'sentence_count': len(sentences),
            'word_count': len(user_query.split()),
            'tech_density': tech_density
        }
        
        logger.info(f"ğŸ§® å¤æ‚åº¦åˆ†æå®Œæˆ: {final_complexity:.3f} (å› å­æ•°:{len(complexity_factors)})")
        return result
    
    def _infer_domain(self, user_query: str) -> str:
        """
        æ¨æ–­ä»»åŠ¡é¢†åŸŸ
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            æ¨æ–­çš„é¢†åŸŸ
        """
        query_lower = user_query.lower()
        
        domain_indicators = {
            'web_development': ['ç½‘ç«™', 'web', 'html', 'css', 'javascript', 'å‰ç«¯', 'åç«¯'],
            'data_science': ['æ•°æ®åˆ†æ', 'æ•°æ®ç§‘å­¦', 'pandas', 'numpy', 'æœºå™¨å­¦ä¹ ', 'æ¨¡å‹', 'é¢„æµ‹'],
            'api_development': ['api', 'æ¥å£', 'rest', 'restful', 'graphql', 'endpoints'],
            'web_scraping': ['çˆ¬è™«', 'spider', 'scrapy', 'æŠ“å–', 'çˆ¬å–', 'crawl'],
            'database': ['æ•°æ®åº“', 'sql', 'mysql', 'postgresql', 'mongodb', 'æŸ¥è¯¢'],
            'system_admin': ['ç³»ç»Ÿ', 'æœåŠ¡å™¨', 'éƒ¨ç½²', 'è¿ç»´', 'docker', 'kubernetes'],
            'mobile_development': ['ç§»åŠ¨', 'app', 'å®‰å“', 'android', 'ios', 'react native'],
            'security': ['å®‰å…¨', 'åŠ å¯†', 'è®¤è¯', 'æˆæƒ', 'é˜²æŠ¤', 'security'],
            'performance': ['æ€§èƒ½', 'ä¼˜åŒ–', 'é€Ÿåº¦', 'æ•ˆç‡', 'benchmark', 'è´Ÿè½½'],
            'automation': ['è‡ªåŠ¨åŒ–', 'è„šæœ¬', 'å®šæ—¶', 'æ‰¹å¤„ç†', 'cron', 'schedule']
        }
        
        domain_scores = {}
        for domain, keywords in domain_indicators.items():
            score = sum(1 for keyword in keywords if keyword in query_lower)
            if score > 0:
                domain_scores[domain] = score
        
        if domain_scores:
            inferred_domain = max(domain_scores, key=domain_scores.get)
            logger.debug(f"ğŸ·ï¸ æ¨æ–­é¢†åŸŸ: {inferred_domain} (åŒ¹é…åº¦:{domain_scores[inferred_domain]})")
            return inferred_domain
        
        return 'general'
    
    def get_confidence_statistics(self) -> Dict[str, Any]:
        """
        è·å–ç½®ä¿¡åº¦ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç½®ä¿¡åº¦ç»Ÿè®¡æ•°æ®
        """
        if not self.confidence_history:
            return {
                'total_assessments': 0,
                'avg_confidence': 0.0,
                'confidence_trend': 'insufficient_data',
                'cache_size': len(self.assessment_cache)
            }
        
        confidences = [item['predicted_confidence'] for item in self.confidence_history]
        avg_confidence = sum(confidences) / len(confidences)
        
        # è®¡ç®—è¶‹åŠ¿
        if len(confidences) >= 5:
            recent_avg = sum(confidences[-5:]) / 5
            earlier_avg = sum(confidences[-10:-5]) / 5 if len(confidences) >= 10 else avg_confidence
            
            if recent_avg > earlier_avg + 0.05:
                trend = 'improving'
            elif recent_avg < earlier_avg - 0.05:
                trend = 'declining'
            else:
                trend = 'stable'
        else:
            trend = 'insufficient_data'
        
        return {
            'total_assessments': len(self.confidence_history),
            'avg_confidence': avg_confidence,
            'min_confidence': min(confidences),
            'max_confidence': max(confidences),
            'confidence_trend': trend,
            'cache_size': len(self.assessment_cache),
            'recent_confidences': confidences[-5:] if len(confidences) >= 5 else confidences
        }
    
    def update_confidence_feedback(self, predicted_confidence: float, 
                                 actual_success: bool, execution_time: float):
        """
        æ›´æ–°ç½®ä¿¡åº¦åé¦ˆï¼Œç”¨äºæ”¹è¿›é¢„æµ‹å‡†ç¡®æ€§
        
        Args:
            predicted_confidence: é¢„æµ‹çš„ç½®ä¿¡åº¦
            actual_success: å®é™…æ‰§è¡Œæ˜¯å¦æˆåŠŸ
            execution_time: æ‰§è¡Œæ—¶é—´
        """
        feedback_record = {
            'timestamp': time.time(),
            'predicted_confidence': predicted_confidence,
            'actual_success': actual_success,
            'execution_time': execution_time,
            'confidence_accuracy': abs(predicted_confidence - (1.0 if actual_success else 0.0))
        }
        
        self.confidence_history.append(feedback_record)
        
        # é™åˆ¶å†å²é•¿åº¦
        if len(self.confidence_history) > 200:
            self.confidence_history = self.confidence_history[-100:]
        
        logger.debug(f"ğŸ“ˆ æ›´æ–°ç½®ä¿¡åº¦åé¦ˆ: é¢„æµ‹={predicted_confidence:.3f}, å®é™…={'æˆåŠŸ' if actual_success else 'å¤±è´¥'}")
    
    def get_quick_analysis_summary(self, user_query: str, execution_context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        è·å–å¿«é€Ÿåˆ†ææ€»ç»“ - PriorReasonerçš„æ–°æ ¸å¿ƒåŠŸèƒ½
        
        æä¾›ä»»åŠ¡çš„å¿«é€Ÿæ¦‚è§ˆï¼ŒåŒ…æ‹¬å¤æ‚åº¦ã€ç½®ä¿¡åº¦ã€é¢†åŸŸç­‰å…³é”®ä¿¡æ¯
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            å¿«é€Ÿåˆ†ææ€»ç»“
        """
        start_time = time.time()
        
        # å¿«é€Ÿåˆ†æ
        complexity_analysis = self.analyze_task_complexity(user_query)
        confidence_score = self.assess_task_confidence(user_query, execution_context)
        
        analysis_time = time.time() - start_time
        
        summary = {
            'domain': complexity_analysis.get('estimated_domain', 'general'),
            'complexity_score': complexity_analysis.get('complexity_score', 0.5),
            'confidence_score': confidence_score,
            'requires_multi_step': complexity_analysis.get('requires_multi_step', False),
            'key_factors': list(complexity_analysis.get('complexity_factors', {}).keys())[:3],
            'analysis_time': analysis_time,
            'recommendation': self._get_analysis_recommendation(
                complexity_analysis.get('complexity_score', 0.5), 
                confidence_score
            )
        }
        
        logger.info(f"âš¡ å¿«é€Ÿåˆ†æå®Œæˆ: {summary['domain']}é¢†åŸŸ, å¤æ‚åº¦{summary['complexity_score']:.2f}, ç½®ä¿¡åº¦{summary['confidence_score']:.2f}")
        return summary
    
    def _get_analysis_recommendation(self, complexity_score: float, confidence_score: float) -> str:
        """
        åŸºäºåˆ†æç»“æœæä¾›å»ºè®®
        
        Args:
            complexity_score: å¤æ‚åº¦åˆ†æ•°
            confidence_score: ç½®ä¿¡åº¦åˆ†æ•°
            
        Returns:
            åˆ†æå»ºè®®
        """
        if complexity_score > 0.8 and confidence_score < 0.4:
            return "é«˜å¤æ‚åº¦ä½ç½®ä¿¡åº¦ä»»åŠ¡ï¼Œå»ºè®®é‡‡ç”¨å¤šé˜¶æ®µéªŒè¯å’Œä¿å®ˆç­–ç•¥"
        elif complexity_score > 0.7:
            return "å¤æ‚ä»»åŠ¡ï¼Œå»ºè®®é‡‡ç”¨ç³»ç»Ÿåˆ†æå’Œåˆ†æ­¥æ‰§è¡Œ"
        elif confidence_score > 0.8:
            return "é«˜ç½®ä¿¡åº¦ä»»åŠ¡ï¼Œå¯ä»¥é‡‡ç”¨ç›´æ¥æ‰§è¡Œç­–ç•¥"
        elif confidence_score < 0.3:
            return "ä½ç½®ä¿¡åº¦ä»»åŠ¡ï¼Œå»ºè®®å¯»æ±‚é¢å¤–ä¿¡æ¯æˆ–æ¾„æ¸…"
        else:
            return "ä¸­ç­‰å¤æ‚åº¦ä»»åŠ¡ï¼Œå»ºè®®é‡‡ç”¨å¹³è¡¡çš„åˆ†æå’Œæ‰§è¡Œç­–ç•¥"
    
    def reset_cache(self):
        """é‡ç½®è¯„ä¼°ç¼“å­˜"""
        self.assessment_cache.clear()
        logger.info("ğŸ”„ è½»é‡çº§åˆ†æåŠ©æ‰‹ç¼“å­˜å·²é‡ç½®")
