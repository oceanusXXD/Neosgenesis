#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ•°æ®ç»“æ„å®šä¹‰ - å­˜æ”¾æ‰€æœ‰æ•°æ®ç±»å’Œç±»å‹å®šä¹‰
Data Structures - contains all data classes and type definitions

æ‰©å±•åŠŸèƒ½:
- çŸ¥è¯†æº¯æº (Knowledge Provenance) æ”¯æŒ
- å­¦ä¹ è·¯å¾„çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸè¿½è¸ª
- çŸ¥è¯†ç½‘ç»œå’Œå…³è”ç®¡ç†
"""

import time
from typing import Dict, List, Optional, Any, Set
from dataclasses import dataclass, field

# å¯¼å…¥çŸ¥è¯†æº¯æºç³»ç»Ÿ
try:
    from ..shared.data_structures import KnowledgeProvenance, SourceReference, KnowledgeSource, CredibilityLevel
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥çŸ¥è¯†æº¯æºç³»ç»Ÿï¼Œè®¾ç½®ä¸ºç©ºç±»å‹ä»¥ä¿æŒå…¼å®¹æ€§
    KnowledgeProvenance = type(None)
    SourceReference = type(None)
    KnowledgeSource = None 
    CredibilityLevel = None


@dataclass
class ReasoningPath:
    """
    ä»£è¡¨ä¸€ä¸ªå®Œæ•´ä¸”ç‹¬ç‰¹çš„æ€è€ƒèŒƒå¼
    
    æ‰©å±•åŠŸèƒ½ï¼š
    - æ”¯æŒçŸ¥è¯†æº¯æº (Knowledge Provenance)
    - å¢å¼ºçš„å…ƒæ•°æ®ç³»ç»Ÿ
    - å­¦ä¹ è·¯å¾„çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸè¿½è¸ª
    """
    # åŸºç¡€è·¯å¾„ä¿¡æ¯ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    path_id: str  # è·¯å¾„çš„å”¯ä¸€æ ‡è¯†ï¼Œä¾‹å¦‚ 'systematic_methodical_v1'
    path_type: str  # è·¯å¾„ç±»å‹ï¼Œå¦‚ 'ç³»ç»Ÿæ–¹æ³•å‹', 'åˆ›æ–°ç›´è§‰å‹', 'æ‰¹åˆ¤è´¨ç–‘å‹'
    description: str  # å¯¹è¿™æ¡æ€ç»´è·¯å¾„çš„è¯¦ç»†æè¿°
    prompt_template: str  # æ‰§è¡Œè¯¥è·¯å¾„æ—¶ï¼Œç”¨äºç”Ÿæˆæœ€ç»ˆæç¤ºçš„æ ¸å¿ƒæ¨¡æ¿
    
    # ğŸ¯ MABå­¦ä¹ ä¿®å¤ï¼šæ–°å¢ç­–ç•¥çº§åˆ«å›ºå®šIDç”¨äºMABå­¦ä¹ 
    strategy_id: str = ""  # ç­–ç•¥çº§åˆ«çš„å›ºå®šIDï¼Œç”¨äºMABå­¦ä¹ ï¼ˆå¦‚'systematic_analytical'ï¼‰
    instance_id: str = ""  # å®ä¾‹çº§åˆ«çš„å”¯ä¸€IDï¼Œç”¨äºä¼šè¯è¿½è¸ªï¼ˆå¦‚'systematic_analytical_v1_1703123456789_1234'ï¼‰
    
    # ğŸŒŸ çŸ¥è¯†æº¯æºç³»ç»Ÿ (Knowledge Provenance)
    provenance: Optional[KnowledgeProvenance] = None  # å®Œæ•´çš„çŸ¥è¯†æº¯æºä¿¡æ¯
    
    # ğŸ” å¢å¼ºçš„å…ƒæ•°æ®ç³»ç»Ÿ
    name: str = ""  # è·¯å¾„å‹å¥½åç§°
    steps: List[str] = field(default_factory=list)  # æ€ç»´æ­¥éª¤è¯¦ç»†åˆ—è¡¨
    keywords: List[str] = field(default_factory=list)  # å…³é”®è¯æ ‡ç­¾
    complexity_level: int = 3  # å¤æ‚åº¦çº§åˆ« (1-5)
    estimated_steps: int = 5  # é¢„ä¼°æ­¥éª¤æ•°
    success_indicators: List[str] = field(default_factory=list)  # æˆåŠŸæŒ‡æ ‡
    failure_patterns: List[str] = field(default_factory=list)  # å¤±è´¥æ¨¡å¼
    
    # ğŸ“Š æ€§èƒ½å’Œä½¿ç”¨ç»Ÿè®¡
    usage_count: int = 0  # ä½¿ç”¨æ¬¡æ•°
    success_rate: float = 0.0  # æˆåŠŸç‡
    avg_execution_time: float = 0.0  # å¹³å‡æ‰§è¡Œæ—¶é—´
    last_used: Optional[float] = None  # æœ€åä½¿ç”¨æ—¶é—´
    
    # ğŸ”— å…³è”å’Œä¸Šä¸‹æ–‡
    context_tags: Set[str] = field(default_factory=set)  # ä¸Šä¸‹æ–‡æ ‡ç­¾
    applicable_domains: List[str] = field(default_factory=list)  # é€‚ç”¨é¢†åŸŸ
    prerequisites: List[str] = field(default_factory=list)  # å‰ç½®æ¡ä»¶
    related_paths: List[str] = field(default_factory=list)  # ç›¸å…³è·¯å¾„ID
    
    # ğŸ¯ å­¦ä¹ å’Œè¿›åŒ–ç›¸å…³
    learning_source: str = "static"  # å­¦ä¹ æ¥æº: static, learned_exploration, manual_addition
    confidence_score: float = 1.0  # ç½®ä¿¡åº¦åˆ†æ•° (0.0-1.0)
    validation_status: str = "unverified"  # éªŒè¯çŠ¶æ€: unverified, pending, verified, conflicting
    evolution_generation: int = 0  # è¿›åŒ–ä»£æ•° (0=åŸå§‹, 1+=æ¼”åŒ–ç‰ˆæœ¬)
    parent_path_id: Optional[str] = None  # çˆ¶è·¯å¾„ID (å¦‚æœæ˜¯æ¼”åŒ–ç‰ˆæœ¬)
    
    # ğŸ“ æ‰©å±•å…ƒæ•°æ®
    metadata: Dict[str, Any] = field(default_factory=dict)  # æ‰©å±•å…ƒæ•°æ®å­—å…¸
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†ï¼šå¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒçŸ¥è¯†æº¯æºåˆå§‹åŒ–"""
        # ğŸ¯ åŸºæœ¬å…¼å®¹æ€§æ£€æŸ¥ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        if not self.strategy_id:
            self.strategy_id = self.path_id
            
        if not self.instance_id:
            self.instance_id = self.path_id
        
        # ğŸ“ ä»ç°æœ‰å­—æ®µæ¨å¯¼å‹å¥½åç§°
        if not self.name:
            self.name = self.path_type or self.path_id
        
        # ğŸ” ä»å…ƒæ•°æ®ä¸­æå–çŸ¥è¯†æº¯æºä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if not self.provenance and self.metadata.get("source"):
            self._initialize_provenance_from_metadata()
        
        # â° è®¾ç½®åˆå§‹æ—¶é—´æˆ³
        if not self.last_used and self.usage_count > 0:
            self.last_used = time.time()
    
    def _initialize_provenance_from_metadata(self):
        """ä»ç°æœ‰metadataåˆå§‹åŒ–çŸ¥è¯†æº¯æºä¿¡æ¯"""
        if KnowledgeProvenance is None:
            return  # çŸ¥è¯†æº¯æºç³»ç»Ÿä¸å¯ç”¨
        
        try:
            # åˆ›å»ºåŸºç¡€æº¯æºè®°å½•
            self.provenance = KnowledgeProvenance(
                knowledge_id=self.path_id,
                confidence_score=self.confidence_score,
                context_tags=self.context_tags.copy() if self.context_tags else set()
            )
            
            # ä»å…ƒæ•°æ®åˆ›å»ºæºå¼•ç”¨
            source_info = self.metadata.get("source")
            if isinstance(source_info, str):
                source_ref = SourceReference(
                    title=f"è·¯å¾„æ¥æº: {source_info}",
                    source_type=self._infer_knowledge_source(source_info),
                    metadata={"original_source": source_info}
                )
                self.provenance.add_source(source_ref, is_primary=True)
            
            # æ·»åŠ å­¦ä¹ ç›¸å…³ä¿¡æ¯
            if "learned_from" in self.metadata:
                self.provenance.add_context_tag("learned_path")
                self.provenance.add_context_tag(self.metadata["learned_from"])
            
            # è®¾ç½®ç½®ä¿¡åº¦
            if "confidence" in self.metadata:
                confidence = float(self.metadata["confidence"])
                self.provenance.confidence_score = confidence
                self.confidence_score = confidence
                
        except Exception as e:
            # å¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼Œè®°å½•ä½†ä¸ä¸­æ–­
            import logging
            logger = logging.getLogger(__name__)
            logger.warning(f"çŸ¥è¯†æº¯æºåˆå§‹åŒ–å¤±è´¥ for {self.path_id}: {e}")
    
    def _infer_knowledge_source(self, source_info: str) -> Optional[Any]:
        """æ ¹æ®æºä¿¡æ¯æ¨æ–­çŸ¥è¯†æ¥æºç±»å‹"""
        if KnowledgeSource is None:
            return None
            
        source_lower = source_info.lower()
        if "web" in source_lower or "ç½‘ç»œ" in source_lower:
            return KnowledgeSource.WEB_SCRAPING
        elif "api" in source_lower:
            return KnowledgeSource.API_QUERY
        elif "exploration" in source_lower or "æ¢ç´¢" in source_lower:
            return KnowledgeSource.KNOWLEDGE_BASE
        elif "user" in source_lower or "ç”¨æˆ·" in source_lower:
            return KnowledgeSource.USER_INPUT
        else:
            return KnowledgeSource.UNKNOWN
    
    # ğŸš€ çŸ¥è¯†æº¯æºç›¸å…³æ–¹æ³•
    
    def add_provenance_source(self, url: Optional[str] = None, title: Optional[str] = None, 
                            author: Optional[str] = None, source_type: Optional[Any] = None,
                            content: Optional[str] = None) -> bool:
        """
        æ·»åŠ çŸ¥è¯†æ¥æºä¿¡æ¯
        
        Args:
            url: æºURL
            title: æºæ ‡é¢˜  
            author: ä½œè€…
            source_type: æ¥æºç±»å‹
            content: å†…å®¹ï¼ˆç”¨äºç”Ÿæˆå“ˆå¸Œï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        if self.provenance is None:
            if KnowledgeProvenance is None:
                return False  # çŸ¥è¯†æº¯æºç³»ç»Ÿä¸å¯ç”¨
            self.provenance = KnowledgeProvenance(knowledge_id=self.path_id)
        
        try:
            source_ref = SourceReference(
                url=url,
                title=title or f"è·¯å¾„æ¥æº: {self.name}",
                author=author,
                source_type=source_type or KnowledgeSource.UNKNOWN if KnowledgeSource else None
            )
            
            if content:
                source_ref.generate_content_hash(content)
            
            self.provenance.add_source(source_ref)
            return True
        except Exception:
            return False
    
    def record_usage(self, success: bool = True, execution_time: Optional[float] = None):
        """
        è®°å½•è·¯å¾„ä½¿ç”¨æƒ…å†µ
        
        Args:
            success: æ˜¯å¦æˆåŠŸ
            execution_time: æ‰§è¡Œæ—¶é—´
        """
        self.usage_count += 1
        self.last_used = time.time()
        
        # æ›´æ–°æˆåŠŸç‡
        if self.usage_count == 1:
            self.success_rate = 1.0 if success else 0.0
        else:
            # æŒ‡æ•°ç§»åŠ¨å¹³å‡
            alpha = 0.1  # å­¦ä¹ ç‡
            new_success_rate = 1.0 if success else 0.0
            self.success_rate = (1 - alpha) * self.success_rate + alpha * new_success_rate
        
        # æ›´æ–°æ‰§è¡Œæ—¶é—´
        if execution_time is not None:
            if self.avg_execution_time == 0.0:
                self.avg_execution_time = execution_time
            else:
                alpha = 0.1
                self.avg_execution_time = (1 - alpha) * self.avg_execution_time + alpha * execution_time
        
        # æ›´æ–°çŸ¥è¯†æº¯æºè®°å½•
        if self.provenance:
            self.provenance.record_usage(success)
    
    def add_context_tag(self, tag: str):
        """æ·»åŠ ä¸Šä¸‹æ–‡æ ‡ç­¾"""
        self.context_tags.add(tag)
        if self.provenance:
            self.provenance.add_context_tag(tag)
    
    def remove_context_tag(self, tag: str):
        """ç§»é™¤ä¸Šä¸‹æ–‡æ ‡ç­¾"""
        self.context_tags.discard(tag)
        if self.provenance:
            self.provenance.remove_context_tag(tag)
    
    def update_confidence(self, new_confidence: float, reason: str = ""):
        """
        æ›´æ–°ç½®ä¿¡åº¦
        
        Args:
            new_confidence: æ–°çš„ç½®ä¿¡åº¦å€¼ (0.0-1.0)
            reason: æ›´æ–°åŸå› 
        """
        old_confidence = self.confidence_score
        self.confidence_score = max(0.0, min(1.0, new_confidence))
        
        # æ›´æ–°çŸ¥è¯†æº¯æºè®°å½•
        if self.provenance:
            from ..shared.data_structures import KnowledgeUpdate
            if KnowledgeUpdate:
                update = KnowledgeUpdate(
                    update_type="confidence_update",
                    reason=reason or "ç½®ä¿¡åº¦æ›´æ–°",
                    confidence_change=self.confidence_score - old_confidence
                )
                update.add_change(f"ç½®ä¿¡åº¦ä» {old_confidence:.3f} æ›´æ–°åˆ° {self.confidence_score:.3f}")
                self.provenance.add_update(update)
    
    def mark_as_verified(self, verification_method: str = "manual", 
                        confidence: float = 0.9, notes: str = ""):
        """
        æ ‡è®°è·¯å¾„ä¸ºå·²éªŒè¯
        
        Args:
            verification_method: éªŒè¯æ–¹æ³•
            confidence: éªŒè¯ç½®ä¿¡åº¦
            notes: éªŒè¯å¤‡æ³¨
        """
        self.validation_status = "verified"
        
        if self.provenance:
            from ..shared.data_structures import KnowledgeValidation, VerificationStatus
            if KnowledgeValidation and VerificationStatus:
                validation = KnowledgeValidation(
                    validation_method=verification_method,
                    status=VerificationStatus.VERIFIED,
                    confidence_score=confidence,
                    notes=notes
                )
                self.provenance.add_validation(validation)
    
    def create_evolved_version(self, changes: List[str], reason: str = "") -> 'ReasoningPath':
        """
        åˆ›å»ºå½“å‰è·¯å¾„çš„è¿›åŒ–ç‰ˆæœ¬
        
        Args:
            changes: å˜æ›´æè¿°åˆ—è¡¨
            reason: è¿›åŒ–åŸå› 
            
        Returns:
            æ–°çš„è¿›åŒ–ç‰ˆæœ¬è·¯å¾„
        """
        # ç”Ÿæˆæ–°çš„è·¯å¾„ID
        new_generation = self.evolution_generation + 1
        new_path_id = f"{self.path_id}_v{new_generation}"
        
        # åˆ›å»ºè¿›åŒ–ç‰ˆæœ¬
        evolved_path = ReasoningPath(
            path_id=new_path_id,
            path_type=self.path_type,
            description=self.description,
            prompt_template=self.prompt_template,
            name=f"{self.name} v{new_generation}",
            steps=self.steps.copy(),
            keywords=self.keywords.copy(),
            complexity_level=self.complexity_level,
            estimated_steps=self.estimated_steps,
            success_indicators=self.success_indicators.copy(),
            failure_patterns=self.failure_patterns.copy(),
            context_tags=self.context_tags.copy(),
            applicable_domains=self.applicable_domains.copy(),
            learning_source="evolved",
            confidence_score=self.confidence_score * 0.9,  # æ–°ç‰ˆæœ¬åˆå§‹ç½®ä¿¡åº¦ç•¥ä½
            evolution_generation=new_generation,
            parent_path_id=self.path_id,
            metadata=self.metadata.copy()
        )
        
        # å¦‚æœçˆ¶è·¯å¾„æœ‰æº¯æºä¿¡æ¯ï¼Œç»§æ‰¿å¹¶æ ‡è®°ä¸ºè¡ç”Ÿ
        if self.provenance:
            evolved_path.provenance = KnowledgeProvenance(
                knowledge_id=new_path_id,
                confidence_score=evolved_path.confidence_score,
                context_tags=self.context_tags.copy()
            )
            
            # ç»§æ‰¿ä¸»è¦æ¥æº
            if self.provenance.primary_source:
                evolved_path.provenance.add_source(self.provenance.primary_source)
            
            # è®°å½•è¿›åŒ–æ›´æ–°
            from ..shared.data_structures import KnowledgeUpdate
            if KnowledgeUpdate:
                update = KnowledgeUpdate(
                    update_type="evolution_update",
                    reason=reason or "è·¯å¾„è¿›åŒ–",
                    changes=changes.copy(),
                    source="evolution_system"
                )
                evolved_path.provenance.add_update(update)
            
            # å»ºç«‹çŸ¥è¯†ç½‘ç»œå…³è”
            evolved_path.provenance.knowledge_network.add_relationship(
                self.path_id, "derived", similarity_score=0.8,
                metadata={"relationship": "evolved_version", "generation": new_generation}
            )
        
        return evolved_path
    
    # ğŸ” æŸ¥è¯¢å’Œåˆ†ææ–¹æ³•
    
    @property
    def is_learned_path(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå­¦ä¹ è·¯å¾„"""
        return self.learning_source in ["learned_exploration", "manual_addition", "evolved"]
    
    @property
    def is_verified(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦å·²éªŒè¯"""
        if self.validation_status == "verified":
            return True
        if self.provenance:
            return self.provenance.is_verified
        return False
    
    @property
    def has_conflicts(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦å­˜åœ¨å†²çª"""
        if self.validation_status == "conflicting":
            return True
        if self.provenance:
            return self.provenance.has_conflicts
        return False
    
    @property
    def age_in_days(self) -> float:
        """è·å–è·¯å¾„å¹´é¾„ï¼ˆå¤©ï¼‰"""
        if self.provenance:
            return self.provenance.age_in_days
        return 0.0
    
    @property
    def freshness_score(self) -> float:
        """è®¡ç®—æ–°é²œåº¦åˆ†æ•°"""
        if self.provenance:
            return self.provenance.freshness_score
        return 1.0  # é™æ€è·¯å¾„é»˜è®¤æ–°é²œåº¦
    
    def get_provenance_summary(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†æº¯æºæ‘˜è¦"""
        base_summary = {
            "path_id": self.path_id,
            "name": self.name,
            "learning_source": self.learning_source,
            "confidence_score": self.confidence_score,
            "validation_status": self.validation_status,
            "usage_count": self.usage_count,
            "success_rate": self.success_rate,
            "is_learned_path": self.is_learned_path,
            "is_verified": self.is_verified,
            "has_conflicts": self.has_conflicts,
            "evolution_generation": self.evolution_generation,
            "parent_path_id": self.parent_path_id,
            "context_tags": list(self.context_tags),
            "applicable_domains": self.applicable_domains
        }
        
        # å¦‚æœæœ‰è¯¦ç»†çš„çŸ¥è¯†æº¯æºä¿¡æ¯ï¼Œæ·»åŠ åˆ°æ‘˜è¦ä¸­
        if self.provenance:
            provenance_summary = self.provenance.get_provenance_summary()
            base_summary.update({
                "detailed_provenance": provenance_summary,
                "age_days": self.age_in_days,
                "freshness_score": self.freshness_score,
                "network_connections": provenance_summary.get("network_connections", 0),
                "source_count": provenance_summary.get("source_count", 0)
            })
        
        return base_summary


@dataclass 
class TaskComplexity:
    """ä»»åŠ¡å¤æ‚åº¦"""
    overall_score: float = 0.5
    factors: Dict[str, float] = field(default_factory=dict)


@dataclass
class EnhancedDecisionArm:
    """å†³ç­–è‡‚ - è¿½è¸ªæ€ç»´è·¯å¾„çš„æ€§èƒ½"""
    path_id: str  # å…³è”çš„æ€ç»´è·¯å¾„ID
    option: str = ""  # è·¯å¾„ç±»å‹/é€‰é¡¹ (å…¼å®¹æ€§å­—æ®µ)
    
    # åŸºç¡€æ€§èƒ½è¿½è¸ª
    success_count: int = 0
    failure_count: int = 0
    total_reward: float = 0.0
    
    # å†å²è®°å½•ï¼ˆé™åˆ¶é•¿åº¦é¿å…å†…å­˜è†¨èƒ€ï¼‰
    recent_rewards: List[float] = field(default_factory=list)  # æœ€è¿‘çš„å¥–åŠ±è®°å½•
    rl_reward_history: List[float] = field(default_factory=list)  # RLå¥–åŠ±å†å²
    recent_results: List[bool] = field(default_factory=list)  # æœ€è¿‘çš„æ‰§è¡Œç»“æœ
    
    # ä½¿ç”¨ç»Ÿè®¡
    activation_count: int = 0
    last_used: float = 0.0
    
    def update_performance(self, success: bool, reward: float):
        """æ›´æ–°æ€§èƒ½æ•°æ®"""
        if success:
            self.success_count += 1
        else:
            self.failure_count += 1
            
        self.total_reward += reward
        self.recent_rewards.append(reward)
        self.rl_reward_history.append(reward)  # æ·»åŠ åˆ°RLå¥–åŠ±å†å²
        self.recent_results.append(success)  # æ·»åŠ åˆ°ç»“æœå†å²
        
        # é™åˆ¶å†å²é•¿åº¦
        if len(self.recent_rewards) > 20:
            self.recent_rewards = self.recent_rewards[-10:]
        if len(self.rl_reward_history) > 50:
            self.rl_reward_history = self.rl_reward_history[-25:]
        if len(self.recent_results) > 50:
            self.recent_results = self.recent_results[-25:]
            
        self.activation_count += 1
        self.last_used = time.time()
    
    @property
    def success_rate(self) -> float:
        """æˆåŠŸç‡"""
        total = self.success_count + self.failure_count
        return self.success_count / max(total, 1)
    
    @property
    def average_reward(self) -> float:
        """å¹³å‡å¥–åŠ±"""
        if not self.recent_rewards:
            return 0.0
        return sum(self.recent_rewards) / len(self.recent_rewards)
    
    @property
    def total_uses(self) -> int:
        """æ€»ä½¿ç”¨æ¬¡æ•°"""
        return self.success_count + self.failure_count


@dataclass
class TaskContext:
    """ä»»åŠ¡ä¸Šä¸‹æ–‡"""
    user_query: str
    task_type: str = "general"
    complexity_score: float = 0.5
    deepseek_confidence: float = 0.5
    real_time_requirements: bool = False
    domain_tags: List[str] = field(default_factory=list)
    execution_context: Optional[Dict] = None
    dynamic_classification: Optional[Dict] = None


@dataclass
class DecisionResult:
    """å†³ç­–ç»“æœæ•°æ®ç»“æ„"""
    timestamp: float
    round_number: int
    user_query: str
    selected_dimensions: Dict[str, str]
    confidence_scores: Dict[str, float]
    task_confidence: float
    complexity_analysis: Dict[str, Any]
    mab_decisions: Dict[str, Dict[str, Any]]
    reasoning: str
    fallback_used: bool
    component_architecture: bool = True
    
    # å¯é€‰å­—æ®µ
    overall_confidence: Optional[float] = None
    algorithm_used: Optional[str] = None
    dimension_count: Optional[int] = None
    bypass_reason: Optional[str] = None
    direct_response: Optional[str] = None


@dataclass
class PerformanceFeedback:
    """æ€§èƒ½åé¦ˆæ•°æ®ç»“æ„"""
    timestamp: float
    execution_success: bool
    execution_time: float
    user_satisfaction: float
    rl_reward: float
    task_completion_score: float = 0.0
    error_details: Optional[str] = None
    output_quality_score: Optional[float] = None


@dataclass
class LimitationAnalysis:
    """å±€é™æ€§åˆ†æç»“æœ"""
    type: str
    severity: float
    description: str
    specific_context: str
    impact: str
    confidence: float
    compensation_strategy: List[str]
    source: str
    timestamp: float


@dataclass
class AlternativeThinkingSignal:
    """æ›¿ä»£æ€è€ƒä¿¡å·"""
    timestamp: float
    user_query: str
    reason: str
    suggested_reassessment: bool
    creative_approaches_needed: bool
    environmental_exploration: bool


@dataclass
class FailureAnalysis:
    """å¤±è´¥åˆ†æç»“æœ"""
    timestamp: float
    user_query: str
    failed_dimensions: Dict[str, str]
    rl_reward: float
    failure_severity: float
    consecutive_failures: int
    context_change_needed: bool
    alternative_strategies: List[str]


@dataclass
class SuccessPattern:
    """æˆåŠŸæ¨¡å¼æ•°æ®ç»“æ„"""
    pattern_id: str
    dimension_combination: Dict[str, str]
    success_contexts: List[str]
    quality_score: float
    replication_count: int
    confidence: float
    last_used: float
    
    
@dataclass
class SystemStatus:
    """ç³»ç»ŸçŠ¶æ€æ•°æ®ç»“æ„"""
    total_rounds: int
    component_architecture: bool
    prior_reasoner_assessments: int
    path_generator_cache_size: int
    mab_converger_arms: int
    convergence_status: Dict[str, bool]
    recent_decisions: int
    
    # æ€§èƒ½æŒ‡æ ‡
    avg_decision_time: Optional[float] = None
    success_rate: Optional[float] = None
    exploration_rate: Optional[float] = None