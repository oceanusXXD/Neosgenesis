#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
åŠ¨æ€æ€ç»´è·¯å¾„åº“ - Dynamic Reasoning Path Library
å¯æˆé•¿çš„"å¤§è„‘çš®å±‚"ï¼Œæ”¯æŒæŒä¹…åŒ–å­˜å‚¨å’ŒåŠ¨æ€æ‰©å±•

è¿™ä¸ªæ¨¡å—å®ç°äº†ä»é™æ€æ¨¡æ¿åˆ°åŠ¨æ€è·¯å¾„åº“çš„å‡çº§ï¼š
1. æŒä¹…åŒ–å­˜å‚¨ï¼šæ”¯æŒJSONæ–‡ä»¶å’ŒSQLiteæ•°æ®åº“å­˜å‚¨
2. åŠ¨æ€ç®¡ç†ï¼šå¯ä»¥åœ¨è¿è¡Œæ—¶æ·»åŠ ã€ä¿®æ”¹ã€åˆ é™¤æ€ç»´è·¯å¾„
3. ç‰ˆæœ¬æ§åˆ¶ï¼šæ”¯æŒè·¯å¾„ç‰ˆæœ¬ç®¡ç†å’Œæ¼”åŒ–è¿½è¸ª
4. æ€§èƒ½åˆ†æï¼šè·Ÿè¸ªæ¯ä¸ªè·¯å¾„çš„ä½¿ç”¨æ•ˆæœå’ŒæˆåŠŸç‡
5. æ™ºèƒ½æ¨èï¼šåŸºäºå†å²è¡¨ç°æ¨èæœ€ä½³è·¯å¾„

æ ¸å¿ƒç†å¿µï¼šè®©AIçš„æ€ç»´æ¨¡å¼èƒ½å¤ŸæŒç»­å­¦ä¹ å’Œè¿›åŒ–
"""

import os
import json
import time
import sqlite3
import hashlib
import logging
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, field, asdict
from enum import Enum
from contextlib import contextmanager
from pathlib import Path
from collections import defaultdict
import threading

from .data_structures import ReasoningPath

logger = logging.getLogger(__name__)


class StorageBackend(Enum):
    """å­˜å‚¨åç«¯ç±»å‹"""
    JSON = "json"
    SQLITE = "sqlite"
    MEMORY = "memory"  # å†…å­˜æ¨¡å¼ï¼Œç”¨äºæµ‹è¯•


class PathCategory(Enum):
    """è·¯å¾„åˆ†ç±»"""
    ANALYTICAL = "analytical"           # åˆ†æå‹
    CREATIVE = "creative"              # åˆ›é€ å‹
    CRITICAL = "critical"              # æ‰¹åˆ¤å‹
    PRACTICAL = "practical"           # å®ç”¨å‹
    COLLABORATIVE = "collaborative"    # åä½œå‹
    ADAPTIVE = "adaptive"             # é€‚åº”å‹
    SYSTEMATIC = "systematic"         # ç³»ç»Ÿå‹
    INTUITIVE = "intuitive"           # ç›´è§‰å‹
    STRATEGIC = "strategic"           # æˆ˜ç•¥å‹
    EXPERIMENTAL = "experimental"     # å®éªŒå‹


class PathStatus(Enum):
    """è·¯å¾„çŠ¶æ€"""
    ACTIVE = "active"                 # æ¿€æ´»çŠ¶æ€
    DEPRECATED = "deprecated"         # å·²åºŸå¼ƒ
    EXPERIMENTAL = "experimental"     # å®éªŒæ€§
    RETIRED = "retired"              # å·²é€€å½¹


@dataclass
class PathMetadata:
    """è·¯å¾„å…ƒæ•°æ®"""
    created_at: float = field(default_factory=time.time)
    updated_at: float = field(default_factory=time.time)
    version: str = "1.0.0"
    author: str = "system"
    category: PathCategory = PathCategory.ANALYTICAL
    status: PathStatus = PathStatus.ACTIVE
    
    # ä½¿ç”¨ç»Ÿè®¡
    usage_count: int = 0
    success_rate: float = 0.0
    average_rating: float = 0.0
    total_execution_time: float = 0.0
    
    # æ ‡ç­¾å’Œæè¿°
    tags: List[str] = field(default_factory=list)
    keywords: List[str] = field(default_factory=list)
    complexity_level: str = "medium"  # "low", "medium", "high"
    
    # å…³è”ä¿¡æ¯
    parent_path_id: Optional[str] = None
    derived_from: List[str] = field(default_factory=list)
    similar_paths: List[str] = field(default_factory=list)


@dataclass
class EnhancedReasoningPath:
    """å¢å¼ºç‰ˆæ€ç»´è·¯å¾„ï¼ŒåŒ…å«å®Œæ•´å…ƒæ•°æ®"""
    # åŸºæœ¬ä¿¡æ¯ï¼ˆç»§æ‰¿è‡ªReasoningPathï¼‰
    path_id: str
    path_type: str
    description: str
    prompt_template: str
    strategy_id: str = ""
    instance_id: str = ""
    
    # å¢å¼ºå…ƒæ•°æ®
    metadata: PathMetadata = field(default_factory=PathMetadata)
    
    # åŠ¨æ€å±æ€§
    is_learned: bool = False  # æ˜¯å¦ä¸ºå­¦ä¹ å¾—åˆ°çš„è·¯å¾„
    learning_source: str = ""  # å­¦ä¹ æ¥æº
    effectiveness_score: float = 0.5  # æ•ˆæœè¯„åˆ†
    
    def to_reasoning_path(self) -> ReasoningPath:
        """è½¬æ¢ä¸ºæ ‡å‡†ReasoningPathå¯¹è±¡"""
        return ReasoningPath(
            path_id=self.path_id,
            path_type=self.path_type,
            description=self.description,
            prompt_template=self.prompt_template,
            strategy_id=self.strategy_id,
            instance_id=self.instance_id
        )
    
    def update_usage_stats(self, success: bool, execution_time: float, rating: Optional[float] = None):
        """æ›´æ–°ä½¿ç”¨ç»Ÿè®¡"""
        self.metadata.usage_count += 1
        
        # æ›´æ–°æˆåŠŸç‡
        if success:
            total_successes = self.metadata.success_rate * (self.metadata.usage_count - 1) + 1
        else:
            total_successes = self.metadata.success_rate * (self.metadata.usage_count - 1)
        
        self.metadata.success_rate = total_successes / self.metadata.usage_count
        
        # æ›´æ–°æ‰§è¡Œæ—¶é—´
        self.metadata.total_execution_time += execution_time
        
        # æ›´æ–°è¯„åˆ†
        if rating is not None:
            if self.metadata.usage_count == 1:
                self.metadata.average_rating = rating
            else:
                total_rating = self.metadata.average_rating * (self.metadata.usage_count - 1) + rating
                self.metadata.average_rating = total_rating / self.metadata.usage_count
        
        # æ›´æ–°æ—¶é—´æˆ³
        self.metadata.updated_at = time.time()


class DynamicPathLibrary:
    """
    ğŸ§  åŠ¨æ€æ€ç»´è·¯å¾„åº“ - å¯æˆé•¿çš„"å¤§è„‘çš®å±‚"
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æŒä¹…åŒ–å­˜å‚¨ç®¡ç† - æ”¯æŒJSONå’ŒSQLiteåç«¯
    2. åŠ¨æ€è·¯å¾„ç®¡ç† - è¿è¡Œæ—¶å¢åˆ æ”¹æŸ¥è·¯å¾„
    3. ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ - è¿½è¸ªè·¯å¾„æ¼”åŒ–å†å²
    4. æ€§èƒ½åˆ†æè·Ÿè¸ª - ç›‘æ§è·¯å¾„ä½¿ç”¨æ•ˆæœ
    5. æ™ºèƒ½æ¨èç³»ç»Ÿ - åŸºäºå†å²æ¨èæœ€ä½³è·¯å¾„
    
    è®¾è®¡åŸåˆ™ï¼š
    - å‘åå…¼å®¹ï¼šæ”¯æŒç°æœ‰é™æ€æ¨¡æ¿çš„æ— ç¼è¿ç§»
    - é«˜æ€§èƒ½ï¼šå†…å­˜ç¼“å­˜+å»¶è¿Ÿå†™å…¥ä¼˜åŒ–
    - çº¿ç¨‹å®‰å…¨ï¼šæ”¯æŒå¤šçº¿ç¨‹å¹¶å‘è®¿é—®
    - æ‰©å±•æ€§ï¼šæ”¯æŒè‡ªå®šä¹‰å­˜å‚¨åç«¯
    """
    
    def __init__(self, 
                 storage_backend: StorageBackend = StorageBackend.JSON,
                 storage_path: str = "data/reasoning_paths",
                 auto_backup: bool = True,
                 cache_size: int = 1000):
        """
        åˆå§‹åŒ–åŠ¨æ€è·¯å¾„åº“
        
        Args:
            storage_backend: å­˜å‚¨åç«¯ç±»å‹
            storage_path: å­˜å‚¨è·¯å¾„ï¼ˆä¸å«æ‰©å±•åï¼‰
            auto_backup: æ˜¯å¦è‡ªåŠ¨å¤‡ä»½
            cache_size: å†…å­˜ç¼“å­˜å¤§å°
        """
        self.storage_backend = storage_backend
        self.storage_path = storage_path
        self.auto_backup = auto_backup
        self.cache_size = cache_size
        
        # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
        self.storage_dir = Path(storage_path).parent
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        # å†…å­˜ç¼“å­˜
        self._cache: Dict[str, EnhancedReasoningPath] = {}
        self._cache_lock = threading.RLock()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_paths": 0,
            "active_paths": 0,
            "learned_paths": 0,
            "total_usages": 0,
            "cache_hits": 0,
            "cache_misses": 0
        }
        
        # åˆå§‹åŒ–å­˜å‚¨
        self._init_storage()
        self._load_all_paths()
        
        logger.info("ğŸ§  åŠ¨æ€æ€ç»´è·¯å¾„åº“å·²åˆå§‹åŒ–")
        logger.info(f"   å­˜å‚¨åç«¯: {storage_backend.value}")
        logger.info(f"   å­˜å‚¨è·¯å¾„: {storage_path}")
        logger.info(f"   ç¼“å­˜å¤§å°: {cache_size}")
        logger.info(f"   å·²åŠ è½½è·¯å¾„: {len(self._cache)}")
    
    def _init_storage(self):
        """åˆå§‹åŒ–å­˜å‚¨åç«¯"""
        if self.storage_backend == StorageBackend.SQLITE:
            self._init_sqlite_storage()
        elif self.storage_backend == StorageBackend.JSON:
            self._init_json_storage()
        # MEMORYæ¨¡å¼ä¸éœ€è¦åˆå§‹åŒ–
    
    def _init_sqlite_storage(self):
        """åˆå§‹åŒ–SQLiteå­˜å‚¨"""
        self.db_path = f"{self.storage_path}.db"
        
        with self._get_db_connection() as conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS reasoning_paths (
                    path_id TEXT PRIMARY KEY,
                    path_type TEXT NOT NULL,
                    description TEXT,
                    prompt_template TEXT NOT NULL,
                    strategy_id TEXT,
                    instance_id TEXT,
                    metadata TEXT,  -- JSONæ ¼å¼çš„å…ƒæ•°æ®
                    is_learned BOOLEAN DEFAULT FALSE,
                    learning_source TEXT,
                    effectiveness_score REAL DEFAULT 0.5,
                    created_at REAL DEFAULT (datetime('now')),
                    updated_at REAL DEFAULT (datetime('now'))
                )
            ''')
            
            # åˆ›å»ºç´¢å¼•
            conn.execute('CREATE INDEX IF NOT EXISTS idx_strategy_id ON reasoning_paths(strategy_id)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_path_type ON reasoning_paths(path_type)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_created_at ON reasoning_paths(created_at)')
            
            conn.commit()
        
        logger.info(f"âœ… SQLiteå­˜å‚¨å·²åˆå§‹åŒ–: {self.db_path}")
    
    def _init_json_storage(self):
        """åˆå§‹åŒ–JSONå­˜å‚¨"""
        self.json_path = f"{self.storage_path}.json"
        
        if not Path(self.json_path).exists():
            # åˆ›å»ºç©ºçš„JSONæ–‡ä»¶
            empty_library = {
                "metadata": {
                    "version": "1.0.0",
                    "created_at": time.time(),
                    "updated_at": time.time(),
                    "total_paths": 0
                },
                "paths": {}
            }
            
            with open(self.json_path, 'w', encoding='utf-8') as f:
                json.dump(empty_library, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… JSONå­˜å‚¨å·²åˆå§‹åŒ–: {self.json_path}")
    
    @contextmanager
    def _get_db_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        if self.storage_backend != StorageBackend.SQLITE:
            raise ValueError("åªæœ‰SQLiteåç«¯æ”¯æŒæ•°æ®åº“è¿æ¥")
        
        conn = sqlite3.connect(self.db_path, timeout=30.0)
        try:
            conn.row_factory = sqlite3.Row
            yield conn
        finally:
            conn.close()
    
    def _load_all_paths(self):
        """ä»å­˜å‚¨åç«¯åŠ è½½æ‰€æœ‰è·¯å¾„åˆ°å†…å­˜ç¼“å­˜"""
        if self.storage_backend == StorageBackend.MEMORY:
            return  # å†…å­˜æ¨¡å¼ä¸éœ€è¦åŠ è½½
        
        try:
            if self.storage_backend == StorageBackend.SQLITE:
                self._load_from_sqlite()
            elif self.storage_backend == StorageBackend.JSON:
                self._load_from_json()
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_stats()
            
            logger.info(f"ğŸ“š å·²åŠ è½½ {len(self._cache)} ä¸ªæ€ç»´è·¯å¾„")
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ€ç»´è·¯å¾„å¤±è´¥: {e}")
    
    def _load_from_sqlite(self):
        """ä»SQLiteåŠ è½½è·¯å¾„"""
        with self._get_db_connection() as conn:
            cursor = conn.execute('''
                SELECT * FROM reasoning_paths 
                WHERE metadata->>'$.status' != 'retired'
                ORDER BY created_at DESC
            ''')
            
            for row in cursor:
                try:
                    # è§£æå…ƒæ•°æ®
                    metadata_dict = json.loads(row['metadata']) if row['metadata'] else {}
                    metadata = PathMetadata(**metadata_dict)
                    
                    # åˆ›å»ºå¢å¼ºè·¯å¾„å¯¹è±¡
                    enhanced_path = EnhancedReasoningPath(
                        path_id=row['path_id'],
                        path_type=row['path_type'],
                        description=row['description'] or "",
                        prompt_template=row['prompt_template'],
                        strategy_id=row['strategy_id'] or "",
                        instance_id=row['instance_id'] or "",
                        metadata=metadata,
                        is_learned=bool(row['is_learned']),
                        learning_source=row['learning_source'] or "",
                        effectiveness_score=row['effectiveness_score'] or 0.5
                    )
                    
                    self._cache[row['path_id']] = enhanced_path
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è·³è¿‡æŸåçš„è·¯å¾„è®°å½• {row['path_id']}: {e}")
    
    def _load_from_json(self):
        """ä»JSONæ–‡ä»¶åŠ è½½è·¯å¾„"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
            json_path_obj = Path(self.json_path)
            if not json_path_obj.exists() or json_path_obj.stat().st_size == 0:
                logger.info(f"ğŸ“ JSONæ–‡ä»¶ '{self.json_path}' ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œè·³è¿‡åŠ è½½ã€‚")
                return

            with open(self.json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            paths_data = data.get('paths', {})
            
            for path_id, path_data in paths_data.items():
                try:
                    # è§£æå…ƒæ•°æ®
                    metadata_dict = path_data.get('metadata', {})
                    metadata = PathMetadata(**metadata_dict)
                    
                    # åˆ›å»ºå¢å¼ºè·¯å¾„å¯¹è±¡
                    enhanced_path = EnhancedReasoningPath(
                        path_id=path_id,
                        path_type=path_data.get('path_type', ''),
                        description=path_data.get('description', ''),
                        prompt_template=path_data.get('prompt_template', ''),
                        strategy_id=path_data.get('strategy_id', ''),
                        instance_id=path_data.get('instance_id', ''),
                        metadata=metadata,
                        is_learned=path_data.get('is_learned', False),
                        learning_source=path_data.get('learning_source', ''),
                        effectiveness_score=path_data.get('effectiveness_score', 0.5)
                    )
                    
                    self._cache[path_id] = enhanced_path
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è·³è¿‡æŸåçš„è·¯å¾„è®°å½• {path_id}: {e}")
        
        except FileNotFoundError:
            logger.info(f"ğŸ“ JSONæ–‡ä»¶ '{self.json_path}' ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°çš„ç©ºåº“ã€‚")
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSONæ–‡ä»¶ '{self.json_path}' æ ¼å¼é”™è¯¯æˆ–ä¸ºç©º: {e}")
            # è¿™é‡Œå¯ä»¥é€‰æ‹©æ€§åœ°å¤‡ä»½æŸåçš„æ–‡ä»¶å¹¶é‡æ–°åˆå§‹åŒ–
            # os.rename(self.json_path, f"{self.json_path}.broken.{int(time.time())}")
            # self._init_json_storage()
    
    def add_path(self, path: Union[ReasoningPath, EnhancedReasoningPath]) -> bool:
        """
        æ·»åŠ æ–°çš„æ€ç»´è·¯å¾„
        
        Args:
            path: è¦æ·»åŠ çš„è·¯å¾„å¯¹è±¡
            
        Returns:
            bool: æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        try:
            # è½¬æ¢ä¸ºå¢å¼ºè·¯å¾„å¯¹è±¡
            if isinstance(path, ReasoningPath):
                enhanced_path = EnhancedReasoningPath(
                    path_id=path.path_id,
                    path_type=path.path_type,
                    description=path.description,
                    prompt_template=path.prompt_template,
                    strategy_id=path.strategy_id,
                    instance_id=path.instance_id,
                    metadata=PathMetadata(
                        created_at=time.time(),
                        author="path_generator"
                    )
                )
            else:
                enhanced_path = path
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if enhanced_path.path_id in self._cache:
                logger.warning(f"âš ï¸ è·¯å¾„å·²å­˜åœ¨ï¼Œè·³è¿‡æ·»åŠ : {enhanced_path.path_id}")
                return False
            
            # æ·»åŠ åˆ°ç¼“å­˜
            with self._cache_lock:
                self._cache[enhanced_path.path_id] = enhanced_path
            
            # æŒä¹…åŒ–å­˜å‚¨
            self._persist_path(enhanced_path)
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats["total_paths"] += 1
            if enhanced_path.metadata.status == PathStatus.ACTIVE:
                self.stats["active_paths"] += 1
            if enhanced_path.is_learned:
                self.stats["learned_paths"] += 1
            
            logger.info(f"âœ… æ–°å¢æ€ç»´è·¯å¾„: {enhanced_path.path_id}")
            logger.debug(f"   ç±»å‹: {enhanced_path.path_type}")
            logger.debug(f"   æ¥æº: {enhanced_path.learning_source or 'manual'}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ æ€ç»´è·¯å¾„å¤±è´¥: {e}")
            return False
    
    def get_path(self, path_id: str) -> Optional[EnhancedReasoningPath]:
        """
        è·å–æŒ‡å®šçš„æ€ç»´è·¯å¾„
        
        Args:
            path_id: è·¯å¾„ID
            
        Returns:
            è·¯å¾„å¯¹è±¡æˆ–None
        """
        with self._cache_lock:
            if path_id in self._cache:
                self.stats["cache_hits"] += 1
                return self._cache[path_id]
            else:
                self.stats["cache_misses"] += 1
                return None
    
    def get_all_paths(self, 
                     status: Optional[PathStatus] = None,
                     category: Optional[PathCategory] = None,
                     include_retired: bool = False) -> Dict[str, EnhancedReasoningPath]:
        """
        è·å–æ‰€æœ‰æ»¡è¶³æ¡ä»¶çš„æ€ç»´è·¯å¾„
        
        Args:
            status: è¿‡æ»¤çŠ¶æ€
            category: è¿‡æ»¤åˆ†ç±»
            include_retired: æ˜¯å¦åŒ…å«å·²é€€å½¹çš„è·¯å¾„
            
        Returns:
            è·¯å¾„å­—å…¸
        """
        filtered_paths = {}
        
        with self._cache_lock:
            for path_id, path in self._cache.items():
                # çŠ¶æ€è¿‡æ»¤
                if not include_retired and path.metadata.status == PathStatus.RETIRED:
                    continue
                
                if status and path.metadata.status != status:
                    continue
                
                if category and path.metadata.category != category:
                    continue
                
                filtered_paths[path_id] = path
        
        return filtered_paths
    
    def get_paths_by_strategy(self, strategy_id: str) -> List[EnhancedReasoningPath]:
        """æ ¹æ®ç­–ç•¥IDè·å–è·¯å¾„"""
        paths = []
        
        with self._cache_lock:
            for path in self._cache.values():
                if path.strategy_id == strategy_id:
                    paths.append(path)
        
        return paths
    
    def update_path_performance(self, 
                               path_id: str, 
                               success: bool, 
                               execution_time: float,
                               rating: Optional[float] = None) -> bool:
        """
        æ›´æ–°è·¯å¾„æ€§èƒ½ç»Ÿè®¡
        
        Args:
            path_id: è·¯å¾„ID
            success: æ˜¯å¦æˆåŠŸ
            execution_time: æ‰§è¡Œæ—¶é—´
            rating: ç”¨æˆ·è¯„åˆ†(0-1)
            
        Returns:
            bool: æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        path = self.get_path(path_id)
        if not path:
            logger.warning(f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨: {path_id}")
            return False
        
        try:
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            path.update_usage_stats(success, execution_time, rating)
            
            # æ›´æ–°æ•ˆæœè¯„åˆ†
            if success:
                # æˆåŠŸæ—¶æå‡æ•ˆæœè¯„åˆ†
                path.effectiveness_score = min(1.0, path.effectiveness_score * 1.05)
            else:
                # å¤±è´¥æ—¶é™ä½æ•ˆæœè¯„åˆ†
                path.effectiveness_score = max(0.1, path.effectiveness_score * 0.95)
            
            # æŒä¹…åŒ–æ›´æ–°
            self._persist_path(path)
            
            # æ›´æ–°å…¨å±€ç»Ÿè®¡
            self.stats["total_usages"] += 1
            
            logger.debug(f"ğŸ“Š æ›´æ–°è·¯å¾„æ€§èƒ½: {path_id}")
            logger.debug(f"   æˆåŠŸç‡: {path.metadata.success_rate:.2%}")
            logger.debug(f"   æ•ˆæœè¯„åˆ†: {path.effectiveness_score:.2f}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°è·¯å¾„æ€§èƒ½å¤±è´¥: {e}")
            return False
    
    def recommend_paths(self, 
                       task_context: Optional[Dict[str, Any]] = None,
                       max_recommendations: int = 5,
                       min_effectiveness: float = 0.3) -> List[EnhancedReasoningPath]:
        """
        åŸºäºå†å²è¡¨ç°æ¨èæœ€ä½³è·¯å¾„
        
        Args:
            task_context: ä»»åŠ¡ä¸Šä¸‹æ–‡ä¿¡æ¯
            max_recommendations: æœ€å¤§æ¨èæ•°é‡
            min_effectiveness: æœ€å°æ•ˆæœåˆ†æ•°
            
        Returns:
            æ¨èçš„è·¯å¾„åˆ—è¡¨
        """
        candidates = []
        
        # æ”¶é›†å€™é€‰è·¯å¾„
        with self._cache_lock:
            for path in self._cache.values():
                if (path.metadata.status == PathStatus.ACTIVE and 
                    path.effectiveness_score >= min_effectiveness):
                    candidates.append(path)
        
        # è®¡ç®—æ¨èåˆ†æ•°
        scored_paths = []
        for path in candidates:
            score = self._calculate_recommendation_score(path, task_context)
            scored_paths.append((score, path))
        
        # æ’åºå¹¶è¿”å›å‰Nä¸ª
        scored_paths.sort(key=lambda x: x[0], reverse=True)
        recommended_paths = [path for score, path in scored_paths[:max_recommendations]]
        
        logger.info(f"ğŸ’¡ æ¨è {len(recommended_paths)} ä¸ªæœ€ä½³è·¯å¾„")
        for i, path in enumerate(recommended_paths, 1):
            logger.debug(f"   {i}. {path.path_type} (æ•ˆæœ: {path.effectiveness_score:.2f})")
        
        return recommended_paths
    
    def _calculate_recommendation_score(self, 
                                      path: EnhancedReasoningPath, 
                                      task_context: Optional[Dict[str, Any]]) -> float:
        """è®¡ç®—è·¯å¾„æ¨èåˆ†æ•°"""
        score = 0.0
        
        # åŸºç¡€æ•ˆæœåˆ†æ•° (40%)
        score += path.effectiveness_score * 0.4
        
        # æˆåŠŸç‡ (30%)
        score += path.metadata.success_rate * 0.3
        
        # ä½¿ç”¨é¢‘æ¬¡ (15%) - ä½¿ç”¨è¶Šå¤šï¼Œç»éªŒè¶Šä¸°å¯Œ
        usage_factor = min(1.0, path.metadata.usage_count / 100)
        score += usage_factor * 0.15
        
        # å¹³å‡è¯„åˆ† (15%)
        score += path.metadata.average_rating * 0.15
        
        # ä¸Šä¸‹æ–‡åŒ¹é…åŠ æˆ
        if task_context:
            context_boost = self._calculate_context_match(path, task_context)
            score *= (1 + context_boost)
        
        return score
    
    def _calculate_context_match(self, 
                               path: EnhancedReasoningPath, 
                               task_context: Dict[str, Any]) -> float:
        """è®¡ç®—è·¯å¾„ä¸ä»»åŠ¡ä¸Šä¸‹æ–‡çš„åŒ¹é…åº¦"""
        match_score = 0.0
        
        # ä»»åŠ¡ç±»å‹åŒ¹é…
        task_type = task_context.get('task_type', '').lower()
        if task_type in path.metadata.keywords:
            match_score += 0.2
        
        # å¤æ‚åº¦åŒ¹é…
        task_complexity = task_context.get('complexity', 'medium')
        if task_complexity == path.metadata.complexity_level:
            match_score += 0.1
        
        # æ ‡ç­¾åŒ¹é…
        task_tags = task_context.get('tags', [])
        if task_tags:
            common_tags = set(task_tags).intersection(set(path.metadata.tags))
            if common_tags:
                match_score += len(common_tags) / len(task_tags) * 0.3
        
        return match_score
    
    def learn_from_exploration(self, 
                             exploration_result: Dict[str, Any],
                             source: str = "knowledge_explorer") -> List[str]:
        """
        ä»çŸ¥è¯†æ¢ç´¢ç»“æœä¸­å­¦ä¹ æ–°çš„æ€ç»´è·¯å¾„
        
        Args:
            exploration_result: æ¢ç´¢ç»“æœ
            source: å­¦ä¹ æ¥æº
            
        Returns:
            æ–°å¢è·¯å¾„çš„IDåˆ—è¡¨
        """
        new_path_ids = []
        
        try:
            # ä»æ¢ç´¢ç»“æœä¸­æå–æ€ç»´ç§å­
            thinking_seeds = exploration_result.get('generated_thinking_seeds', [])
            
            for seed_data in thinking_seeds:
                # ç”Ÿæˆæ–°çš„æ€ç»´è·¯å¾„
                new_path = self._create_path_from_seed(seed_data, source)
                if new_path and self.add_path(new_path):
                    new_path_ids.append(new_path.path_id)
            
            logger.info(f"ğŸŒ± ä»æ¢ç´¢ç»“æœå­¦ä¹ åˆ° {len(new_path_ids)} ä¸ªæ–°è·¯å¾„")
            
        except Exception as e:
            logger.error(f"âŒ ä»æ¢ç´¢ç»“æœå­¦ä¹ å¤±è´¥: {e}")
        
        return new_path_ids
    
    def _create_path_from_seed(self, 
                             seed_data: Dict[str, Any], 
                             source: str) -> Optional[EnhancedReasoningPath]:
        """ä»æ€ç»´ç§å­åˆ›å»ºæ–°çš„è·¯å¾„"""
        try:
            seed_id = seed_data.get('seed_id', '')
            seed_content = seed_data.get('seed_content', '')
            creativity_level = seed_data.get('creativity_level', 'medium')
            
            if not seed_content:
                return None
            
            # ç”Ÿæˆè·¯å¾„ID
            path_id = f"learned_{hashlib.md5(seed_content.encode()).hexdigest()[:8]}"
            
            # ç¡®å®šè·¯å¾„ç±»å‹å’Œåˆ†ç±»
            if creativity_level == 'high':
                path_type = "å­¦ä¹ åˆ›æ–°å‹"
                category = PathCategory.CREATIVE
            elif 'cross_domain' in seed_data.get('cross_domain_connections', []):
                path_type = "å­¦ä¹ è·¨åŸŸå‹"
                category = PathCategory.ADAPTIVE
            else:
                path_type = "å­¦ä¹ åˆ†æå‹"
                category = PathCategory.ANALYTICAL
            
            # æ„å»ºæç¤ºæ¨¡æ¿
            prompt_template = f"""åŸºäºå­¦ä¹ åˆ°çš„æ€ç»´æ¨¡å¼è§£å†³ä»»åŠ¡ï¼š{{task}}

ğŸ§  **å­¦ä¹ åˆ°çš„æ€ç»´è·¯å¾„**ï¼š
{seed_content}

ğŸ’¡ **åº”ç”¨ç­–ç•¥**ï¼š
1. **æ¨¡å¼è¯†åˆ«**: è¯†åˆ«ä»»åŠ¡ä¸­çš„å…³é”®æ¨¡å¼å’Œç»“æ„
2. **çŸ¥è¯†åº”ç”¨**: åº”ç”¨å­¦ä¹ åˆ°çš„æ€ç»´æ–¹å¼å’Œæ–¹æ³•
3. **åˆ›æ–°èåˆ**: ç»“åˆå·²æœ‰çŸ¥è¯†è¿›è¡Œåˆ›æ–°æ€è€ƒ
4. **æ•ˆæœéªŒè¯**: éªŒè¯è§£å†³æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§å’Œå¯è¡Œæ€§

åŸºäºæ€ç»´ç§å­ï¼š{{thinking_seed}}
è¯·åº”ç”¨å­¦ä¹ åˆ°çš„æ€ç»´æ¨¡å¼æä¾›è§£å†³æ–¹æ¡ˆã€‚"""
            
            # åˆ›å»ºå…ƒæ•°æ®
            metadata = PathMetadata(
                created_at=time.time(),
                author=source,
                category=category,
                status=PathStatus.EXPERIMENTAL,  # æ–°å­¦ä¹ çš„è·¯å¾„å…ˆæ ‡è®°ä¸ºå®éªŒæ€§
                tags=["learned", "adaptive", creativity_level],
                keywords=seed_data.get('potential_applications', []),
                complexity_level=creativity_level
            )
            
            # åˆ›å»ºå¢å¼ºè·¯å¾„
            enhanced_path = EnhancedReasoningPath(
                path_id=path_id,
                path_type=path_type,
                description=f"ä»{source}å­¦ä¹ åˆ°çš„æ€ç»´è·¯å¾„ï¼š{seed_content[:100]}...",
                prompt_template=prompt_template,
                strategy_id=f"learned_{creativity_level}",
                instance_id=f"{path_id}_{int(time.time())}",
                metadata=metadata,
                is_learned=True,
                learning_source=source,
                effectiveness_score=0.5  # åˆå§‹æ•ˆæœåˆ†æ•°
            )
            
            return enhanced_path
            
        except Exception as e:
            logger.error(f"âŒ ä»ç§å­åˆ›å»ºè·¯å¾„å¤±è´¥: {e}")
            return None
    
    def _persist_path(self, path: EnhancedReasoningPath):
        """æŒä¹…åŒ–è·¯å¾„åˆ°å­˜å‚¨åç«¯"""
        if self.storage_backend == StorageBackend.MEMORY:
            return  # å†…å­˜æ¨¡å¼ä¸æŒä¹…åŒ–
        
        try:
            if self.storage_backend == StorageBackend.SQLITE:
                self._persist_to_sqlite(path)
            elif self.storage_backend == StorageBackend.JSON:
                self._persist_to_json(path)
        
        except Exception as e:
            logger.error(f"âŒ æŒä¹…åŒ–è·¯å¾„å¤±è´¥ {path.path_id}: {e}")
    
    def _persist_to_sqlite(self, path: EnhancedReasoningPath):
        """æŒä¹…åŒ–åˆ°SQLiteæ•°æ®åº“"""
        with self._get_db_connection() as conn:
            conn.execute('''
                INSERT OR REPLACE INTO reasoning_paths 
                (path_id, path_type, description, prompt_template, strategy_id, instance_id,
                 metadata, is_learned, learning_source, effectiveness_score, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                path.path_id,
                path.path_type,
                path.description,
                path.prompt_template,
                path.strategy_id,
                path.instance_id,
                json.dumps(asdict(path.metadata), ensure_ascii=False),
                path.is_learned,
                path.learning_source,
                path.effectiveness_score,
                time.time()
            ))
            
            conn.commit()
    
    def _persist_to_json(self, path: EnhancedReasoningPath):
        """æŒä¹…åŒ–åˆ°JSONæ–‡ä»¶"""
        try:
            # è¯»å–ç°æœ‰æ•°æ®
            with open(self.json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æ›´æ–°è·¯å¾„æ•°æ®
            path_data = {
                "path_type": path.path_type,
                "description": path.description,
                "prompt_template": path.prompt_template,
                "strategy_id": path.strategy_id,
                "instance_id": path.instance_id,
                "metadata": asdict(path.metadata),
                "is_learned": path.is_learned,
                "learning_source": path.learning_source,
                "effectiveness_score": path.effectiveness_score
            }
            
            data["paths"][path.path_id] = path_data
            data["metadata"]["updated_at"] = time.time()
            data["metadata"]["total_paths"] = len(data["paths"])
            
            # å†™å›æ–‡ä»¶
            with open(self.json_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        
        except Exception as e:
            logger.error(f"âŒ JSONæŒä¹…åŒ–å¤±è´¥: {e}")
    
    def _update_stats(self):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        with self._cache_lock:
            self.stats["total_paths"] = len(self._cache)
            self.stats["active_paths"] = sum(1 for path in self._cache.values() 
                                           if path.metadata.status == PathStatus.ACTIVE)
            self.stats["learned_paths"] = sum(1 for path in self._cache.values() 
                                            if path.is_learned)
            self.stats["total_usages"] = sum(path.metadata.usage_count 
                                           for path in self._cache.values())
    
    def migrate_from_templates(self, templates_dict: Dict[str, ReasoningPath]) -> int:
        """
        ä»é™æ€æ¨¡æ¿è¿ç§»åˆ°åŠ¨æ€åº“
        
        Args:
            templates_dict: é™æ€æ¨¡æ¿å­—å…¸
            
        Returns:
            è¿ç§»çš„è·¯å¾„æ•°é‡
        """
        migrated_count = 0
        
        logger.info("ğŸšš å¼€å§‹ä»é™æ€æ¨¡æ¿è¿ç§»...")
        
        for template_id, template in templates_dict.items():
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                if template.path_id in self._cache:
                    continue
                
                # åˆ›å»ºå¢å¼ºè·¯å¾„
                enhanced_path = EnhancedReasoningPath(
                    path_id=template.path_id,
                    path_type=template.path_type,
                    description=template.description,
                    prompt_template=template.prompt_template,
                    strategy_id=template.strategy_id or template_id,
                    instance_id=template.instance_id or template.path_id,
                    metadata=PathMetadata(
                        created_at=time.time(),
                        author="legacy_migration",
                        category=self._infer_category_from_type(template.path_type),
                        status=PathStatus.ACTIVE,
                        tags=["legacy", "migrated"],
                        keywords=self._extract_keywords_from_description(template.description)
                    ),
                    is_learned=False,
                    learning_source="static_template",
                    effectiveness_score=0.6  # ç»™äºˆä¸­ç­‰çš„åˆå§‹è¯„åˆ†
                )
                
                if self.add_path(enhanced_path):
                    migrated_count += 1
                    
            except Exception as e:
                logger.warning(f"âš ï¸ è¿ç§»æ¨¡æ¿å¤±è´¥ {template_id}: {e}")
        
        logger.info(f"âœ… è¿ç§»å®Œæˆ: {migrated_count} ä¸ªè·¯å¾„")
        return migrated_count
    
    def _infer_category_from_type(self, path_type: str) -> PathCategory:
        """ä»è·¯å¾„ç±»å‹æ¨æ–­åˆ†ç±»"""
        type_lower = path_type.lower()
        
        if "åˆ†æ" in type_lower or "ç³»ç»Ÿ" in type_lower:
            return PathCategory.ANALYTICAL
        elif "åˆ›æ–°" in type_lower or "åˆ›é€ " in type_lower:
            return PathCategory.CREATIVE
        elif "æ‰¹åˆ¤" in type_lower or "è´¨ç–‘" in type_lower:
            return PathCategory.CRITICAL
        elif "å®ç”¨" in type_lower or "åŠ¡å®" in type_lower:
            return PathCategory.PRACTICAL
        elif "åä½œ" in type_lower:
            return PathCategory.COLLABORATIVE
        elif "é€‚åº”" in type_lower or "çµæ´»" in type_lower:
            return PathCategory.ADAPTIVE
        else:
            return PathCategory.ANALYTICAL  # é»˜è®¤
    
    def _extract_keywords_from_description(self, description: str) -> List[str]:
        """ä»æè¿°ä¸­æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–
        import re
        words = re.findall(r'\b[\u4e00-\u9fff]+\b', description)
        return [word for word in words if len(word) > 1][:5]  # å–å‰5ä¸ªå…³é”®è¯
    
    def backup(self, backup_path: Optional[str] = None) -> bool:
        """
        å¤‡ä»½è·¯å¾„åº“
        
        Args:
            backup_path: å¤‡ä»½è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            bool: å¤‡ä»½æ˜¯å¦æˆåŠŸ
        """
        try:
            if backup_path is None:
                timestamp = int(time.time())
                backup_path = f"{self.storage_path}_backup_{timestamp}"
            
            if self.storage_backend == StorageBackend.JSON:
                import shutil
                shutil.copy2(self.json_path, f"{backup_path}.json")
                logger.info(f"ğŸ’¾ JSONå¤‡ä»½å®Œæˆ: {backup_path}.json")
                
            elif self.storage_backend == StorageBackend.SQLITE:
                import shutil
                shutil.copy2(self.db_path, f"{backup_path}.db")
                logger.info(f"ğŸ’¾ SQLiteå¤‡ä»½å®Œæˆ: {backup_path}.db")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
            return False
    
    def get_library_stats(self) -> Dict[str, Any]:
        """è·å–è·¯å¾„åº“ç»Ÿè®¡ä¿¡æ¯"""
        self._update_stats()
        
        return {
            **self.stats,
            "storage_backend": self.storage_backend.value,
            "storage_path": self.storage_path,
            "cache_efficiency": (self.stats["cache_hits"] / 
                               max(1, self.stats["cache_hits"] + self.stats["cache_misses"])),
            "top_performers": self._get_top_performing_paths(5),
            "category_distribution": self._get_category_distribution()
        }
    
    def _get_top_performing_paths(self, limit: int = 5) -> List[Dict[str, Any]]:
        """è·å–è¡¨ç°æœ€ä½³çš„è·¯å¾„"""
        paths = list(self._cache.values())
        paths.sort(key=lambda p: p.effectiveness_score, reverse=True)
        
        return [
            {
                "path_id": path.path_id,
                "path_type": path.path_type,
                "effectiveness_score": path.effectiveness_score,
                "success_rate": path.metadata.success_rate,
                "usage_count": path.metadata.usage_count
            }
            for path in paths[:limit]
        ]
    
    def _get_category_distribution(self) -> Dict[str, int]:
        """è·å–åˆ†ç±»åˆ†å¸ƒ"""
        distribution = defaultdict(int)
        
        for path in self._cache.values():
            distribution[path.metadata.category.value] += 1
        
        return dict(distribution)
