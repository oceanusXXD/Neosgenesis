#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è¯­ä¹‰åˆ†æå™¨ - åŸºäºLLMçš„æ™ºèƒ½æ–‡æœ¬åˆ†æ
Semantic Analyzer - LLM-based intelligent text analysis

æ ¸å¿ƒèŒè´£ï¼š
1. æ›¿æ¢ç¡¬ç¼–ç å…³é”®è¯åˆ¤æ–­ï¼Œä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰ç†è§£
2. æ”¯æŒå¤šä»»åŠ¡å¹¶è¡Œåˆ†æï¼ˆæ„å›¾è¯†åˆ«ã€æƒ…æ„Ÿåˆ†æã€å¤æ‚åº¦è¯„ä¼°ç­‰ï¼‰
3. è¿”å›ç»“æ„åŒ–çš„JSONåˆ†æç»“æœ
4. æä¾›å¯æ‰©å±•çš„åˆ†æä»»åŠ¡æ¡†æ¶

è®¾è®¡ç†å¿µï¼š
- æ™ºèƒ½è€Œéæ­»æ¿ï¼šç†è§£åŒä¹‰è¯ã€ä¸Šä¸‹æ–‡å’Œå¤æ‚å¥å¼
- å¯é…ç½®ä»»åŠ¡ï¼šæ”¯æŒè‡ªå®šä¹‰åˆ†æä»»åŠ¡å’Œè¾“å‡ºæ ¼å¼
- é«˜æ•ˆå¯é ï¼šå†…ç½®ç¼“å­˜ã€é”™è¯¯å¤„ç†å’Œé™çº§æœºåˆ¶
"""

import json
import time
import logging
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass, asdict
from enum import Enum
import hashlib

logger = logging.getLogger(__name__)

class AnalysisTaskType(Enum):
    """åˆ†æä»»åŠ¡ç±»å‹æšä¸¾"""
    INTENT_DETECTION = "intent_detection"           # æ„å›¾è¯†åˆ«
    SENTIMENT_ANALYSIS = "sentiment_analysis"       # æƒ…æ„Ÿåˆ†æ
    COMPLEXITY_ASSESSMENT = "complexity_assessment" # å¤æ‚åº¦è¯„ä¼°
    DOMAIN_CLASSIFICATION = "domain_classification" # é¢†åŸŸåˆ†ç±»
    URGENCY_EVALUATION = "urgency_evaluation"       # ç´§æ€¥ç¨‹åº¦è¯„ä¼°
    KEYWORD_EXTRACTION = "keyword_extraction"       # å…³é”®è¯æå–
    TOPIC_MODELING = "topic_modeling"               # ä¸»é¢˜å»ºæ¨¡
    LANGUAGE_DETECTION = "language_detection"       # è¯­è¨€æ£€æµ‹
    CUSTOM_ANALYSIS = "custom_analysis"             # è‡ªå®šä¹‰åˆ†æ

@dataclass
class AnalysisTask:
    """å•ä¸ªåˆ†æä»»åŠ¡å®šä¹‰"""
    task_type: AnalysisTaskType
    description: str
    expected_output_format: Dict[str, Any]
    prompt_template: Optional[str] = None
    confidence_threshold: float = 0.7
    
@dataclass 
class AnalysisResult:
    """å•ä¸ªåˆ†æç»“æœ"""
    task_type: AnalysisTaskType
    result: Dict[str, Any]
    confidence: float
    processing_time: float
    success: bool = True
    error_message: Optional[str] = None

@dataclass
class SemanticAnalysisResponse:
    """å®Œæ•´çš„è¯­ä¹‰åˆ†æå“åº”"""
    input_text: str
    analysis_results: Dict[str, AnalysisResult]
    total_processing_time: float
    overall_success: bool
    cache_hit: bool = False
    llm_provider: Optional[str] = None
    
class SemanticAnalyzer:
    """è¯­ä¹‰åˆ†æå™¨ - åŸºäºLLMçš„æ™ºèƒ½æ–‡æœ¬åˆ†æå¼•æ“"""
    
    def __init__(self, llm_manager=None, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–è¯­ä¹‰åˆ†æå™¨
        
        Args:
            llm_manager: LLMç®¡ç†å™¨å®ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨åˆ›å»º
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«åˆ†æå‚æ•°å’ŒLLMè®¾ç½®
        """
        self.llm_manager = llm_manager
        self.config = config or self._get_default_config()
        
        # åˆ†æç»“æœç¼“å­˜
        self.analysis_cache = {}
        self.cache_ttl = self.config.get('cache_ttl', 300)  # 5åˆ†é’Ÿç¼“å­˜
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_analyses': 0,
            'cache_hits': 0,
            'successful_analyses': 0,
            'failed_analyses': 0,
            'total_processing_time': 0.0
        }
        
        # é¢„å®šä¹‰åˆ†æä»»åŠ¡æ¨¡æ¿
        self.builtin_tasks = self._initialize_builtin_tasks()
        
        logger.info("ğŸ” SemanticAnalyzer å·²åˆå§‹åŒ–")
        
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'cache_ttl': 300,  # ç¼“å­˜æ—¶é—´
            'max_retries': 3,  # æœ€å¤§é‡è¯•æ¬¡æ•°
            'timeout': 30,     # è¯·æ±‚è¶…æ—¶æ—¶é—´
            'batch_size': 5,   # æ‰¹å¤„ç†å¤§å°
            'enable_fallback': True,  # å¯ç”¨é™çº§æœºåˆ¶
            'confidence_threshold': 0.7,  # é»˜è®¤ç½®ä¿¡åº¦é˜ˆå€¼
            'model_name': 'deepseek-chat',  # é»˜è®¤æ¨¡å‹
            'temperature': 0.1,  # ä½æ¸©åº¦ä¿è¯ç»“æœç¨³å®šæ€§
        }
        
    def _initialize_builtin_tasks(self) -> Dict[str, AnalysisTask]:
        """åˆå§‹åŒ–å†…ç½®åˆ†æä»»åŠ¡"""
        tasks = {}
        
        # æ„å›¾è¯†åˆ«ä»»åŠ¡
        tasks['intent_detection'] = AnalysisTask(
            task_type=AnalysisTaskType.INTENT_DETECTION,
            description="è¯†åˆ«ç”¨æˆ·è¾“å…¥çš„æ„å›¾å’Œç›®çš„",
            expected_output_format={
                "primary_intent": "string",  # ä¸»è¦æ„å›¾
                "secondary_intents": ["string"],  # æ¬¡è¦æ„å›¾
                "confidence": "float",  # ç½®ä¿¡åº¦
                "intent_category": "string",  # æ„å›¾ç±»åˆ«
                "action_required": "boolean"  # æ˜¯å¦éœ€è¦è¡ŒåŠ¨
            },
            prompt_template="""è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æ„å›¾ï¼š

æ–‡æœ¬: "{text}"

è¯·è¯†åˆ«ç”¨æˆ·çš„æ„å›¾å¹¶è¿”å›JSONæ ¼å¼ç»“æœï¼š
{{
    "primary_intent": "ä¸»è¦æ„å›¾ï¼ˆå¦‚ï¼šä¿¡æ¯æŸ¥è¯¢ã€é—®é¢˜è§£å†³ã€ä»»åŠ¡æ‰§è¡Œç­‰ï¼‰",
    "secondary_intents": ["æ¬¡è¦æ„å›¾åˆ—è¡¨"],
    "confidence": 0.0-1.0ä¹‹é—´çš„ç½®ä¿¡åº¦åˆ†æ•°,
    "intent_category": "æ„å›¾ç±»åˆ«ï¼ˆå¦‚ï¼šquestion, request, command, greetingç­‰ï¼‰",
    "action_required": true/false æ˜¯å¦éœ€è¦å…·ä½“è¡ŒåŠ¨
}}

è¯·ä»…è¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""
        )
        
        # æƒ…æ„Ÿåˆ†æä»»åŠ¡
        tasks['sentiment_analysis'] = AnalysisTask(
            task_type=AnalysisTaskType.SENTIMENT_ANALYSIS,
            description="åˆ†ææ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘å’Œæƒ…ç»ªçŠ¶æ€",
            expected_output_format={
                "overall_sentiment": "string",  # æ€»ä½“æƒ…æ„Ÿ
                "sentiment_score": "float",     # æƒ…æ„Ÿåˆ†æ•°
                "emotions": {"emotion": "float"},  # å…·ä½“æƒ…ç»ª
                "emotional_intensity": "string"   # æƒ…æ„Ÿå¼ºåº¦
            },
            prompt_template="""è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå’Œæƒ…ç»ªï¼š

æ–‡æœ¬: "{text}"

è¯·è¿”å›JSONæ ¼å¼çš„æƒ…æ„Ÿåˆ†æç»“æœï¼š
{{
    "overall_sentiment": "positive/negative/neutral",
    "sentiment_score": -1.0åˆ°1.0ä¹‹é—´çš„åˆ†æ•°ï¼ˆ-1æœ€è´Ÿé¢ï¼Œ1æœ€æ­£é¢ï¼‰ï¼Œ
    "emotions": {{
        "joy": 0.0-1.0,
        "anger": 0.0-1.0,
        "fear": 0.0-1.0,
        "sadness": 0.0-1.0,
        "surprise": 0.0-1.0,
        "trust": 0.0-1.0
    }},
    "emotional_intensity": "low/medium/high"
}}

è¯·ä»…è¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""
        )
        
        # å¤æ‚åº¦è¯„ä¼°ä»»åŠ¡
        tasks['complexity_assessment'] = AnalysisTask(
            task_type=AnalysisTaskType.COMPLEXITY_ASSESSMENT,
            description="è¯„ä¼°ä»»åŠ¡æˆ–é—®é¢˜çš„å¤æ‚ç¨‹åº¦",
            expected_output_format={
                "complexity_level": "string",      # å¤æ‚åº¦ç­‰çº§
                "complexity_score": "float",       # å¤æ‚åº¦åˆ†æ•°
                "complexity_factors": ["string"],  # å¤æ‚åº¦å› ç´ 
                "estimated_effort": "string",      # é¢„ä¼°å·¥ä½œé‡
                "requires_expertise": "boolean"    # æ˜¯å¦éœ€è¦ä¸“ä¸šçŸ¥è¯†
            },
            prompt_template="""è¯·è¯„ä¼°ä»¥ä¸‹ä»»åŠ¡æˆ–é—®é¢˜çš„å¤æ‚ç¨‹åº¦ï¼š

æ–‡æœ¬: "{text}"

è¯·è¿”å›JSONæ ¼å¼çš„å¤æ‚åº¦è¯„ä¼°ç»“æœï¼š
{{
    "complexity_level": "low/medium/high/expert",
    "complexity_score": 0.0-1.0ä¹‹é—´çš„å¤æ‚åº¦åˆ†æ•°,
    "complexity_factors": ["å¯¼è‡´å¤æ‚çš„å…·ä½“å› ç´ åˆ—è¡¨"],
    "estimated_effort": "minimal/moderate/substantial/extensive",
    "requires_expertise": true/false
}}

è¯„ä¼°æ ‡å‡†ï¼š
- Low: ç®€å•ç›´æ¥çš„ä»»åŠ¡ï¼Œå‡ åˆ†é’Ÿå†…å¯å®Œæˆ
- Medium: éœ€è¦ä¸€äº›æ€è€ƒå’Œæ­¥éª¤çš„ä»»åŠ¡
- High: å¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡ï¼Œéœ€è¦æ·±å…¥åˆ†æ
- Expert: éœ€è¦ä¸“ä¸šçŸ¥è¯†å’Œå¤§é‡æ—¶é—´çš„ä»»åŠ¡

è¯·ä»…è¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""
        )
        
        # é¢†åŸŸåˆ†ç±»ä»»åŠ¡
        tasks['domain_classification'] = AnalysisTask(
            task_type=AnalysisTaskType.DOMAIN_CLASSIFICATION,
            description="è¯†åˆ«æ–‡æœ¬æ‰€å±çš„ä¸“ä¸šé¢†åŸŸæˆ–ä¸»é¢˜åŸŸ",
            expected_output_format={
                "primary_domain": "string",        # ä¸»è¦é¢†åŸŸ
                "secondary_domains": ["string"],   # æ¬¡è¦é¢†åŸŸ  
                "domain_confidence": "float",      # é¢†åŸŸç½®ä¿¡åº¦
                "is_interdisciplinary": "boolean", # æ˜¯å¦è·¨é¢†åŸŸ
                "technical_level": "string"        # æŠ€æœ¯æ°´å¹³
            },
            prompt_template="""è¯·è¯†åˆ«ä»¥ä¸‹æ–‡æœ¬æ‰€å±çš„ä¸“ä¸šé¢†åŸŸï¼š

æ–‡æœ¬: "{text}"

è¯·è¿”å›JSONæ ¼å¼çš„é¢†åŸŸåˆ†ç±»ç»“æœï¼š
{{
    "primary_domain": "ä¸»è¦ä¸“ä¸šé¢†åŸŸ",
    "secondary_domains": ["ç›¸å…³çš„æ¬¡è¦é¢†åŸŸ"],
    "domain_confidence": 0.0-1.0ä¹‹é—´çš„ç½®ä¿¡åº¦,
    "is_interdisciplinary": true/false,
    "technical_level": "basic/intermediate/advanced/expert"
}}

é¢†åŸŸåŒ…æ‹¬ä½†ä¸é™äºï¼š
æŠ€æœ¯ï¼ˆprogramming, ai, database, systemï¼‰ï¼Œå•†ä¸šï¼ˆmarketing, finance, strategyï¼‰ï¼Œ
å­¦æœ¯ï¼ˆresearch, theory, analysisï¼‰ï¼Œç”Ÿæ´»ï¼ˆhealth, travel, educationï¼‰ï¼Œ
åˆ›æ„ï¼ˆdesign, art, writingï¼‰ç­‰

è¯·ä»…è¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""
        )
        
        # ç´§æ€¥ç¨‹åº¦è¯„ä¼°ä»»åŠ¡
        tasks['urgency_evaluation'] = AnalysisTask(
            task_type=AnalysisTaskType.URGENCY_EVALUATION,
            description="è¯„ä¼°ä»»åŠ¡çš„ç´§æ€¥ç¨‹åº¦å’Œä¼˜å…ˆçº§",
            expected_output_format={
                "urgency_level": "string",         # ç´§æ€¥ç¨‹åº¦
                "urgency_score": "float",          # ç´§æ€¥åº¦åˆ†æ•°
                "time_sensitivity": "string",      # æ—¶é—´æ•æ„Ÿåº¦
                "consequences": "string",          # å»¶è¿Ÿåæœ
                "priority_rank": "integer"         # ä¼˜å…ˆçº§æ’å
            },
            prompt_template="""è¯·è¯„ä¼°ä»¥ä¸‹ä»»åŠ¡çš„ç´§æ€¥ç¨‹åº¦ï¼š

æ–‡æœ¬: "{text}"

è¯·è¿”å›JSONæ ¼å¼çš„ç´§æ€¥ç¨‹åº¦è¯„ä¼°ï¼š
{{
    "urgency_level": "low/medium/high/critical",
    "urgency_score": 0.0-1.0ä¹‹é—´çš„ç´§æ€¥åº¦åˆ†æ•°,
    "time_sensitivity": "flexible/moderate/strict/immediate",
    "consequences": "å»¶è¿Ÿå¤„ç†çš„åæœæè¿°",
    "priority_rank": 1-10ä¹‹é—´çš„ä¼˜å…ˆçº§æ’åï¼ˆ10æœ€é«˜ï¼‰
}}

è¯„ä¼°æ ‡å‡†ï¼š
- Low: å¯ä»¥ç¨åå¤„ç†ï¼Œæ— æ˜ç¡®æ—¶é—´é™åˆ¶
- Medium: å»ºè®®åŠæ—¶å¤„ç†ï¼Œæœ‰ä¸€å®šæ—¶é—´è¦æ±‚
- High: éœ€è¦å°½å¿«å¤„ç†ï¼Œæœ‰æ˜ç¡®æœŸé™
- Critical: éœ€è¦ç«‹å³å¤„ç†ï¼Œå»¶è¿Ÿä¼šæœ‰ä¸¥é‡åæœ

è¯·ä»…è¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""
        )
        
        return tasks
    
    def analyze(self, 
                text: str, 
                tasks: Union[List[str], List[AnalysisTask], str],
                **kwargs) -> SemanticAnalysisResponse:
        """
        æ‰§è¡Œè¯­ä¹‰åˆ†æ
        
        Args:
            text: è¦åˆ†æçš„æ–‡æœ¬
            tasks: åˆ†æä»»åŠ¡åˆ—è¡¨ï¼Œå¯ä»¥æ˜¯ä»»åŠ¡åç§°å­—ç¬¦ä¸²åˆ—è¡¨ã€AnalysisTaskå¯¹è±¡åˆ—è¡¨æˆ–å•ä¸ªä»»åŠ¡å
            **kwargs: é¢å¤–çš„åˆ†æå‚æ•°
            
        Returns:
            SemanticAnalysisResponse: åˆ†æç»“æœ
        """
        start_time = time.time()
        self.stats['total_analyses'] += 1
        
        try:
            # ç»Ÿä¸€ä»»åŠ¡æ ¼å¼
            task_list = self._prepare_tasks(tasks)
            
            # æ£€æŸ¥ç¼“å­˜
            cache_key = self._generate_cache_key(text, task_list)
            cached_result = self._get_cached_result(cache_key)
            if cached_result:
                self.stats['cache_hits'] += 1
                logger.debug(f"ğŸ¯ ç¼“å­˜å‘½ä¸­: {cache_key}")
                return cached_result
                
            # æ‰§è¡Œåˆ†æ
            results = {}
            overall_success = True
            llm_provider = None
            
            for task in task_list:
                try:
                    result = self._execute_single_task(text, task, **kwargs)
                    results[task.task_type.value] = result
                    
                    if not result.success:
                        overall_success = False
                        
                    # è®°å½•ä½¿ç”¨çš„LLMæä¾›å•†
                    if llm_provider is None and hasattr(self.llm_manager, 'last_used_provider'):
                        llm_provider = getattr(self.llm_manager, 'last_used_provider', None)
                        
                except Exception as e:
                    logger.error(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥ {task.task_type.value}: {e}")
                    results[task.task_type.value] = AnalysisResult(
                        task_type=task.task_type,
                        result={},
                        confidence=0.0,
                        processing_time=0.0,
                        success=False,
                        error_message=str(e)
                    )
                    overall_success = False
            
            # åˆ›å»ºå“åº”å¯¹è±¡
            total_time = time.time() - start_time
            response = SemanticAnalysisResponse(
                input_text=text,
                analysis_results=results,
                total_processing_time=total_time,
                overall_success=overall_success,
                cache_hit=False,
                llm_provider=llm_provider
            )
            
            # ç¼“å­˜ç»“æœ
            self._cache_result(cache_key, response)
            
            # æ›´æ–°ç»Ÿè®¡
            if overall_success:
                self.stats['successful_analyses'] += 1
            else:
                self.stats['failed_analyses'] += 1
            self.stats['total_processing_time'] += total_time
            
            logger.info(f"ğŸ” è¯­ä¹‰åˆ†æå®Œæˆ: {len(results)}é¡¹ä»»åŠ¡, è€—æ—¶{total_time:.2f}s")
            return response
            
        except Exception as e:
            logger.error(f"âŒ è¯­ä¹‰åˆ†æå¤±è´¥: {e}")
            self.stats['failed_analyses'] += 1
            
            return SemanticAnalysisResponse(
                input_text=text,
                analysis_results={},
                total_processing_time=time.time() - start_time,
                overall_success=False,
                cache_hit=False,
                llm_provider=None
            )
    
    def _prepare_tasks(self, tasks: Union[List[str], List[AnalysisTask], str]) -> List[AnalysisTask]:
        """å‡†å¤‡åˆ†æä»»åŠ¡åˆ—è¡¨"""
        if isinstance(tasks, str):
            # å•ä¸ªä»»åŠ¡åç§°
            if tasks in self.builtin_tasks:
                return [self.builtin_tasks[tasks]]
            else:
                raise ValueError(f"æœªçŸ¥çš„å†…ç½®ä»»åŠ¡: {tasks}")
                
        elif isinstance(tasks, list):
            task_list = []
            for task in tasks:
                if isinstance(task, str):
                    # ä»»åŠ¡åç§°å­—ç¬¦ä¸²
                    if task in self.builtin_tasks:
                        task_list.append(self.builtin_tasks[task])
                    else:
                        raise ValueError(f"æœªçŸ¥çš„å†…ç½®ä»»åŠ¡: {task}")
                elif isinstance(task, AnalysisTask):
                    # AnalysisTaskå¯¹è±¡
                    task_list.append(task)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {type(task)}")
            return task_list
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ä»»åŠ¡æ ¼å¼: {type(tasks)}")
    
    def _execute_single_task(self, text: str, task: AnalysisTask, **kwargs) -> AnalysisResult:
        """æ‰§è¡Œå•ä¸ªåˆ†æä»»åŠ¡"""
        start_time = time.time()
        
        try:
            # å‡†å¤‡æç¤ºè¯
            prompt = task.prompt_template.format(text=text) if task.prompt_template else f"è¯·åˆ†æ: {text}"
            
            # è°ƒç”¨LLM (è¿™é‡Œéœ€è¦å®ç°LLMè°ƒç”¨é€»è¾‘)
            llm_response = self._call_llm(prompt, task, **kwargs)
            
            # è§£æå“åº”
            try:
                result_data = json.loads(llm_response) if isinstance(llm_response, str) else llm_response
                confidence = result_data.get('confidence', task.confidence_threshold)
            except json.JSONDecodeError as e:
                logger.warning(f"âš ï¸ JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é™çº§å¤„ç†: {e}")
                result_data = {"raw_response": llm_response, "parse_error": str(e)}
                confidence = 0.5
            
            processing_time = time.time() - start_time
            
            return AnalysisResult(
                task_type=task.task_type,
                result=result_data,
                confidence=confidence,
                processing_time=processing_time,
                success=True
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸ {task.task_type.value}: {e}")
            
            return AnalysisResult(
                task_type=task.task_type,
                result={},
                confidence=0.0,
                processing_time=processing_time,
                success=False,
                error_message=str(e)
            )
    
    def _call_llm(self, prompt: str, task: AnalysisTask, **kwargs) -> str:
        """è°ƒç”¨LLMè¿›è¡Œåˆ†æ"""
        if not self.llm_manager:
            # å¦‚æœæ²¡æœ‰LLMç®¡ç†å™¨ï¼Œå°è¯•åˆ›å»ºä¸€ä¸ª
            try:
                from ..providers.llm_manager import LLMManager
                self.llm_manager = LLMManager()
                logger.info("ğŸ¤– è‡ªåŠ¨åˆ›å»ºLLMç®¡ç†å™¨")
            except ImportError:
                logger.error("âŒ æ— æ³•å¯¼å…¥LLMManagerï¼ŒSemanticAnalyzeréœ€è¦LLMæ”¯æŒ")
                if self.config['enable_fallback']:
                    return self._fallback_analysis(prompt, task)
                raise RuntimeError("SemanticAnalyzer requires LLM support")
        
        try:
            # æ„å»ºç³»ç»Ÿæ¶ˆæ¯
            system_message = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯­ä¹‰åˆ†æåŠ©æ‰‹ï¼Œä¸“é—¨è´Ÿè´£åˆ†ææ–‡æœ¬å¹¶è¿”å›ç»“æ„åŒ–çš„JSONç»“æœã€‚è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—è¯´æ˜ã€‚"
            
            # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
            messages = [
                {"role": "system", "content": system_message},
                {"role": "user", "content": prompt}
            ]
            
            # ä½¿ç”¨LLMç®¡ç†å™¨è°ƒç”¨
            response = self.llm_manager.chat_completion(
                messages=messages,
                model=kwargs.get('model', self.config['model_name']),
                temperature=kwargs.get('temperature', self.config['temperature']),
                max_tokens=kwargs.get('max_tokens', 2000),
                timeout=kwargs.get('timeout', self.config['timeout'])
            )
            
            if response and response.success:
                # è®°å½•ä½¿ç”¨çš„æä¾›å•†
                if hasattr(response, 'provider'):
                    self.llm_manager.last_used_provider = response.provider
                return response.content.strip()
            else:
                error_msg = response.error_message if response else "LLMè°ƒç”¨æ— å“åº”"
                logger.warning(f"âš ï¸ LLMè°ƒç”¨å¤±è´¥: {error_msg}")
                
                if self.config['enable_fallback']:
                    return self._fallback_analysis(prompt, task)
                else:
                    raise RuntimeError(f"LLMè°ƒç”¨å¤±è´¥: {error_msg}")
                
        except Exception as e:
            logger.error(f"âŒ LLMè°ƒç”¨å¼‚å¸¸: {e}")
            if self.config['enable_fallback']:
                return self._fallback_analysis(prompt, task)
            else:
                raise
    
    def _fallback_analysis(self, prompt: str, task: AnalysisTask) -> str:
        """é™çº§åˆ†ææ–¹æ³• - å½“LLMä¸å¯ç”¨æ—¶çš„ç®€å•è§„åˆ™åˆ†æ"""
        logger.warning("âš ï¸ ä½¿ç”¨é™çº§åˆ†ææ–¹æ³•")
        
        # æå–æ–‡æœ¬è¿›è¡Œç®€å•åˆ†æ
        text = prompt.split('"')[1] if '"' in prompt else prompt
        
        # ç®€å•çš„è§„åˆ™basedåˆ†æä½œä¸ºé™çº§
        fallback_results = {
            AnalysisTaskType.INTENT_DETECTION: self._fallback_intent_detection(text),
            AnalysisTaskType.SENTIMENT_ANALYSIS: self._fallback_sentiment_analysis(text),
            AnalysisTaskType.COMPLEXITY_ASSESSMENT: self._fallback_complexity_assessment(text),
            AnalysisTaskType.DOMAIN_CLASSIFICATION: self._fallback_domain_classification(text),
            AnalysisTaskType.URGENCY_EVALUATION: self._fallback_urgency_evaluation(text)
        }
        
        result = fallback_results.get(task.task_type, {"status": "fallback_analysis", "confidence": 0.2})
        return json.dumps(result, ensure_ascii=False)
    
    def _fallback_intent_detection(self, text: str) -> Dict[str, Any]:
        """é™çº§æ„å›¾è¯†åˆ«"""
        text_lower = text.lower()
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        question_indicators = ['ä»€ä¹ˆ', 'å¦‚ä½•', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'å“ªé‡Œ', 'è°', 'what', 'how', 'why', 'where', 'who']
        request_indicators = ['å¸®åŠ©', 'éœ€è¦', 'è¯·', 'èƒ½å¦', 'å¯ä»¥', 'help', 'please', 'can you', 'could you']
        urgent_indicators = ['ç´§æ€¥', 'æ€¥éœ€', 'ç«‹å³', 'é©¬ä¸Š', 'urgent', 'asap', 'immediately']
        
        primary_intent = "information_seeking"
        confidence = 0.4
        action_required = True
        
        if any(indicator in text_lower for indicator in question_indicators):
            primary_intent = "question_asking"
            confidence = 0.6
        elif any(indicator in text_lower for indicator in request_indicators):
            primary_intent = "help_request"
            confidence = 0.7
        elif any(indicator in text_lower for indicator in urgent_indicators):
            primary_intent = "urgent_request"
            confidence = 0.8
        elif any(greeting in text_lower for greeting in ['ä½ å¥½', 'hello', 'hi']):
            primary_intent = "greeting"
            confidence = 0.9
            action_required = False
        
        return {
            "primary_intent": primary_intent,
            "secondary_intents": [],
            "confidence": confidence,
            "intent_category": "query" if primary_intent in ["question_asking", "information_seeking"] else "request",
            "action_required": action_required
        }
    
    def _fallback_sentiment_analysis(self, text: str) -> Dict[str, Any]:
        """é™çº§æƒ…æ„Ÿåˆ†æ"""
        # ç®€å•çš„æ­£è´Ÿé¢è¯æ±‡ç»Ÿè®¡
        positive_words = ['å¥½', 'ä¼˜ç§€', 'æ£’', 'èµ', 'å–œæ¬¢', 'æ»¡æ„', 'æˆåŠŸ', 'æœ‰æ•ˆ', 'åˆ›æ–°', 'good', 'great', 'excellent', 'love', 'like']
        negative_words = ['å·®', 'å', 'ç³Ÿç³•', 'å¤±è´¥', 'é—®é¢˜', 'å›°éš¾', 'é”™è¯¯', 'ä¸å¥½', 'bad', 'terrible', 'fail', 'problem', 'difficult']
        
        text_lower = text.lower()
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        
        if positive_count > negative_count:
            overall_sentiment = "positive"
            sentiment_score = min(0.8, 0.5 + (positive_count - negative_count) * 0.1)
            intensity = "medium" if positive_count > 2 else "low"
        elif negative_count > positive_count:
            overall_sentiment = "negative"
            sentiment_score = max(-0.8, -0.5 - (negative_count - positive_count) * 0.1)
            intensity = "medium" if negative_count > 2 else "low"
        else:
            overall_sentiment = "neutral"
            sentiment_score = 0.0
            intensity = "low"
        
        return {
            "overall_sentiment": overall_sentiment,
            "sentiment_score": sentiment_score,
            "emotions": {"trust": 0.5, "joy": max(0, sentiment_score)},
            "emotional_intensity": intensity
        }
    
    def _fallback_complexity_assessment(self, text: str) -> Dict[str, Any]:
        """é™çº§å¤æ‚åº¦è¯„ä¼°"""
        text_lower = text.lower()
        
        # åŸºäºæ–‡æœ¬é•¿åº¦å’Œå…³é”®è¯çš„ç®€å•è¯„ä¼°
        complexity_score = 0.3  # åŸºç¡€åˆ†æ•°
        
        # é•¿åº¦å› ç´ 
        if len(text) > 200:
            complexity_score += 0.3
        elif len(text) > 100:
            complexity_score += 0.2
        elif len(text) > 50:
            complexity_score += 0.1
        
        # å¤æ‚æ€§æŒ‡æ ‡
        complex_indicators = ['è®¾è®¡', 'æ¶æ„', 'ç³»ç»Ÿ', 'ç®—æ³•', 'ä¼˜åŒ–', 'æ·±åº¦', 'è¯¦ç»†', 'å…¨é¢', 'architecture', 'system', 'complex', 'advanced']
        complexity_score += min(0.4, len([ind for ind in complex_indicators if ind in text_lower]) * 0.1)
        
        complexity_score = min(1.0, complexity_score)
        
        if complexity_score >= 0.7:
            level = "high"
            effort = "substantial"
            expertise = True
        elif complexity_score >= 0.5:
            level = "medium"
            effort = "moderate"
            expertise = False
        else:
            level = "low"
            effort = "minimal"
            expertise = False
        
        return {
            "complexity_level": level,
            "complexity_score": complexity_score,
            "complexity_factors": ["æ–‡æœ¬é•¿åº¦", "æŠ€æœ¯æœ¯è¯­"] if complexity_score > 0.5 else ["ç®€å•ä»»åŠ¡"],
            "estimated_effort": effort,
            "requires_expertise": expertise
        }
    
    def _fallback_domain_classification(self, text: str) -> Dict[str, Any]:
        """é™çº§é¢†åŸŸåˆ†ç±»"""
        text_lower = text.lower()
        
        # é¢†åŸŸå…³é”®è¯æ˜ å°„
        domain_keywords = {
            "technology": ['æŠ€æœ¯', 'ç¼–ç¨‹', 'api', 'ç®—æ³•', 'æ•°æ®åº“', 'ç³»ç»Ÿ', 'æ¶æ„', 'programming', 'algorithm', 'database', 'system'],
            "business": ['å•†ä¸š', 'å¸‚åœº', 'è¥é”€', 'é”€å”®', 'å•†åŠ¡', 'ç®¡ç†', 'business', 'marketing', 'sales', 'management'],
            "academic": ['å­¦æœ¯', 'ç ”ç©¶', 'è®ºæ–‡', 'ç†è®º', 'åˆ†æ', 'å­¦ä¹ ', 'academic', 'research', 'study', 'analysis'],
            "creative": ['åˆ›æ„', 'è®¾è®¡', 'è‰ºæœ¯', 'åˆ›ä½œ', 'æƒ³è±¡', 'creative', 'design', 'art', 'imagination'],
            "health": ['å¥åº·', 'åŒ»ç–—', 'ä¿å¥', 'åŒ»å­¦', 'health', 'medical', 'healthcare'],
            "general": []
        }
        
        domain_scores = {}
        for domain, keywords in domain_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            if score > 0:
                domain_scores[domain] = score / len(keywords) if keywords else 0
        
        if domain_scores:
            primary_domain = max(domain_scores.items(), key=lambda x: x[1])[0]
            confidence = min(0.8, domain_scores[primary_domain] * 2)
        else:
            primary_domain = "general"
            confidence = 0.3
        
        return {
            "primary_domain": primary_domain,
            "secondary_domains": [d for d, s in domain_scores.items() if d != primary_domain and s > 0],
            "domain_confidence": confidence,
            "is_interdisciplinary": len(domain_scores) > 2,
            "technical_level": "intermediate" if primary_domain == "technology" else "basic"
        }
    
    def _fallback_urgency_evaluation(self, text: str) -> Dict[str, Any]:
        """é™çº§ç´§æ€¥ç¨‹åº¦è¯„ä¼°"""
        text_lower = text.lower()
        
        urgency_indicators = {
            "critical": ['ç´§æ€¥', 'æ€¥éœ€', 'ç«‹å³', 'é©¬ä¸Š', 'ç°åœ¨', 'urgent', 'asap', 'immediately', 'now', 'critical'],
            "high": ['å°½å¿«', 'è¾ƒå¿«', 'å¿«é€Ÿ', 'soon', 'quickly', 'fast'],
            "medium": ['ä¸€èˆ¬', 'æ™®é€š', 'æ­£å¸¸', 'normal', 'regular'],
            "low": ['æ…¢æ…¢', 'æœ‰æ—¶é—´', 'ä¸æ€¥', 'éšæ—¶', 'whenever', 'no rush', 'slowly']
        }
        
        urgency_level = "medium"  # é»˜è®¤
        urgency_score = 0.5
        
        for level, indicators in urgency_indicators.items():
            if any(indicator in text_lower for indicator in indicators):
                urgency_level = level
                if level == "critical":
                    urgency_score = 0.9
                elif level == "high":
                    urgency_score = 0.7
                elif level == "medium":
                    urgency_score = 0.5
                else:  # low
                    urgency_score = 0.3
                break
        
        time_sensitivity_map = {
            "critical": "immediate",
            "high": "strict", 
            "medium": "moderate",
            "low": "flexible"
        }
        
        priority_map = {
            "critical": 9,
            "high": 7,
            "medium": 5,
            "low": 3
        }
        
        return {
            "urgency_level": urgency_level,
            "urgency_score": urgency_score,
            "time_sensitivity": time_sensitivity_map[urgency_level],
            "consequences": "å¯èƒ½å½±å“åç»­å·¥ä½œ" if urgency_score > 0.6 else "å½±å“è¾ƒå°",
            "priority_rank": priority_map[urgency_level]
        }
    
    def _generate_cache_key(self, text: str, tasks: List[AnalysisTask]) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        task_signatures = [f"{task.task_type.value}:{task.description[:50]}" for task in tasks]
        combined = f"{text}|{','.join(task_signatures)}"
        return hashlib.md5(combined.encode('utf-8')).hexdigest()
    
    def _get_cached_result(self, cache_key: str) -> Optional[SemanticAnalysisResponse]:
        """è·å–ç¼“å­˜ç»“æœ"""
        if cache_key in self.analysis_cache:
            cached_data, timestamp = self.analysis_cache[cache_key]
            if time.time() - timestamp < self.cache_ttl:
                cached_data.cache_hit = True
                return cached_data
            else:
                # ç¼“å­˜å·²è¿‡æœŸ
                del self.analysis_cache[cache_key]
        return None
    
    def _cache_result(self, cache_key: str, result: SemanticAnalysisResponse):
        """ç¼“å­˜åˆ†æç»“æœ"""
        self.analysis_cache[cache_key] = (result, time.time())
        
        # ç®€å•çš„ç¼“å­˜æ¸…ç†ï¼šå¦‚æœç¼“å­˜è¿‡å¤šï¼Œæ¸…ç†ä¸€åŠ
        if len(self.analysis_cache) > 1000:
            keys_to_remove = list(self.analysis_cache.keys())[:500]
            for key in keys_to_remove:
                del self.analysis_cache[key]
            logger.info("ğŸ§¹ ç¼“å­˜æ¸…ç†å®Œæˆ")
    
    def add_custom_task(self, task: AnalysisTask) -> None:
        """æ·»åŠ è‡ªå®šä¹‰åˆ†æä»»åŠ¡"""
        self.builtin_tasks[task.task_type.value] = task
        logger.info(f"âœ… å·²æ·»åŠ è‡ªå®šä¹‰ä»»åŠ¡: {task.task_type.value}")
    
    def get_available_tasks(self) -> Dict[str, str]:
        """è·å–å¯ç”¨çš„åˆ†æä»»åŠ¡åˆ—è¡¨"""
        return {task_id: task.description for task_id, task in self.builtin_tasks.items()}
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–åˆ†æç»Ÿè®¡ä¿¡æ¯"""
        stats = self.stats.copy()
        stats['cache_hit_rate'] = (
            self.stats['cache_hits'] / max(self.stats['total_analyses'], 1)
        )
        stats['success_rate'] = (
            self.stats['successful_analyses'] / max(self.stats['total_analyses'], 1)  
        )
        stats['average_processing_time'] = (
            self.stats['total_processing_time'] / max(self.stats['total_analyses'], 1)
        )
        return stats
    
    def clear_cache(self):
        """æ¸…ç©ºåˆ†æç¼“å­˜"""
        self.analysis_cache.clear()
        logger.info("ğŸ§¹ åˆ†æç¼“å­˜å·²æ¸…ç©º")
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            'total_analyses': 0,
            'cache_hits': 0,
            'successful_analyses': 0,
            'failed_analyses': 0,
            'total_processing_time': 0.0
        }
        logger.info("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")


# ä¾¿æ·å‡½æ•°
def create_semantic_analyzer(llm_manager=None, config=None) -> SemanticAnalyzer:
    """åˆ›å»ºè¯­ä¹‰åˆ†æå™¨å®ä¾‹"""
    return SemanticAnalyzer(llm_manager=llm_manager, config=config)

def quick_analyze(text: str, tasks: Union[List[str], str] = "intent_detection", 
                 llm_manager=None) -> Dict[str, Any]:
    """å¿«é€Ÿè¯­ä¹‰åˆ†æ - ä¾¿æ·æ–¹æ³•"""
    analyzer = create_semantic_analyzer(llm_manager)
    response = analyzer.analyze(text, tasks)
    
    # è¿”å›ç®€åŒ–çš„ç»“æœå­—å…¸
    results = {}
    for task_type, result in response.analysis_results.items():
        if result.success:
            results[task_type] = result.result
        else:
            results[task_type] = {"error": result.error_message}
    
    return results


if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    print("ğŸ” SemanticAnalyzer æµ‹è¯•")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = create_semantic_analyzer()
    
    # æµ‹è¯•åˆ†æ
    test_text = "æˆ‘æ€¥éœ€ä¸€ä¸ªé«˜æ€§èƒ½çš„æœºå™¨å­¦ä¹ APIè§£å†³æ–¹æ¡ˆ"
    test_tasks = ['intent_detection', 'sentiment_analysis', 'complexity_assessment', 'domain_classification']
    
    print(f"æµ‹è¯•æ–‡æœ¬: {test_text}")
    print(f"åˆ†æä»»åŠ¡: {test_tasks}")
    
    # æ³¨æ„ï¼šè¿™ä¸ªæµ‹è¯•éœ€è¦æœ‰LLMç®¡ç†å™¨æ”¯æŒæ‰èƒ½æ­£å¸¸è¿è¡Œ
    try:
        response = analyzer.analyze(test_text, test_tasks)
        print(f"åˆ†æç»“æœ: {response}")
        print(f"ç»Ÿè®¡ä¿¡æ¯: {analyzer.get_stats()}")
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥ï¼ˆæ­£å¸¸ï¼Œéœ€è¦LLMæ”¯æŒï¼‰: {e}")
    
    print("âœ… SemanticAnalyzer æ¨¡å—åŠ è½½æˆåŠŸ")
