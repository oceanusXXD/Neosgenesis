#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è‡ªä¸»çŸ¥è¯†æ¢å‹˜æ¨¡å— - Knowledge Explorer
Agentè¿æ¥å¤–éƒ¨æ™ºæ…§çš„æ¡¥æ¢

è¿™ä¸ªæ¨¡å—å®ç°äº†è®¤çŸ¥é£è½®çš„"æ¢ç´¢è§¦è§’"ï¼Œè´Ÿè´£ï¼š
1. ä¸»åŠ¨æ¢å‹˜å¤–éƒ¨ä¸–ç•Œçš„æ–°çŸ¥è¯†å’Œæ™ºæ…§
2. å¤šæºä¿¡æ¯çš„è·å–ã€æ•´åˆå’Œè´¨é‡è¯„ä¼°
3. åŸºäºæ¢ç´¢ç»“æœç”Ÿæˆæ–°çš„æ€ç»´ç§å­
4. ä¸ºè®¤çŸ¥é£è½®æä¾›æŒç»­çš„"è¥å…»è¾“å…¥"

æ ¸å¿ƒç†å¿µï¼šè®©AIä»å†…å‘å‹æ€ç»´æ‰©å±•ä¸ºå¤–å‘å‹è®¤çŸ¥æ¢ç´¢è€…
"""

import time
import random
import logging
import asyncio
import hashlib
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
from collections import defaultdict
import json

try:
    from .search_tools import WebSearchClient
except ImportError:
    WebSearchClient = None

logger = logging.getLogger(__name__)


class ExplorationStrategy(Enum):
    """æ¢ç´¢ç­–ç•¥æšä¸¾"""
    DOMAIN_EXPANSION = "domain_expansion"           # é¢†åŸŸæ‰©å±•æ¢ç´¢
    TREND_MONITORING = "trend_monitoring"           # è¶‹åŠ¿ç›‘æ§æ¢ç´¢
    GAP_ANALYSIS = "gap_analysis"                   # çŸ¥è¯†ç¼ºå£åˆ†æ
    CROSS_DOMAIN_LEARNING = "cross_domain_learning" # è·¨åŸŸå­¦ä¹ æ¢ç´¢
    SERENDIPITY_DISCOVERY = "serendipity_discovery" # å¶ç„¶å‘ç°æ¢ç´¢
    EXPERT_KNOWLEDGE = "expert_knowledge"           # ä¸“å®¶çŸ¥è¯†è·å–
    COMPETITIVE_INTELLIGENCE = "competitive_intelligence" # ç«äº‰æƒ…æŠ¥åˆ†æ


class KnowledgeQuality(Enum):
    """çŸ¥è¯†è´¨é‡ç­‰çº§"""
    EXCELLENT = "excellent"     # ä¼˜ç§€ï¼šé«˜å¯ä¿¡åº¦ã€é«˜åˆ›æ–°æ€§
    GOOD = "good"              # è‰¯å¥½ï¼šä¸­ç­‰è´¨é‡ï¼Œæœ‰ä¸€å®šä»·å€¼
    FAIR = "fair"              # ä¸€èˆ¬ï¼šåŸºç¡€ä¿¡æ¯ï¼Œå‚è€ƒä»·å€¼
    POOR = "poor"              # è¾ƒå·®ï¼šè´¨é‡å­˜ç–‘ï¼Œéœ€è¦éªŒè¯
    UNRELIABLE = "unreliable"   # ä¸å¯é ï¼šä¸å»ºè®®ä½¿ç”¨


@dataclass
class ExplorationTarget:
    """æ¢ç´¢ç›®æ ‡æ•°æ®ç»“æ„"""
    target_id: str
    target_type: str  # "concept", "trend", "technology", "methodology", "domain"
    description: str
    keywords: List[str] = field(default_factory=list)
    priority: float = 0.5  # 0-1, 1ä¸ºæœ€é«˜ä¼˜å…ˆçº§
    exploration_depth: int = 1  # æ¢ç´¢æ·±åº¦å±‚çº§
    context: Dict[str, Any] = field(default_factory=dict)
    created_at: float = field(default_factory=time.time)


@dataclass
class KnowledgeItem:
    """çŸ¥è¯†é¡¹æ•°æ®ç»“æ„"""
    knowledge_id: str
    content: str
    source: str
    source_type: str  # "web_search", "api_call", "database", "expert_system"
    quality: KnowledgeQuality
    confidence_score: float = 0.5  # 0-1, ç½®ä¿¡åº¦åˆ†æ•°
    relevance_score: float = 0.5   # 0-1, ç›¸å…³æ€§åˆ†æ•°
    novelty_score: float = 0.5     # 0-1, æ–°é¢–æ€§åˆ†æ•°
    
    # å…ƒæ•°æ®
    extraction_method: str = ""
    language: str = "zh"
    discovered_at: float = field(default_factory=time.time)
    tags: List[str] = field(default_factory=list)
    related_concepts: List[str] = field(default_factory=list)
    
    # éªŒè¯çŠ¶æ€
    is_verified: bool = False
    verification_method: str = ""
    verification_score: float = 0.0


@dataclass
class ThinkingSeed:
    """æ€ç»´ç§å­æ•°æ®ç»“æ„"""
    seed_id: str
    seed_content: str
    source_knowledge: List[str] = field(default_factory=list)  # æ¥æºçŸ¥è¯†é¡¹IDåˆ—è¡¨
    creativity_level: str = "medium"  # "low", "medium", "high"
    potential_applications: List[str] = field(default_factory=list)
    generated_strategy: str = ""
    confidence: float = 0.5
    
    # è®¤çŸ¥è·¯å¾„ç›¸å…³
    suggested_reasoning_paths: List[str] = field(default_factory=list)
    cross_domain_connections: List[str] = field(default_factory=list)
    
    # å…ƒæ•°æ®
    generated_at: float = field(default_factory=time.time)
    generation_context: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ExplorationResult:
    """æ¢ç´¢ç»“æœæ•°æ®ç»“æ„"""
    exploration_id: str
    strategy: ExplorationStrategy
    targets: List[ExplorationTarget]
    
    # æ¢ç´¢æˆæœ
    discovered_knowledge: List[KnowledgeItem] = field(default_factory=list)
    generated_seeds: List[ThinkingSeed] = field(default_factory=list)
    identified_trends: List[Dict[str, Any]] = field(default_factory=list)
    cross_domain_insights: List[Dict[str, Any]] = field(default_factory=list)
    
    # æ‰§è¡Œç»Ÿè®¡
    execution_time: float = 0.0
    success_rate: float = 0.0
    quality_score: float = 0.0
    
    # å…ƒæ•°æ®
    timestamp: float = field(default_factory=time.time)
    context: Dict[str, Any] = field(default_factory=dict)


class KnowledgeExplorer:
    """
    ğŸŒ è‡ªä¸»çŸ¥è¯†æ¢å‹˜æ¨¡å— - Agentçš„"å¤–éƒ¨æ™ºæ…§è¿æ¥å™¨"
    
    æ ¸å¿ƒèŒè´£ï¼š
    1. ä¸»åŠ¨æ¢å‹˜å¤–éƒ¨ä¸–ç•Œçš„æ–°çŸ¥è¯†å’Œè¶‹åŠ¿
    2. å¤šæºä¿¡æ¯è·å–ï¼šç½‘ç»œæœç´¢ã€APIè°ƒç”¨ã€ä¸“å®¶ç³»ç»Ÿ
    3. æ™ºèƒ½çŸ¥è¯†è´¨é‡è¯„ä¼°å’Œè¿‡æ»¤æœºåˆ¶
    4. åŸºäºæ¢ç´¢å‘ç°ç”Ÿæˆé«˜è´¨é‡æ€ç»´ç§å­
    5. ä¸ºè®¤çŸ¥é£è½®æä¾›æŒç»­çš„çŸ¥è¯†"è¥å…»è¾“å…¥"
    
    è®¾è®¡åŸåˆ™ï¼š
    - ä¸»åŠ¨æ€§ï¼šä¸ç­‰å¾…æŒ‡ä»¤ï¼Œä¸»åŠ¨å‘ç°æœºä¼š
    - å¤šæ ·æ€§ï¼šæ”¯æŒå¤šç§æ¢ç´¢ç­–ç•¥å’Œä¿¡æ¯æº
    - è´¨é‡ä¼˜å…ˆï¼šä¸¥æ ¼çš„çŸ¥è¯†è´¨é‡è¯„ä¼°ä½“ç³»
    - é€‚åº”æ€§ï¼šæ ¹æ®æ¢ç´¢æ•ˆæœåŠ¨æ€è°ƒæ•´ç­–ç•¥
    """
    
    def __init__(self, 
                 llm_client=None,
                 web_search_client=None,
                 config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–çŸ¥è¯†æ¢å‹˜æ¨¡å—
        
        Args:
            llm_client: LLMå®¢æˆ·ç«¯ï¼ˆç”¨äºæ™ºèƒ½åˆ†æï¼‰
            web_search_client: ç½‘ç»œæœç´¢å®¢æˆ·ç«¯
            config: æ¢å‹˜é…ç½®å‚æ•°
        """
        self.llm_client = llm_client
        self.web_search_client = web_search_client
        
        # é…ç½®å‚æ•°
        self.config = {
            # æ¢ç´¢ç­–ç•¥é…ç½®
            "exploration_strategies": {
                "default_strategy": ExplorationStrategy.DOMAIN_EXPANSION,
                "strategy_rotation": True,              # æ˜¯å¦è½®æ¢ç­–ç•¥
                "max_parallel_explorations": 3,        # æœ€å¤§å¹¶è¡Œæ¢ç´¢æ•°
                "exploration_timeout": 120.0           # æ¢ç´¢è¶…æ—¶æ—¶é—´
            },
            
            # è´¨é‡æ§åˆ¶é…ç½®
            "quality_control": {
                "min_confidence_threshold": 0.4,       # æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
                "min_relevance_threshold": 0.3,        # æœ€å°ç›¸å…³æ€§é˜ˆå€¼
                "enable_cross_validation": True,       # å¯ç”¨äº¤å‰éªŒè¯
                "quality_decay_factor": 0.1            # è´¨é‡è¡°å‡å› å­
            },
            
            # ç§å­ç”Ÿæˆé…ç½®
            "seed_generation": {
                "max_seeds_per_exploration": 5,        # æ¯æ¬¡æ¢ç´¢æœ€å¤§ç§å­æ•°
                "creativity_boost_factor": 1.2,        # åˆ›æ„æå‡å› å­
                "cross_domain_bonus": 0.3,            # è·¨åŸŸè¿æ¥å¥–åŠ±
                "enable_serendipity": True             # å¯ç”¨å¶ç„¶å‘ç°
            },
            
            # ä¿¡æ¯æºé…ç½®
            "information_sources": {
                "enable_web_search": True,             # å¯ç”¨ç½‘ç»œæœç´¢
                "enable_api_calls": False,             # å¯ç”¨APIè°ƒç”¨
                "enable_database_query": False,       # å¯ç”¨æ•°æ®åº“æŸ¥è¯¢
                "max_results_per_source": 10          # æ¯ä¸ªä¿¡æ¯æºæœ€å¤§ç»“æœæ•°
            }
        }
        
        # åˆå¹¶ç”¨æˆ·é…ç½®
        if config:
            self._merge_config(self.config, config)
        
        # åˆå§‹åŒ–ä¿¡æ¯æºå®¢æˆ·ç«¯
        if not self.web_search_client and self.config["information_sources"]["enable_web_search"]:
            try:
                if WebSearchClient:
                    self.web_search_client = WebSearchClient(
                        max_results=self.config["information_sources"]["max_results_per_source"]
                    )
                    logger.info("ğŸŒ ç½‘ç»œæœç´¢å®¢æˆ·ç«¯å·²åˆå§‹åŒ–")
                else:
                    logger.warning("âš ï¸ WebSearchClient ä¸å¯ç”¨ï¼Œç½‘ç»œæœç´¢åŠŸèƒ½å°†è¢«ç¦ç”¨")
            except Exception as e:
                logger.warning(f"âš ï¸ ç½‘ç»œæœç´¢å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # æ¢ç´¢å†å²å’Œç»Ÿè®¡
        self.exploration_history: List[ExplorationResult] = []
        self.knowledge_cache: Dict[str, KnowledgeItem] = {}
        self.seed_cache: Dict[str, ThinkingSeed] = {}
        
        # ç­–ç•¥æ€§èƒ½ç»Ÿè®¡
        self.strategy_performance: Dict[str, Dict[str, float]] = defaultdict(
            lambda: {"success_rate": 0.0, "avg_quality": 0.0, "total_seeds": 0}
        )
        
        # æ¢ç´¢ç›®æ ‡ç®¡ç†
        self.active_targets: List[ExplorationTarget] = []
        self.completed_targets: List[ExplorationTarget] = []
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_explorations": 0,
            "successful_explorations": 0,
            "total_knowledge_discovered": 0,
            "total_seeds_generated": 0,
            "average_quality_score": 0.0,
            "average_execution_time": 0.0
        }
        
        logger.info("ğŸŒ KnowledgeExplorer åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   ç½‘ç»œæœç´¢: {'å¯ç”¨' if self.web_search_client else 'ç¦ç”¨'}")
        logger.info(f"   LLMåˆ†æ: {'å¯ç”¨' if self.llm_client else 'ç¦ç”¨'}")
        logger.info("ğŸ” å¤–éƒ¨æ™ºæ…§è¿æ¥å™¨å·²å°±ç»ª - ä¸»åŠ¨æ¢ç´¢æ¨¡å¼å¯åŠ¨")
    
    def explore_knowledge(self, 
                         targets: List[ExplorationTarget],
                         strategy: Optional[ExplorationStrategy] = None) -> ExplorationResult:
        """
        æ‰§è¡ŒçŸ¥è¯†æ¢å‹˜ä»»åŠ¡ - æ ¸å¿ƒå…¥å£æ–¹æ³•
        
        Args:
            targets: æ¢ç´¢ç›®æ ‡åˆ—è¡¨
            strategy: æ¢ç´¢ç­–ç•¥ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            å®Œæ•´çš„æ¢ç´¢ç»“æœ
        """
        start_time = time.time()
        exploration_id = f"exploration_{int(time.time() * 1000)}"
        
        # ç¡®å®šæ¢ç´¢ç­–ç•¥
        if not strategy:
            strategy = self._select_optimal_strategy(targets)
        
        logger.info(f"ğŸŒ å¼€å§‹çŸ¥è¯†æ¢å‹˜: {exploration_id}")
        logger.info(f"   ç­–ç•¥: {strategy.value}")
        logger.info(f"   ç›®æ ‡æ•°é‡: {len(targets)}")
        
        try:
            # åˆ›å»ºæ¢ç´¢ç»“æœå¯¹è±¡
            result = ExplorationResult(
                exploration_id=exploration_id,
                strategy=strategy,
                targets=targets
            )
            
            # æ‰§è¡Œæ¢ç´¢æµç¨‹
            self._execute_exploration_pipeline(result)
            
            # è®¡ç®—æ‰§è¡Œç»Ÿè®¡
            result.execution_time = time.time() - start_time
            result.success_rate = self._calculate_success_rate(result)
            result.quality_score = self._calculate_quality_score(result)
            
            # æ›´æ–°ç¼“å­˜å’Œç»Ÿè®¡
            self._update_caches_and_stats(result)
            
            logger.info(f"âœ… çŸ¥è¯†æ¢å‹˜å®Œæˆ: {exploration_id}")
            logger.info(f"   æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}s")
            logger.info(f"   å‘ç°çŸ¥è¯†: {len(result.discovered_knowledge)} é¡¹")
            logger.info(f"   ç”Ÿæˆç§å­: {len(result.generated_seeds)} ä¸ª")
            logger.info(f"   è´¨é‡è¯„åˆ†: {result.quality_score:.2f}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†æ¢å‹˜å¤±è´¥: {exploration_id} - {e}")
            # è¿”å›ç©ºç»“æœä½†åŒ…å«é”™è¯¯ä¿¡æ¯
            return ExplorationResult(
                exploration_id=exploration_id,
                strategy=strategy,
                targets=targets,
                execution_time=time.time() - start_time,
                context={"error": str(e)}
            )
    
    def _execute_exploration_pipeline(self, result: ExplorationResult):
        """æ‰§è¡Œå®Œæ•´çš„æ¢ç´¢æµæ°´çº¿"""
        logger.info("ğŸ”„ æ‰§è¡Œæ¢ç´¢æµæ°´çº¿...")
        
        # é˜¶æ®µ1: ä¿¡æ¯æ”¶é›†
        logger.info("ğŸ“¡ é˜¶æ®µ1: ä¿¡æ¯æ”¶é›†")
        raw_information = self._collect_information(result.targets, result.strategy)
        
        # é˜¶æ®µ2: çŸ¥è¯†æå–å’Œè´¨é‡è¯„ä¼°
        logger.info("ğŸ” é˜¶æ®µ2: çŸ¥è¯†æå–å’Œè´¨é‡è¯„ä¼°")
        result.discovered_knowledge = self._extract_and_evaluate_knowledge(
            raw_information, result.targets
        )
        
        # é˜¶æ®µ3: æ€ç»´ç§å­ç”Ÿæˆ
        logger.info("ğŸŒ± é˜¶æ®µ3: æ€ç»´ç§å­ç”Ÿæˆ")
        result.generated_seeds = self._generate_thinking_seeds(
            result.discovered_knowledge, result.strategy
        )
        
        # é˜¶æ®µ4: è¶‹åŠ¿åˆ†æ
        logger.info("ğŸ“ˆ é˜¶æ®µ4: è¶‹åŠ¿åˆ†æ")
        result.identified_trends = self._analyze_trends(
            result.discovered_knowledge, result.targets
        )
        
        # é˜¶æ®µ5: è·¨åŸŸæ´å¯Ÿå‘ç°
        logger.info("ğŸ”— é˜¶æ®µ5: è·¨åŸŸæ´å¯Ÿå‘ç°")
        result.cross_domain_insights = self._discover_cross_domain_insights(
            result.discovered_knowledge, result.generated_seeds
        )
        
        logger.info("âœ… æ¢ç´¢æµæ°´çº¿æ‰§è¡Œå®Œæˆ")
    
    def _collect_information(self, 
                           targets: List[ExplorationTarget], 
                           strategy: ExplorationStrategy) -> List[Dict[str, Any]]:
        """ä¿¡æ¯æ”¶é›†é˜¶æ®µ - ä»å¤šä¸ªä¿¡æ¯æºè·å–åŸå§‹ä¿¡æ¯"""
        raw_information = []
        
        for target in targets[:self.config["exploration_strategies"]["max_parallel_explorations"]]:
            logger.debug(f"ğŸ¯ æ”¶é›†ç›®æ ‡ä¿¡æ¯: {target.target_id}")
            
            # ç½‘ç»œæœç´¢
            if (self.web_search_client and 
                self.config["information_sources"]["enable_web_search"]):
                web_results = self._search_web_information(target, strategy)
                raw_information.extend(web_results)
            
            # APIè°ƒç”¨ï¼ˆé¢„ç•™æ¥å£ï¼‰
            if self.config["information_sources"]["enable_api_calls"]:
                api_results = self._query_api_sources(target, strategy)
                raw_information.extend(api_results)
            
            # æ•°æ®åº“æŸ¥è¯¢ï¼ˆé¢„ç•™æ¥å£ï¼‰
            if self.config["information_sources"]["enable_database_query"]:
                db_results = self._query_database_sources(target, strategy)
                raw_information.extend(db_results)
        
        logger.info(f"ğŸ“¡ ä¿¡æ¯æ”¶é›†å®Œæˆ: è·å– {len(raw_information)} æ¡åŸå§‹ä¿¡æ¯")
        return raw_information
    
    def _search_web_information(self, 
                              target: ExplorationTarget, 
                              strategy: ExplorationStrategy) -> List[Dict[str, Any]]:
        """æ‰§è¡Œç½‘ç»œæœç´¢"""
        if not self.web_search_client:
            return []
        
        try:
            # æ„å»ºæœç´¢æŸ¥è¯¢
            search_queries = self._build_search_queries(target, strategy)
            web_results = []
            
            for query in search_queries[:3]:  # é™åˆ¶æŸ¥è¯¢æ•°é‡
                logger.debug(f"ğŸ” æœç´¢æŸ¥è¯¢: {query}")
                
                results = self.web_search_client.search(query)
                for result in results:
                    web_results.append({
                        "content": result.get("snippet", ""),
                        "title": result.get("title", ""),
                        "url": result.get("link", ""),
                        "source": "web_search",
                        "query": query,
                        "target_id": target.target_id,
                        "collected_at": time.time()
                    })
            
            logger.debug(f"ğŸŒ ç½‘ç»œæœç´¢å®Œæˆ: {len(web_results)} æ¡ç»“æœ")
            return web_results
            
        except Exception as e:
            logger.error(f"âŒ ç½‘ç»œæœç´¢å¤±è´¥: {e}")
            return []
    
    def _build_search_queries(self, 
                            target: ExplorationTarget, 
                            strategy: ExplorationStrategy) -> List[str]:
        """æ„å»ºé’ˆå¯¹ä¸åŒç­–ç•¥çš„æœç´¢æŸ¥è¯¢"""
        base_keywords = target.keywords + [target.description]
        queries = []
        
        if strategy == ExplorationStrategy.TREND_MONITORING:
            for keyword in base_keywords[:2]:
                queries.extend([
                    f"{keyword} æœ€æ–°è¶‹åŠ¿ 2024",
                    f"{keyword} å‘å±•åŠ¨æ€",
                    f"{keyword} æœªæ¥å±•æœ›"
                ])
        
        elif strategy == ExplorationStrategy.DOMAIN_EXPANSION:
            for keyword in base_keywords[:2]:
                queries.extend([
                    f"{keyword} ç›¸å…³æŠ€æœ¯",
                    f"{keyword} åº”ç”¨é¢†åŸŸ",
                    f"{keyword} åˆ›æ–°åº”ç”¨"
                ])
        
        elif strategy == ExplorationStrategy.GAP_ANALYSIS:
            for keyword in base_keywords[:2]:
                queries.extend([
                    f"{keyword} æŒ‘æˆ˜é—®é¢˜",
                    f"{keyword} æŠ€æœ¯ç“¶é¢ˆ",
                    f"{keyword} è§£å†³æ–¹æ¡ˆ"
                ])
        
        elif strategy == ExplorationStrategy.CROSS_DOMAIN_LEARNING:
            for keyword in base_keywords[:2]:
                queries.extend([
                    f"{keyword} è·¨å­¦ç§‘åº”ç”¨",
                    f"{keyword} å…¶ä»–é¢†åŸŸ",
                    f"{keyword} èåˆåˆ›æ–°"
                ])
        
        elif strategy == ExplorationStrategy.EXPERT_KNOWLEDGE:
            for keyword in base_keywords[:2]:
                queries.extend([
                    f"{keyword} ä¸“å®¶è§‚ç‚¹",
                    f"{keyword} æœ€ä½³å®è·µ",
                    f"{keyword} ä¸“ä¸šæ–¹æ³•è®º",
                    f"{keyword} è¡Œä¸šç»éªŒ",
                    f"{keyword} æƒå¨æŒ‡å—"
                ])
        
        else:
            # é»˜è®¤æŸ¥è¯¢
            queries.extend(base_keywords[:3])
        
        return queries[:5]  # é™åˆ¶æŸ¥è¯¢æ•°é‡
    
    def _query_api_sources(self, 
                         target: ExplorationTarget, 
                         strategy: ExplorationStrategy) -> List[Dict[str, Any]]:
        """æŸ¥è¯¢APIä¿¡æ¯æºï¼ˆé¢„ç•™æ¥å£ï¼‰"""
        # è¿™é‡Œå¯ä»¥é›†æˆå„ç§APIï¼š
        # - å­¦æœ¯è®ºæ–‡API (arXiv, PubMedç­‰)
        # - æ–°é—»API (News APIç­‰)
        # - æŠ€æœ¯æ–‡æ¡£API (GitHub, Stack Overflowç­‰)
        # - ä¸“ä¸šæ•°æ®åº“API
        
        return []  # å½“å‰ä¸ºç©ºå®ç°
    
    def _query_database_sources(self, 
                              target: ExplorationTarget, 
                              strategy: ExplorationStrategy) -> List[Dict[str, Any]]:
        """æŸ¥è¯¢æ•°æ®åº“ä¿¡æ¯æºï¼ˆé¢„ç•™æ¥å£ï¼‰"""
        # è¿™é‡Œå¯ä»¥é›†æˆï¼š
        # - å†…éƒ¨çŸ¥è¯†åº“
        # - è¡Œä¸šæ•°æ®åº“
        # - å†å²æ¢ç´¢ç¼“å­˜
        
        return []  # å½“å‰ä¸ºç©ºå®ç°
    
    def _extract_and_evaluate_knowledge(self, 
                                      raw_information: List[Dict[str, Any]], 
                                      targets: List[ExplorationTarget]) -> List[KnowledgeItem]:
        """çŸ¥è¯†æå–å’Œè´¨é‡è¯„ä¼°"""
        knowledge_items = []
        
        for info in raw_information:
            try:
                # æå–çŸ¥è¯†å†…å®¹
                knowledge_item = self._extract_knowledge_from_info(info, targets)
                if knowledge_item:
                    # è¯„ä¼°çŸ¥è¯†è´¨é‡
                    self._evaluate_knowledge_quality(knowledge_item)
                    
                    # è´¨é‡è¿‡æ»¤
                    if self._passes_quality_filter(knowledge_item):
                        knowledge_items.append(knowledge_item)
                        logger.debug(f"âœ… çŸ¥è¯†æå–æˆåŠŸ: {knowledge_item.knowledge_id}")
                    else:
                        logger.debug(f"âŒ çŸ¥è¯†è´¨é‡ä¸åˆæ ¼: {knowledge_item.knowledge_id}")
            
            except Exception as e:
                logger.debug(f"âš ï¸ çŸ¥è¯†æå–å¤±è´¥: {e}")
                continue
        
        logger.info(f"ğŸ” çŸ¥è¯†æå–å®Œæˆ: {len(knowledge_items)} é¡¹é«˜è´¨é‡çŸ¥è¯†")
        return knowledge_items
    
    def _extract_knowledge_from_info(self, 
                                   info: Dict[str, Any], 
                                   targets: List[ExplorationTarget]) -> Optional[KnowledgeItem]:
        """ä»åŸå§‹ä¿¡æ¯ä¸­æå–çŸ¥è¯†é¡¹"""
        content = info.get("content", "")
        if not content or len(content.strip()) < 10:
            return None
        
        # ç”ŸæˆçŸ¥è¯†ID
        content_hash = hashlib.md5(content.encode()).hexdigest()[:8]
        knowledge_id = f"knowledge_{content_hash}_{int(time.time())}"
        
        # åˆ›å»ºçŸ¥è¯†é¡¹
        knowledge_item = KnowledgeItem(
            knowledge_id=knowledge_id,
            content=content,
            source=info.get("url", info.get("source", "unknown")),
            source_type=info.get("source", "unknown"),
            quality=KnowledgeQuality.FAIR,  # åˆå§‹è´¨é‡ç­‰çº§
            extraction_method="automatic_extraction",
            tags=self._extract_tags_from_content(content),
            related_concepts=self._extract_concepts_from_content(content, targets)
        )
        
        return knowledge_item
    
    def _evaluate_knowledge_quality(self, knowledge_item: KnowledgeItem):
        """è¯„ä¼°çŸ¥è¯†è´¨é‡ - å¤šç»´åº¦è¯„ä¼°ä½“ç³»"""
        
        # 1. ç½®ä¿¡åº¦è¯„ä¼°ï¼ˆåŸºäºæ¥æºå¯ä¿¡åº¦ï¼‰
        confidence_score = self._assess_source_credibility(knowledge_item.source_type)
        
        # 2. ç›¸å…³æ€§è¯„ä¼°ï¼ˆåŸºäºå†…å®¹ç›¸å…³åº¦ï¼‰
        relevance_score = self._assess_content_relevance(knowledge_item.content)
        
        # 3. æ–°é¢–æ€§è¯„ä¼°ï¼ˆåŸºäºå†…å®¹ç‹¬ç‰¹æ€§ï¼‰
        novelty_score = self._assess_content_novelty(knowledge_item.content)
        
        # 4. ç»¼åˆè´¨é‡è¯„ä¼°
        overall_score = (confidence_score * 0.4 + 
                        relevance_score * 0.4 + 
                        novelty_score * 0.2)
        
        # æ›´æ–°çŸ¥è¯†é¡¹è¯„åˆ†
        knowledge_item.confidence_score = confidence_score
        knowledge_item.relevance_score = relevance_score
        knowledge_item.novelty_score = novelty_score
        
        # ç¡®å®šè´¨é‡ç­‰çº§
        if overall_score >= 0.8:
            knowledge_item.quality = KnowledgeQuality.EXCELLENT
        elif overall_score >= 0.6:
            knowledge_item.quality = KnowledgeQuality.GOOD
        elif overall_score >= 0.4:
            knowledge_item.quality = KnowledgeQuality.FAIR
        elif overall_score >= 0.2:
            knowledge_item.quality = KnowledgeQuality.POOR
        else:
            knowledge_item.quality = KnowledgeQuality.UNRELIABLE
        
        logger.debug(f"ğŸ“Š è´¨é‡è¯„ä¼°å®Œæˆ: {knowledge_item.knowledge_id} - {knowledge_item.quality.value}")
    
    def _assess_source_credibility(self, source_type: str) -> float:
        """è¯„ä¼°ä¿¡æ¯æºå¯ä¿¡åº¦"""
        credibility_scores = {
            "web_search": 0.6,
            "academic_paper": 0.9,
            "expert_system": 0.8,
            "database": 0.7,
            "api_call": 0.6,
            "unknown": 0.3
        }
        return credibility_scores.get(source_type, 0.3)
    
    def _assess_content_relevance(self, content: str) -> float:
        """è¯„ä¼°å†…å®¹ç›¸å…³æ€§ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        # åŸºäºå†…å®¹é•¿åº¦å’Œå…³é”®è¯å¯†åº¦çš„ç®€å•è¯„ä¼°
        content_length = len(content)
        if content_length < 50:
            return 0.3
        elif content_length < 200:
            return 0.5
        elif content_length < 500:
            return 0.7
        else:
            return 0.8
    
    def _assess_content_novelty(self, content: str) -> float:
        """è¯„ä¼°å†…å®¹æ–°é¢–æ€§"""
        # æ£€æŸ¥æ˜¯å¦ä¸å·²æœ‰çŸ¥è¯†é‡å¤
        for cached_item in list(self.knowledge_cache.values())[-10:]:  # æ£€æŸ¥æœ€è¿‘10é¡¹
            if self._calculate_content_similarity(content, cached_item.content) > 0.8:
                return 0.2  # é«˜åº¦ç›¸ä¼¼ï¼Œæ–°é¢–æ€§ä½
        
        return 0.6  # é»˜è®¤ä¸­ç­‰æ–°é¢–æ€§
    
    def _calculate_content_similarity(self, content1: str, content2: str) -> float:
        """è®¡ç®—å†…å®¹ç›¸ä¼¼æ€§ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        words1 = set(content1.lower().split())
        words2 = set(content2.lower().split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0.0
    
    def _passes_quality_filter(self, knowledge_item: KnowledgeItem) -> bool:
        """çŸ¥è¯†è´¨é‡è¿‡æ»¤å™¨"""
        min_confidence = self.config["quality_control"]["min_confidence_threshold"]
        min_relevance = self.config["quality_control"]["min_relevance_threshold"]
        
        return (knowledge_item.confidence_score >= min_confidence and
                knowledge_item.relevance_score >= min_relevance and
                knowledge_item.quality != KnowledgeQuality.UNRELIABLE)
    
    def _generate_thinking_seeds(self, 
                               knowledge_items: List[KnowledgeItem], 
                               strategy: ExplorationStrategy) -> List[ThinkingSeed]:
        """åŸºäºå‘ç°çš„çŸ¥è¯†ç”Ÿæˆæ€ç»´ç§å­"""
        thinking_seeds = []
        max_seeds = self.config["seed_generation"]["max_seeds_per_exploration"]
        
        # æŒ‰è´¨é‡æ’åºçŸ¥è¯†é¡¹
        sorted_knowledge = sorted(knowledge_items, 
                                key=lambda k: (k.confidence_score + k.relevance_score + k.novelty_score) / 3, 
                                reverse=True)
        
        # ä¸ºé«˜è´¨é‡çŸ¥è¯†ç”Ÿæˆç§å­
        for knowledge_item in sorted_knowledge[:max_seeds]:
            seed = self._create_thinking_seed_from_knowledge(knowledge_item, strategy)
            if seed:
                thinking_seeds.append(seed)
        
        # ç”Ÿæˆè·¨çŸ¥è¯†èåˆç§å­
        if len(knowledge_items) >= 2:
            fusion_seeds = self._create_fusion_thinking_seeds(knowledge_items[:3], strategy)
            thinking_seeds.extend(fusion_seeds)
        
        # é™åˆ¶ç§å­æ•°é‡
        thinking_seeds = thinking_seeds[:max_seeds]
        
        logger.info(f"ğŸŒ± æ€ç»´ç§å­ç”Ÿæˆå®Œæˆ: {len(thinking_seeds)} ä¸ª")
        return thinking_seeds
    
    def _create_thinking_seed_from_knowledge(self, 
                                           knowledge_item: KnowledgeItem, 
                                           strategy: ExplorationStrategy) -> Optional[ThinkingSeed]:
        """ä»å•ä¸ªçŸ¥è¯†é¡¹åˆ›å»ºæ€ç»´ç§å­"""
        
        # åŸºäºç­–ç•¥è°ƒæ•´ç§å­å†…å®¹
        if strategy == ExplorationStrategy.TREND_MONITORING:
            seed_content = f"åŸºäºè¶‹åŠ¿ç›‘æ§å‘ç°ï¼š{knowledge_item.content[:100]}..."
            creativity_level = "medium"
        
        elif strategy == ExplorationStrategy.CROSS_DOMAIN_LEARNING:
            seed_content = f"è·¨åŸŸå­¦ä¹ æ´å¯Ÿï¼š{knowledge_item.content[:100]}..."
            creativity_level = "high"
        
        elif strategy == ExplorationStrategy.GAP_ANALYSIS:
            seed_content = f"ç¼ºå£åˆ†æå‘ç°ï¼š{knowledge_item.content[:100]}..."
            creativity_level = "medium"
        
        elif strategy == ExplorationStrategy.EXPERT_KNOWLEDGE:
            seed_content = f"ä¸“å®¶çŸ¥è¯†æ´å¯Ÿï¼š{knowledge_item.content[:100]}..."
            creativity_level = "high"
        
        else:
            seed_content = f"æ¢ç´¢å‘ç°ï¼š{knowledge_item.content[:100]}..."
            creativity_level = "medium"
        
        # ç”Ÿæˆç§å­ID
        seed_id = f"seed_{knowledge_item.knowledge_id}_{int(time.time())}"
        
        # åˆ›å»ºæ€ç»´ç§å­
        thinking_seed = ThinkingSeed(
            seed_id=seed_id,
            seed_content=seed_content,
            source_knowledge=[knowledge_item.knowledge_id],
            creativity_level=creativity_level,
            potential_applications=self._suggest_applications(knowledge_item),
            generated_strategy=strategy.value,
            confidence=min(knowledge_item.confidence_score * 1.1, 1.0),  # è½»å¾®æå‡
            suggested_reasoning_paths=self._suggest_reasoning_paths(knowledge_item, strategy),
            generation_context={
                "strategy": strategy.value,
                "source_quality": knowledge_item.quality.value,
                "generated_from": "single_knowledge_item"
            }
        )
        
        return thinking_seed
    
    def _create_fusion_thinking_seeds(self, 
                                    knowledge_items: List[KnowledgeItem], 
                                    strategy: ExplorationStrategy) -> List[ThinkingSeed]:
        """åˆ›å»ºèåˆæ€ç»´ç§å­ - æ•´åˆå¤šä¸ªçŸ¥è¯†é¡¹çš„åˆ›æ–°ç§å­"""
        fusion_seeds = []
        
        if len(knowledge_items) < 2:
            return fusion_seeds
        
        # åˆ›å»ºçŸ¥è¯†èåˆç§å­
        fusion_content = self._fuse_knowledge_contents(knowledge_items)
        fusion_id = f"fusion_seed_{int(time.time())}"
        
        fusion_seed = ThinkingSeed(
            seed_id=fusion_id,
            seed_content=f"èåˆæ´å¯Ÿï¼š{fusion_content}",
            source_knowledge=[k.knowledge_id for k in knowledge_items],
            creativity_level="high",  # èåˆç§å­é€šå¸¸æ›´æœ‰åˆ›æ„
            potential_applications=self._suggest_fusion_applications(knowledge_items),
            generated_strategy=strategy.value,
            confidence=sum(k.confidence_score for k in knowledge_items) / len(knowledge_items),
            cross_domain_connections=self._identify_cross_domain_connections(knowledge_items),
            generation_context={
                "strategy": strategy.value,
                "generated_from": "knowledge_fusion",
                "fusion_count": len(knowledge_items)
            }
        )
        
        fusion_seeds.append(fusion_seed)
        return fusion_seeds
    
    def _fuse_knowledge_contents(self, knowledge_items: List[KnowledgeItem]) -> str:
        """èåˆå¤šä¸ªçŸ¥è¯†é¡¹çš„å†…å®¹"""
        contents = [k.content[:50] for k in knowledge_items[:3]]  # å–å‰50å­—ç¬¦
        return "ã€".join(contents) + " çš„ç»¼åˆåˆ›æ–°æ€è·¯"
    
    def _suggest_applications(self, knowledge_item: KnowledgeItem) -> List[str]:
        """å»ºè®®çŸ¥è¯†åº”ç”¨é¢†åŸŸ"""
        base_applications = [
            "é—®é¢˜è§£å†³ç­–ç•¥",
            "åˆ›æ–°æ€ç»´è·¯å¾„",
            "å†³ç­–ä¼˜åŒ–æ–¹æ¡ˆ"
        ]
        
        # åŸºäºçŸ¥è¯†æ ‡ç­¾å¢åŠ ç‰¹å®šåº”ç”¨
        specific_applications = []
        for tag in knowledge_item.tags[:2]:
            specific_applications.append(f"{tag}ç›¸å…³åº”ç”¨")
        
        return base_applications + specific_applications
    
    def _suggest_reasoning_paths(self, 
                               knowledge_item: KnowledgeItem, 
                               strategy: ExplorationStrategy) -> List[str]:
        """å»ºè®®æ¨ç†è·¯å¾„"""
        base_paths = ["analytical_reasoning", "creative_synthesis"]
        
        strategy_specific_paths = {
            ExplorationStrategy.TREND_MONITORING: ["trend_analysis_path", "predictive_reasoning"],
            ExplorationStrategy.CROSS_DOMAIN_LEARNING: ["analogical_reasoning", "cross_domain_transfer"],
            ExplorationStrategy.GAP_ANALYSIS: ["problem_solving_path", "systematic_analysis"],
            ExplorationStrategy.DOMAIN_EXPANSION: ["exploratory_reasoning", "domain_bridging"],
            ExplorationStrategy.EXPERT_KNOWLEDGE: ["expert_reasoning_path", "professional_methodology"]
        }
        
        specific_paths = strategy_specific_paths.get(strategy, [])
        return base_paths + specific_paths
    
    def _suggest_fusion_applications(self, knowledge_items: List[KnowledgeItem]) -> List[str]:
        """å»ºè®®èåˆçŸ¥è¯†çš„åº”ç”¨"""
        return [
            "è·¨é¢†åŸŸåˆ›æ–°è§£å†³æ–¹æ¡ˆ",
            "ç»¼åˆå†³ç­–ä¼˜åŒ–ç­–ç•¥",
            "å¤šç»´åº¦é—®é¢˜åˆ†ææ–¹æ³•",
            "ç³»ç»Ÿæ€§æ€ç»´å‡çº§è·¯å¾„"
        ]
    
    def _identify_cross_domain_connections(self, knowledge_items: List[KnowledgeItem]) -> List[str]:
        """è¯†åˆ«è·¨åŸŸè¿æ¥"""
        connections = []
        domains = set()
        
        # ä»æ ‡ç­¾ä¸­æå–é¢†åŸŸä¿¡æ¯
        for item in knowledge_items:
            domains.update(item.tags[:2])  # å–å‰2ä¸ªæ ‡ç­¾ä½œä¸ºé¢†åŸŸ
        
        # ç”Ÿæˆè·¨åŸŸè¿æ¥æè¿°
        domain_list = list(domains)
        for i in range(len(domain_list)):
            for j in range(i+1, len(domain_list)):
                connections.append(f"{domain_list[i]}ä¸{domain_list[j]}çš„èåˆåˆ›æ–°")
        
        return connections[:3]  # é™åˆ¶è¿æ¥æ•°é‡
    
    def _analyze_trends(self, 
                       knowledge_items: List[KnowledgeItem], 
                       targets: List[ExplorationTarget]) -> List[Dict[str, Any]]:
        """åˆ†æè¯†åˆ«çš„è¶‹åŠ¿"""
        trends = []
        
        # åŸºäºçŸ¥è¯†å†…å®¹è¯†åˆ«è¶‹åŠ¿å…³é”®è¯
        trend_keywords = self._extract_trend_keywords(knowledge_items)
        
        for keyword in trend_keywords[:3]:  # é™åˆ¶è¶‹åŠ¿æ•°é‡
            trend = {
                "trend_id": f"trend_{keyword}_{int(time.time())}",
                "trend_name": f"{keyword}ç›¸å…³è¶‹åŠ¿",
                "confidence": 0.6,
                "supporting_knowledge": [k.knowledge_id for k in knowledge_items 
                                       if keyword.lower() in k.content.lower()],
                "time_horizon": "short_term",
                "impact_prediction": f"{keyword}å°†åœ¨ç›¸å…³é¢†åŸŸäº§ç”Ÿé‡è¦å½±å“",
                "identified_at": time.time()
            }
            trends.append(trend)
        
        logger.info(f"ğŸ“ˆ è¶‹åŠ¿åˆ†æå®Œæˆ: è¯†åˆ« {len(trends)} ä¸ªè¶‹åŠ¿")
        return trends
    
    def _extract_trend_keywords(self, knowledge_items: List[KnowledgeItem]) -> List[str]:
        """æå–è¶‹åŠ¿å…³é”®è¯"""
        keyword_frequency = defaultdict(int)
        
        for item in knowledge_items:
            words = item.content.lower().split()
            for word in words:
                if len(word) > 3:  # è¿‡æ»¤çŸ­è¯
                    keyword_frequency[word] += 1
        
        # è¿”å›é¢‘æ¬¡æœ€é«˜çš„å…³é”®è¯
        sorted_keywords = sorted(keyword_frequency.items(), key=lambda x: x[1], reverse=True)
        return [word for word, freq in sorted_keywords[:5] if freq > 1]
    
    def _discover_cross_domain_insights(self, 
                                      knowledge_items: List[KnowledgeItem], 
                                      thinking_seeds: List[ThinkingSeed]) -> List[Dict[str, Any]]:
        """å‘ç°è·¨åŸŸæ´å¯Ÿ"""
        insights = []
        
        # åŸºäºæ€ç»´ç§å­çš„è·¨åŸŸè¿æ¥
        for seed in thinking_seeds:
            if seed.cross_domain_connections:
                insight = {
                    "insight_id": f"cross_domain_{seed.seed_id}",
                    "insight_type": "cross_domain_connection",
                    "description": f"å‘ç°{seed.cross_domain_connections[0]}çš„åˆ›æ–°æœºä¼š",
                    "supporting_seeds": [seed.seed_id],
                    "potential_impact": "high",
                    "confidence": seed.confidence,
                    "discovered_at": time.time()
                }
                insights.append(insight)
        
        logger.info(f"ğŸ”— è·¨åŸŸæ´å¯Ÿå‘ç°å®Œæˆ: {len(insights)} ä¸ªæ´å¯Ÿ")
        return insights
    
    def _extract_tags_from_content(self, content: str) -> List[str]:
        """ä»å†…å®¹ä¸­æå–æ ‡ç­¾ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        # è¿™é‡Œå¯ä»¥ä½¿ç”¨NLPæŠ€æœ¯è¿›è¡Œå…³é”®è¯æå–
        words = content.lower().split()
        tags = [word for word in words if len(word) > 4][:5]  # ç®€å•å–é•¿è¯ä½œä¸ºæ ‡ç­¾
        return tags
    
    def _extract_concepts_from_content(self, 
                                     content: str, 
                                     targets: List[ExplorationTarget]) -> List[str]:
        """ä»å†…å®¹ä¸­æå–ç›¸å…³æ¦‚å¿µ"""
        concepts = []
        content_lower = content.lower()
        
        # åŸºäºç›®æ ‡å…³é”®è¯æå–ç›¸å…³æ¦‚å¿µ
        for target in targets:
            for keyword in target.keywords:
                if keyword.lower() in content_lower:
                    concepts.append(keyword)
        
        return concepts[:3]  # é™åˆ¶æ¦‚å¿µæ•°é‡
    
    # ==================== ç­–ç•¥é€‰æ‹©ä¸ä¼˜åŒ– ====================
    
    def _select_optimal_strategy(self, targets: List[ExplorationTarget]) -> ExplorationStrategy:
        """åŸºäºç›®æ ‡å’Œå†å²è¡¨ç°é€‰æ‹©æœ€ä¼˜æ¢ç´¢ç­–ç•¥"""
        
        # å¦‚æœæ²¡æœ‰å†å²æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥
        if not self.strategy_performance:
            return self.config["exploration_strategies"]["default_strategy"]
        
        # åŸºäºå†å²è¡¨ç°é€‰æ‹©ç­–ç•¥
        best_strategy = None
        best_score = 0.0
        
        for strategy_name, performance in self.strategy_performance.items():
            # ç»¼åˆè¯„åˆ†ï¼šæˆåŠŸç‡ * 0.6 + å¹³å‡è´¨é‡ * 0.4
            score = (performance["success_rate"] * 0.6 + 
                    performance["avg_quality"] * 0.4)
            
            if score > best_score:
                best_score = score
                try:
                    best_strategy = ExplorationStrategy(strategy_name)
                except ValueError:
                    continue
        
        return best_strategy or self.config["exploration_strategies"]["default_strategy"]
    
    def _calculate_success_rate(self, result: ExplorationResult) -> float:
        """è®¡ç®—æ¢ç´¢æˆåŠŸç‡"""
        if not result.targets:
            return 0.0
        
        successful_targets = 0
        for target in result.targets:
            # å¦‚æœç›®æ ‡äº§ç”Ÿäº†çŸ¥è¯†æˆ–ç§å­ï¼Œè§†ä¸ºæˆåŠŸ
            target_knowledge = [k for k in result.discovered_knowledge 
                              if target.target_id in k.related_concepts]
            target_seeds = [s for s in result.generated_seeds 
                          if any(target.target_id in s.generation_context.get("related_targets", []))]
            
            if target_knowledge or target_seeds:
                successful_targets += 1
        
        return successful_targets / len(result.targets)
    
    def _calculate_quality_score(self, result: ExplorationResult) -> float:
        """è®¡ç®—æ•´ä½“è´¨é‡è¯„åˆ†"""
        if not result.discovered_knowledge:
            return 0.0
        
        total_score = 0.0
        for knowledge in result.discovered_knowledge:
            knowledge_score = (knowledge.confidence_score + 
                             knowledge.relevance_score + 
                             knowledge.novelty_score) / 3
            total_score += knowledge_score
        
        return total_score / len(result.discovered_knowledge)
    
    def _update_caches_and_stats(self, result: ExplorationResult):
        """æ›´æ–°ç¼“å­˜å’Œç»Ÿè®¡ä¿¡æ¯"""
        # æ›´æ–°æ¢ç´¢å†å²
        self.exploration_history.append(result)
        
        # æ›´æ–°çŸ¥è¯†ç¼“å­˜
        for knowledge in result.discovered_knowledge:
            self.knowledge_cache[knowledge.knowledge_id] = knowledge
        
        # æ›´æ–°ç§å­ç¼“å­˜
        for seed in result.generated_seeds:
            self.seed_cache[seed.seed_id] = seed
        
        # æ›´æ–°ç­–ç•¥æ€§èƒ½
        strategy_name = result.strategy.value
        self.strategy_performance[strategy_name]["success_rate"] = (
            (self.strategy_performance[strategy_name]["success_rate"] + result.success_rate) / 2
        )
        self.strategy_performance[strategy_name]["avg_quality"] = (
            (self.strategy_performance[strategy_name]["avg_quality"] + result.quality_score) / 2
        )
        self.strategy_performance[strategy_name]["total_seeds"] += len(result.generated_seeds)
        
        # æ›´æ–°å…¨å±€ç»Ÿè®¡
        self.stats["total_explorations"] += 1
        if result.success_rate > 0.5:
            self.stats["successful_explorations"] += 1
        self.stats["total_knowledge_discovered"] += len(result.discovered_knowledge)
        self.stats["total_seeds_generated"] += len(result.generated_seeds)
        
        # æ›´æ–°å¹³å‡å€¼
        total_explorations = self.stats["total_explorations"]
        self.stats["average_quality_score"] = (
            (self.stats["average_quality_score"] * (total_explorations - 1) + result.quality_score) / 
            total_explorations
        )
        self.stats["average_execution_time"] = (
            (self.stats["average_execution_time"] * (total_explorations - 1) + result.execution_time) / 
            total_explorations
        )
        
        # æ¸…ç†è¿‡æœŸç¼“å­˜
        self._cleanup_caches()
    
    def _cleanup_caches(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        max_history = 100
        max_knowledge_cache = 500
        max_seed_cache = 300
        
        # æ¸…ç†æ¢ç´¢å†å²
        if len(self.exploration_history) > max_history:
            self.exploration_history = self.exploration_history[-max_history//2:]
        
        # æ¸…ç†çŸ¥è¯†ç¼“å­˜ï¼ˆä¿ç•™æœ€æ–°çš„ï¼‰
        if len(self.knowledge_cache) > max_knowledge_cache:
            sorted_knowledge = sorted(
                self.knowledge_cache.items(),
                key=lambda x: x[1].discovered_at,
                reverse=True
            )
            self.knowledge_cache = dict(sorted_knowledge[:max_knowledge_cache//2])
        
        # æ¸…ç†ç§å­ç¼“å­˜ï¼ˆä¿ç•™æœ€æ–°çš„ï¼‰
        if len(self.seed_cache) > max_seed_cache:
            sorted_seeds = sorted(
                self.seed_cache.items(),
                key=lambda x: x[1].generated_at,
                reverse=True
            )
            self.seed_cache = dict(sorted_seeds[:max_seed_cache//2])
    
    # ==================== å…¬å…±æ¥å£æ–¹æ³• ====================
    
    def create_exploration_targets_from_context(self, 
                                              context: Dict[str, Any]) -> List[ExplorationTarget]:
        """åŸºäºä¸Šä¸‹æ–‡åˆ›å»ºæ¢ç´¢ç›®æ ‡"""
        targets = []
        
        # ä»ä¸Šä¸‹æ–‡æå–å…³é”®ä¿¡æ¯
        session_insights = context.get("session_insights", {})
        knowledge_gaps = context.get("current_knowledge_gaps", [])
        
        # åŸºäºçŸ¥è¯†ç¼ºå£åˆ›å»ºç›®æ ‡
        for gap in knowledge_gaps[:3]:  # é™åˆ¶ç›®æ ‡æ•°é‡
            target = ExplorationTarget(
                target_id=f"gap_target_{gap.get('gap_id', 'unknown')}",
                target_type="knowledge_gap",
                description=gap.get("description", "çŸ¥è¯†ç¼ºå£æ¢ç´¢"),
                keywords=gap.get("keywords", [gap.get("area", "")]),
                priority=gap.get("exploration_priority", 0.5)
            )
            targets.append(target)
        
        # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„ç¼ºå£ï¼Œåˆ›å»ºé€šç”¨æ¢ç´¢ç›®æ ‡
        if not targets:
            general_target = ExplorationTarget(
                target_id=f"general_target_{int(time.time())}",
                target_type="general_exploration",
                description="é€šç”¨çŸ¥è¯†æ¢ç´¢",
                keywords=["æŠ€æœ¯è¶‹åŠ¿", "åˆ›æ–°æ–¹æ³•", "æœ€ä½³å®è·µ"],
                priority=0.6
            )
            targets.append(general_target)
        
        return targets
    
    def get_exploration_stats(self) -> Dict[str, Any]:
        """è·å–æ¢ç´¢ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self.stats,
            "strategy_performance": dict(self.strategy_performance),
            "cache_status": {
                "knowledge_cache_size": len(self.knowledge_cache),
                "seed_cache_size": len(self.seed_cache),
                "exploration_history_size": len(self.exploration_history)
            },
            "recent_explorations": len([r for r in self.exploration_history 
                                      if time.time() - r.timestamp < 3600])  # æœ€è¿‘1å°æ—¶
        }
    
    def _merge_config(self, base_config: Dict, user_config: Dict):
        """é€’å½’åˆå¹¶é…ç½®"""
        for key, value in user_config.items():
            if key in base_config and isinstance(base_config[key], dict) and isinstance(value, dict):
                self._merge_config(base_config[key], value)
            else:
                base_config[key] = value
