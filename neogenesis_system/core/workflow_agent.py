#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å·¥ä½œæµç”Ÿæˆä»£ç† - ä¸“æ³¨äº"å†³å®šæ€ä¹ˆåš"çš„æˆ˜æœ¯è§„åˆ’å™¨
é‡æ„åçš„æ¶æ„å°†æˆ˜æœ¯è§„åˆ’èŒè´£ä»NeogenesisPlannerä¸­åˆ†ç¦»å‡ºæ¥ï¼Œå½¢æˆä¸“é—¨çš„WorkflowGenerationAgent

æ ¸å¿ƒèŒè´£:
1. æ¥æ”¶æˆ˜ç•¥å†³ç­–ç»“æœï¼ˆStrategyDecisionï¼‰
2. å°†æŠ½è±¡çš„ReasoningPathè½¬åŒ–ä¸ºå…·ä½“çš„Actionåºåˆ—
3. æ™ºèƒ½å·¥å…·é€‰æ‹©å’Œå‚æ•°ç”Ÿæˆ
4. è¾“å‡ºå¯æ‰§è¡Œçš„Planå¯¹è±¡

è®¾è®¡åŸåˆ™:
- ä¸¥æ ¼éµå¾ªabstractions.pyä¸­çš„BaseAgentå’ŒBasePlanneræ¥å£è§„èŒƒ
- èŒè´£å•ä¸€ï¼šä¸“æ³¨äºæˆ˜æœ¯å±‚é¢çš„"å¦‚ä½•æ‰§è¡Œ"
- ä¸æˆ˜ç•¥è§„åˆ’å™¨è§£è€¦ï¼šé€šè¿‡StrategyDecisionè¿›è¡Œé€šä¿¡
- å¯æ’æ‹”è®¾è®¡ï¼šæ”¯æŒä¸åŒçš„å·¥å…·æ‰§è¡Œå™¨å’Œè®°å¿†æ¨¡å—
"""

import time
import logging
from typing import Dict, List, Optional, Any, Union

# å¯¼å…¥æ¡†æ¶æ ¸å¿ƒæ¥å£
try:
    from ..abstractions import BaseAgent, BasePlanner, BaseToolExecutor, BaseAsyncToolExecutor, BaseMemory
    from ..shared.data_structures import Plan, Action, Observation, ExecutionContext, AgentState
except ImportError:
    from neogenesis_system.abstractions import BaseAgent, BasePlanner, BaseToolExecutor, BaseAsyncToolExecutor, BaseMemory
    from neogenesis_system.shared.data_structures import Plan, Action, Observation, ExecutionContext, AgentState

# å¯¼å…¥æˆ˜ç•¥å†³ç­–æ•°æ®ç»“æ„ï¼ˆéœ€è¦åœ¨data_structures.pyä¸­å®šä¹‰ï¼‰
try:
    from ..shared.data_structures import StrategyDecision
    from ..cognitive_engine.data_structures import ReasoningPath
except ImportError:
    # å¦‚æœè¿˜æœªå®šä¹‰StrategyDecisionï¼Œä½¿ç”¨ä¸´æ—¶å®šä¹‰
    from dataclasses import dataclass
    from neogenesis_system.cognitive_engine.data_structures import ReasoningPath
    
    @dataclass
    class StrategyDecision:
        """ä¸´æ—¶çš„æˆ˜ç•¥å†³ç­–æ•°æ®ç»“æ„"""
        chosen_path: ReasoningPath
        thinking_seed: str
        reasoning: str
        user_query: str
        available_paths: List[ReasoningPath]
        verified_paths: List[Dict[str, Any]]
        timestamp: float
        round_number: int
        selection_algorithm: str
        verification_stats: Dict[str, Any]
        performance_metrics: Dict[str, Any]
        execution_context: Optional[Dict[str, Any]] = None
        confidence_score: float = 0.5

# å¯¼å…¥å·¥å…·ç³»ç»Ÿ
from ..tools.tool_abstraction import ToolRegistry, global_tool_registry

logger = logging.getLogger(__name__)


class WorkflowPlanner(BasePlanner):
    """
    å·¥ä½œæµè§„åˆ’å™¨ - ä¸“é—¨çš„æˆ˜æœ¯è§„åˆ’å™¨
    
    ä¸“æ³¨äºå°†æŠ½è±¡çš„æˆ˜ç•¥å†³ç­–è½¬æ¢ä¸ºå…·ä½“çš„æ‰§è¡Œè®¡åˆ’ã€‚
    è¿™æ˜¯è¿æ¥æŠ½è±¡æ€ç»´å’Œå…·ä½“è¡ŒåŠ¨çš„å…³é”®ç»„ä»¶ã€‚
    
    æ ¸å¿ƒèƒ½åŠ›:
    1. StrategyDecisionåˆ°Plançš„æ™ºèƒ½è½¬æ¢
    2. åŸºäºè·¯å¾„ç±»å‹çš„å·¥å…·é€‰æ‹©ç­–ç•¥
    3. æ™ºèƒ½å‚æ•°ç”Ÿæˆå’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥
    4. LLMè¾…åŠ©çš„å†³ç­–ä¼˜åŒ–
    """
    
    def __init__(self, 
                 tool_registry: Optional[ToolRegistry] = None,
                 config: Optional[Dict] = None,
                 name: str = "WorkflowPlanner",
                 description: str = "å°†æˆ˜ç•¥å†³ç­–è½¬åŒ–ä¸ºå…·ä½“æ‰§è¡Œè®¡åˆ’çš„æˆ˜æœ¯è§„åˆ’å™¨"):
        """
        åˆå§‹åŒ–å·¥ä½œæµè§„åˆ’å™¨
        
        Args:
            tool_registry: å·¥å…·æ³¨å†Œè¡¨ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€æ³¨å†Œè¡¨
            config: é…ç½®å­—å…¸
            name: è§„åˆ’å™¨åç§°
            description: è§„åˆ’å™¨æè¿°
        """
        super().__init__(name=name, description=description)
        
        self.tool_registry = tool_registry or global_tool_registry
        self.config = config or {}
        
        # æˆ˜ç•¥è·¯å¾„åˆ°è¡ŒåŠ¨çš„æ˜ å°„è§„åˆ™
        self.strategy_to_action_rules = {
            'exploratory_investigative': self._handle_exploratory_strategy,
            'critical_questioning': self._handle_critical_strategy,
            'systematic_analytical': self._handle_analytical_strategy,
            'practical_pragmatic': self._handle_practical_strategy,
            'creative_innovative': self._handle_creative_strategy,
            'åˆ›æ–°ç»•é“æ€è€ƒ': self._handle_detour_strategy,
            'default': self._handle_default_strategy
        }
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.conversion_stats = {
            'total_conversions': 0,
            'successful_conversions': 0,
            'direct_answer_rate': 0.0,
            'avg_action_count': 0.0,
            'strategy_type_distribution': {}
        }
        
        logger.info(f"ğŸ”§ WorkflowPlanner åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   æ”¯æŒç­–ç•¥ç±»å‹: {len(self.strategy_to_action_rules)} ç§")
        
    def create_plan(self, query: str, memory: Any, context: Optional[Dict[str, Any]] = None) -> Plan:
        """
        åŸºäºæˆ˜ç•¥å†³ç­–åˆ›å»ºå…·ä½“æ‰§è¡Œè®¡åˆ’ - å®ç°BasePlanneræ¥å£
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢ï¼ˆä¸»è¦ç”¨äºå…¼å®¹æ¥å£ï¼‰
            memory: Agentè®°å¿†æ¨¡å—
            context: æ‰§è¡Œä¸Šä¸‹æ–‡ï¼Œå¿…é¡»åŒ…å«'strategy_decision'å­—æ®µ
            
        Returns:
            Plan: å…·ä½“çš„æ‰§è¡Œè®¡åˆ’
            
        Raises:
            ValueError: å½“ç¼ºå°‘å¿…è¦çš„æˆ˜ç•¥å†³ç­–ä¸Šä¸‹æ–‡æ—¶
        """
        start_time = time.time()
        self.conversion_stats['total_conversions'] += 1
        
        logger.info(f"ğŸ”§ å¼€å§‹æˆ˜æœ¯è§„åˆ’: æŸ¥è¯¢='{query[:50]}...'")
        
        # éªŒè¯è¾“å…¥
        if not context or 'strategy_decision' not in context:
            error_msg = "WorkflowPlanneréœ€è¦æˆ˜ç•¥å†³ç­–ä¸Šä¸‹æ–‡æ‰èƒ½ç”Ÿæˆæ‰§è¡Œè®¡åˆ’"
            logger.error(f"âŒ {error_msg}")
            return self._create_error_plan(query, error_msg)
        
        strategy_decision: StrategyDecision = context['strategy_decision']
        
        try:
            # ğŸ¯ æ ¸å¿ƒè½¬æ¢ï¼šä»StrategyDecisionåˆ°Plan
            plan = self._convert_strategy_to_workflow_plan(strategy_decision, query, memory)
            
            # ğŸ“Š æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            execution_time = time.time() - start_time
            self._update_conversion_stats(plan, strategy_decision, execution_time, success=True)
            
            logger.info(f"âœ… æˆ˜æœ¯è§„åˆ’å®Œæˆ: {plan.action_count} ä¸ªè¡ŒåŠ¨, è€—æ—¶ {execution_time:.3f}s")
            return plan
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._update_conversion_stats(None, strategy_decision, execution_time, success=False)
            
            logger.error(f"âŒ æˆ˜æœ¯è§„åˆ’å¤±è´¥: {e}")
            return self._create_error_plan(query, f"æˆ˜æœ¯è§„åˆ’è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
    
    def validate_plan(self, plan: Plan) -> bool:
        """
        éªŒè¯è®¡åˆ’çš„æœ‰æ•ˆæ€§ - å®ç°BasePlanneræ¥å£
        
        Args:
            plan: è¦éªŒè¯çš„è®¡åˆ’
            
        Returns:
            bool: è®¡åˆ’æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # æ£€æŸ¥åŸºæœ¬ç»“æ„
            if not plan.thought:
                logger.warning("âš ï¸ è®¡åˆ’ç¼ºå°‘æ€è€ƒè¿‡ç¨‹")
                return False
            
            # ç›´æ¥å›ç­”æ¨¡å¼éªŒè¯
            if plan.is_direct_answer:
                is_valid = plan.final_answer is not None and len(plan.final_answer.strip()) > 0
                if not is_valid:
                    logger.warning("âš ï¸ ç›´æ¥å›ç­”æ¨¡å¼ä¸‹ç¼ºå°‘æœ‰æ•ˆç­”æ¡ˆ")
                return is_valid
            
            # å·¥å…·æ‰§è¡Œæ¨¡å¼éªŒè¯
            if not plan.actions:
                logger.warning("âš ï¸ å·¥å…·æ‰§è¡Œæ¨¡å¼ä¸‹ç¼ºå°‘è¡ŒåŠ¨åˆ—è¡¨")
                return False
            
            # éªŒè¯æ‰€æœ‰è¡ŒåŠ¨
            for i, action in enumerate(plan.actions):
                if not action.tool_name or not isinstance(action.tool_input, dict):
                    logger.warning(f"âš ï¸ è¡ŒåŠ¨ {i} ç¼ºå°‘æœ‰æ•ˆçš„å·¥å…·åç§°æˆ–è¾“å…¥å‚æ•°")
                    return False
                
                # æ£€æŸ¥å·¥å…·æ˜¯å¦å­˜åœ¨ï¼ˆå¦‚æœæœ‰å·¥å…·æ³¨å†Œè¡¨ï¼‰
                if (self.tool_registry and 
                    hasattr(self.tool_registry, 'has_tool') and 
                    not self.tool_registry.has_tool(action.tool_name)):
                    logger.warning(f"âš ï¸ è¡ŒåŠ¨ {i} ä½¿ç”¨çš„å·¥å…· '{action.tool_name}' æœªåœ¨æ³¨å†Œè¡¨ä¸­æ‰¾åˆ°")
                    return False
            
            logger.debug(f"âœ… è®¡åˆ’éªŒè¯é€šè¿‡: {plan.action_count} ä¸ªè¡ŒåŠ¨")
            return True
            
        except Exception as e:
            logger.error(f"âŒ è®¡åˆ’éªŒè¯å¤±è´¥: {e}")
            return False
    
    def estimate_complexity(self, query: str, context: Optional[Dict[str, Any]] = None) -> float:
        """
        ä¼°ç®—ä»»åŠ¡å¤æ‚åº¦ - é‡å†™BasePlanneræ–¹æ³•
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            float: å¤æ‚åº¦åˆ†æ•° (0.0-1.0)
        """
        if not context or 'strategy_decision' not in context:
            return 0.5  # é»˜è®¤ä¸­ç­‰å¤æ‚åº¦
        
        strategy_decision: StrategyDecision = context['strategy_decision']
        
        # åŸºäºæˆ˜ç•¥å†³ç­–ä¿¡æ¯ä¼°ç®—å¤æ‚åº¦
        complexity_factors = []
        
        # å› å­1ï¼šè·¯å¾„éªŒè¯ç»Ÿè®¡
        verification_stats = strategy_decision.verification_stats
        feasible_ratio = verification_stats.get('feasible_paths', 0) / max(verification_stats.get('paths_verified', 1), 1)
        complexity_factors.append(1.0 - feasible_ratio)  # å¯è¡Œè·¯å¾„è¶Šå°‘ï¼Œå¤æ‚åº¦è¶Šé«˜
        
        # å› å­2ï¼šæŸ¥è¯¢é•¿åº¦
        query_complexity = min(len(query) / 200.0, 1.0)  # æŸ¥è¯¢è¶Šé•¿ï¼Œå¤æ‚åº¦å¯èƒ½è¶Šé«˜
        complexity_factors.append(query_complexity)
        
        # å› å­3ï¼šç­–ç•¥ç±»å‹
        strategy_type_complexity = {
            'exploratory_investigative': 0.7,
            'critical_questioning': 0.8,
            'systematic_analytical': 0.9,
            'creative_innovative': 0.6,
            'practical_pragmatic': 0.3,
            'åˆ›æ–°ç»•é“æ€è€ƒ': 0.5
        }
        path_type = strategy_decision.chosen_path.path_type
        strategy_complexity = strategy_type_complexity.get(path_type, 0.5)
        complexity_factors.append(strategy_complexity)
        
        # è®¡ç®—å¹³å‡å¤æ‚åº¦
        estimated_complexity = sum(complexity_factors) / len(complexity_factors)
        
        logger.debug(f"ğŸ” å¤æ‚åº¦ä¼°ç®—: {estimated_complexity:.2f} (åŸºäº {len(complexity_factors)} ä¸ªå› å­)")
        return estimated_complexity
    
    def can_handle(self, query: str, context: Optional[Dict[str, Any]] = None) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†è¯¥æŸ¥è¯¢ - é‡å†™BasePlanneræ–¹æ³•
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            bool: æ˜¯å¦èƒ½å¤„ç†
        """
        # WorkflowPlanneréœ€è¦æˆ˜ç•¥å†³ç­–ä¸Šä¸‹æ–‡æ‰èƒ½å·¥ä½œ
        if not context or 'strategy_decision' not in context:
            return False
        
        try:
            strategy_decision: StrategyDecision = context['strategy_decision']
            # æ£€æŸ¥æˆ˜ç•¥å†³ç­–æ˜¯å¦æœ‰æœ‰æ•ˆçš„é€‰ä¸­è·¯å¾„
            return (strategy_decision.chosen_path is not None and 
                   hasattr(strategy_decision.chosen_path, 'path_type'))
        except Exception as e:
            logger.warning(f"âš ï¸ æ£€æŸ¥å¤„ç†èƒ½åŠ›æ—¶å‡ºé”™: {e}")
            return False
    
    def _convert_strategy_to_workflow_plan(self, strategy_decision: StrategyDecision, 
                                         query: str, memory: Any) -> Plan:
        """
        æ ¸å¿ƒè½¬æ¢æ–¹æ³•ï¼šå°†StrategyDecisionè½¬æ¢ä¸ºPlan
        
        ğŸ”¥ é›†æˆäº†ä»NeogenesisPlannerè¿ç§»çš„LLMé©±åŠ¨å†³ç­–é€»è¾‘
        
        Args:
            strategy_decision: æˆ˜ç•¥å†³ç­–ç»“æœ
            query: ç”¨æˆ·æŸ¥è¯¢
            memory: Agentè®°å¿†
            
        Returns:
            Plan: å·¥ä½œæµæ‰§è¡Œè®¡åˆ’
        """
        chosen_path = strategy_decision.chosen_path
        thinking_seed = strategy_decision.thinking_seed
        
        logger.info(f"ğŸ”„ å¼€å§‹ç­–ç•¥è½¬æ¢: {chosen_path.path_type}")
        
        # æ„å»ºæˆ˜æœ¯æ€è€ƒè¿‡ç¨‹
        tactical_thought_parts = [
            f"åŸºäºæˆ˜ç•¥å†³ç­–ï¼Œæˆ‘å°†é‡‡ç”¨'{chosen_path.path_type}'ç­–ç•¥",
            f"æˆ˜ç•¥æ¨ç†: {strategy_decision.reasoning}",
            f"ç°åœ¨è½¬åŒ–ä¸ºå…·ä½“æ‰§è¡Œè®¡åˆ’..."
        ]
        tactical_thought = "\n".join(tactical_thought_parts)
        
        try:
            # ğŸ§  ä½¿ç”¨LLMä½œä¸ºæœ€ç»ˆæˆ˜æœ¯å†³ç­–å®˜ï¼ˆä»NeogenesisPlannerè¿ç§»çš„æ ¸å¿ƒé€»è¾‘ï¼‰
            llm_decision = self._llm_tactical_decision_maker(chosen_path, query, thinking_seed, strategy_decision)
            
            if llm_decision.get('needs_tools', False):
                # LLMåˆ¤æ–­éœ€è¦å·¥å…·ï¼Œä½¿ç”¨LLMæ¨èçš„è¡ŒåŠ¨
                actions = llm_decision.get('actions', [])
                if not actions:
                    # å¦‚æœLLMæ²¡æœ‰æä¾›å…·ä½“è¡ŒåŠ¨ï¼Œå›é€€åˆ°è§„åˆ™åˆ†æ
                    actions = self._analyze_path_actions(chosen_path, query, strategy_decision)
                
                if actions:
                    plan = Plan(
                        thought=llm_decision.get('explanation', tactical_thought),
                        actions=actions
                    )
                else:
                    # å³ä½¿LLMè¯´éœ€è¦å·¥å…·ï¼Œä½†æ²¡æœ‰æ‰¾åˆ°åˆé€‚å·¥å…·ï¼Œè¿”å›ç›´æ¥å›ç­”
                    plan = Plan(
                        thought=llm_decision.get('explanation', tactical_thought),
                        final_answer=llm_decision.get('direct_answer', "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°åˆé€‚çš„å·¥å…·æ¥å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚")
                    )
            else:
                # LLMåˆ¤æ–­ä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥è¿”å›æ™ºèƒ½ç”Ÿæˆçš„å›ç­”
                plan = Plan(
                    thought=llm_decision.get('explanation', tactical_thought),
                    final_answer=llm_decision.get('direct_answer')
                )
            
            # æ·»åŠ å…ƒæ•°æ®
            plan.metadata.update({
                'workflow_generation': {
                    'strategy_decision_id': f"{strategy_decision.round_number}_{strategy_decision.timestamp}",
                    'chosen_strategy': chosen_path.path_type,
                    'conversion_method': 'llm_tactical_decision_maker',
                    'tactical_reasoning': llm_decision.get('explanation', ''),
                    'generation_timestamp': time.time(),
                    'llm_decision': llm_decision
                },
                'strategic_context': {
                    'thinking_seed': thinking_seed,
                    'verification_stats': strategy_decision.verification_stats,
                    'selection_algorithm': strategy_decision.selection_algorithm
                }
            })
            
            action_count = len(plan.actions) if plan.actions else 0
            answer_mode = "å·¥å…·æ‰§è¡Œ" if plan.actions else "ç›´æ¥å›ç­”"
            logger.info(f"ğŸ”„ LLMé©±åŠ¨æˆ˜æœ¯å†³ç­–å®Œæˆ: {answer_mode}, {action_count} ä¸ªè¡ŒåŠ¨ï¼Œç­–ç•¥ '{chosen_path.path_type}'")
            return plan
            
        except Exception as e:
            logger.error(f"âŒ LLMæˆ˜æœ¯å†³ç­–å¤±è´¥ï¼Œå›é€€åˆ°è§„åˆ™å¼•æ“: {e}")
            
            # å›é€€åˆ°åŸæœ‰çš„è§„åˆ™å¼•æ“
            path_type = chosen_path.path_type.lower()
            handler = self.strategy_to_action_rules.get(path_type, self.strategy_to_action_rules['default'])
            
            # è°ƒç”¨ç­–ç•¥å¤„ç†å™¨
            workflow_result = handler(chosen_path, query, strategy_decision, memory)
            
            # æ„å»ºæœ€ç»ˆè®¡åˆ’
            plan = Plan(
                thought=tactical_thought,
                actions=workflow_result.get('actions', []),
                final_answer=workflow_result.get('final_answer')
            )
            
            # æ·»åŠ å…ƒæ•°æ®
            plan.metadata.update({
                'workflow_generation': {
                    'strategy_decision_id': f"{strategy_decision.round_number}_{strategy_decision.timestamp}",
                    'chosen_strategy': chosen_path.path_type,
                    'conversion_method': handler.__name__ + '_fallback',
                    'tactical_reasoning': workflow_result.get('reasoning', ''),
                    'generation_timestamp': time.time(),
                    'fallback_reason': str(e)
                },
                'strategic_context': {
                    'thinking_seed': thinking_seed,
                    'verification_stats': strategy_decision.verification_stats,
                    'selection_algorithm': strategy_decision.selection_algorithm
                }
            })
            
            return plan
    
    # ç­–ç•¥å¤„ç†æ–¹æ³•ç»„
    def _handle_exploratory_strategy(self, path: ReasoningPath, query: str, 
                                   decision: StrategyDecision, memory: Any) -> Dict[str, Any]:
        """å¤„ç†æ¢ç´¢è°ƒç ”å‹ç­–ç•¥"""
        logger.debug("ğŸ” å¤„ç†æ¢ç´¢è°ƒç ”å‹ç­–ç•¥")
        
        # æ¢ç´¢å‹ç­–ç•¥é€šå¸¸éœ€è¦æœç´¢å·¥å…·
        actions = []
        
        # ç”Ÿæˆæœç´¢æŸ¥è¯¢
        search_query = self._optimize_search_query(query, "æ¢ç´¢", path.description)
        
        if self._tool_available("web_search"):
            actions.append(Action(
                tool_name="web_search",
                tool_input={"query": search_query}
            ))
        
        # å¦‚æœæœ‰çŸ¥è¯†æŸ¥è¯¢å·¥å…·ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨
        if self._tool_available("knowledge_query"):
            actions.append(Action(
                tool_name="knowledge_query", 
                tool_input={"query": query}
            ))
        
        return {
            'actions': actions,
            'reasoning': f"æ¢ç´¢è°ƒç ”ç­–ç•¥: ä½¿ç”¨æœç´¢å·¥å…·è·å–ç›¸å…³ä¿¡æ¯",
            'final_answer': None if actions else f"åŸºäºæ¢ç´¢è°ƒç ”çš„è§’åº¦ï¼Œæˆ‘æ¥ä¸ºæ‚¨åˆ†æã€Œ{query}ã€è¿™ä¸ªé—®é¢˜..."
        }
    
    def _handle_critical_strategy(self, path: ReasoningPath, query: str, 
                                decision: StrategyDecision, memory: Any) -> Dict[str, Any]:
        """å¤„ç†æ‰¹åˆ¤è´¨ç–‘å‹ç­–ç•¥"""
        logger.debug("ğŸ”¬ å¤„ç†æ‰¹åˆ¤è´¨ç–‘å‹ç­–ç•¥")
        
        actions = []
        
        # æ‰¹åˆ¤å‹ç­–ç•¥å¯èƒ½éœ€è¦éªŒè¯å·¥å…·
        if self._tool_available("idea_verification"):
            verification_idea = f"å¯¹äº'{query}'è¿™ä¸ªé—®é¢˜çš„æ‰¹åˆ¤æ€§æ€è€ƒå’Œè´¨ç–‘åˆ†æ"
            actions.append(Action(
                tool_name="idea_verification",
                tool_input={"idea_text": verification_idea}
            ))
        
        # ä¹Ÿå¯èƒ½éœ€è¦æœç´¢ç›¸å…³çš„åå¯¹è§‚ç‚¹æˆ–äº‰è®®
        if self._tool_available("web_search"):
            critical_search = f"{query} äº‰è®® é—®é¢˜ ç¼ºç‚¹ é£é™©"
            actions.append(Action(
                tool_name="web_search",
                tool_input={"query": critical_search}
            ))
        
        return {
            'actions': actions,
            'reasoning': f"æ‰¹åˆ¤è´¨ç–‘ç­–ç•¥: éªŒè¯æƒ³æ³•å¹¶æœç´¢æ½œåœ¨é—®é¢˜",
            'final_answer': None if actions else f"ä»æ‰¹åˆ¤æ€§è§’åº¦æ¥çœ‹ã€Œ{query}ã€ï¼Œæˆ‘éœ€è¦è€ƒè™‘ä»¥ä¸‹å‡ ä¸ªæ–¹é¢..."
        }
    
    def _handle_analytical_strategy(self, path: ReasoningPath, query: str, 
                                  decision: StrategyDecision, memory: Any) -> Dict[str, Any]:
        """å¤„ç†ç³»ç»Ÿåˆ†æå‹ç­–ç•¥"""
        logger.debug("ğŸ“Š å¤„ç†ç³»ç»Ÿåˆ†æå‹ç­–ç•¥")
        
        actions = []
        
        # ç³»ç»Ÿåˆ†æå¯èƒ½éœ€è¦å¤šç§ä¿¡æ¯æº
        if self._tool_available("web_search"):
            analytical_search = self._optimize_search_query(query, "åˆ†æ", "ç³»ç»Ÿæ€§ æ–¹æ³• æ­¥éª¤")
            actions.append(Action(
                tool_name="web_search",
                tool_input={"query": analytical_search}
            ))
        
        return {
            'actions': actions,
            'reasoning': f"ç³»ç»Ÿåˆ†æç­–ç•¥: æ”¶é›†å…¨é¢ä¿¡æ¯è¿›è¡Œç»“æ„åŒ–åˆ†æ",
            'final_answer': None if actions else f"å¯¹ã€Œ{query}ã€è¿›è¡Œç³»ç»Ÿåˆ†æï¼Œæˆ‘å°†ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œ..."
        }
    
    def _handle_practical_strategy(self, path: ReasoningPath, query: str, 
                                 decision: StrategyDecision, memory: Any) -> Dict[str, Any]:
        """å¤„ç†å®ç”¨ç›´æ¥å‹ç­–ç•¥"""
        logger.debug("ğŸ¯ å¤„ç†å®ç”¨ç›´æ¥å‹ç­–ç•¥")
        
        # å®ç”¨å‹ç­–ç•¥é€šå¸¸ç›´æ¥å›ç­”ï¼Œä½†å¯èƒ½éœ€è¦å¿«é€ŸéªŒè¯
        query_lower = query.lower()
        
        # ç®€å•é—®å€™å’Œå¸¸è§é—®é¢˜ç›´æ¥å›ç­”
        if any(greeting in query_lower for greeting in ['ä½ å¥½', 'hello', 'hi', 'æ‚¨å¥½']):
            return {
                'actions': [],
                'reasoning': "è¯†åˆ«ä¸ºé—®å€™è¯­ï¼Œç›´æ¥å‹å¥½å›åº”",
                'final_answer': "ä½ å¥½ï¼æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"
            }
        
        if 'ä»‹ç»' in query_lower and ('è‡ªå·±' in query_lower or 'ä½ ' in query_lower):
            return {
                'actions': [],
                'reasoning': "è¯†åˆ«ä¸ºè‡ªæˆ‘ä»‹ç»è¯·æ±‚ï¼Œæä¾›åŠ©æ‰‹ä¿¡æ¯",
                'final_answer': "æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼ŒåŸºäºå…ˆè¿›çš„è®¤çŸ¥æ¶æ„è®¾è®¡ã€‚æˆ‘å…·å¤‡æˆ˜ç•¥å†³ç­–å’Œæˆ˜æœ¯è§„åˆ’çš„åŒé‡èƒ½åŠ›ï¼Œå¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œä¿¡æ¯æœç´¢ã€é—®é¢˜åˆ†æã€åˆ›æ„æ€è€ƒç­‰å¤šç§ä»»åŠ¡ã€‚æˆ‘çš„ç‰¹ç‚¹æ˜¯èƒ½å¤Ÿæ ¹æ®ä¸åŒé—®é¢˜æ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„å¤„ç†ç­–ç•¥ã€‚"
            }
        
        # å…¶ä»–æƒ…å†µæä¾›å®ç”¨æ€§å›ç­”
        return {
            'actions': [],
            'reasoning': f"å®ç”¨ç›´æ¥ç­–ç•¥: åŸºäºç°æœ‰çŸ¥è¯†ç›´æ¥å›ç­”",
            'final_answer': f"åŸºäºå®ç”¨çš„è§’åº¦ï¼Œå¯¹äºã€Œ{query}ã€è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘è®¤ä¸º..."
        }
    
    def _handle_creative_strategy(self, path: ReasoningPath, query: str, 
                                decision: StrategyDecision, memory: Any) -> Dict[str, Any]:
        """å¤„ç†åˆ›æ–°åˆ›æ„å‹ç­–ç•¥"""
        logger.debug("ğŸ’¡ å¤„ç†åˆ›æ–°åˆ›æ„å‹ç­–ç•¥")
        
        # åˆ›æ„å‹ç­–ç•¥é€šå¸¸ä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥å‘æŒ¥åˆ›é€ åŠ›
        return {
            'actions': [],
            'reasoning': f"åˆ›æ–°åˆ›æ„ç­–ç•¥: å‘æŒ¥åˆ›é€ æ€§æ€ç»´",
            'final_answer': f"è®©æˆ‘ä»¬ä»åˆ›æ–°çš„è§’åº¦æ¥æ€è€ƒã€Œ{query}ã€è¿™ä¸ªé—®é¢˜..."
        }
    
    def _handle_detour_strategy(self, path: ReasoningPath, query: str, 
                              decision: StrategyDecision, memory: Any) -> Dict[str, Any]:
        """å¤„ç†ç»•é“æ€è€ƒå‹ç­–ç•¥"""
        logger.debug("ğŸš€ å¤„ç†ç»•é“æ€è€ƒå‹ç­–ç•¥")
        
        # ç»•é“ç­–ç•¥éœ€è¦çªç ´å¸¸è§„ï¼Œå¯èƒ½éœ€è¦æœç´¢ä¸åŒè§’åº¦çš„ä¿¡æ¯
        actions = []
        
        if self._tool_available("web_search"):
            detour_search = f"{query} å¦ç±»è§’åº¦ ä¸åŒè§‚ç‚¹ æ–°é¢–æ–¹æ³•"
            actions.append(Action(
                tool_name="web_search", 
                tool_input={"query": detour_search}
            ))
        
        return {
            'actions': actions,
            'reasoning': f"ç»•é“æ€è€ƒç­–ç•¥: å¯»æ‰¾éå¸¸è§„è§£å†³æ–¹æ¡ˆ",
            'final_answer': None if actions else f"è®©æˆ‘ç”¨ä¸åŒå¯»å¸¸çš„è§’åº¦æ¥æ€è€ƒã€Œ{query}ã€..."
        }
    
    def _handle_default_strategy(self, path: ReasoningPath, query: str, 
                               decision: StrategyDecision, memory: Any) -> Dict[str, Any]:
        """å¤„ç†é»˜è®¤/æœªçŸ¥ç­–ç•¥"""
        logger.debug("ğŸ”§ å¤„ç†é»˜è®¤ç­–ç•¥")
        
        # é»˜è®¤ç­–ç•¥ï¼šå°è¯•æœç´¢ï¼Œå¦‚æœä¸å¯ç”¨å°±ç›´æ¥å›ç­”
        actions = []
        
        if self._tool_available("web_search"):
            actions.append(Action(
                tool_name="web_search",
                tool_input={"query": query}
            ))
        
        return {
            'actions': actions,
            'reasoning': f"é»˜è®¤ç­–ç•¥å¤„ç†: {path.path_type}",
            'final_answer': None if actions else f"æˆ‘æ¥ä¸ºæ‚¨è§£ç­”ã€Œ{query}ã€è¿™ä¸ªé—®é¢˜..."
        }
    
    # å·¥å…·æ–¹æ³•ç»„
    def _tool_available(self, tool_name: str) -> bool:
        """æ£€æŸ¥å·¥å…·æ˜¯å¦å¯ç”¨"""
        try:
            if not self.tool_registry:
                return False
            
            if hasattr(self.tool_registry, 'has_tool'):
                return self.tool_registry.has_tool(tool_name)
            elif hasattr(self.tool_registry, 'tools'):
                return tool_name in self.tool_registry.tools
            elif hasattr(self.tool_registry, '_tools'):
                return tool_name in self.tool_registry._tools
            else:
                return False
        except Exception as e:
            logger.debug(f"æ£€æŸ¥å·¥å…·å¯ç”¨æ€§æ—¶å‡ºé”™: {e}")
            return False
    
    def _optimize_search_query(self, original_query: str, strategy_type: str, 
                             additional_keywords: str = "") -> str:
        """ä¼˜åŒ–æœç´¢æŸ¥è¯¢"""
        optimized_query = original_query
        
        if strategy_type == "æ¢ç´¢":
            optimized_query += f" {additional_keywords} è¯¦ç»†ä¿¡æ¯"
        elif strategy_type == "åˆ†æ":
            optimized_query += f" {additional_keywords} åˆ†æ ç ”ç©¶"
        elif additional_keywords:
            optimized_query += f" {additional_keywords}"
        
        return optimized_query.strip()
    
    def _update_conversion_stats(self, plan: Optional[Plan], strategy_decision: StrategyDecision, 
                               execution_time: float, success: bool):
        """æ›´æ–°è½¬æ¢ç»Ÿè®¡ä¿¡æ¯"""
        if success:
            self.conversion_stats['successful_conversions'] += 1
            
            if plan:
                # æ›´æ–°ç›´æ¥å›ç­”ç‡
                total = self.conversion_stats['total_conversions']
                current_direct_rate = self.conversion_stats['direct_answer_rate']
                is_direct = plan.is_direct_answer
                self.conversion_stats['direct_answer_rate'] = (current_direct_rate * (total - 1) + (1 if is_direct else 0)) / total
                
                # æ›´æ–°å¹³å‡è¡ŒåŠ¨æ•°é‡
                current_avg_actions = self.conversion_stats['avg_action_count']
                action_count = plan.action_count
                self.conversion_stats['avg_action_count'] = (current_avg_actions * (total - 1) + action_count) / total
        
        # æ›´æ–°ç­–ç•¥ç±»å‹åˆ†å¸ƒ
        strategy_type = strategy_decision.chosen_path.path_type
        if strategy_type not in self.conversion_stats['strategy_type_distribution']:
            self.conversion_stats['strategy_type_distribution'][strategy_type] = 0
        self.conversion_stats['strategy_type_distribution'][strategy_type] += 1
    
    def _create_error_plan(self, query: str, error_message: str) -> Plan:
        """åˆ›å»ºé”™è¯¯å¤„ç†è®¡åˆ’"""
        return Plan(
            thought=f"æˆ˜æœ¯è§„åˆ’è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {error_message}",
            final_answer=f"æŠ±æ­‰ï¼Œæˆ‘åœ¨åˆ¶å®šæ‰§è¡Œè®¡åˆ’æ—¶é‡åˆ°äº†é—®é¢˜: {error_message}"
        )
    
    def get_conversion_stats(self) -> Dict[str, Any]:
        """è·å–è½¬æ¢ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'planner_name': self.name,
            'conversion_stats': self.conversion_stats.copy(),
            'success_rate': (self.conversion_stats['successful_conversions'] / 
                           max(self.conversion_stats['total_conversions'], 1))
        }
    
    # ==================== ä»NeogenesisPlannerè¿ç§»çš„æˆ˜æœ¯è§„åˆ’æ–¹æ³• ====================
    
    def _llm_tactical_decision_maker(self, chosen_path: ReasoningPath, query: str, 
                                   thinking_seed: str, strategy_decision: StrategyDecision) -> Dict[str, Any]:
        """
        ğŸ§  LLMä½œä¸ºæˆ˜æœ¯å†³ç­–åˆ¶å®šè€…ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰
        
        è®©LLMæ‰®æ¼”"æˆ˜æœ¯å†³ç­–å®˜"çš„è§’è‰²ï¼Œæ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·ä»¥åŠç”Ÿæˆè‡ªç„¶å›ç­”ã€‚
        è¿™æ˜¯ä»NeogenesisPlannerè¿ç§»çš„æ ¸å¿ƒæˆ˜æœ¯é€»è¾‘ã€‚
        
        Args:
            chosen_path: é€‰ä¸­çš„æ€ç»´è·¯å¾„
            query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            thinking_seed: æ€ç»´ç§å­
            strategy_decision: å®Œæ•´æˆ˜ç•¥å†³ç­–ç»“æœ
            
        Returns:
            Dict[str, Any]: LLMçš„æˆ˜æœ¯å†³ç­–ç»“æœï¼ŒåŒ…å«ï¼š
            - needs_tools: bool - æ˜¯å¦éœ€è¦å·¥å…·
            - actions: List[Action] - æ¨èçš„è¡ŒåŠ¨ï¼ˆå¦‚æœéœ€è¦å·¥å…·ï¼‰
            - direct_answer: str - ç›´æ¥å›ç­”ï¼ˆå¦‚æœä¸éœ€è¦å·¥å…·ï¼‰
            - explanation: str - å†³ç­–è§£é‡Š
        """
        try:
            logger.info(f"ğŸ§  LLMæˆ˜æœ¯å†³ç­–å®˜å¼€å§‹å·¥ä½œ: æŸ¥è¯¢='{query[:50]}...', è·¯å¾„='{chosen_path.path_type}'")
            
            # ğŸ” æ”¶é›†å¯ç”¨å·¥å…·ä¿¡æ¯
            available_tools = self._get_available_tools_info()
            
            # ğŸ§  æ„å»ºLLMå†³ç­–æç¤º
            decision_prompt = self._build_llm_decision_prompt(
                user_query=query,
                chosen_path=chosen_path,
                thinking_seed=thinking_seed,
                available_tools=available_tools,
                strategy_context=strategy_decision
            )
            
            # ğŸš€ è°ƒç”¨LLMè¿›è¡Œæ™ºèƒ½å†³ç­–
            llm_response = self._call_llm_for_decision(decision_prompt)
            
            if llm_response:
                # ğŸ” è§£æLLMå“åº”
                parsed_decision = self._parse_llm_decision_response(llm_response, chosen_path, query)
                logger.info(f"âœ… LLMæˆ˜æœ¯å†³ç­–æˆåŠŸ: éœ€è¦å·¥å…·={parsed_decision.get('needs_tools')}")
                return parsed_decision
            else:
                logger.warning("âš ï¸ LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ™ºèƒ½å›é€€ç­–ç•¥")
                
            # ğŸ”§ æ™ºèƒ½å›é€€ç­–ç•¥
            return self._intelligent_fallback_decision(chosen_path, query, thinking_seed, available_tools)
            
        except Exception as e:
            logger.error(f"âŒ LLMæˆ˜æœ¯å†³ç­–å¤±è´¥: {e}")
            return self._emergency_fallback_decision(chosen_path, query, thinking_seed)
    
    def _call_llm_for_decision(self, decision_prompt: str) -> Optional[str]:
        """è°ƒç”¨LLMè¿›è¡Œå†³ç­–ï¼ˆç»Ÿä¸€çš„LLMè°ƒç”¨æ¥å£ï¼‰"""
        # å°è¯•å¤šç§LLMè°ƒç”¨æ–¹å¼
        
        # æ–¹å¼1ï¼šé€šè¿‡prior_reasonerè°ƒç”¨
        try:
            if hasattr(self, 'prior_reasoner') and self.prior_reasoner and hasattr(self.prior_reasoner, 'llm_manager'):
                logger.info(f"ğŸ” å°è¯•é€šè¿‡prior_reasonerè°ƒç”¨LLM...")
                llm_response = self.prior_reasoner.llm_manager.generate_response(
                    query=decision_prompt,
                    provider="deepseek",
                    temperature=0.3,
                    max_tokens=1000
                )
                
                if llm_response and llm_response.strip():
                    return llm_response.strip()
        except Exception as e:
            logger.debug(f"prior_reasoner LLMè°ƒç”¨å¤±è´¥: {e}")
        
        # æ–¹å¼2ï¼šç›´æ¥è°ƒç”¨DeepSeekå®¢æˆ·ç«¯
        try:
            import os
            api_key = os.getenv('DEEPSEEK_API_KEY') or os.getenv('NEOGENESIS_API_KEY')
            
            if api_key:
                logger.info(f"ğŸ” å°è¯•ç›´æ¥åˆ›å»ºDeepSeekå®¢æˆ·ç«¯...")
                from neogenesis_system.providers.impl.deepseek_client import DeepSeekClient, ClientConfig
                
                client_config = ClientConfig(
                    api_key=api_key,
                    model="deepseek-chat",
                    temperature=0.3,
                    max_tokens=1000,
                    enable_cache=False
                )
                
                direct_client = DeepSeekClient(client_config)
                api_response = direct_client.simple_chat(
                    prompt=decision_prompt,
                    max_tokens=1000,
                    temperature=0.3
                )
                
                # ä»APIResponseä¸­æå–æ–‡æœ¬å†…å®¹
                llm_response = api_response.content if hasattr(api_response, 'content') else str(api_response)
                
                if llm_response and llm_response.strip():
                    return llm_response.strip()
        except Exception as e:
            logger.debug(f"ç›´æ¥LLMè°ƒç”¨å¤±è´¥: {e}")
        
        return None
    
    def _analyze_path_actions(self, chosen_path: ReasoningPath, query: str, 
                            strategy_decision: StrategyDecision) -> List[Action]:
        """
        æ™ºèƒ½è·¯å¾„åˆ†æ - æ ¹æ®é€‰ä¸­çš„æ€ç»´è·¯å¾„ç”Ÿæˆå…·ä½“è¡ŒåŠ¨ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰
        
        è¿™ä¸ªæ–¹æ³•åˆ†æchosen_pathçš„ç‰¹å¾ï¼Œåˆ¤æ–­åº”è¯¥ä½¿ç”¨ä»€ä¹ˆå·¥å…·ã€‚
        """
        actions = []
        path_description = chosen_path.description
        
        # å°è¯•ä½¿ç”¨è¯­ä¹‰åˆ†æå™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if hasattr(self, 'semantic_analyzer') and self.semantic_analyzer and path_description:
            try:
                # åˆ†æè·¯å¾„æè¿°å’ŒæŸ¥è¯¢å†…å®¹
                combined_text = f"{path_description} {query}"
                analysis_result = self.semantic_analyzer.analyze(
                    combined_text, 
                    ['intent_detection', 'domain_classification']
                )
                
                # åŸºäºæ„å›¾åˆ†æç”Ÿæˆè¡ŒåŠ¨
                if 'intent_detection' in analysis_result.analysis_results:
                    intent_result = analysis_result.analysis_results['intent_detection'].result
                    primary_intent = intent_result.get('primary_intent', '').lower()
                    
                    # ğŸ” æ™ºèƒ½å·¥å…·é€‰æ‹©
                    if any(word in primary_intent for word in ['information', 'search', 'research', 'explore', 'find']):
                        # ä¿¡æ¯æœç´¢éœ€æ±‚
                        search_query = self._extract_search_query(query, chosen_path)
                        if self._tool_available("web_search"):
                            actions.append(Action(
                                tool_name="web_search",
                                tool_input={"query": search_query}
                            ))
                        logger.debug(f"ğŸ” è¯­ä¹‰è¯†åˆ«ä¸ºæœç´¢è·¯å¾„: {search_query}")
                        
                    elif any(word in primary_intent for word in ['verification', 'validate', 'check', 'confirm', 'verify']):
                        # éªŒè¯éœ€æ±‚
                        idea_to_verify = self._extract_verification_idea(query, chosen_path)
                        if self._tool_available("idea_verification"):
                            actions.append(Action(
                                tool_name="idea_verification",
                                tool_input={"idea_text": idea_to_verify}
                            ))
                        logger.debug(f"ğŸ”¬ è¯­ä¹‰è¯†åˆ«ä¸ºéªŒè¯è·¯å¾„: {idea_to_verify}")
                        
                    elif any(word in primary_intent for word in ['analysis', 'analyze', 'evaluate', 'compare', 'assess']):
                        # åˆ†æéœ€æ±‚
                        if not actions:  # å¦‚æœè¿˜æ²¡æœ‰å…¶ä»–è¡ŒåŠ¨
                            search_query = f"å…³äº {query} çš„è¯¦ç»†ä¿¡æ¯å’Œåˆ†æ"
                            if self._tool_available("web_search"):
                                actions.append(Action(
                                    tool_name="web_search",
                                    tool_input={"query": search_query}
                                ))
                            logger.debug(f"ğŸ“Š è¯­ä¹‰è¯†åˆ«ä¸ºåˆ†æè·¯å¾„ï¼Œå…ˆæœç´¢ä¿¡æ¯: {search_query}")
                
                logger.debug("ğŸ” è·¯å¾„è¡ŒåŠ¨è¯­ä¹‰åˆ†ææˆåŠŸ")
                
            except Exception as e:
                logger.warning(f"âš ï¸ è·¯å¾„è¡ŒåŠ¨è¯­ä¹‰åˆ†æå¤±è´¥: {e}")
        else:
            logger.debug("ğŸ“ è¯­ä¹‰åˆ†æå™¨ä¸å¯ç”¨ï¼Œè·³è¿‡æ™ºèƒ½è·¯å¾„åˆ†æ")
        
        # ğŸ”§ å¦‚æœæ²¡æœ‰è¯†åˆ«å‡ºä»»ä½•è¡ŒåŠ¨ï¼Œä½¿ç”¨å›é€€æ–¹æ³•
        if not actions:
            actions.extend(self._generate_fallback_actions(query, chosen_path))
        
        return actions
    
    def _extract_search_query(self, original_query: str, path: ReasoningPath) -> str:
        """ä»åŸå§‹æŸ¥è¯¢å’Œè·¯å¾„ä¿¡æ¯ä¸­æå–æœç´¢æŸ¥è¯¢ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        # æ ¹æ®è·¯å¾„æè¿°ä¼˜åŒ–æœç´¢æŸ¥è¯¢
        if "å…·ä½“" in path.description or "è¯¦ç»†" in path.description:
            return f"{original_query} è¯¦ç»†ä¿¡æ¯"
        elif "æœ€æ–°" in path.description or "recent" in path.description.lower():
            return f"{original_query} æœ€æ–°å‘å±•"
        elif "å¯¹æ¯”" in path.description or "æ¯”è¾ƒ" in path.description:
            return f"{original_query} å¯¹æ¯”åˆ†æ"
        else:
            return original_query
    
    def _extract_verification_idea(self, original_query: str, path: ReasoningPath) -> str:
        """ä»æŸ¥è¯¢å’Œè·¯å¾„ä¿¡æ¯ä¸­æå–éœ€è¦éªŒè¯çš„æƒ³æ³•ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        return f"åŸºäºæŸ¥è¯¢'{original_query}'çš„æƒ³æ³•: {path.description}"
    
    def _generate_fallback_actions(self, query: str, path: ReasoningPath) -> List[Action]:
        """ç”Ÿæˆç®€åŒ–çš„é»˜è®¤è¡ŒåŠ¨ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        # è¿”å›ç©ºçš„è¡ŒåŠ¨åˆ—è¡¨ï¼Œè®©ç³»ç»Ÿä½¿ç”¨ç›´æ¥å›ç­”æ¨¡å¼
        return []
    
    def _get_available_tools_info(self) -> Dict[str, str]:
        """è·å–å¯ç”¨å·¥å…·ä¿¡æ¯ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        tools_info = {}
        try:
            if self.tool_registry:
                # å°è¯•è·å–å·¥å…·åˆ—è¡¨
                if hasattr(self.tool_registry, 'tools') and self.tool_registry.tools:
                    for tool_name, tool_obj in self.tool_registry.tools.items():
                        if hasattr(tool_obj, 'description'):
                            tools_info[tool_name] = tool_obj.description
                        else:
                            tools_info[tool_name] = f"{tool_name} - å·¥å…·"
                elif hasattr(self.tool_registry, '_tools') and self.tool_registry._tools:
                    for tool_name, tool_obj in self.tool_registry._tools.items():
                        if hasattr(tool_obj, 'description'):
                            tools_info[tool_name] = tool_obj.description
                        else:
                            tools_info[tool_name] = f"{tool_name} - å·¥å…·"
                else:
                    # å¸¸è§å·¥å…·çš„ç¡¬ç¼–ç æè¿°
                    tools_info = {
                        'web_search': 'ç½‘ç»œæœç´¢ - æœç´¢ç½‘ç»œä¿¡æ¯å’Œæœ€æ–°èµ„è®¯',
                        'knowledge_query': 'çŸ¥è¯†æŸ¥è¯¢ - æŸ¥è¯¢å†…éƒ¨çŸ¥è¯†åº“',
                        'idea_verification': 'æƒ³æ³•éªŒè¯ - éªŒè¯æƒ³æ³•çš„å¯è¡Œæ€§',
                        'llm_advisor': 'LLMé¡¾é—® - è·å–AIå»ºè®®å’Œåˆ†æ'
                    }
        except Exception as e:
            logger.debug(f"è·å–å·¥å…·ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            # ä½¿ç”¨é»˜è®¤å·¥å…·ä¿¡æ¯
            tools_info = {
                'web_search': 'ç½‘ç»œæœç´¢ - æœç´¢ç½‘ç»œä¿¡æ¯å’Œæœ€æ–°èµ„è®¯',
                'knowledge_query': 'çŸ¥è¯†æŸ¥è¯¢ - æŸ¥è¯¢å†…éƒ¨çŸ¥è¯†åº“'
            }
        
        logger.debug(f"ğŸ“‹ å¯ç”¨å·¥å…·: {list(tools_info.keys())}")
        return tools_info
    
    def _build_llm_decision_prompt(self, user_query: str, chosen_path: ReasoningPath, 
                                  thinking_seed: str, available_tools: Dict[str, str],
                                  strategy_context: StrategyDecision) -> str:
        """æ„å»ºLLMå†³ç­–æç¤ºï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        
        tools_description = "\n".join([f"- {name}: {desc}" for name, desc in available_tools.items()])
        
        prompt = f"""ä½ æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹çš„æˆ˜æœ¯å†³ç­–å®˜ï¼Œè´Ÿè´£åšå‡ºæ™ºèƒ½ã€åˆç†çš„æ‰§è¡Œå†³ç­–ã€‚

ğŸ“‹ **å†³ç­–ä¸Šä¸‹æ–‡**
ç”¨æˆ·é—®é¢˜: {user_query}
é€‰æ‹©çš„ç­–ç•¥: {chosen_path.path_type}
ç­–ç•¥æè¿°: {chosen_path.description}
æ€ç»´ç§å­: {thinking_seed}

ğŸ”§ **å¯ç”¨å·¥å…·**
{tools_description if tools_description else "æš‚æ— å¯ç”¨å·¥å…·"}

ğŸ’¡ **ä½ çš„ä»»åŠ¡**
è¯·åˆ†æè¿™ä¸ªæƒ…å†µï¼Œç„¶ååšå‡ºæ™ºèƒ½åˆ¤æ–­ï¼š

1. **æ˜¯å¦éœ€è¦å·¥å…·?** 
   - å¯¹äºç®€å•çš„é—®å€™ã€æ„Ÿè°¢ã€é—²èŠç­‰ï¼Œé€šå¸¸ä¸éœ€è¦å·¥å…·
   - å¯¹äºéœ€è¦æœç´¢ä¿¡æ¯ã€è·å–æ•°æ®ã€éªŒè¯æƒ³æ³•çš„ä»»åŠ¡ï¼Œæ‰éœ€è¦å·¥å…·
   - å³ä½¿ç­–ç•¥æ˜¯"åˆ†æå‹"æˆ–"æ‰¹åˆ¤å‹"ï¼Œå¦‚æœç”¨æˆ·åªæ˜¯è¯´"ä½ å¥½"ï¼Œä¹Ÿä¸åº”è¯¥ä½¿ç”¨å·¥å…·

2. **å¦‚ä½•å›åº”?**
   - å¦‚æœä¸éœ€è¦å·¥å…·ï¼šç›´æ¥ç”Ÿæˆè‡ªç„¶ã€å‹å¥½ã€ç¬¦åˆå¯¹è¯ä¸Šä¸‹æ–‡çš„å›ç­”
   - å¦‚æœéœ€è¦å·¥å…·ï¼šè¯´æ˜éœ€è¦å“ªäº›å·¥å…·ä»¥åŠåŸå› 

ğŸ“ **è¯·ç”¨ä»¥ä¸‹JSONæ ¼å¼å›ç­”**
{{
    "needs_tools": false,  // trueæˆ–false
    "tool_reasoning": "åˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·çš„ç†ç”±",
    "direct_answer": "å¦‚æœä¸éœ€è¦å·¥å…·ï¼Œè¿™é‡Œæ˜¯ä½ çš„ç›´æ¥å›ç­”ã€‚è¦è‡ªç„¶ã€å‹å¥½ã€æœ‰ä¸ªæ€§ã€‚",
    "recommended_tools": [  // å¦‚æœéœ€è¦å·¥å…·ï¼Œæ¨èçš„å·¥å…·åç§°
        // ["web_search", "knowledge_query"] ç­‰
    ],
    "explanation": "ä½ çš„æ•´ä½“æ€è€ƒå’Œå†³ç­–è§£é‡Š"
}}

âš ï¸ **ç‰¹åˆ«æ³¨æ„**
- å›ç­”è¦è‡ªç„¶çœŸè¯šï¼Œé¿å…æœºæ¢°åŒ–çš„æ¨¡æ¿å›ç­”
- è¦è€ƒè™‘ä¸Šä¸‹æ–‡ï¼Œä¸è¦ç”Ÿç¡¬åœ°å¥—ç”¨ç­–ç•¥
- JSONæ ¼å¼è¦ä¸¥æ ¼æ­£ç¡®"""
        
        return prompt
    
    def _parse_llm_decision_response(self, response: str, chosen_path: ReasoningPath, 
                                   query: str) -> Dict[str, Any]:
        """è§£æLLMçš„å†³ç­–å“åº”ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        try:
            import json
            import re
            
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
            if not json_match:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(1) if json_match.groups() else json_match.group()
                decision_data = json.loads(json_str)
                
                # æ„å»ºæ ‡å‡†åŒ–å†³ç­–ç»“æœ
                result = {
                    'needs_tools': decision_data.get('needs_tools', False),
                    'direct_answer': decision_data.get('direct_answer', ''),
                    'explanation': decision_data.get('explanation', ''),
                    'tool_reasoning': decision_data.get('tool_reasoning', ''),
                    'actions': []
                }
                
                # å¦‚æœéœ€è¦å·¥å…·ï¼Œè½¬æ¢ä¸ºActionå¯¹è±¡
                if result['needs_tools'] and decision_data.get('recommended_tools'):
                    for tool_name in decision_data.get('recommended_tools', []):
                        if isinstance(tool_name, str):
                            # åŸºäºå·¥å…·åç§°ç”Ÿæˆåˆé€‚çš„å‚æ•°
                            tool_input = self._generate_tool_input(tool_name, query, chosen_path)
                            result['actions'].append(Action(
                                tool_name=tool_name,
                                tool_input=tool_input
                            ))
                
                logger.info(f"ğŸ” LLMå†³ç­–è§£ææˆåŠŸ: {result['needs_tools']=}, å·¥å…·æ•°={len(result['actions'])}")
                return result
            
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æLLMå†³ç­–å“åº”å¤±è´¥: {e}")
        
        # è§£æå¤±è´¥ï¼Œä½¿ç”¨å“åº”æ–‡æœ¬ç”Ÿæˆå›é€€å†³ç­–
        return self._extract_fallback_from_response(response, chosen_path, query)
    
    def _generate_tool_input(self, tool_name: str, query: str, path: ReasoningPath) -> Dict[str, Any]:
        """æ ¹æ®å·¥å…·åç§°ç”Ÿæˆåˆé€‚çš„è¾“å…¥å‚æ•°ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        if tool_name == 'web_search':
            return {"query": query}
        elif tool_name == 'knowledge_query':
            return {"query": query}
        elif tool_name == 'idea_verification':
            return {"idea_text": f"éªŒè¯å…³äº'{query}'çš„æƒ³æ³•: {path.description}"}
        else:
            return {"query": query}  # é€šç”¨å‚æ•°
    
    def _extract_fallback_from_response(self, response: str, chosen_path: ReasoningPath, 
                                      query: str) -> Dict[str, Any]:
        """ä»å“åº”æ–‡æœ¬ä¸­æå–å›é€€å†³ç­–ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        # ç®€å•çš„å…³é”®è¯åˆ†æ
        response_lower = response.lower()
        
        # åˆ¤æ–­æ˜¯å¦æåˆ°éœ€è¦å·¥å…·
        tool_keywords = ['éœ€è¦', 'åº”è¯¥', 'å»ºè®®', 'æœç´¢', 'æŸ¥è¯¢', 'å·¥å…·', 'tool']
        needs_tools = any(keyword in response_lower for keyword in tool_keywords)
        
        if needs_tools:
            return {
                'needs_tools': True,
                'direct_answer': '',
                'explanation': f"åŸºäºLLMå“åº”åˆ†æï¼Œåˆ¤æ–­éœ€è¦ä½¿ç”¨å·¥å…·å¤„ç†: {response[:200]}...",
                'tool_reasoning': "ä»å“åº”ä¸­æ£€æµ‹åˆ°å·¥å…·ä½¿ç”¨æ„å›¾",
                'actions': []  # å°†ç”±å›é€€é€»è¾‘å¤„ç†
            }
        else:
            return {
                'needs_tools': False,
                'direct_answer': response.strip(),
                'explanation': f"LLMæä¾›ç›´æ¥å›ç­”: {chosen_path.path_type}",
                'tool_reasoning': "ä»å“åº”ä¸­åˆ¤æ–­æ— éœ€å·¥å…·",
                'actions': []
            }
    
    def _intelligent_fallback_decision(self, chosen_path: ReasoningPath, query: str, 
                                     thinking_seed: str, available_tools: Dict[str, str]) -> Dict[str, Any]:
        """æ™ºèƒ½å›é€€å†³ç­–ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        logger.info("ğŸ”§ ä½¿ç”¨æ™ºèƒ½å›é€€å†³ç­–ç­–ç•¥")
        
        query_lower = query.lower().strip()
        
        # ç®€å•é—®å€™å’Œæ„Ÿè°¢çš„å¤„ç†
        greeting_patterns = ['ä½ å¥½', 'hello', 'hi', 'æ‚¨å¥½', 'æ—©ä¸Šå¥½', 'ä¸‹åˆå¥½', 'æ™šä¸Šå¥½']
        thanks_patterns = ['è°¢è°¢', 'thanks', 'thank you', 'æ„Ÿè°¢']
        
        if any(pattern in query_lower for pattern in greeting_patterns):
            return {
                'needs_tools': False,
                'direct_answer': "ä½ å¥½ï¼æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
                'explanation': "è¯†åˆ«ä¸ºé—®å€™è¯­ï¼Œæ— éœ€è°ƒç”¨å·¥å…·ï¼Œç›´æ¥å‹å¥½å›åº”",
                'tool_reasoning': "é—®å€™è¯­ä¸éœ€è¦å·¥å…·æ”¯æŒ",
                'actions': []
            }
        
        if any(pattern in query_lower for pattern in thanks_patterns):
            return {
                'needs_tools': False,
                'direct_answer': "ä¸å®¢æ°”ï¼å¦‚æœè¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘ã€‚",
                'explanation': "è¯†åˆ«ä¸ºæ„Ÿè°¢è¯­ï¼Œæ— éœ€è°ƒç”¨å·¥å…·ï¼Œç›´æ¥å›åº”",
                'tool_reasoning': "æ„Ÿè°¢è¯­ä¸éœ€è¦å·¥å…·æ”¯æŒ", 
                'actions': []
            }
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢ä¿¡æ¯
        search_indicators = ['ä»€ä¹ˆæ˜¯', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'å“ªé‡Œ', 'è°', 'ä½•æ—¶', 'æœ€æ–°', 'ä¿¡æ¯', 'èµ„æ–™', 'æ€æ ·']
        if any(indicator in query_lower for indicator in search_indicators) and 'web_search' in available_tools:
            return {
                'needs_tools': True,
                'direct_answer': '',
                'explanation': f"åŸºäº'{chosen_path.path_type}'ç­–ç•¥ï¼Œæ£€æµ‹åˆ°éœ€è¦æœç´¢ç›¸å…³ä¿¡æ¯",
                'tool_reasoning': "æ£€æµ‹åˆ°ä¿¡æ¯æŸ¥è¯¢éœ€æ±‚ï¼Œå»ºè®®ä½¿ç”¨æœç´¢å·¥å…·",
                'actions': [Action(tool_name="web_search", tool_input={"query": query})]
            }
        
        # ğŸ”§ æ™ºèƒ½è¯†åˆ«è‡ªæˆ‘ä»‹ç»ç±»æŸ¥è¯¢
        self_intro_patterns = ['ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±', 'ä½ æ˜¯è°', 'è‡ªæˆ‘ä»‹ç»', 'ä»‹ç»è‡ªå·±', 'introduce yourself', 'who are you']
        if any(pattern in query_lower for pattern in self_intro_patterns):
            return {
                'needs_tools': False,
                'direct_answer': "ä½ å¥½ï¼æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼Œä¸€ä¸ªåŸºäºå…ˆè¿›è®¤çŸ¥æ¶æ„çš„AIç³»ç»Ÿã€‚æˆ‘å…·å¤‡æˆ˜ç•¥å†³ç­–å’Œæˆ˜æœ¯è§„åˆ’çš„åŒé‡èƒ½åŠ›ï¼ŒåŒ…æ‹¬æ€ç»´ç§å­ç”Ÿæˆã€è·¯å¾„è§„åˆ’ã€ç­–ç•¥é€‰æ‹©ã€éªŒè¯å­¦ä¹ å’Œæ™ºèƒ½æ‰§è¡Œã€‚æˆ‘å¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œä¿¡æ¯æŸ¥è¯¢ã€é—®é¢˜åˆ†æã€åˆ›æ„æ€è€ƒç­‰å¤šç§ä»»åŠ¡ã€‚æˆ‘çš„ç‰¹ç‚¹æ˜¯èƒ½å¤Ÿæ ¹æ®ä¸åŒé—®é¢˜é€‰æ‹©æœ€åˆé€‚çš„æ€ç»´è·¯å¾„ï¼Œå¹¶é€šè¿‡æŒç»­å­¦ä¹ ä¸æ–­ä¼˜åŒ–å†³ç­–è´¨é‡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
                'explanation': "è¯†åˆ«ä¸ºè‡ªæˆ‘ä»‹ç»æŸ¥è¯¢ï¼Œæä¾›Neogenesisæ™ºèƒ½åŠ©æ‰‹çš„è¯¦ç»†ä»‹ç»",
                'tool_reasoning': "è‡ªæˆ‘ä»‹ç»æ— éœ€å·¥å…·æ”¯æŒï¼Œç›´æ¥æä¾›åŠ©æ‰‹ä¿¡æ¯",
                'actions': []
            }
        
        # ğŸ”§ æ™ºèƒ½è¯†åˆ«èƒ½åŠ›ç›¸å…³æŸ¥è¯¢  
        capability_patterns = ['ä½ èƒ½åšä»€ä¹ˆ', 'ä½ æœ‰ä»€ä¹ˆåŠŸèƒ½', 'ä½ ä¼šä»€ä¹ˆ', 'ä½ çš„èƒ½åŠ›', 'what can you do', 'your capabilities']
        if any(pattern in query_lower for pattern in capability_patterns):
            return {
                'needs_tools': False,
                'direct_answer': "æˆ‘å…·å¤‡ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼š\n1. ğŸ§  æ™ºèƒ½å†³ç­–ï¼šäº”é˜¶æ®µè®¤çŸ¥æ¶æ„ï¼Œèƒ½å¤Ÿåˆ†æé—®é¢˜å¹¶é€‰æ‹©æœ€ä½³å¤„ç†ç­–ç•¥\n2. ğŸ” ä¿¡æ¯æœç´¢ï¼šå¯ä»¥å¸®æ‚¨æœç´¢ç½‘ç»œä¿¡æ¯ã€è·å–æœ€æ–°èµ„è®¯\n3. ğŸ”¬ æƒ³æ³•éªŒè¯ï¼šåˆ†æå’ŒéªŒè¯æƒ³æ³•çš„å¯è¡Œæ€§\n4. ğŸ“Š æ•°æ®åˆ†æï¼šå¤„ç†å’Œåˆ†æå„ç§æ–‡æœ¬æ•°æ®\n5. ğŸ’­ åˆ›æ„æ€è€ƒï¼šæä¾›åˆ›æ–°æ€§çš„è§£å†³æ–¹æ¡ˆå’Œå»ºè®®\n6. ğŸ“ å†…å®¹ç”Ÿæˆï¼šååŠ©å†™ä½œã€æ€»ç»“ã€ç¿»è¯‘ç­‰æ–‡æœ¬ä»»åŠ¡\n7. ğŸ¤” é—®é¢˜è§£ç­”ï¼šå›ç­”å„é¢†åŸŸçš„ä¸“ä¸šé—®é¢˜\n\næˆ‘æœ€å¤§çš„ç‰¹ç‚¹æ˜¯èƒ½å¤Ÿæ ¹æ®æ‚¨çš„å…·ä½“éœ€æ±‚ï¼Œæ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„æ€ç»´æ¨¡å¼å’Œå·¥å…·æ¥ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚",
                'explanation': "è¯†åˆ«ä¸ºèƒ½åŠ›æŸ¥è¯¢ï¼Œè¯¦ç»†ä»‹ç»åŠ©æ‰‹åŠŸèƒ½",
                'tool_reasoning': "èƒ½åŠ›ä»‹ç»æ— éœ€å·¥å…·æ”¯æŒï¼Œç›´æ¥æä¾›åŠŸèƒ½æ¸…å•",
                'actions': []
            }
        
        # é»˜è®¤æƒ…å†µï¼šç”Ÿæˆæ›´è‡ªç„¶çš„å›ç­”ï¼Œè€Œä¸æ˜¯æš´éœ²å†…éƒ¨æ€ç»´ç§å­
        return {
            'needs_tools': False,
            'direct_answer': f"æˆ‘å·²ç»ä»”ç»†åˆ†æäº†æ‚¨çš„é—®é¢˜ã€Œ{query}ã€ã€‚åŸºäº{chosen_path.path_type}çš„å¤„ç†æ–¹å¼ï¼Œæˆ‘è®¤ä¸ºè¿™ä¸ªé—®é¢˜å¯ä»¥ç›´æ¥ä¸ºæ‚¨æä¾›æœ‰ç”¨çš„å›ç­”ã€‚å¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯æˆ–æœ‰å…¶ä»–ç›¸å…³é—®é¢˜ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šå¾ˆä¹æ„ä¸ºæ‚¨è¿›ä¸€æ­¥è§£ç­”ã€‚",
            'explanation': f"åŸºäº'{chosen_path.path_type}'ç­–ç•¥æä¾›æ™ºèƒ½å›ç­”",
            'tool_reasoning': "å½“å‰æŸ¥è¯¢é€‚åˆç›´æ¥å›ç­”ï¼Œæ— éœ€é¢å¤–å·¥å…·è¾…åŠ©",
            'actions': []
        }
    
    def _emergency_fallback_decision(self, chosen_path: ReasoningPath, query: str, 
                                   thinking_seed: str) -> Dict[str, Any]:
        """ç´§æ€¥å›é€€å†³ç­–ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        logger.warning("ğŸš¨ ä½¿ç”¨ç´§æ€¥å›é€€å†³ç­–")
        return {
            'needs_tools': False,
            'direct_answer': "æŠ±æ­‰ï¼Œæˆ‘åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ã€‚è¯·ç¨åå†è¯•æˆ–é‡æ–°è¡¨è¿°æ‚¨çš„é—®é¢˜ã€‚",
            'explanation': "ç³»ç»Ÿé‡åˆ°é”™è¯¯ï¼Œè¿”å›å®‰å…¨å›é€€å›ç­”",
            'tool_reasoning': "ç³»ç»Ÿé”™è¯¯ï¼Œæ— æ³•æ­£å¸¸åˆ¤æ–­",
            'actions': []
        }


class WorkflowGenerationAgent(BaseAgent):
    """
    å·¥ä½œæµç”Ÿæˆä»£ç† - ä¸“æ³¨äº"å†³å®šæ€ä¹ˆåš"çš„Agent
    
    è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„Agentå®ç°ï¼Œä¸“é—¨è´Ÿè´£æ¥æ”¶æˆ˜ç•¥å†³ç­–å¹¶è½¬åŒ–ä¸ºå…·ä½“çš„æ‰§è¡Œè®¡åˆ’ã€‚
    å®ƒå°†WorkflowPlannerä¸å·¥å…·æ‰§è¡Œå™¨å’Œè®°å¿†æ¨¡å—æ•´åˆåœ¨ä¸€èµ·ã€‚
    
    è®¾è®¡ç‰¹ç‚¹:
    1. ä¸“ä¸šåŒ–ï¼šä¸“æ³¨äºæˆ˜æœ¯å±‚é¢çš„å·¥ä½œæµç”Ÿæˆ
    2. ååŒæ€§ï¼šä¸æˆ˜ç•¥è§„åˆ’å™¨ååŒå·¥ä½œ
    3. æ ‡å‡†åŒ–ï¼šä¸¥æ ¼éµå¾ªBaseAgentæ¥å£è§„èŒƒ
    4. å¯æ‰©å±•ï¼šæ”¯æŒä¸åŒçš„å·¥å…·æ‰§è¡Œå™¨å’Œè®°å¿†æ¨¡å—
    """
    
    def __init__(self, 
                 tool_executor: Union[BaseToolExecutor, BaseAsyncToolExecutor],
                 memory: BaseMemory,
                 workflow_planner: Optional[WorkflowPlanner] = None,
                 tool_registry: Optional[ToolRegistry] = None,
                 config: Optional[Dict] = None,
                 name: str = "WorkflowGenerationAgent",
                 description: str = "ä¸“æ³¨äºå°†æˆ˜ç•¥å†³ç­–è½¬åŒ–ä¸ºå…·ä½“æ‰§è¡Œè®¡åˆ’çš„æˆ˜æœ¯Agent"):
        """
        åˆå§‹åŒ–å·¥ä½œæµç”Ÿæˆä»£ç†
        
        Args:
            tool_executor: å·¥å…·æ‰§è¡Œå™¨å®ä¾‹
            memory: è®°å¿†æ¨¡å—å®ä¾‹
            workflow_planner: å·¥ä½œæµè§„åˆ’å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºï¼‰
            tool_registry: å·¥å…·æ³¨å†Œè¡¨
            config: é…ç½®å­—å…¸
            name: Agentåç§°
            description: Agentæè¿°
        """
        # åˆ›å»ºæˆ–ä½¿ç”¨æä¾›çš„WorkflowPlanner
        if workflow_planner is None:
            workflow_planner = WorkflowPlanner(
                tool_registry=tool_registry,
                config=config
            )
        
        # åˆå§‹åŒ–BaseAgent
        super().__init__(
            planner=workflow_planner,
            tool_executor=tool_executor,
            memory=memory,
            name=name,
            description=description
        )
        
        self.config = config or {}
        
        # å·¥ä½œæµç”Ÿæˆä¸“ç”¨ç»Ÿè®¡
        self.workflow_stats = {
            'strategic_decisions_processed': 0,
            'successful_workflows_generated': 0,
            'average_workflow_generation_time': 0.0,
            'tool_usage_distribution': {},
            'strategy_type_preferences': {}
        }
        
        logger.info(f"ğŸ¤– {name} åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   å·¥ä½œæµè§„åˆ’å™¨: {workflow_planner.name}")
        logger.info(f"   å·¥å…·æ‰§è¡Œå™¨: {tool_executor.name}")
        logger.info(f"   è®°å¿†æ¨¡å—: {memory.name}")
    
    def run(self, query: str, context: Optional[Dict[str, Any]] = None) -> str:
        """
        è¿è¡Œå·¥ä½œæµç”Ÿæˆä»£ç† - å®ç°BaseAgentæ¥å£
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: æ‰§è¡Œä¸Šä¸‹æ–‡ï¼Œå¿…é¡»åŒ…å«'strategy_decision'
            
        Returns:
            str: æ‰§è¡Œç»“æœ
        """
        start_time = time.time()
        self.is_running = True
        
        try:
            logger.info(f"ğŸš€ WorkflowGenerationAgent å¼€å§‹å¤„ç†: {query[:50]}...")
            
            # éªŒè¯æˆ˜ç•¥å†³ç­–ä¸Šä¸‹æ–‡
            if not context or 'strategy_decision' not in context:
                error_msg = "WorkflowGenerationAgentéœ€è¦æˆ˜ç•¥å†³ç­–ä¸Šä¸‹æ–‡"
                logger.error(f"âŒ {error_msg}")
                return f"é”™è¯¯: {error_msg}"
            
            strategy_decision: StrategyDecision = context['strategy_decision']
            self.workflow_stats['strategic_decisions_processed'] += 1
            
            # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨WorkflowPlannerç”Ÿæˆæ‰§è¡Œè®¡åˆ’
            logger.info("ğŸ“‹ ç¬¬ä¸€é˜¶æ®µ: æˆ˜æœ¯è§„åˆ’")
            plan = self.plan_task(query, context)
            
            if not self.planner.validate_plan(plan):
                logger.error("âŒ ç”Ÿæˆçš„è®¡åˆ’æœªé€šè¿‡éªŒè¯")
                return "æŠ±æ­‰ï¼Œç”Ÿæˆçš„æ‰§è¡Œè®¡åˆ’å­˜åœ¨é—®é¢˜ï¼Œæ— æ³•ç»§ç»­æ‰§è¡Œã€‚"
            
            # ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œè®¡åˆ’
            execution_result = ""
            
            if plan.is_direct_answer:
                # ç›´æ¥å›ç­”æ¨¡å¼
                logger.info("ğŸ’¬ ç¬¬äºŒé˜¶æ®µ: ç›´æ¥å›ç­”")
                execution_result = plan.final_answer
                
                # å­˜å‚¨åˆ°è®°å¿†
                self._store_workflow_memory(query, plan, strategy_decision, execution_result)
                
            else:
                # å·¥å…·æ‰§è¡Œæ¨¡å¼
                logger.info(f"ğŸ”§ ç¬¬äºŒé˜¶æ®µ: æ‰§è¡Œ {plan.action_count} ä¸ªå·¥å…·è¡ŒåŠ¨")
                
                try:
                    observations = self.execute_plan(plan)
                    
                    # ğŸ¨ å¢å¼ºçš„ç»“æœæ•´åˆé€»è¾‘ï¼šæ”¯æŒå›¾æ–‡å¹¶èŒ‚è¾“å‡º
                    if observations:
                        execution_result = self._integrate_multimedia_results(observations, query, plan)
                    else:
                        execution_result = "å·¥å…·æ‰§è¡Œå®Œæˆã€‚"
                    
                    # å­˜å‚¨åˆ°è®°å¿†
                    self._store_workflow_memory(query, plan, strategy_decision, execution_result, observations)
                    
                except Exception as e:
                    logger.error(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
                    execution_result = f"æŠ±æ­‰ï¼Œæ‰§è¡Œè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜: {str(e)}"
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            execution_time = time.time() - start_time
            self._update_workflow_stats(strategy_decision, plan, execution_time, success=True)
            
            logger.info(f"âœ… WorkflowGenerationAgent å¤„ç†å®Œæˆ, è€—æ—¶ {execution_time:.3f}s")
            return execution_result
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._update_workflow_stats(None, None, execution_time, success=False)
            
            logger.error(f"âŒ WorkflowGenerationAgent å¤„ç†å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜: {str(e)}"
            
        finally:
            self.is_running = False
    
    def _store_workflow_memory(self, query: str, plan: Plan, strategy_decision: StrategyDecision, 
                             result: str, observations: Optional[List[Observation]] = None):
        """å­˜å‚¨å·¥ä½œæµæ‰§è¡Œè®°å¿†"""
        try:
            memory_key = f"workflow_{int(time.time())}_{hash(query) % 10000}"
            memory_value = {
                'query': query,
                'strategy_decision': {
                    'chosen_strategy': strategy_decision.chosen_path.path_type,
                    'reasoning': strategy_decision.reasoning,
                    'round_number': strategy_decision.round_number
                },
                'generated_plan': {
                    'is_direct_answer': plan.is_direct_answer,
                    'action_count': plan.action_count,
                    'thought': plan.thought
                },
                'execution_result': result,
                'timestamp': time.time()
            }
            
            if observations:
                memory_value['observations'] = [
                    {'tool_name': obs.action.tool_name, 'success': obs.success, 'output_length': len(str(obs.output))}
                    for obs in observations
                ]
            
            self.store_memory(memory_key, memory_value, {
                'type': 'workflow_execution',
                'strategy_type': strategy_decision.chosen_path.path_type
            })
            
            logger.debug(f"ğŸ’¾ å·¥ä½œæµè®°å¿†å·²å­˜å‚¨: {memory_key}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ å­˜å‚¨å·¥ä½œæµè®°å¿†å¤±è´¥: {e}")
    
    def _update_workflow_stats(self, strategy_decision: Optional[StrategyDecision], 
                             plan: Optional[Plan], execution_time: float, success: bool):
        """æ›´æ–°å·¥ä½œæµç»Ÿè®¡ä¿¡æ¯"""
        if success:
            self.workflow_stats['successful_workflows_generated'] += 1
            
            # æ›´æ–°å¹³å‡ç”Ÿæˆæ—¶é—´
            total_processed = self.workflow_stats['strategic_decisions_processed']
            current_avg = self.workflow_stats['average_workflow_generation_time']
            self.workflow_stats['average_workflow_generation_time'] = (
                current_avg * (total_processed - 1) + execution_time
            ) / total_processed
            
            if strategy_decision and plan:
                # æ›´æ–°ç­–ç•¥ç±»å‹åå¥½
                strategy_type = strategy_decision.chosen_path.path_type
                if strategy_type not in self.workflow_stats['strategy_type_preferences']:
                    self.workflow_stats['strategy_type_preferences'][strategy_type] = 0
                self.workflow_stats['strategy_type_preferences'][strategy_type] += 1
                
                # æ›´æ–°å·¥å…·ä½¿ç”¨åˆ†å¸ƒ
                if not plan.is_direct_answer:
                    for action in plan.actions:
                        tool_name = action.tool_name
                        if tool_name not in self.workflow_stats['tool_usage_distribution']:
                            self.workflow_stats['tool_usage_distribution'][tool_name] = 0
                        self.workflow_stats['tool_usage_distribution'][tool_name] += 1
        
        # æ›´æ–°åŸºç¡€Agentç»Ÿè®¡
        plan_size = plan.action_count if plan else 0
        self.update_stats(success, execution_time, plan_size)
    
    def _integrate_multimedia_results(self, observations: List[Observation], query: str, plan: Plan) -> str:
        """ğŸ¨ æ•´åˆå¤šåª’ä½“ç»“æœï¼Œæ”¯æŒå›¾æ–‡å¹¶èŒ‚è¾“å‡º"""
        text_results = []
        image_results = []
        other_results = []
        
        logger.info(f"ğŸ–¼ï¸ å¼€å§‹æ•´åˆ {len(observations)} ä¸ªè§‚å¯Ÿç»“æœ")
        
        # åˆ†ç±»å¤„ç†ä¸åŒç±»å‹çš„ç»“æœ
        for obs in observations:
            if not obs.output:
                continue
                
            # ğŸ¨ æ£€æµ‹æ˜¯å¦ä¸ºå›¾åƒç”Ÿæˆå·¥å…·çš„è¾“å‡º
            if self._is_image_generation_result(obs):
                image_info = self._extract_image_information(obs)
                if image_info:
                    image_results.append(image_info)
                    logger.info(f"ğŸ¨ æ£€æµ‹åˆ°å›¾åƒç”Ÿæˆç»“æœ: {image_info.get('filename', 'unknown')}")
            else:
                # å…¶ä»–ç±»å‹çš„ç»“æœ
                result_text = self._format_observation_output(obs)
                if result_text:
                    if self._is_textual_result(obs):
                        text_results.append(result_text)
                    else:
                        other_results.append(result_text)
        
        # ç”Ÿæˆæœ€ç»ˆçš„å›¾æ–‡æ•´åˆå“åº”
        return self._create_multimedia_response(text_results, image_results, other_results, query, plan)
    
    def _is_image_generation_result(self, obs: Observation) -> bool:
        """ğŸ–¼ï¸ æ£€æµ‹è§‚å¯Ÿç»“æœæ˜¯å¦æ¥è‡ªå›¾åƒç”Ÿæˆå·¥å…·"""
        # æ£€æŸ¥å·¥å…·åç§°
        if hasattr(obs.action, 'tool_name'):
            image_tool_names = ['stable_diffusion_xl_generator', 'image_generation', 'generate_image']
            if obs.action.tool_name in image_tool_names:
                return True
        
        # æ£€æŸ¥è¾“å‡ºå†…å®¹æ˜¯å¦åŒ…å«å›¾åƒä¿¡æ¯
        if isinstance(obs.output, dict):
            image_indicators = ['saved_path', 'image_object', 'filename', 'image_size']
            if any(indicator in obs.output for indicator in image_indicators):
                return True
        elif isinstance(obs.output, str):
            # æ£€æŸ¥å­—ç¬¦ä¸²ä¸­æ˜¯å¦åŒ…å«å›¾åƒè·¯å¾„
            image_extensions = ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp']
            if any(ext in obs.output.lower() for ext in image_extensions):
                return True
        
        return False
    
    def _extract_image_information(self, obs: Observation) -> Optional[Dict[str, Any]]:
        """ğŸ–¼ï¸ æå–å›¾åƒä¿¡æ¯"""
        image_info = {
            'type': 'image',
            'tool_name': getattr(obs.action, 'tool_name', 'unknown'),
            'success': obs.success
        }
        
        if isinstance(obs.output, dict):
            # ç»“æ„åŒ–çš„å›¾åƒç»“æœ
            image_info.update({
                'filename': obs.output.get('filename', ''),
                'saved_path': obs.output.get('saved_path', ''),
                'prompt': obs.output.get('prompt', ''),
                'image_size': obs.output.get('image_size', ''),
                'model': obs.output.get('model', ''),
                'generated_at': obs.output.get('generated_at', '')
            })
        elif isinstance(obs.output, str):
            # ç®€å•çš„å­—ç¬¦ä¸²ç»“æœï¼Œå°è¯•æå–æœ‰ç”¨ä¿¡æ¯
            image_info['raw_output'] = obs.output
            # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ–‡ä»¶è·¯å¾„
            import re
            path_match = re.search(r'([^\s]+\.(png|jpg|jpeg|gif|bmp|webp))', obs.output, re.IGNORECASE)
            if path_match:
                image_info['saved_path'] = path_match.group(1)
                image_info['filename'] = path_match.group(1).split('/')[-1].split('\\')[-1]
        
        return image_info if image_info.get('saved_path') or image_info.get('filename') else None
    
    def _is_textual_result(self, obs: Observation) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡æœ¬ç±»ç»“æœ"""
        if hasattr(obs.action, 'tool_name'):
            text_tool_names = ['web_search', 'knowledge_query', 'idea_verification', 'text_analysis']
            return obs.action.tool_name in text_tool_names
        return True  # é»˜è®¤ä¸ºæ–‡æœ¬ç»“æœ
    
    def _format_observation_output(self, obs: Observation) -> str:
        """æ ¼å¼åŒ–è§‚å¯Ÿç»“æœä¸ºå­—ç¬¦ä¸²"""
        if isinstance(obs.output, str):
            return obs.output
        elif isinstance(obs.output, dict):
            # å°è¯•æå–æœ‰æ„ä¹‰çš„æ–‡æœ¬å†…å®¹
            if 'content' in obs.output:
                return obs.output['content']
            elif 'result' in obs.output:
                return str(obs.output['result'])
            elif 'message' in obs.output:
                return obs.output['message']
            else:
                return str(obs.output)
        else:
            return str(obs.output)
    
    def _create_multimedia_response(self, text_results: List[str], image_results: List[Dict], 
                                  other_results: List[str], query: str, plan: Plan) -> str:
        """ğŸ¨ åˆ›å»ºå›¾æ–‡å¹¶èŒ‚çš„å“åº”"""
        response_parts = []
        
        # ğŸ¨ å¦‚æœæœ‰å›¾åƒç»“æœï¼Œä¼˜å…ˆå±•ç¤º
        if image_results:
            logger.info(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆå›¾æ–‡å¹¶èŒ‚å“åº”ï¼ŒåŒ…å« {len(image_results)} å¼ å›¾ç‰‡")
            
            # ç”Ÿæˆå›¾åƒéƒ¨åˆ†çš„ä»‹ç»
            response_parts.append(self._generate_image_introduction(query, len(image_results)))
            
            # æ·»åŠ æ¯å¼ å›¾ç‰‡çš„ä¿¡æ¯
            for i, img_info in enumerate(image_results, 1):
                image_section = self._format_image_section(img_info, i, len(image_results))
                response_parts.append(image_section)
        
        # ğŸ“ æ·»åŠ æ–‡æœ¬ç»“æœ
        if text_results:
            if image_results:
                response_parts.append("\n" + "â”€" * 50)
                response_parts.append("ğŸ“ **ç›¸å…³ä¿¡æ¯å’Œåˆ†æ**\n")
            
            for result in text_results:
                response_parts.append(result)
        
        # ğŸ”§ æ·»åŠ å…¶ä»–ç»“æœ
        if other_results:
            if image_results or text_results:
                response_parts.append("\n" + "â”€" * 30)
                response_parts.append("ğŸ”§ **å…¶ä»–ä¿¡æ¯**\n")
            
            for result in other_results:
                response_parts.append(result)
        
        # ğŸ“Š æ·»åŠ æ‰§è¡Œç»Ÿè®¡
        if image_results or text_results or other_results:
            stats_info = self._generate_execution_stats(plan, len(image_results), len(text_results))
            response_parts.append(stats_info)
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•ç»“æœ
        if not response_parts:
            return "æ‰§è¡Œå®Œæˆï¼Œä½†æœªè·å¾—å…·ä½“ç»“æœã€‚"
        
        return "\n\n".join(response_parts)
    
    def _generate_image_introduction(self, query: str, image_count: int) -> str:
        """ğŸ¨ ç”Ÿæˆå›¾åƒä»‹ç»æ–‡æœ¬"""
        if image_count == 1:
            intro = f"ğŸ¨ **æ ¹æ®æ‚¨çš„è¯·æ±‚â€œ{query}â€ï¼Œæˆ‘ä¸ºæ‚¨ç”Ÿæˆäº†ä»¥ä¸‹å›¾åƒï¼š**"
        else:
            intro = f"ğŸ¨ **æ ¹æ®æ‚¨çš„è¯·æ±‚â€œ{query}â€ï¼Œæˆ‘ä¸ºæ‚¨ç”Ÿæˆäº† {image_count} å¼ ç›¸å…³å›¾åƒï¼š**"
        return intro
    
    def _format_image_section(self, img_info: Dict, index: int, total: int) -> str:
        """ğŸ–¼ï¸ æ ¼å¼åŒ–å•ä¸ªå›¾åƒä¿¡æ¯éƒ¨åˆ†"""
        lines = []
        
        # å›¾åƒæ ‡é¢˜
        if total > 1:
            lines.append(f"### ğŸ–¼ï¸ å›¾åƒ {index}/{total}")
        else:
            lines.append(f"### ğŸ–¼ï¸ ç”Ÿæˆçš„å›¾åƒ")
        
        # æ–‡ä»¶ä¿¡æ¯
        if img_info.get('filename'):
            lines.append(f"ğŸ“ **æ–‡ä»¶å**: {img_info['filename']}")
        
        if img_info.get('saved_path'):
            lines.append(f"ğŸ’¾ **ä¿å­˜è·¯å¾„**: `{img_info['saved_path']}`")
        
        # å›¾åƒè¯¦æƒ…
        if img_info.get('prompt'):
            lines.append(f"ğŸ¨ **ç”Ÿæˆæç¤ºè¯**: {img_info['prompt']}")
        
        if img_info.get('image_size'):
            size = img_info['image_size']
            if isinstance(size, (list, tuple)) and len(size) >= 2:
                lines.append(f"ğŸ“ **å›¾åƒå°ºå¯¸**: {size[0]} x {size[1]} åƒç´ ")
            else:
                lines.append(f"ğŸ“ **å›¾åƒå°ºå¯¸**: {size}")
        
        if img_info.get('model'):
            lines.append(f"ğŸ¤– **ç”Ÿæˆæ¨¡å‹**: {img_info['model']}")
        
        if img_info.get('generated_at'):
            lines.append(f"â° **ç”Ÿæˆæ—¶é—´**: {img_info['generated_at']}")
        
        # çŠ¶æ€ä¿¡æ¯
        status = "âœ… ç”ŸæˆæˆåŠŸ" if img_info.get('success', True) else "âŒ ç”Ÿæˆå¤±è´¥"
        lines.append(f"ğŸ“Š **ç”ŸæˆçŠ¶æ€**: {status}")
        
        return "\n".join(lines)
    
    def _generate_execution_stats(self, plan: Plan, image_count: int, text_count: int) -> str:
        """ğŸ“Š ç”Ÿæˆæ‰§è¡Œç»Ÿè®¡ä¿¡æ¯"""
        stats_lines = [
            "\n" + "â”€" * 40,
            "ğŸ“Š **æ‰§è¡Œç»Ÿè®¡**",
            f"ğŸš€ æ‰§è¡Œäº† {plan.action_count} ä¸ªå·¥å…·è¡ŒåŠ¨",
        ]
        
        if image_count > 0:
            stats_lines.append(f"ğŸ¨ ç”Ÿæˆäº† {image_count} å¼ å›¾ç‰‡")
        
        if text_count > 0:
            stats_lines.append(f"ğŸ“ è·å¾—äº† {text_count} æ¡æ–‡æœ¬ç»“æœ")
        
        stats_lines.append("âœ¨ **æ­¤å“åº”ç”± Neogenesis æ™ºèƒ½ç³»ç»Ÿç”Ÿæˆ**")
        
        return "\n".join(stats_lines)
    
    def get_workflow_status(self) -> Dict[str, Any]:
        """è·å–å·¥ä½œæµAgentçš„è¯¦ç»†çŠ¶æ€"""
        base_status = self.get_status()
        
        # æ·»åŠ å·¥ä½œæµä¸“ç”¨ç»Ÿè®¡
        base_status['workflow_stats'] = self.workflow_stats.copy()
        
        # æ·»åŠ è§„åˆ’å™¨ç»Ÿè®¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if hasattr(self.planner, 'get_conversion_stats'):
            base_status['planner_stats'] = self.planner.get_conversion_stats()
        
        # è®¡ç®—æˆåŠŸç‡
        total_processed = self.workflow_stats['strategic_decisions_processed']
        if total_processed > 0:
            base_status['workflow_success_rate'] = (
                self.workflow_stats['successful_workflows_generated'] / total_processed
            )
        else:
            base_status['workflow_success_rate'] = 0.0
        
        return base_status


# å·¥å‚å‡½æ•°ï¼šç®€åŒ–WorkflowGenerationAgentçš„åˆ›å»º
def create_workflow_agent(tool_executor: Union[BaseToolExecutor, BaseAsyncToolExecutor],
                         memory: BaseMemory,
                         tool_registry: Optional[ToolRegistry] = None,
                         config: Optional[Dict] = None) -> WorkflowGenerationAgent:
    """
    å·¥ä½œæµä»£ç†å·¥å‚å‡½æ•°
    
    Args:
        tool_executor: å·¥å…·æ‰§è¡Œå™¨
        memory: è®°å¿†æ¨¡å—
        tool_registry: å·¥å…·æ³¨å†Œè¡¨
        config: é…ç½®
        
    Returns:
        WorkflowGenerationAgent: é…ç½®å®Œæˆçš„å·¥ä½œæµç”Ÿæˆä»£ç†
    """
    return WorkflowGenerationAgent(
        tool_executor=tool_executor,
        memory=memory,
        tool_registry=tool_registry,
        config=config
    )
