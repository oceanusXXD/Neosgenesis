#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç­–ç•¥è§£é‡Šå™¨ - å¤šé˜¶æ®µå†³ç­–é“¾æ¡çš„æ ¸å¿ƒç»„ä»¶
å®Œç¾ä½“ç°LLMç­–ç•¥å»ºè®® â†’ MABæ•°æ®é©±åŠ¨é€‰æ‹© â†’ ç­–ç•¥è§£æç”Ÿæˆå·¥å…·è°ƒç”¨çš„è®¾è®¡ç†å¿µ
"""

from typing import Dict, List, Any, Optional
import logging
import time
import random

logger = logging.getLogger(__name__)


class StrategyInterpreter:
    """
    ç­–ç•¥è§£é‡Šå™¨ - å°†æ€ç»´è·¯å¾„çš„ç­–ç•¥ç‰¹å¾è½¬æ¢ä¸ºå…·ä½“çš„å·¥å…·è°ƒç”¨ç­–ç•¥
    
    è¿™æ˜¯è¿æ¥"å®è§‚ç­–ç•¥"å’Œ"å…·ä½“è¡ŒåŠ¨"çš„å…³é”®æ¡¥æ¢ç»„ä»¶ï¼Œ
    é¿å…äº†ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼Œè€Œæ˜¯åŸºäºç­–ç•¥çš„æ·±å±‚è¯­ä¹‰ç‰¹å¾ã€‚
    """
    
    def __init__(self):
        self.name = "StrategyInterpreter"
        
        # ç­–ç•¥ç‰¹å¾åˆ°å·¥å…·ç­–ç•¥çš„æ˜ å°„è¡¨
        self.strategy_feature_mappings = {
            # ç³»ç»Ÿåˆ†æå‹ç­–ç•¥ç‰¹å¾
            'systematic_analytical': {
                'primary_tools': ['knowledge_query', 'data_analysis'],
                'secondary_tools': ['web_search'],
                'execution_pattern': 'sequential',  # é¡ºåºæ‰§è¡Œ
                'confidence_threshold': 0.7,
                'description': 'é€»è¾‘åˆ†æã€ç»“æ„åŒ–æ€è€ƒ'
            },
            
            # æ¢ç´¢ç ”ç©¶å‹ç­–ç•¥ç‰¹å¾  
            'exploratory_investigative': {
                'primary_tools': ['web_search', 'tavily_search'],
                'secondary_tools': ['firecrawl_scrape'],
                'execution_pattern': 'parallel',  # å¹¶è¡Œæ‰§è¡Œ
                'confidence_threshold': 0.6,
                'description': 'æ·±å…¥è°ƒç ”ã€ä¿¡æ¯æ”¶é›†'
            },
            
            # æ‰¹åˆ¤è´¨ç–‘å‹ç­–ç•¥ç‰¹å¾
            'critical_questioning': {
                'primary_tools': ['idea_verification', 'text_analysis'],
                'secondary_tools': ['web_search'],
                'execution_pattern': 'validation_focused',
                'confidence_threshold': 0.8,
                'description': 'è´¨ç–‘åˆ†æã€é£é™©è¯„ä¼°'
            },
            
            # å®ç”¨å¯¼å‘å‹ç­–ç•¥ç‰¹å¾
            'practical_pragmatic': {
                'primary_tools': ['knowledge_query'],
                'secondary_tools': ['web_search'],
                'execution_pattern': 'direct',  # ç›´æ¥é«˜æ•ˆ
                'confidence_threshold': 0.5,
                'description': 'å®é™…å¯è¡Œã€æ•ˆç‡ä¼˜å…ˆ'
            },
            
            # åˆ›æ–°ç›´è§‰å‹ç­–ç•¥ç‰¹å¾
            'creative_innovative': {
                'primary_tools': [],  # ä¸»è¦ä¾é LLMåˆ›æ„ï¼Œå°‘ç”¨å·¥å…·
                'secondary_tools': ['web_search'],
                'execution_pattern': 'creative_direct',
                'confidence_threshold': 0.9,  # é«˜ç½®ä¿¡åº¦æ‰ä½¿ç”¨å·¥å…·
                'description': 'åˆ›é€ æ€§æ€ç»´ã€çªç ´å¸¸è§„'
            },
            
            # ç»¼åˆå…¨é¢å‹ç­–ç•¥ç‰¹å¾
            'holistic_comprehensive': {
                'primary_tools': ['web_search', 'knowledge_query', 'data_analysis'],
                'secondary_tools': ['idea_verification'],
                'execution_pattern': 'comprehensive',
                'confidence_threshold': 0.6,
                'description': 'æ•´ä½“è€ƒè™‘ã€å…¨å±€æ€ç»´'
            },
            
            # ğŸš¨ æ–°å¢ï¼šåˆ›æ–°ç»•é“æ€è€ƒç­–ç•¥ç‰¹å¾
            'åˆ›æ–°ç»•é“æ€è€ƒ': {
                'primary_tools': [],  # ä¸»è¦ä¾é ç›´æ¥å›ç­”ï¼Œé¿å…è¿‡åº¦å·¥å…·åŒ–
                'secondary_tools': ['knowledge_query'],
                'execution_pattern': 'direct_creative',  # åˆ›æ–°ç›´æ¥å›ç­”æ¨¡å¼
                'confidence_threshold': 0.3,  # ä½é˜ˆå€¼ï¼Œä¼˜å…ˆç›´æ¥å›ç­”
                'description': 'çªç ´å¸¸è§„ï¼Œåˆ›æ–°æ€ç»´å›ç­”'
            },
            
            # è‡ªé€‚åº”çµæ´»å‹ç­–ç•¥ç‰¹å¾
            'adaptive_flexible': {
                'primary_tools': [],  # æ ¹æ®æƒ…å†µçµæ´»é€‰æ‹©
                'secondary_tools': ['knowledge_query', 'web_search'],
                'execution_pattern': 'adaptive_direct',
                'confidence_threshold': 0.4,
                'description': 'çµæ´»é€‚åº”ã€å› æƒ…è€Œå˜'
            },
            
            # ğŸ¨ æ–°å¢ï¼šè§†è§‰åˆ›æ„å‹ç­–ç•¥ç‰¹å¾
            'creative_visual': {
                'primary_tools': ['image_generation', 'stable_diffusion_xl_generator'],
                'secondary_tools': ['knowledge_query', 'web_search'],
                'execution_pattern': 'visual_creation',
                'confidence_threshold': 0.8,  # é«˜ç½®ä¿¡åº¦ç¡®ä¿è§†è§‰éœ€æ±‚æ˜ç¡®
                'description': 'è§†è§‰åˆ›ä½œã€å›¾åƒç”Ÿæˆã€è‰ºæœ¯åˆ›æ„',
                'visual_context': {
                    'primary_purpose': 'creation',
                    'output_types': ['image', 'illustration', 'design'],
                    'style_considerations': True
                }
            },
            
            # ğŸ–¼ï¸ æ–°å¢ï¼šè®¾è®¡å¯¼å‘å‹ç­–ç•¥ç‰¹å¾
            'design_oriented': {
                'primary_tools': ['image_generation', 'stable_diffusion_xl_generator'],
                'secondary_tools': ['web_search', 'knowledge_query'],
                'execution_pattern': 'iterative_design',
                'confidence_threshold': 0.7,
                'description': 'ä¸“ä¸šè®¾è®¡ã€ç•Œé¢åŸå‹ã€å“ç‰Œè§†è§‰',
                'visual_context': {
                    'primary_purpose': 'professional_design',
                    'output_types': ['logo', 'ui_mockup', 'brand_design', 'poster'],
                    'style_considerations': True,
                    'brand_awareness': True
                }
            },
            
            # ğŸ” æ–°å¢ï¼šæ¦‚å¿µå¯è§†åŒ–ç­–ç•¥ç‰¹å¾
            'conceptual_visualization': {
                'primary_tools': ['image_generation'],
                'secondary_tools': ['knowledge_query'],
                'execution_pattern': 'concept_illustration',
                'confidence_threshold': 0.6,
                'description': 'æ¦‚å¿µè§£é‡Šã€æƒ³è±¡æç»˜ã€åœºæ™¯å±•ç¤º',
                'visual_context': {
                    'primary_purpose': 'conceptualization',
                    'output_types': ['conceptual_art', 'scene_illustration', 'explanatory_visual'],
                    'educational_value': True
                }
            }
        }
        
        # æŸ¥è¯¢ä¸Šä¸‹æ–‡åˆ†æå™¨
        self.context_analyzers = {
            'domain_specific': self._analyze_domain_context,
            'urgency_level': self._analyze_urgency_context,
            'complexity_level': self._analyze_complexity_context,
            'visual_needs': self._analyze_visual_needs_context,  # ğŸ¨ å¼ƒç”¨ï¼šè§†è§‰éœ€æ±‚åˆ†æï¼ˆä¿æŒå…¼å®¹ï¼‰
            'visual_intelligence': self._perform_visual_intelligence_decision,  # ğŸ¨ æ–°å¢ï¼šè§†è§‰æ™ºèƒ½å†³ç­–
            'output_format': self._analyze_output_format_context, # ğŸ“Š æ–°å¢ï¼šè¾“å‡ºæ ¼å¼åˆ†æ
        }
        
        # ğŸ” åˆå§‹åŒ–SemanticAnalyzerå®ä¾‹ï¼ˆç”¨äºè§†è§‰éœ€æ±‚åˆ†æï¼‰
        self.semantic_analyzer = None
        try:
            from ..cognitive_engine.semantic_analyzer import create_semantic_analyzer
            self.semantic_analyzer = create_semantic_analyzer()
            logger.info("ğŸ” StrategyInterpreter å·²é›†æˆSemanticAnalyzer")
        except ImportError as e:
            logger.warning(f"âš ï¸ SemanticAnalyzerä¸å¯ç”¨ï¼Œä½¿ç”¨é™çº§åˆ†æï¼š {e}")
        except Exception as e:
            logger.warning(f"âš ï¸ SemanticAnalyzeråˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨é™çº§åˆ†æï¼š {e}")
        
        logger.info("ğŸ§  ç­–ç•¥è§£é‡Šå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def interpret_strategy_to_actions(self, chosen_path, query: str, 
                                    mab_confidence: float, decision_context: Dict) -> List:
        """
        æ ¸å¿ƒæ–¹æ³•ï¼šå°†é€‰ä¸­çš„æ€ç»´è·¯å¾„ç­–ç•¥è§£é‡Šä¸ºå…·ä½“çš„å·¥å…·è°ƒç”¨è¡ŒåŠ¨
        
        Args:
            chosen_path: MABé€‰ä¸­çš„æœ€ä¼˜æ€ç»´è·¯å¾„
            query: åŸå§‹ç”¨æˆ·æŸ¥è¯¢
            mab_confidence: MABå¯¹è¿™ä¸ªé€‰æ‹©çš„ç½®ä¿¡åº¦
            decision_context: å†³ç­–ä¸Šä¸‹æ–‡
            
        Returns:
            å…·ä½“çš„Actionåˆ—è¡¨
        """
        logger.info(f"ğŸ¯ å¼€å§‹ç­–ç•¥è§£é‡Š: {chosen_path.path_type}")
        logger.info(f"   MABç½®ä¿¡åº¦: {mab_confidence:.2f}")
        
        # 1. è·å–ç­–ç•¥ç‰¹å¾
        strategy_features = self._extract_strategy_features(chosen_path)
        
        # 2. åˆ†ææŸ¥è¯¢ä¸Šä¸‹æ–‡
        query_context = self._analyze_query_context(query, decision_context)
        
        # 3. ç­–ç•¥é€‚é…å†³ç­–
        action_strategy = self._decide_action_strategy(
            strategy_features, query_context, mab_confidence
        )
        
        # 4. ç”Ÿæˆå…·ä½“è¡ŒåŠ¨
        actions = self._generate_concrete_actions(
            action_strategy, chosen_path, query, query_context
        )
        
        logger.info(f"âœ… ç­–ç•¥è§£é‡Šå®Œæˆ: ç”Ÿæˆ {len(actions)} ä¸ªè¡ŒåŠ¨")
        return actions
    
    def _extract_strategy_features(self, chosen_path) -> Dict[str, Any]:
        """æå–æ€ç»´è·¯å¾„çš„ç­–ç•¥ç‰¹å¾"""
        path_type = chosen_path.path_type.lower()
        
        # ä»æ˜ å°„è¡¨è·å–ç­–ç•¥ç‰¹å¾
        if path_type in self.strategy_feature_mappings:
            base_features = self.strategy_feature_mappings[path_type].copy()
        else:
            # æœªçŸ¥ç­–ç•¥ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤ç‰¹å¾
            logger.warning(f"âš ï¸ æœªçŸ¥ç­–ç•¥ç±»å‹: {path_type}ï¼Œä½¿ç”¨é»˜è®¤ç‰¹å¾")
            base_features = self.strategy_feature_mappings['practical_pragmatic'].copy()
        
        # å¢å¼ºç‰¹å¾ï¼šåˆ†æè·¯å¾„æè¿°ä¸­çš„è¯­ä¹‰ä¿¡æ¯
        description_features = self._analyze_path_description(chosen_path.description)
        base_features.update(description_features)
        
        # å¢å¼ºç‰¹å¾ï¼šä»prompt_templateä¸­æå–æ‰§è¡Œæç¤º
        template_features = self._analyze_prompt_template(getattr(chosen_path, 'prompt_template', ''))
        base_features.update(template_features)
        
        return base_features
    
    def _analyze_path_description(self, description: str) -> Dict[str, Any]:
        """åˆ†æè·¯å¾„æè¿°ä¸­çš„è¯­ä¹‰ç‰¹å¾"""
        features = {}
        description_lower = description.lower() if description else ""
        
        # ä¿¡æ¯æ”¶é›†å€¾å‘åˆ†æ
        if any(word in description_lower for word in ['æœç´¢', 'è°ƒç ”', 'æ¢ç´¢', 'æ”¶é›†', 'æŸ¥æ‰¾']):
            features['requires_information_gathering'] = True
            features['information_depth'] = 'deep' if 'æ·±å…¥' in description_lower else 'surface'
        
        # éªŒè¯éœ€æ±‚åˆ†æ
        if any(word in description_lower for word in ['éªŒè¯', 'ç¡®è®¤', 'æ£€æŸ¥', 'å®¡æŸ¥', 'è´¨ç–‘']):
            features['requires_verification'] = True
            features['verification_strictness'] = 'high' if 'ä¸¥æ ¼' in description_lower else 'moderate'
        
        # åˆ›æ–°éœ€æ±‚åˆ†æ
        if any(word in description_lower for word in ['åˆ›æ–°', 'åˆ›æ„', 'çªç ´', 'æ–°é¢–']):
            features['innovation_focus'] = True
            features['tool_dependency'] = 'low'  # åˆ›æ–°å‹è·¯å¾„è¾ƒå°‘ä¾èµ–å·¥å…·
        
        return features
    
    def _analyze_prompt_template(self, prompt_template: str) -> Dict[str, Any]:
        """åˆ†ææç¤ºæ¨¡æ¿ä¸­çš„æ‰§è¡ŒæŒ‡ç¤º"""
        features = {}
        template_lower = prompt_template.lower() if prompt_template else ""
        
        # åˆ†ææ¨¡æ¿ä¸­çš„å·¥å…·ä½¿ç”¨æš—ç¤º
        if 'æœç´¢' in template_lower or 'search' in template_lower:
            features['template_suggests_search'] = True
        
        if 'åˆ†æ' in template_lower or 'analyze' in template_lower:
            features['template_suggests_analysis'] = True
            
        if 'éªŒè¯' in template_lower or 'verify' in template_lower:
            features['template_suggests_verification'] = True
        
        return features
    
    # ==================== ğŸ¨ è§†è§‰æ™ºèƒ½å†³ç­–ç³»ç»Ÿ ====================
    
    def _perform_visual_intelligence_decision(self, query: str, context: Dict) -> Dict[str, Any]:
        """
        ğŸ¨ æ‰§è¡Œè§†è§‰æ™ºèƒ½å†³ç­– - ä»"åˆ¤æ–­éœ€æ±‚"å‡çº§ä¸º"è¯„ä¼°æœºä¼š"
        
        è¿™æ˜¯ç­–ç•¥è§£é‡Šå™¨çš„æ ¸å¿ƒå‡çº§ï¼šä¸å†ç®€å•æ‰§è¡Œï¼Œè€Œæ˜¯æ™ºèƒ½å†³ç­–ã€‚
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: å†³ç­–ä¸Šä¸‹æ–‡
            
        Returns:
            Dict: ç»¼åˆçš„è§†è§‰å†³ç­–æŠ¥å‘Š
        """
        logger.info(f"ğŸ¨ å¯åŠ¨è§†è§‰æ™ºèƒ½å†³ç­–ç³»ç»Ÿ: {query[:50]}...")
        
        try:
            # é˜¶æ®µ1ï¼šè¯„ä¼°è§†è§‰å¢å¼ºæœºä¼š
            opportunity_assessment = self._assess_visual_enhancement_opportunity(query, context)
            
            # é˜¶æ®µ2ï¼šé£é™©è¯„ä¼°
            risk_assessment = self._assess_visual_generation_risks(opportunity_assessment, context)
            
            # é˜¶æ®µ3ï¼šæœºä¼šè¯„åˆ†
            opportunity_score = self._score_visual_opportunity(opportunity_assessment, risk_assessment)
            
            # é˜¶æ®µ4ï¼šæœ€ç»ˆå†³ç­–
            final_decision = self._make_final_visual_decision(
                opportunity_assessment, risk_assessment, opportunity_score, context
            )
            
            logger.info(
                f"âœ… è§†è§‰æ™ºèƒ½å†³ç­–å®Œæˆ: {final_decision['should_generate']} "
                f"(æœºä¼šå¼ºåº¦: {opportunity_score:.2f}, å†³ç­–ç½®ä¿¡åº¦: {final_decision['decision_confidence']:.2f})"
            )
            
            return final_decision
            
        except Exception as e:
            logger.error(f"âŒ è§†è§‰æ™ºèƒ½å†³ç­–å¼‚å¸¸: {e}")
            # å®‰å…¨é™çº§ï¼šè¿”å›ä¿å®ˆå†³ç­–
            return self._create_safe_fallback_decision(query, str(e))
    
    def _assess_visual_enhancement_opportunity(self, query: str, context: Dict) -> Dict[str, Any]:
        """ğŸ” è¯„ä¼°è§†è§‰å¢å¼ºæœºä¼š"""
        if not self.semantic_analyzer:
            logger.warning("âš ï¸ SemanticAnalyzerä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–æœºä¼šè¯„ä¼°")
            return self._simple_opportunity_assessment(query)
        
        try:
            # ä½¿ç”¨æ–°çš„è§†è§‰å¢å¼ºæœºä¼šè¯„ä¼°ä»»åŠ¡
            response = self.semantic_analyzer.analyze(
                text=query,
                tasks=[
                    'visual_enhancement_opportunity',
                    'interaction_context_analysis',
                    'aesthetic_preference_inference'
                ]
            )
            
            if not response.overall_success:
                logger.warning("âš ï¸ è¯­ä¹‰åˆ†æå¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–è¯„ä¼°")
                return self._simple_opportunity_assessment(query)
            
            # æå–åˆ†æç»“æœ
            opportunity_result = response.analysis_results.get('visual_enhancement_opportunity')
            context_result = response.analysis_results.get('interaction_context_analysis')
            aesthetic_result = response.analysis_results.get('aesthetic_preference_inference')
            
            # æ„å»ºç»¼åˆæœºä¼šè¯„ä¼°
            assessment = {
                'has_opportunity': False,
                'opportunity_strength': 0.0,
                'opportunity_type': 'none',
                'analysis_quality': 'failed'
            }
            
            if opportunity_result and opportunity_result.success:
                opp_data = opportunity_result.result
                assessment.update({
                    'has_opportunity': opp_data.get('has_visual_opportunity', False),
                    'opportunity_strength': opp_data.get('opportunity_strength', 0.0),
                    'opportunity_type': opp_data.get('opportunity_type', 'none'),
                    'context_analysis': opp_data.get('context_analysis', {}),
                    'visual_recommendations': opp_data.get('visual_recommendations', {}),
                    'timing_assessment': opp_data.get('timing_assessment', {}),
                    'personalization': opp_data.get('personalization', {}),
                    'analysis_quality': 'high',
                    'analysis_confidence': opportunity_result.confidence
                })
            
            # æ•´åˆæƒ…å¢ƒåˆ†æ
            if context_result and context_result.success:
                assessment['interaction_context'] = context_result.result
            
            # æ•´åˆå®¡ç¾åå¥½
            if aesthetic_result and aesthetic_result.success:
                assessment['aesthetic_preferences'] = aesthetic_result.result
            
            logger.debug(f"ğŸ” æœºä¼šè¯„ä¼°å®Œæˆ: {assessment['opportunity_type']}, å¼ºåº¦={assessment['opportunity_strength']:.2f}")
            return assessment
            
        except Exception as e:
            logger.error(f"âŒ æœºä¼šè¯„ä¼°å¼‚å¸¸: {e}")
            return self._simple_opportunity_assessment(query)
    
    def _assess_visual_generation_risks(self, opportunity: Dict[str, Any], context: Dict) -> Dict[str, Any]:
        """âš ï¸ è¯„ä¼°è§†è§‰ç”Ÿæˆçš„é£é™©"""
        risks = {
            'overall_risk_level': 'low',
            'risk_score': 0.0,
            'risk_factors': [],
            'mitigation_suggestions': []
        }
        
        risk_score = 0.0
        
        # é£é™©å› å­—1ï¼šæ—¶æœºä¸åˆé€‚
        timing = opportunity.get('timing_assessment', {})
        if timing.get('generation_timing') == 'not_recommended':
            risks['risk_factors'].append('ç”Ÿæˆæ—¶æœºä¸åˆé€‚')
            risk_score += 0.3
        elif timing.get('context_appropriateness', 1.0) < 0.5:
            risks['risk_factors'].append('æƒ…å¢ƒé€‚å®œåº¦è¾ƒä½')
            risk_score += 0.2
        
        # é£é™©å› å­—2ï¼šç”¨æˆ·å‡†å¤‡åº¦ä¸è¶³
        if timing.get('user_readiness', 1.0) < 0.4:
            risks['risk_factors'].append('ç”¨æˆ·å‡†å¤‡åº¦ä¸è¶³')
            risk_score += 0.25
        
        # é£é™©å› å­—3ï¼šä½æœºä¼šå¼ºåº¦
        if opportunity.get('opportunity_strength', 0) < 0.3:
            risks['risk_factors'].append('è§†è§‰å¢å¼ºæœºä¼šå¼±')
            risk_score += 0.35
        
        # é£é™©å› å­—4ï¼šæƒ…ç»ªä¸åŒ¹é…
        context_analysis = opportunity.get('context_analysis', {})
        if context_analysis.get('user_emotional_state') in ['frustrated', 'angry', 'overwhelmed']:
            risks['risk_factors'].append('ç”¨æˆ·æƒ…ç»ªçŠ¶æ€ä¸é€‚å®œ')
            risk_score += 0.4
        
        # é£é™©å› å­—5ï¼šå¤æ‚åº¦è¿‡é«˜
        if context_analysis.get('content_complexity') == 'very_high':
            risks['risk_factors'].append('å†…å®¹å¤æ‚åº¦è¿‡é«˜ï¼Œå¯èƒ½å¹²æ‰°ç†è§£')
            risk_score += 0.15
        
        # é£é™©çº§åˆ«è¯„å®š
        if risk_score >= 0.7:
            risks['overall_risk_level'] = 'high'
        elif risk_score >= 0.4:
            risks['overall_risk_level'] = 'medium'
        else:
            risks['overall_risk_level'] = 'low'
        
        risks['risk_score'] = min(risk_score, 1.0)
        
        # ç”Ÿæˆé£é™©ç¼“è§£å»ºè®®
        if risks['risk_factors']:
            risks['mitigation_suggestions'] = self._generate_risk_mitigation_suggestions(
                risks['risk_factors'], opportunity
            )
        
        logger.debug(f"âš ï¸ é£é™©è¯„ä¼°: {risks['overall_risk_level']} (åˆ†æ•°: {risk_score:.2f})")
        return risks
    
    def _score_visual_opportunity(self, opportunity: Dict[str, Any], risks: Dict[str, Any]) -> float:
        """ğŸ¯ è¯„åˆ†è§†è§‰æœºä¼š - ç»¼åˆæœºä¼šå’Œé£é™©"""
        base_score = opportunity.get('opportunity_strength', 0.0)
        risk_penalty = risks.get('risk_score', 0.0)
        
        # åŸºç¡€æœºä¼šåˆ†æ•°
        opportunity_score = base_score
        
        # é£é™©æƒ©ç½š
        opportunity_score *= (1.0 - risk_penalty * 0.5)  # é£é™©æœ€å¤šå‡åŠåˆ†
        
        # æƒ…å¢ƒåŠ åˆ†
        timing = opportunity.get('timing_assessment', {})
        if timing.get('generation_timing') == 'immediate':
            opportunity_score *= 1.2  # ç«‹å³ç”ŸæˆåŠ åˆ†
        elif timing.get('generation_timing') == 'contextually_appropriate':
            opportunity_score *= 1.1  # é€‚å®œæ—¶æœºåŠ åˆ†
        
        # å®¡ç¾åŒ¹é…åŠ åˆ†
        aesthetic = opportunity.get('aesthetic_preferences', {})
        if aesthetic.get('confidence_metrics', {}).get('preference_certainty', 0) > 0.7:
            opportunity_score *= 1.15  # å®¡ç¾åå¥½æ¸…æ™°åŠ åˆ†
        
        final_score = max(0.0, min(1.0, opportunity_score))  # é™åˆ¶åœ¨ 0-1 èŒƒå›´
        
        logger.debug(f"ğŸ¯ æœºä¼šè¯„åˆ†: {base_score:.2f} -> {final_score:.2f} (é£é™©æƒ©ç½š: {risk_penalty:.2f})")
        return final_score
    
    def _make_final_visual_decision(self, opportunity: Dict, risks: Dict, score: float, context: Dict) -> Dict[str, Any]:
        """ğŸ¯ åšå‡ºæœ€ç»ˆçš„è§†è§‰å†³ç­–"""
        
        # å†³ç­–é˜ˆå€¼ - å¯æ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´
        decision_threshold = self._calculate_decision_threshold(opportunity, context)
        
        should_generate = score >= decision_threshold
        
        # ç‰¹æ®Šæƒ…å†µå¤„ç†
        if risks.get('overall_risk_level') == 'high':
            should_generate = False
            decision_reason = f"é£é™©è¿‡é«˜ ({', '.join(risks.get('risk_factors', [])[:2])})"
        elif not opportunity.get('has_opportunity', False):
            should_generate = False
            decision_reason = "æ— æ˜æ˜¾çš„è§†è§‰å¢å¼ºæœºä¼š"
        elif should_generate:
            decision_reason = f"æœºä¼šè¯„åˆ† {score:.2f} è¶…è¿‡é˜ˆå€¼ {decision_threshold:.2f}"
        else:
            decision_reason = f"æœºä¼šè¯„åˆ† {score:.2f} ä½äºé˜ˆå€¼ {decision_threshold:.2f}"
        
        # æ„å»ºå†³ç­–æŠ¥å‘Š
        decision = {
            'should_generate': should_generate,
            'decision_confidence': self._calculate_decision_confidence(score, risks, opportunity),
            'decision_reason': decision_reason,
            'opportunity_score': score,
            'decision_threshold': decision_threshold,
            'risk_level': risks.get('overall_risk_level', 'unknown'),
            
            # ç”Ÿæˆå»ºè®®
            'recommended_visual_type': opportunity.get('visual_recommendations', {}).get('primary_visual_type', 'unknown'),
            'style_suggestions': opportunity.get('visual_recommendations', {}).get('style_suggestions', []),
            'generation_timing': opportunity.get('timing_assessment', {}).get('generation_timing', 'immediate'),
            'generation_purpose': opportunity.get('opportunity_type', 'unknown'),
            'suggested_elements': opportunity.get('personalization', {}).get('suggested_elements', []),
            
            # è°ƒè¯•ä¿¡æ¯
            'debug_info': {
                'opportunity_assessment': opportunity,
                'risk_assessment': risks,
                'decision_process': 'visual_intelligence_v2'
            }
        }
        
        return decision
    
    # ==================== ğŸ› ï¸ è¾…åŠ©å†³ç­–æ–¹æ³• ====================
    
    def _calculate_decision_threshold(self, opportunity: Dict, context: Dict) -> float:
        """ğŸ¯ è®¡ç®—å†³ç­–é˜ˆå€¼ - åŸºäºæƒ…å¢ƒåŠ¨æ€è°ƒæ•´"""
        base_threshold = 0.6  # é»˜è®¤é˜ˆå€¼
        
        # æ ¹æ®äº¤äº’é˜¶æ®µè°ƒæ•´
        interaction_phase = opportunity.get('context_analysis', {}).get('interaction_phase', '')
        if interaction_phase == 'creative_brainstorming':
            base_threshold -= 0.1  # åˆ›æ„é˜¶æ®µé™ä½é˜ˆå€¼
        elif interaction_phase == 'problem_solving':
            base_threshold += 0.1  # é—®é¢˜è§£å†³é˜¶æ®µæé«˜é˜ˆå€¼
        
        # æ ¹æ®ç”¨æˆ·æƒ…ç»ªè°ƒæ•´
        emotional_state = opportunity.get('context_analysis', {}).get('user_emotional_state', '')
        if emotional_state in ['excited', 'inspired', 'curious']:
            base_threshold -= 0.05  # ç§¯ææƒ…ç»ªé™ä½é˜ˆå€¼
        elif emotional_state in ['frustrated', 'overwhelmed']:
            base_threshold += 0.15  # æ¶ˆææƒ…ç»ªæé«˜é˜ˆå€¼
        
        # æ ¹æ®æœºä¼šç±»å‹è°ƒæ•´
        opportunity_type = opportunity.get('opportunity_type', '')
        if opportunity_type == 'explicit_request':
            base_threshold = 0.3  # æ˜ç¡®è¯·æ±‚æ˜¾è‘—é™ä½é˜ˆå€¼
        elif opportunity_type == 'emotional_resonance':
            base_threshold -= 0.1  # æƒ…æ„Ÿå…±é¸£é€‚åº¦é™ä½é˜ˆå€¼
        
        return max(0.2, min(0.9, base_threshold))  # é™åˆ¶åœ¨åˆç†èŒƒå›´
    
    def _calculate_decision_confidence(self, score: float, risks: Dict, opportunity: Dict) -> float:
        """ğŸ¯ è®¡ç®—å†³ç­–ç½®ä¿¡åº¦"""
        # åŸºç¡€ç½®ä¿¡åº¦åŸºäºåˆ†æ•°
        base_confidence = score
        
        # åˆ†æè´¨é‡å½±å“
        analysis_quality = opportunity.get('analysis_quality', 'low')
        if analysis_quality == 'high':
            base_confidence *= 1.1
        elif analysis_quality == 'low':
            base_confidence *= 0.8
        
        # é£é™©çº§åˆ«å½±å“
        risk_level = risks.get('overall_risk_level', 'medium')
        if risk_level == 'low':
            base_confidence *= 1.05
        elif risk_level == 'high':
            base_confidence *= 0.7
        
        # è¯­ä¹‰åˆ†æç½®ä¿¡åº¦å½±å“
        analysis_confidence = opportunity.get('analysis_confidence', 0.5)
        base_confidence = (base_confidence + analysis_confidence) / 2
        
        return max(0.1, min(0.95, base_confidence))
    
    def _simple_opportunity_assessment(self, query: str) -> Dict[str, Any]:
        """ğŸ”„ ç®€åŒ–çš„æœºä¼šè¯„ä¼° - å½“SemanticAnalyzerä¸å¯ç”¨æ—¶çš„é™çº§æ–¹æ¡ˆ"""
        logger.info("ğŸ”„ ä½¿ç”¨ç®€åŒ–æœºä¼šè¯„ä¼°")
        
        # åŸºäºå…³é”®è¯çš„ç®€å•åˆ¤æ–­
        explicit_keywords = ['ç”»', 'å›¾', 'è®¾è®¡', 'ç”Ÿæˆå›¾ç‰‡', 'åˆ¶ä½œ', 'ç»˜åˆ¶', 'æ¸²æŸ“', 'logo', 'æ•ˆæœå›¾']
        implicit_keywords = ['ç†è§£', 'è§£é‡Š', 'å·¥ä½œåŸç†', 'ç»“æ„', 'æ¶æ„', 'æµç¨‹', 'æ¼”ç¤º']
        creative_keywords = ['åˆ›æ„', 'çµæ„Ÿ', 'æƒ³è±¡', 'è®¾è®¡ç†å¿µ', 'å“ç‰Œ', 'è§†è§‰']
        
        query_lower = query.lower()
        
        # æ˜¾å¼è¯·æ±‚
        if any(keyword in query_lower for keyword in explicit_keywords):
            return {
                'has_opportunity': True,
                'opportunity_strength': 0.8,
                'opportunity_type': 'explicit_request',
                'analysis_quality': 'simple',
                'timing_assessment': {'generation_timing': 'immediate', 'context_appropriateness': 0.8}
            }
        
        # éšå«éœ€æ±‚æ–½æ•™è‚²
        elif any(keyword in query_lower for keyword in implicit_keywords):
            return {
                'has_opportunity': True,
                'opportunity_strength': 0.6,
                'opportunity_type': 'educational_support',
                'analysis_quality': 'simple',
                'timing_assessment': {'generation_timing': 'after_text_response', 'context_appropriateness': 0.7}
            }
        
        # åˆ›æ„æ¿€å‘
        elif any(keyword in query_lower for keyword in creative_keywords):
            return {
                'has_opportunity': True,
                'opportunity_strength': 0.7,
                'opportunity_type': 'creative_inspiration',
                'analysis_quality': 'simple',
                'timing_assessment': {'generation_timing': 'contextually_appropriate', 'context_appropriateness': 0.75}
            }
        
        # é»˜è®¤ä½æœºä¼š
        else:
            return {
                'has_opportunity': False,
                'opportunity_strength': 0.2,
                'opportunity_type': 'minimal_visual_opportunity',
                'analysis_quality': 'simple',
                'timing_assessment': {'generation_timing': 'not_recommended', 'context_appropriateness': 0.3}
            }
    
    def _generate_risk_mitigation_suggestions(self, risk_factors: List[str], opportunity: Dict) -> List[str]:
        """ğŸ›¡ï¸ ç”Ÿæˆé£é™©ç¼“è§£å»ºè®®"""
        suggestions = []
        
        if 'ç”Ÿæˆæ—¶æœºä¸åˆé€‚' in risk_factors:
            suggestions.append('å»ºè®®åœ¨æ–‡æœ¬å›ç­”åæä¾›è§†è§‰è¡¥å……')
        
        if 'ç”¨æˆ·å‡†å¤‡åº¦ä¸è¶³' in risk_factors:
            suggestions.append('å¯å…ˆè¯¢é—®ç”¨æˆ·æ˜¯å¦éœ€è¦è§†è§‰è¾…åŠ©')
        
        if 'è§†è§‰å¢å¼ºæœºä¼šå¼±' in risk_factors:
            suggestions.append('ä¼˜å…ˆæä¾›æ–‡æœ¬è§£ç­”ï¼Œè¡¥å……è§†è§‰å…ƒç´ ')
        
        if 'ç”¨æˆ·æƒ…ç»ªçŠ¶æ€ä¸é€‚å®œ' in risk_factors:
            suggestions.append('å…ˆå¤„ç†æƒ…ç»ªé—®é¢˜ï¼Œåè€ƒè™‘è§†è§‰å†…å®¹')
        
        return suggestions
    
    def _create_safe_fallback_decision(self, query: str, error: str) -> Dict[str, Any]:
        """ğŸ”„ åˆ›å»ºå®‰å…¨çš„é™çº§å†³ç­–"""
        logger.warning(f"ğŸ”„ ä½¿ç”¨å®‰å…¨é™çº§å†³ç­–: {error}")
        
        return {
            'should_generate': False,
            'decision_confidence': 0.3,
            'decision_reason': f'ç³»ç»Ÿå¼‚å¸¸ï¼Œé‡‡ç”¨ä¿å®ˆç­–ç•¥: {error}',
            'opportunity_score': 0.0,
            'risk_level': 'unknown',
            'recommended_visual_type': 'none',
            'generation_timing': 'not_recommended',
            'debug_info': {'fallback_reason': error}
        }
    
    def _create_intelligent_image_generation_action(self, query: str, visual_decision: Dict, context: Dict):
        """ğŸ¨ åˆ›å»ºæ™ºèƒ½çš„å›¾åƒç”Ÿæˆè¡ŒåŠ¨ - å‡çº§ç‰ˆæœ¬"""
        try:
            from neogenesis_system.abstractions import Action
        except ImportError:
            class Action:
                def __init__(self, tool_name, tool_input):
                    self.tool_name = tool_name
                    self.tool_input = tool_input
        
        # åŸºäºæ™ºèƒ½å†³ç­–ç”Ÿæˆä¼˜åŒ–çš„æç¤ºè¯
        prompt = self._generate_intelligent_image_prompt(query, visual_decision, context)
        
        # æ„å»ºæ™ºèƒ½å·¥å…·è¾“å…¥
        tool_input = {
            "prompt": prompt,
            "save_image": True,
            "style_hint": self._extract_intelligent_style_hint(visual_decision),
            "generation_context": {
                "opportunity_type": visual_decision.get('generation_purpose', 'unknown'),
                "timing": visual_decision.get('generation_timing', 'immediate'),
                "confidence": visual_decision.get('decision_confidence', 0.5),
                "visual_type": visual_decision.get('recommended_visual_type', 'unknown')
            }
        }
        
        logger.info(
            f"ğŸ¨ åˆ›å»ºæ™ºèƒ½å›¾åƒç”Ÿæˆè¡ŒåŠ¨: {visual_decision['generation_purpose']} "
            f"(ç½®ä¿¡åº¦: {visual_decision['decision_confidence']:.2f})"
        )
        
        return Action('stable_diffusion_xl_generator', tool_input)
    
    def _generate_intelligent_image_prompt(self, query: str, visual_decision: Dict, context: Dict) -> str:
        """ğŸ¨ ç”Ÿæˆæ™ºèƒ½åŒ–çš„å›¾åƒæç¤ºè¯"""
        base_prompt = query.strip()
        
        # æ ¹æ®è§†è§‰ç±»å‹ä¼˜åŒ–
        visual_type = visual_decision.get('recommended_visual_type', 'unknown')
        style_suggestions = visual_decision.get('style_suggestions', [])
        suggested_elements = visual_decision.get('suggested_elements', [])
        
        # æ ¹æ®æœºä¼šç±»å‹ä¼˜åŒ–æç¤ºè¯
        opportunity_type = visual_decision.get('generation_purpose', 'unknown')
        
        if opportunity_type == 'explicit_request':
            # æ˜ç¡®è¯·æ±‚ï¼Œä¿æŒåŸå§‹æ„å›¾
            optimized_prompt = base_prompt
        elif opportunity_type == 'educational_support':
            # æ•™è‚²æ”¯æŒï¼Œæ·»åŠ æ¸…æ™°çš„è§£é‡Šæ€§å…ƒç´ 
            optimized_prompt = f"{base_prompt}, clear educational diagram, informative illustration, step-by-step visual"
        elif opportunity_type == 'creative_inspiration':
            # åˆ›æ„æ¿€å‘ï¼Œæ·»åŠ åˆ›æ–°å…ƒç´ 
            optimized_prompt = f"{base_prompt}, creative concept art, innovative design, inspirational visual"
        elif opportunity_type == 'emotional_resonance':
            # æƒ…æ„Ÿå…±é¸£ï¼Œæ·»åŠ æ¸©æš–å…ƒç´ 
            optimized_prompt = f"{base_prompt}, calming and soothing, emotional connection, peaceful atmosphere"
        else:
            optimized_prompt = f"{base_prompt}, high quality, detailed"
        
        # æ·»åŠ é£æ ¼å»ºè®®
        if style_suggestions:
            style_text = ', '.join(style_suggestions[:3])
            optimized_prompt += f", {style_text}"
        
        # æ·»åŠ å»ºè®®å…ƒç´ 
        if suggested_elements:
            elements_text = ', '.join(suggested_elements[:2])
            optimized_prompt += f", featuring {elements_text}"
        
        return optimized_prompt
    
    def _extract_intelligent_style_hint(self, visual_decision: Dict) -> str:
        """ğŸ¨ æå–æ™ºèƒ½åŒ–çš„é£æ ¼æç¤º"""
        style_suggestions = visual_decision.get('style_suggestions', [])
        if style_suggestions:
            return ', '.join(style_suggestions[:2])
        
        # é»˜è®¤é£æ ¼åŸºäºæœºä¼šç±»å‹
        opportunity_type = visual_decision.get('generation_purpose', 'unknown')
        style_mapping = {
            'explicit_request': 'high quality, detailed',
            'educational_support': 'clear, informative, structured',
            'creative_inspiration': 'creative, innovative, artistic',
            'emotional_resonance': 'calm, soothing, warm'
        }
        
        return style_mapping.get(opportunity_type, 'professional, clean')
    
    def _analyze_query_context(self, query: str, decision_context: Dict) -> Dict[str, Any]:
        """ç»¼åˆåˆ†ææŸ¥è¯¢ä¸Šä¸‹æ–‡"""
        context = {}
        
        # åº”ç”¨æ‰€æœ‰ä¸Šä¸‹æ–‡åˆ†æå™¨
        for analyzer_name, analyzer_func in self.context_analyzers.items():
            try:
                context[analyzer_name] = analyzer_func(query, decision_context)
            except Exception as e:
                logger.warning(f"âš ï¸ ä¸Šä¸‹æ–‡åˆ†æå™¨ {analyzer_name} å¤±è´¥: {e}")
                context[analyzer_name] = {}
        
        return context
    
    def _analyze_domain_context(self, query: str, context: Dict) -> Dict[str, Any]:
        """åˆ†æé¢†åŸŸä¸Šä¸‹æ–‡"""
        query_lower = query.lower()
        
        domain_indicators = {
            'technical': ['æŠ€æœ¯', 'ç¼–ç¨‹', 'ä»£ç ', 'ç®—æ³•', 'ç³»ç»Ÿ', 'python', 'java'],
            'business': ['å•†ä¸š', 'å•†åŠ¡', 'å¸‚åœº', 'è¥é”€', 'é”€å”®', 'ç®¡ç†'],
            'academic': ['å­¦æœ¯', 'ç ”ç©¶', 'è®ºæ–‡', 'ç†è®º', 'åˆ†æ'],
            'general': []  # é»˜è®¤
        }
        
        for domain, keywords in domain_indicators.items():
            if any(keyword in query_lower for keyword in keywords):
                return {'domain': domain, 'specificity': 'high'}
        
        return {'domain': 'general', 'specificity': 'low'}
    
    def _analyze_urgency_context(self, query: str, context: Dict) -> Dict[str, Any]:
        """åˆ†æç´§æ€¥ç¨‹åº¦ä¸Šä¸‹æ–‡"""
        urgency_keywords = {
            'high': ['ç´§æ€¥', 'æ€¥éœ€', 'ç«‹å³', 'é©¬ä¸Š', 'urgent', 'asap'],
            'medium': ['å°½å¿«', 'è¾ƒå¿«', 'soon'],
            'low': ['ä»€ä¹ˆæ—¶å€™', 'æœ‰æ—¶é—´', 'æ…¢æ…¢']
        }
        
        query_lower = query.lower()
        for level, keywords in urgency_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                return {'level': level}
        
        return {'level': 'medium'}  # é»˜è®¤ä¸­ç­‰ç´§æ€¥ç¨‹åº¦
    
    def _analyze_visual_needs_context(self, query: str, context: Dict) -> Dict[str, Any]:
        """ğŸ¨ åˆ†ææŸ¥è¯¢çš„è§†è§‰éœ€æ±‚ - å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨_perform_visual_intelligence_decision"""
        logger.warning("ğŸš¨ _analyze_visual_needs_context å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨æ–°çš„è§†è§‰æ™ºèƒ½å†³ç­–ç³»ç»Ÿ")
        
        # ä¿æŒå‘åå…¼å®¹ï¼Œè°ƒç”¨æ–°çš„å†³ç­–ç³»ç»Ÿ
        visual_decision = self._perform_visual_intelligence_decision(query, context)
        
        # è½¬æ¢ä¸ºæ—§æ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
        return {
            'needs_visual': visual_decision['should_generate'],
            'confidence': visual_decision['decision_confidence'],
            'visual_type': visual_decision.get('recommended_visual_type', 'unknown'),
            'visual_purpose': visual_decision.get('generation_purpose', ''),
            'suggested_elements': visual_decision.get('suggested_elements', []),
            'analysis_source': 'visual_intelligence_decision_v2'
        }
                
        except Exception as e:
            logger.error(f"âŒ è§†è§‰éœ€æ±‚åˆ†æå¤±è´¥: {e}")
            visual_analysis = self._fallback_visual_needs_analysis(query)
        
        return visual_analysis
    
    def _analyze_output_format_context(self, query: str, context: Dict) -> Dict[str, Any]:
        """ğŸ“Š åˆ†ææŸ¥è¯¢çš„è¾“å‡ºæ ¼å¼éœ€æ±‚"""
        format_analysis = {'preferred_format': 'text', 'confidence': 0.0}
        
        try:
            if self.semantic_analyzer:
                # ä½¿ç”¨SemanticAnalyzerè¿›è¡Œæ™ºèƒ½åˆ†æ
                response = self.semantic_analyzer.analyze(
                    text=query,
                    tasks=['output_format_analysis']
                )
                
                if response.overall_success:
                    result = response.analysis_results.get('output_format_analysis')
                    if result and result.success:
                        format_data = result.result
                        format_analysis.update({
                            'preferred_format': format_data.get('preferred_format', 'text'),
                            'alternative_formats': format_data.get('alternative_formats', []),
                            'format_confidence': format_data.get('format_confidence', 0.0),
                            'output_medium': format_data.get('output_medium', 'text_response'),
                            'interaction_type': format_data.get('interaction_type', 'one_time_answer'),
                            'analysis_source': 'semantic_analyzer'
                        })
                        logger.debug(f"ğŸ“Š SemanticAnalyzeræ ¼å¼åˆ†æ: é¦–é€‰æ ¼å¼={format_analysis['preferred_format']}, ç½®ä¿¡åº¦={format_analysis.get('format_confidence', 0.0):.2f}")
                else:
                    logger.warning("âš ï¸ SemanticAnalyzeræ ¼å¼åˆ†æå¤±è´¥ï¼Œä½¿ç”¨é™çº§æ–¹æ³•")
                    format_analysis = self._fallback_output_format_analysis(query)
            else:
                # SemanticAnalyzerä¸å¯ç”¨ï¼Œä½¿ç”¨é™çº§åˆ†æ
                format_analysis = self._fallback_output_format_analysis(query)
                
        except Exception as e:
            logger.error(f"âŒ è¾“å‡ºæ ¼å¼åˆ†æå¤±è´¥: {e}")
            format_analysis = self._fallback_output_format_analysis(query)
        
        return format_analysis
    
    def _fallback_visual_needs_analysis(self, query: str) -> Dict[str, Any]:
        """ğŸ”„ é™çº§è§†è§‰éœ€æ±‚åˆ†æï¼ˆåŸºäºå…³é”®è¯åŒ¹é…ï¼‰"""
        query_lower = query.lower()
        
        # è§†è§‰ç›¸å…³å…³é”®è¯
        direct_visual_keywords = ['ç”»', 'è®¾è®¡', 'ç”Ÿæˆå›¾ç‰‡', 'åˆ›ä½œ', 'åˆ¶ä½œ', 'ç»˜åˆ¶', 'draw', 'design', 'create image', 'generate image', 'make']
        implicit_visual_keywords = ['æƒ³è±¡', 'å±•ç¤º', 'æ ·å­', 'çœ‹èµ·æ¥', 'å¤–è§‚', 'é£æ ¼', 'imagine', 'visualize', 'show', 'look like', 'appearance']
        design_keywords = ['logo', 'ui', 'ç•Œé¢', 'åŸå‹', 'æ’å›¾', 'å›¾æ ‡', 'æµ·æŠ¥', 'å¹¿å‘Š', 'mockup', 'prototype', 'illustration', 'banner', 'poster']
        
        if any(keyword in query_lower for keyword in direct_visual_keywords):
            return {
                'needs_visual': True,
                'confidence': 0.9,
                'visual_type': 'direct_creation',
                'visual_purpose': 'creation_request',
                'analysis_source': 'fallback_keywords'
            }
        elif any(keyword in query_lower for keyword in implicit_visual_keywords):
            return {
                'needs_visual': True,
                'confidence': 0.7,
                'visual_type': 'conceptual_illustration',
                'visual_purpose': 'concept_visualization',
                'analysis_source': 'fallback_keywords'
            }
        elif any(keyword in query_lower for keyword in design_keywords):
            return {
                'needs_visual': True,
                'confidence': 0.8,
                'visual_type': 'design_work',
                'visual_purpose': 'professional_design',
                'analysis_source': 'fallback_keywords'
            }
        else:
            return {
                'needs_visual': False,
                'confidence': 0.3,
                'visual_type': 'none',
                'visual_purpose': '',
                'analysis_source': 'fallback_keywords'
            }
    
    def _fallback_output_format_analysis(self, query: str) -> Dict[str, Any]:
        """ğŸ”„ é™çº§è¾“å‡ºæ ¼å¼åˆ†æï¼ˆåŸºäºå…³é”®è¯åŒ¹é…ï¼‰"""
        query_lower = query.lower()
        
        # æ ¼å¼ç›¸å…³å…³é”®è¯
        image_keywords = ['å›¾', 'ç”»', 'è®¾è®¡', 'image', 'picture', 'design', 'visual']
        
        if any(keyword in query_lower for keyword in image_keywords):
            return {
                'preferred_format': 'image',
                'format_confidence': 0.8,
                'output_medium': 'visual_content',
                'analysis_source': 'fallback_keywords'
            }
        else:
            return {
                'preferred_format': 'text',
                'format_confidence': 0.5,
                'output_medium': 'text_response',
                'analysis_source': 'fallback_keywords'
            }
    
    def _analyze_complexity_context(self, query: str, context: Dict) -> Dict[str, Any]:
        """åˆ†æå¤æ‚ç¨‹åº¦ä¸Šä¸‹æ–‡"""
        # åŸºäºæŸ¥è¯¢é•¿åº¦å’Œå¤æ‚åº¦æŒ‡æ ‡è¯„ä¼°
        complexity_score = 0
        
        # é•¿åº¦å› ç´ 
        if len(query) > 100:
            complexity_score += 2
        elif len(query) > 50:
            complexity_score += 1
        
        # å¤æ‚åº¦å…³é”®è¯
        complex_keywords = ['å¦‚ä½•å®ç°', 'è®¾è®¡æ–¹æ¡ˆ', 'æ¶æ„', 'ç³»ç»Ÿ', 'è¯¦ç»†', 'å…¨é¢']
        complexity_score += sum(1 for keyword in complex_keywords if keyword in query)
        
        if complexity_score >= 3:
            return {'level': 'high', 'requires_comprehensive_approach': True}
        elif complexity_score >= 1:
            return {'level': 'medium', 'requires_balanced_approach': True}
        else:
            return {'level': 'low', 'requires_simple_approach': True}
    
    def _decide_action_strategy(self, strategy_features: Dict, query_context: Dict, 
                              mab_confidence: float) -> Dict[str, Any]:
        """åŸºäºç­–ç•¥ç‰¹å¾å’ŒæŸ¥è¯¢ä¸Šä¸‹æ–‡å†³å®šè¡ŒåŠ¨ç­–ç•¥"""
        
        # åŸºç¡€å·¥å…·é€‰æ‹©
        primary_tools = strategy_features.get('primary_tools', [])
        secondary_tools = strategy_features.get('secondary_tools', [])
        
        # æ ¹æ®MABç½®ä¿¡åº¦è°ƒæ•´å·¥å…·ä½¿ç”¨ç­–ç•¥
        confidence_threshold = strategy_features.get('confidence_threshold', 0.6)
        
        if mab_confidence < confidence_threshold:
            # ä½ç½®ä¿¡åº¦ï¼šæ›´ä¿å®ˆï¼Œä½¿ç”¨æ›´å¤šéªŒè¯å·¥å…·
            logger.info(f"ğŸ” MABç½®ä¿¡åº¦ ({mab_confidence:.2f}) ä½äºé˜ˆå€¼ ({confidence_threshold})ï¼Œé‡‡ç”¨ä¿å®ˆç­–ç•¥")
            if 'idea_verification' not in primary_tools:
                secondary_tools.append('idea_verification')
        
        # æ ¹æ®æŸ¥è¯¢å¤æ‚åº¦è°ƒæ•´ç­–ç•¥
        complexity = query_context.get('complexity_level', {}).get('level', 'medium')
        if complexity == 'high':
            # é«˜å¤æ‚åº¦ï¼šä½¿ç”¨æ›´å…¨é¢çš„å·¥å…·ç»„åˆ
            if 'web_search' not in primary_tools:
                primary_tools.append('web_search')
            if strategy_features.get('execution_pattern') != 'creative_direct':
                primary_tools.append('data_analysis')
        
        # æ ¹æ®ç´§æ€¥ç¨‹åº¦è°ƒæ•´ç­–ç•¥
        urgency = query_context.get('urgency_level', {}).get('level', 'medium')
        execution_pattern = strategy_features.get('execution_pattern', 'sequential')
        
        if urgency == 'high':
            # é«˜ç´§æ€¥ï¼šä¼˜åŒ–æ‰§è¡Œæ¨¡å¼ï¼Œå‡å°‘å·¥å…·æ•°é‡
            execution_pattern = 'direct'
            primary_tools = primary_tools[:2]  # é™åˆ¶æœ€å¤š2ä¸ªä¸»è¦å·¥å…·
        
        return {
            'primary_tools': primary_tools,
            'secondary_tools': secondary_tools,
            'execution_pattern': execution_pattern,
            'max_parallel_tools': 3 if urgency != 'high' else 1,
            'strategy_confidence': mab_confidence,
            'context_factors': {
                'complexity': complexity,
                'urgency': urgency,
                'domain': query_context.get('domain_specific', {}).get('domain', 'general')
            }
        }
    
    def _generate_concrete_actions(self, action_strategy: Dict, chosen_path, 
                                 query: str, query_context: Dict) -> List:
        """ç”Ÿæˆå…·ä½“çš„å·¥å…·è°ƒç”¨è¡ŒåŠ¨"""
        try:
            from neogenesis_system.abstractions import Action
        except ImportError:
            # å›é€€åˆ°ç®€å•çš„Actionå®šä¹‰
            class Action:
                def __init__(self, tool_name, tool_input):
                    self.tool_name = tool_name
                    self.tool_input = tool_input
                    self.execution_mode = 'sequential'
        
        actions = []
        primary_tools = action_strategy['primary_tools']
        execution_pattern = action_strategy['execution_pattern']
        
        logger.info(f"ğŸ”§ ç”Ÿæˆå…·ä½“è¡ŒåŠ¨: {len(primary_tools)} ä¸ªä¸»è¦å·¥å…·")
        logger.info(f"   æ‰§è¡Œæ¨¡å¼: {execution_pattern}")
        
        # ğŸ¨ æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦è§†è§‰åŒ–å·¥å…·
        visual_needs = query_context.get('visual_needs', {})
        if visual_needs.get('needs_visual', False):
            confidence = visual_needs.get('confidence', 0.0)
            visual_type = visual_needs.get('visual_type', 'unknown')
            logger.info(f"ğŸ¨ æ£€æµ‹åˆ°è§†è§‰éœ€æ±‚: ç±»å‹={visual_type}, ç½®ä¿¡åº¦={confidence:.2f}")
            
            # ä¼˜å…ˆå¤„ç†è§†è§‰ç›¸å…³çš„æ‰§è¡Œæ¨¡å¼
            if execution_pattern in ['visual_creation', 'iterative_design', 'concept_illustration']:
                logger.info(f"ğŸ¨ ä½¿ç”¨è§†è§‰åŒ–æ‰§è¡Œæ¨¡å¼: {execution_pattern}")
                # ä¼˜å…ˆåˆ›å»ºå›¾åƒç”Ÿæˆè¡ŒåŠ¨
                image_action = self._create_image_generation_action(query, visual_needs, query_context)
                if image_action:
                    actions.append(image_action)
                    logger.info("âœ¨ å·²æ·»åŠ å›¾åƒç”Ÿæˆè¡ŒåŠ¨")
                
                # å¯¹äºè®¾è®¡å¯¼å‘ç±»å‹ï¼Œå¯èƒ½è¿˜éœ€è¦ä¸€äº›ç ”ç©¶å·¥å…·
                if visual_type == 'professional_design' and 'web_search' not in [action.tool_name for action in actions]:
                    # æ·»åŠ è®¾è®¡çµæ„Ÿçš„æœç´¢
                    design_search_action = self._create_design_research_action(query, visual_needs)
                    if design_search_action:
                        actions.append(design_search_action)
                        logger.info("ğŸ” å·²æ·»åŠ è®¾è®¡ç ”ç©¶è¡ŒåŠ¨")
                
                return actions  # ç›´æ¥è¿”å›è§†è§‰åŒ–è¡ŒåŠ¨ç»„åˆ
        
        # ğŸš¨ å¯¹ç‰¹å®šæ‰§è¡Œæ¨¡å¼ä¼˜å…ˆé€‰æ‹©ç›´æ¥å›ç­”
        if execution_pattern in ['direct_creative', 'adaptive_direct', 'creative_direct']:
            logger.info(f"ğŸ¯ æ£€æµ‹åˆ°ç›´æ¥å›ç­”ä¼˜å…ˆæ¨¡å¼: {execution_pattern}")
            # è¿”å›ç©ºçš„actionsåˆ—è¡¨ï¼Œè®©plannerä½¿ç”¨ç›´æ¥å›ç­”
            return []
        
        # æ ‡å‡†å·¥å…·é€‰æ‹©é€»è¾‘
        for tool_name in primary_tools:
            try:
                action = self._create_tool_action(tool_name, query, chosen_path, query_context)
                if action:
                    actions.append(action)
            except Exception as e:
                logger.warning(f"âš ï¸ åˆ›å»ºå·¥å…·è¡ŒåŠ¨å¤±è´¥ {tool_name}: {e}")
        
        # æ ¹æ®æ‰§è¡Œæ¨¡å¼è°ƒæ•´è¡ŒåŠ¨å±æ€§
        if execution_pattern == 'parallel' and len(actions) > 1:
            # æ ‡è®°ä¸ºå¯å¹¶è¡Œæ‰§è¡Œ
            for action in actions:
                if hasattr(action, 'execution_mode'):
                    action.execution_mode = 'parallel'
        
        return actions
    
    def _create_tool_action(self, tool_name: str, query: str, chosen_path,
                          query_context: Dict):
        """ä¸ºç‰¹å®šå·¥å…·åˆ›å»ºè¡ŒåŠ¨"""
        try:
            from neogenesis_system.abstractions import Action
        except ImportError:
            class Action:
                def __init__(self, tool_name, tool_input):
                    self.tool_name = tool_name
                    self.tool_input = tool_input
        
        # æ ¹æ®å·¥å…·ç±»å‹ç”Ÿæˆåˆé€‚çš„è¾“å…¥å‚æ•°
        if tool_name == 'web_search' or tool_name == 'tavily_search':
            search_query = self._optimize_search_query(query, chosen_path, query_context)
            return Action(tool_name, {"query": search_query, "max_results": 5})
        
        elif tool_name == 'idea_verification':
            idea_to_verify = self._extract_verification_target(query, chosen_path)
            return Action(tool_name, {"idea_text": idea_to_verify})
        
        elif tool_name == 'knowledge_query':
            topic = self._extract_knowledge_topic(query, chosen_path)
            return Action(tool_name, {"topic": topic})
        
        elif tool_name == 'data_analysis':
            return Action(tool_name, {
                "data_type": "text",
                "data": query,
                "analysis_type": "comprehensive"
            })
        
        # ğŸ¨ æ–°å¢ï¼šå›¾åƒç”Ÿæˆå·¥å…·æ”¯æŒ - æ™ºèƒ½å†³ç­–ç‰ˆæœ¬
        elif tool_name in ['image_generation', 'stable_diffusion_xl_generator']:
            # ä½¿ç”¨æ–°çš„è§†è§‰æ™ºèƒ½å†³ç­–ç³»ç»Ÿ
            visual_decision = self._perform_visual_intelligence_decision(query, query_context)
            
            if visual_decision['should_generate']:
                return self._create_intelligent_image_generation_action(query, visual_decision, query_context)
            else:
                logger.info(f"ğŸš« è§†è§‰æ™ºèƒ½å†³ç­–ï¼šä¸é€‚åˆç”Ÿæˆå›¾åƒ - {visual_decision['decision_reason']}")
                return None
        
        else:
            logger.warning(f"âš ï¸ æœªçŸ¥å·¥å…·ç±»å‹: {tool_name}")
            return None
    
    def _create_image_generation_action(self, query: str, visual_needs: Dict, query_context: Dict):
        """ğŸ¨ åˆ›å»ºå›¾åƒç”Ÿæˆå·¥å…·è¡ŒåŠ¨"""
        try:
            from neogenesis_system.abstractions import Action
        except ImportError:
            class Action:
                def __init__(self, tool_name, tool_input):
                    self.tool_name = tool_name
                    self.tool_input = tool_input
        
        # ç”Ÿæˆä¼˜åŒ–çš„æç¤ºè¯
        prompt = self._generate_image_prompt(query, visual_needs, query_context)
        
        # ä½¿ç”¨stable_diffusion_xl_generatorå·¥å…·
        tool_input = {
            "prompt": prompt,
            "save_image": True,
            "style_hint": self._extract_style_hint(visual_needs, query_context)
        }
        
        logger.info(f"ğŸ¨ åˆ›å»ºå›¾åƒç”Ÿæˆè¡ŒåŠ¨: {prompt[:50]}...")
        return Action('stable_diffusion_xl_generator', tool_input)
    
    def _create_design_research_action(self, query: str, visual_needs: Dict):
        """ğŸ” ä¸ºè®¾è®¡é¡¹ç›®åˆ›å»ºç ”ç©¶è¡ŒåŠ¨"""
        try:
            from neogenesis_system.abstractions import Action
        except ImportError:
            class Action:
                def __init__(self, tool_name, tool_input):
                    self.tool_name = tool_name
                    self.tool_input = tool_input
        
        # ä¸ºè®¾è®¡é¡¹ç›®ä¼˜åŒ–çš„æœç´¢æŸ¥è¯¢
        visual_type = visual_needs.get('visual_type', 'design')
        
        if visual_type == 'professional_design':
            search_query = f"{query} è®¾è®¡çµæ„Ÿ æœ€ä½³å®è·µ æœ€æ–°è¶‹åŠ¿"
        elif visual_type == 'logo':
            search_query = f"{query} logoè®¾è®¡ å“ç‰Œè§†è§‰ è®¾è®¡ç†å¿µ"
        elif visual_type == 'ui_mockup':
            search_query = f"{query} UIè®¾è®¡ ç”¨æˆ·ä½“éªŒ ç•Œé¢è®¾è®¡"
        else:
            search_query = f"{query} è§†è§‰è®¾è®¡ åˆ›æ„çµæ„Ÿ"
        
        return Action('web_search', {
            "query": search_query,
            "max_results": 3  # é™åˆ¶ç»“æœæ•°é‡ï¼Œä¼˜å…ˆå›¾åƒç”Ÿæˆ
        })
    
    def _generate_image_prompt(self, query: str, visual_needs: Dict, query_context: Dict) -> str:
        """ğŸ¨ ä¸ºå›¾åƒç”Ÿæˆç”Ÿæˆä¼˜åŒ–çš„æç¤ºè¯"""
        visual_type = visual_needs.get('visual_type', 'unknown')
        visual_purpose = visual_needs.get('visual_purpose', '')
        suggested_elements = visual_needs.get('suggested_elements', [])
        
        # åŸºç¡€æç¤ºè¯
        base_prompt = query.strip()
        
        # æ ¹æ®è§†è§‰ç±»å‹ä¼˜åŒ–æç¤ºè¯
        if visual_type == 'direct_creation':
            # ç›´æ¥åˆ›ä½œè¯·æ±‚ï¼Œä¿æŒåŸå§‹æ„å›¾
            optimized_prompt = base_prompt
        
        elif visual_type == 'professional_design':
            # ä¸“ä¸šè®¾è®¡ï¼Œæ·»åŠ è®¾è®¡è¦ç´ 
            optimized_prompt = f"{base_prompt}, professional design, clean and modern, high quality"
            
        elif visual_type == 'conceptual_illustration':
            # æ¦‚å¿µæ’å›¾ï¼Œæ·»åŠ æè¿°æ€§å…ƒç´ 
            optimized_prompt = f"{base_prompt}, conceptual illustration, detailed, explanatory visual"
            
        elif visual_type == 'design_work':
            # è®¾è®¡ä½œå“ï¼Œæ ¹æ®å…·ä½“ç±»å‹ä¼˜åŒ–
            if 'logo' in base_prompt.lower():
                optimized_prompt = f"{base_prompt}, minimalist logo design, vector style, brand identity"
            elif any(ui_word in base_prompt.lower() for ui_word in ['ui', 'ç•Œé¢', 'interface']):
                optimized_prompt = f"{base_prompt}, UI design mockup, user interface, clean layout"
            else:
                optimized_prompt = f"{base_prompt}, professional design, creative, high quality"
        
        else:
            # é»˜è®¤å¤„ç†
            optimized_prompt = f"{base_prompt}, artistic, detailed, high quality"
        
        # æ·»åŠ å»ºè®®å…ƒç´ 
        if suggested_elements:
            elements_text = ', '.join(suggested_elements[:3])  # é™åˆ¶å…ƒç´ æ•°é‡
            optimized_prompt += f", {elements_text}"
        
        # æ·»åŠ é€šç”¨è´¨é‡æå‡å…³é”®è¯
        optimized_prompt += ", detailed, professional quality, realistic"
        
        logger.debug(f"ğŸ¨ ç”Ÿæˆçš„å›¾åƒæç¤ºè¯: {optimized_prompt}")
        return optimized_prompt
    
    def _extract_style_hint(self, visual_needs: Dict, query_context: Dict) -> str:
        """ğŸ¨ æå–é£æ ¼æç¤º"""
        visual_type = visual_needs.get('visual_type', 'unknown')
        domain = query_context.get('domain_specific', {}).get('domain', 'general')
        
        # æ ¹æ®ç±»å‹å’Œé¢†åŸŸæä¾›é£æ ¼æç¤º
        style_hints = {
            'professional_design': 'clean, modern, professional',
            'conceptual_illustration': 'artistic, conceptual, detailed',
            'direct_creation': 'creative, artistic',
            'design_work': 'design-focused, brand-appropriate'
        }
        
        domain_hints = {
            'technical': 'tech-oriented, clean, futuristic',
            'business': 'professional, corporate, sophisticated',
            'academic': 'scholarly, detailed, informative',
            'creative': 'artistic, expressive, imaginative'
        }
        
        style = style_hints.get(visual_type, 'artistic, detailed')
        if domain != 'general':
            style += f", {domain_hints.get(domain, '')}"
        
        return style
    
    def _optimize_search_query(self, original_query: str, chosen_path, query_context: Dict) -> str:
        """ä¼˜åŒ–æœç´¢æŸ¥è¯¢"""
        # åŸºç¡€æŸ¥è¯¢
        optimized_query = original_query
        
        # æ ¹æ®ç­–ç•¥ç±»å‹ä¼˜åŒ–
        if chosen_path.path_type == 'exploratory_investigative':
            optimized_query += " æ·±å…¥åˆ†æ æœ€æ–°å‘å±•"
        elif chosen_path.path_type == 'critical_questioning':
            optimized_query += " é£é™© æŒ‘æˆ˜ é—®é¢˜"
        elif chosen_path.path_type == 'systematic_analytical':
            optimized_query += " ç³»ç»Ÿæ–¹æ³• è§£å†³æ–¹æ¡ˆ"
        
        # æ ¹æ®é¢†åŸŸä¼˜åŒ–
        domain = query_context.get('domain_specific', {}).get('domain', 'general')
        if domain == 'technical':
            optimized_query += " æŠ€æœ¯å®ç°"
        elif domain == 'business':
            optimized_query += " å•†ä¸šåº”ç”¨"
        
        return optimized_query
    
    def _extract_verification_target(self, query: str, chosen_path) -> str:
        """æå–éœ€è¦éªŒè¯çš„ç›®æ ‡"""
        # å¦‚æœæŸ¥è¯¢ä¸­åŒ…å«æ˜ç¡®çš„æƒ³æ³•æˆ–æ–¹æ¡ˆï¼Œæå–å‡ºæ¥
        verification_phrases = ['è¿™ä¸ªæƒ³æ³•', 'è¿™ä¸ªæ–¹æ¡ˆ', 'è¿™ç§æ–¹æ³•', 'å¯è¡Œå—', 'æ˜¯å¦å¯è¡Œ']
        
        for phrase in verification_phrases:
            if phrase in query:
                return query
        
        # å¦åˆ™åŸºäºè·¯å¾„ç±»å‹æ„é€ éªŒè¯ç›®æ ‡
        return f"å…³äº'{query}'çš„å¯è¡Œæ€§å’Œæ½œåœ¨é£é™©"
    
    def _extract_knowledge_topic(self, query: str, chosen_path) -> str:
        """æå–çŸ¥è¯†æŸ¥è¯¢ä¸»é¢˜"""
        return query[:100]  # é™åˆ¶é•¿åº¦
    
    def _extract_analysis_target(self, query: str) -> str:
        """æå–åˆ†æç›®æ ‡"""
        return query


class ImprovedMockNeogenesisPlanner:
    """
    æ”¹è¿›çš„Mockè§„åˆ’å™¨ - åœ¨ç®€åŒ–ç¯å¢ƒä¸‹ä¹Ÿä½“ç°å¤šé˜¶æ®µå†³ç­–æ€æƒ³
    
    å³ä½¿åœ¨Mockç¯å¢ƒä¸­ï¼Œä¹Ÿè¦ä½“ç°:
    1. ç­–ç•¥ç”Ÿæˆ (ç®€åŒ–ç‰ˆPathGenerator)
    2. ç­–ç•¥é€‰æ‹© (ç®€åŒ–ç‰ˆMAB)  
    3. ç­–ç•¥è§£æ (ä½¿ç”¨StrategyInterpreter)
    """
    
    def __init__(self):
        self.name = "ImprovedMockNeogenesisPlanner"
        self.strategy_interpreter = StrategyInterpreter()
        
        # ç®€åŒ–çš„ç­–ç•¥æ¨¡æ¿
        self.mock_strategy_templates = {
            'search_focused': {
                'path_type': 'exploratory_investigative',
                'description': 'ä¿¡æ¯æœç´¢å’Œè°ƒç ”å¯¼å‘çš„ç­–ç•¥',
                'prompt_template': 'æ·±å…¥æœç´¢å’Œç ”ç©¶å…³äº{task}çš„ä¿¡æ¯',
                'trigger_keywords': ['æœç´¢', 'æŸ¥æ‰¾', 'ä¿¡æ¯', 'èµ„æ–™', 'äº†è§£', 'ä»€ä¹ˆæ˜¯']
            },
            'verification_focused': {
                'path_type': 'critical_questioning',
                'description': 'éªŒè¯å’Œè´¨ç–‘å¯¼å‘çš„ç­–ç•¥',
                'prompt_template': 'æ‰¹åˆ¤æ€§åˆ†æå’ŒéªŒè¯{task}çš„å¯è¡Œæ€§',
                'trigger_keywords': ['éªŒè¯', 'å¯è¡Œ', 'é£é™©', 'é—®é¢˜', 'ç¼ºç‚¹', 'æ˜¯å¦']
            },
            'analysis_focused': {
                'path_type': 'systematic_analytical',
                'description': 'ç³»ç»Ÿåˆ†æå¯¼å‘çš„ç­–ç•¥',
                'prompt_template': 'ç³»ç»Ÿæ€§åˆ†æ{task}çš„å„ä¸ªæ–¹é¢',
                'trigger_keywords': ['åˆ†æ', 'å¦‚ä½•', 'æ–¹æ³•', 'æ­¥éª¤', 'å®ç°', 'è®¾è®¡']
            },
            'direct_answer': {
                'path_type': 'practical_pragmatic',
                'description': 'å®ç”¨ç›´æ¥å›ç­”ç­–ç•¥',
                'prompt_template': 'åŸºäºç°æœ‰çŸ¥è¯†ç›´æ¥å›ç­”{task}',
                'trigger_keywords': ['ä½ å¥½', 'hello', 'ä»‹ç»', 'å¸®åŠ©']
            }
        }
        
        # ç®€åŒ–çš„é€‰æ‹©ç»Ÿè®¡ (æ¨¡æ‹ŸMAB)
        self.strategy_success_stats = {
            'search_focused': {'success_count': 10, 'total_count': 15},
            'verification_focused': {'success_count': 8, 'total_count': 12},
            'analysis_focused': {'success_count': 12, 'total_count': 18},
            'direct_answer': {'success_count': 20, 'total_count': 25}
        }
        
        logger.info("ğŸ¤– æ”¹è¿›çš„Mockè§„åˆ’å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def create_plan(self, query: str, memory, context=None):
        """æ”¹è¿›çš„è®¡åˆ’åˆ›å»º - ä½“ç°ç®€åŒ–çš„å¤šé˜¶æ®µå†³ç­–"""
        try:
            from neogenesis_system.abstractions import Plan
        except ImportError:
            class Plan:
                def __init__(self, thought, final_answer=None, actions=None):
                    self.thought = thought
                    self.final_answer = final_answer
                    self.actions = actions or []
                    self.is_direct_answer = final_answer is not None
        
        logger.info(f"ğŸ¤– Mockè§„åˆ’å™¨å¼€å§‹å¤šé˜¶æ®µå†³ç­–: {query[:50]}...")
        
        # é˜¶æ®µ1: ç­–ç•¥å€™é€‰ç”Ÿæˆ (ç®€åŒ–çš„PathGenerator)
        candidate_strategies = self._generate_candidate_strategies(query)
        logger.info(f"ğŸ§  ç”Ÿæˆç­–ç•¥å€™é€‰: {[s['path_type'] for s in candidate_strategies]}")
        
        # é˜¶æ®µ2: ç­–ç•¥é€‰æ‹© (ç®€åŒ–çš„MAB)
        chosen_strategy = self._select_best_strategy(candidate_strategies, query)
        logger.info(f"ğŸ¯ é€‰æ‹©ç­–ç•¥: {chosen_strategy['path_type']}")
        
        # é˜¶æ®µ3: ç­–ç•¥è§£æä¸ºè¡ŒåŠ¨ (ä½¿ç”¨StrategyInterpreter)
        mock_reasoning_path = self._create_mock_reasoning_path(chosen_strategy, query)
        
        # ä½¿ç”¨ç­–ç•¥è§£é‡Šå™¨ç”Ÿæˆè¡ŒåŠ¨
        try:
            actions = self.strategy_interpreter.interpret_strategy_to_actions(
                chosen_path=mock_reasoning_path,
                query=query,
                mab_confidence=0.8,  # Mockç½®ä¿¡åº¦
                decision_context=context or {}
            )
        except Exception as e:
            logger.warning(f"âš ï¸ ç­–ç•¥è§£é‡Šå™¨è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–é€»è¾‘: {e}")
            actions = self._fallback_action_generation(chosen_strategy, query)
        
        # æ„å»ºæœ€ç»ˆè®¡åˆ’
        if not actions:
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ¢å¤ç›´æ¥å›ç­”æ¨¡å¼ï¼Œé’ˆå¯¹ç®€å•é—®å€™å’Œä»‹ç»ç±»é—®é¢˜
            # é¿å…æ‰€æœ‰é—®é¢˜éƒ½è¢«å¼ºåˆ¶è¿›å…¥å·¥å…·æ‰§è¡Œè·¯å¾„
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç®€å•çš„ç›´æ¥å›ç­”ç±»å‹
            query_lower = query.lower().strip()
            is_simple_greeting = any(greeting in query_lower for greeting in ['ä½ å¥½', 'hello', 'hi', 'æ‚¨å¥½'])
            is_simple_intro = "ä»‹ç»" in query_lower and ("è‡ªå·±" in query_lower or "ä½ " in query_lower)
            is_simple_thanks = any(thanks in query_lower for thanks in ['è°¢è°¢', 'thanks', 'thank you', 'æ„Ÿè°¢'])
            is_simple_help = any(help_word in query_lower for help_word in ['å¸®åŠ©', 'èƒ½åšä»€ä¹ˆ', 'åŠŸèƒ½'])
            
            if is_simple_greeting or is_simple_intro or is_simple_thanks or is_simple_help:
                # ä½¿ç”¨ç›´æ¥å›ç­”æ¨¡å¼ - ä¸éœ€è¦å·¥å…·è°ƒç”¨
                return Plan(
                    thought=f"åŸºäºå¤šé˜¶æ®µå†³ç­–ï¼Œè¯†åˆ«ä¸ºç®€å•é—®å€™/ä»‹ç»ç±»æŸ¥è¯¢ï¼Œé€‰æ‹©ç›´æ¥å›ç­”ç­–ç•¥",
                    final_answer=self._generate_direct_answer_for_simple_query(query)
                )
            
            # å¯¹äºå…¶ä»–å¤æ‚é—®é¢˜ï¼Œç”Ÿæˆå·¥å…·è°ƒç”¨
            if chosen_strategy['path_type'] == 'practical_pragmatic':
                actions = [Action("knowledge_query", {"topic": query})]
            elif chosen_strategy['path_type'] == 'exploratory_investigative':
                actions = [Action("web_search", {"query": query})]
            elif chosen_strategy['path_type'] == 'critical_questioning':
                actions = [Action("idea_verification", {"idea_text": query})]
            else:
                # é»˜è®¤ä½¿ç”¨knowledge_queryå·¥å…·
                actions = [Action("knowledge_query", {"topic": query})]
        
        # å·¥å…·æ‰§è¡Œæ¨¡å¼
        return Plan(
            thought=f"åŸºäºå¤šé˜¶æ®µå†³ç­–ï¼Œé€‰æ‹©'{chosen_strategy['path_type']}'ç­–ç•¥ï¼Œé€šè¿‡å·¥å…·è°ƒç”¨ç”Ÿæˆä¸“ä¸šå›ç­”ï¼ˆ{len(actions)}ä¸ªè¡ŒåŠ¨ï¼‰",
            actions=actions
        )
    
    def _generate_direct_answer_for_simple_query(self, query: str) -> str:
        """ä¸ºç®€å•æŸ¥è¯¢ç”Ÿæˆç›´æ¥å›ç­”"""
        query_lower = query.lower().strip()
        
        # é—®å€™ç±»
        if any(greeting in query_lower for greeting in ['ä½ å¥½', 'hello', 'hi', 'æ‚¨å¥½']):
            return "ä½ å¥½ï¼æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"
        
        # ä»‹ç»ç±»  
        if "ä»‹ç»" in query_lower and ("è‡ªå·±" in query_lower or "ä½ " in query_lower):
            return "æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œä¿¡æ¯æŸ¥è¯¢ã€é—®é¢˜åˆ†æã€åˆ›æ„æ€è€ƒç­‰å¤šç§ä»»åŠ¡ã€‚æˆ‘ä¼šæ ¹æ®ä¸åŒé—®é¢˜æ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„å¤„ç†æ–¹å¼ï¼Œä¸ºæ‚¨æä¾›å‡†ç¡®æœ‰ç”¨çš„å¸®åŠ©ã€‚"
        
        # æ„Ÿè°¢ç±»
        if any(thanks in query_lower for thanks in ['è°¢è°¢', 'thanks', 'thank you', 'æ„Ÿè°¢']):
            return "ä¸å®¢æ°”ï¼å¦‚æœè¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘ã€‚"
        
        # åŠŸèƒ½æŸ¥è¯¢ç±»
        if any(help_word in query_lower for help_word in ['å¸®åŠ©', 'èƒ½åšä»€ä¹ˆ', 'åŠŸèƒ½']):
            return "æˆ‘å¯ä»¥å¸®æ‚¨æœç´¢ä¿¡æ¯ã€åˆ†æé—®é¢˜ã€éªŒè¯æƒ³æ³•ã€å›ç­”å„é¢†åŸŸé—®é¢˜ç­‰ã€‚æˆ‘çš„ç‰¹ç‚¹æ˜¯èƒ½æ ¹æ®ä¸åŒé—®é¢˜æ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„å¤„ç†æ–¹å¼ï¼Œä¸ºæ‚¨æä¾›æœ‰ä»·å€¼çš„å¸®åŠ©ã€‚"
        
        # é»˜è®¤å›ç­” - ä½¿ç”¨LLMæˆ–è¯šå®è¯´æ˜é™åˆ¶ï¼Œé¿å…é¢„è®¾æ¨¡æ¿
        try:
            # å°è¯•ä½¿ç”¨LLMç”Ÿæˆç®€æ´å›ç­”
            from neogenesis_system.providers.impl.deepseek_client import DeepSeekClient, ClientConfig
            import os
            
            api_key = os.getenv('DEEPSEEK_API_KEY') or os.getenv('NEOGENESIS_API_KEY')
            if api_key:
                client_config = ClientConfig(
                    api_key=api_key,
                    model="deepseek-chat",
                    temperature=0.7,
                    max_tokens=300
                )
                client = DeepSeekClient(client_config)
                
                prompt = f"""è¯·ç®€æ´å›ç­”ç”¨æˆ·é—®é¢˜ï¼š{query}

å¦‚æœæ— æ³•å‡†ç¡®å›ç­”ï¼Œè¯·è¯šå®è¯´æ˜é™åˆ¶ã€‚ä¿æŒå‹å¥½è¯­æ°”ï¼š"""
                
                api_response = client.simple_chat(prompt=prompt, max_tokens=300, temperature=0.7)
                llm_response = api_response.content if hasattr(api_response, 'content') else str(api_response)
                
                if llm_response and llm_response.strip():
                    return llm_response.strip()
                    
        except Exception as e:
            logger.warning(f"âš ï¸ ç­–ç•¥è§£é‡Šå™¨é»˜è®¤LLMè°ƒç”¨å¤±è´¥: {e}")
        
        # æœ€ç»ˆè¯šå®å›ç­” - ä¸ä½¿ç”¨é¢„è®¾æ¨¡æ¿
        if "æ—¶é—´" in query_lower or "å‡ ç‚¹" in query_lower:
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è·å–å½“å‰çš„å®æ—¶æ—¶é—´ä¿¡æ¯ã€‚å»ºè®®æ‚¨æŸ¥çœ‹æ‚¨çš„è®¾å¤‡æ—¶é’Ÿæˆ–æœç´¢å¼•æ“è·å–å‡†ç¡®æ—¶é—´ã€‚"
        elif "å¤©æ°”" in query_lower:
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è·å–å®æ—¶å¤©æ°”ä¿¡æ¯ã€‚å»ºè®®æ‚¨æŸ¥çœ‹å¤©æ°”åº”ç”¨æˆ–ç½‘ç«™è·å–æœ€æ–°å¤©æ°”é¢„æŠ¥ã€‚"
        else:
            return f"å…³äºæ‚¨çš„é—®é¢˜ã€Œ{query}ã€ï¼Œæˆ‘å¾ˆæ„¿æ„å¸®åŠ©æ‚¨ï¼Œä½†æˆ‘å¯èƒ½éœ€è¦æ›´å¤šä¿¡æ¯æ‰èƒ½æä¾›å‡†ç¡®çš„å›ç­”ã€‚è¯·é—®æ‚¨èƒ½æä¾›æ›´å¤šå…·ä½“ç»†èŠ‚å—ï¼Ÿ"

    def _generate_candidate_strategies(self, query: str) -> List[Dict]:
        """ç”Ÿæˆå€™é€‰ç­–ç•¥ - ç®€åŒ–ç‰ˆPathGenerator"""
        candidates = []
        query_lower = query.lower()
        
        # ä¸ºæ¯ä¸ªç­–ç•¥æ¨¡æ¿è®¡ç®—ç›¸å…³åº¦
        for strategy_id, template in self.mock_strategy_templates.items():
            relevance_score = 0
            
            # åŸºäºå…³é”®è¯åŒ¹é…è®¡ç®—ç›¸å…³åº¦
            for keyword in template['trigger_keywords']:
                if keyword in query_lower:
                    relevance_score += 1
            
            # æ ‡å‡†åŒ–ç›¸å…³åº¦åˆ†æ•°
            max_possible_score = len(template['trigger_keywords'])
            normalized_score = relevance_score / max_possible_score if max_possible_score > 0 else 0.1
            
            candidates.append({
                'strategy_id': strategy_id,
                'relevance_score': normalized_score,
                **template
            })
        
        # æŒ‰ç›¸å…³åº¦æ’åº
        candidates.sort(key=lambda x: x['relevance_score'], reverse=True)
        
        # è¿”å›å‰3ä¸ªæœ€ç›¸å…³çš„ç­–ç•¥
        return candidates[:3]
    
    def _select_best_strategy(self, candidates: List[Dict], query: str) -> Dict:
        """é€‰æ‹©æœ€ä½³ç­–ç•¥ - ç®€åŒ–ç‰ˆMAB"""
        if not candidates:
            return self.mock_strategy_templates['direct_answer']
        
        best_strategy = None
        best_score = -1
        
        for candidate in candidates:
            strategy_id = candidate['strategy_id']
            
            # è·å–å†å²æˆåŠŸç‡ (æ¨¡æ‹ŸMABæ•°æ®)
            stats = self.strategy_success_stats.get(strategy_id, {'success_count': 1, 'total_count': 2})
            success_rate = stats['success_count'] / stats['total_count']
            
            # ç»“åˆç›¸å…³åº¦å’ŒæˆåŠŸç‡ (ç®€åŒ–çš„UCBç®—æ³•)
            exploration_bonus = 0.1  # ç®€åŒ–çš„æ¢ç´¢å¥–åŠ±
            combined_score = (
                candidate['relevance_score'] * 0.6 +  # ç›¸å…³åº¦æƒé‡
                success_rate * 0.3 +                  # æˆåŠŸç‡æƒé‡
                exploration_bonus * 0.1               # æ¢ç´¢å¥–åŠ±æƒé‡
            )
            
            if combined_score > best_score:
                best_score = combined_score
                best_strategy = candidate
        
        # æ›´æ–°é€‰æ‹©ç»Ÿè®¡ (æ¨¡æ‹ŸMABå­¦ä¹ )
        if best_strategy:
            strategy_id = best_strategy['strategy_id']
            self.strategy_success_stats[strategy_id]['total_count'] += 1
        
        return best_strategy or self.mock_strategy_templates['direct_answer']
    
    def _create_mock_reasoning_path(self, strategy: Dict, query: str):
        """åˆ›å»ºMockçš„ReasoningPathå¯¹è±¡"""
        try:
            from neogenesis_system.cognitive_engine.path_generator import ReasoningPath
        except ImportError:
            # ç®€å•çš„Mock ReasoningPath
            class ReasoningPath:
                def __init__(self, path_id, path_type, description, prompt_template, strategy_id):
                    self.path_id = path_id
                    self.path_type = path_type
                    self.description = description
                    self.prompt_template = prompt_template
                    self.strategy_id = strategy_id
        
        return ReasoningPath(
            path_id=f"mock_{strategy['strategy_id']}",
            path_type=strategy['path_type'],
            description=strategy['description'],
            prompt_template=strategy['prompt_template'].format(task=query),
            strategy_id=strategy['strategy_id']
        )
    
    def _fallback_action_generation(self, strategy: Dict, query: str) -> List:
        """ç®€åŒ–çš„è¡ŒåŠ¨ç”Ÿæˆå›é€€é€»è¾‘"""
        try:
            from neogenesis_system.abstractions import Action
        except ImportError:
            class Action:
                def __init__(self, tool_name, tool_input):
                    self.tool_name = tool_name
                    self.tool_input = tool_input
        
        actions = []
        strategy_type = strategy['path_type']
        
        if strategy_type == 'exploratory_investigative':
            actions.append(Action("web_search", {"query": query}))
        elif strategy_type == 'critical_questioning':
            actions.append(Action("idea_verification", {"idea_text": query}))
        elif strategy_type == 'systematic_analytical':
            actions.append(Action("knowledge_query", {"topic": query}))
        
        return actions
    
    def _generate_mock_direct_answer(self, strategy: Dict, query: str) -> str:
        """ç”ŸæˆMockç›´æ¥å›ç­” - ç§»é™¤é¢„è®¾å›ç­”ï¼Œç¡®ä¿ä½¿ç”¨çœŸå®çš„å¤šå†³ç­–é“¾æ¡"""
        strategy_type = strategy['path_type']
        
        # ğŸ”§ é‡è¦ä¿®æ”¹ï¼šç§»é™¤æ‰€æœ‰é¢„è®¾å›ç­”ï¼ŒåŒ…æ‹¬é—®å€™è¯­çš„é¢„è®¾å›å¤
        # ç¡®ä¿æ‰€æœ‰é—®é¢˜éƒ½é€šè¿‡çœŸæ­£çš„å¤šé˜¶æ®µå†³ç­–å’Œå·¥å…·è°ƒç”¨æ¥å¤„ç†
        
        # ä¸å†æä¾›é¢„è®¾çš„é—®å€™å›ç­”ï¼Œè€Œæ˜¯è¿”å›Noneæˆ–ç©ºå­—ç¬¦ä¸²ï¼Œ
        # è¿™æ ·ä¼šå¼ºåˆ¶ç³»ç»Ÿä½¿ç”¨å·¥å…·æ‰§è¡Œæµç¨‹
        return ""  # è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œå¼ºåˆ¶èµ°å·¥å…·æ‰§è¡Œæµç¨‹
    
    def validate_plan(self, plan):
        """éªŒè¯è®¡åˆ’"""
        return True
    
    def get_stats(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "name": self.name,
            "total_rounds": 0,
            "strategy_success_stats": self.strategy_success_stats
        }
