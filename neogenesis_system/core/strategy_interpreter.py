#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç­–ç•¥è§£é‡Šå™¨ - å¤šé˜¶æ®µå†³ç­–é“¾æ¡çš„æ ¸å¿ƒç»„ä»¶
å®Œç¾ä½“ç°LLMç­–ç•¥å»ºè®® â†’ MABæ•°æ®é©±åŠ¨é€‰æ‹© â†’ ç­–ç•¥è§£æç”Ÿæˆå·¥å…·è°ƒç”¨çš„è®¾è®¡ç†å¿µ
"""

from typing import Dict, List, Any, Optional
import logging
import time
import random

logger = logging.getLogger(__name__)


class StrategyInterpreter:
    """
    ç­–ç•¥è§£é‡Šå™¨ - å°†æ€ç»´è·¯å¾„çš„ç­–ç•¥ç‰¹å¾è½¬æ¢ä¸ºå…·ä½“çš„å·¥å…·è°ƒç”¨ç­–ç•¥
    
    è¿™æ˜¯è¿æ¥"å®è§‚ç­–ç•¥"å’Œ"å…·ä½“è¡ŒåŠ¨"çš„å…³é”®æ¡¥æ¢ç»„ä»¶ï¼Œ
    é¿å…äº†ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼Œè€Œæ˜¯åŸºäºç­–ç•¥çš„æ·±å±‚è¯­ä¹‰ç‰¹å¾ã€‚
    """
    
    def __init__(self):
        self.name = "StrategyInterpreter"
        
        # ç­–ç•¥ç‰¹å¾åˆ°å·¥å…·ç­–ç•¥çš„æ˜ å°„è¡¨
        self.strategy_feature_mappings = {
            # ç³»ç»Ÿåˆ†æå‹ç­–ç•¥ç‰¹å¾
            'systematic_analytical': {
                'primary_tools': ['knowledge_query', 'data_analysis'],
                'secondary_tools': ['web_search'],
                'execution_pattern': 'sequential',  # é¡ºåºæ‰§è¡Œ
                'confidence_threshold': 0.7,
                'description': 'é€»è¾‘åˆ†æã€ç»“æ„åŒ–æ€è€ƒ'
            },
            
            # æ¢ç´¢ç ”ç©¶å‹ç­–ç•¥ç‰¹å¾  
            'exploratory_investigative': {
                'primary_tools': ['web_search', 'tavily_search'],
                'secondary_tools': ['firecrawl_scrape'],
                'execution_pattern': 'parallel',  # å¹¶è¡Œæ‰§è¡Œ
                'confidence_threshold': 0.6,
                'description': 'æ·±å…¥è°ƒç ”ã€ä¿¡æ¯æ”¶é›†'
            },
            
            # æ‰¹åˆ¤è´¨ç–‘å‹ç­–ç•¥ç‰¹å¾
            'critical_questioning': {
                'primary_tools': ['idea_verification', 'text_analysis'],
                'secondary_tools': ['web_search'],
                'execution_pattern': 'validation_focused',
                'confidence_threshold': 0.8,
                'description': 'è´¨ç–‘åˆ†æã€é£é™©è¯„ä¼°'
            },
            
            # å®ç”¨å¯¼å‘å‹ç­–ç•¥ç‰¹å¾
            'practical_pragmatic': {
                'primary_tools': ['knowledge_query'],
                'secondary_tools': ['web_search'],
                'execution_pattern': 'direct',  # ç›´æ¥é«˜æ•ˆ
                'confidence_threshold': 0.5,
                'description': 'å®é™…å¯è¡Œã€æ•ˆç‡ä¼˜å…ˆ'
            },
            
            # åˆ›æ–°ç›´è§‰å‹ç­–ç•¥ç‰¹å¾
            'creative_innovative': {
                'primary_tools': [],  # ä¸»è¦ä¾é LLMåˆ›æ„ï¼Œå°‘ç”¨å·¥å…·
                'secondary_tools': ['web_search'],
                'execution_pattern': 'creative_direct',
                'confidence_threshold': 0.9,  # é«˜ç½®ä¿¡åº¦æ‰ä½¿ç”¨å·¥å…·
                'description': 'åˆ›é€ æ€§æ€ç»´ã€çªç ´å¸¸è§„'
            },
            
            # ç»¼åˆå…¨é¢å‹ç­–ç•¥ç‰¹å¾
            'holistic_comprehensive': {
                'primary_tools': ['web_search', 'knowledge_query', 'data_analysis'],
                'secondary_tools': ['idea_verification'],
                'execution_pattern': 'comprehensive',
                'confidence_threshold': 0.6,
                'description': 'æ•´ä½“è€ƒè™‘ã€å…¨å±€æ€ç»´'
            },
            
            # ğŸš¨ æ–°å¢ï¼šåˆ›æ–°ç»•é“æ€è€ƒç­–ç•¥ç‰¹å¾
            'åˆ›æ–°ç»•é“æ€è€ƒ': {
                'primary_tools': [],  # ä¸»è¦ä¾é ç›´æ¥å›ç­”ï¼Œé¿å…è¿‡åº¦å·¥å…·åŒ–
                'secondary_tools': ['knowledge_query'],
                'execution_pattern': 'direct_creative',  # åˆ›æ–°ç›´æ¥å›ç­”æ¨¡å¼
                'confidence_threshold': 0.3,  # ä½é˜ˆå€¼ï¼Œä¼˜å…ˆç›´æ¥å›ç­”
                'description': 'çªç ´å¸¸è§„ï¼Œåˆ›æ–°æ€ç»´å›ç­”'
            },
            
            # è‡ªé€‚åº”çµæ´»å‹ç­–ç•¥ç‰¹å¾
            'adaptive_flexible': {
                'primary_tools': [],  # æ ¹æ®æƒ…å†µçµæ´»é€‰æ‹©
                'secondary_tools': ['knowledge_query', 'web_search'],
                'execution_pattern': 'adaptive_direct',
                'confidence_threshold': 0.4,
                'description': 'çµæ´»é€‚åº”ã€å› æƒ…è€Œå˜'
            }
        }
        
        # æŸ¥è¯¢ä¸Šä¸‹æ–‡åˆ†æå™¨
        self.context_analyzers = {
            'domain_specific': self._analyze_domain_context,
            'urgency_level': self._analyze_urgency_context,
            'complexity_level': self._analyze_complexity_context
        }
        
        logger.info("ğŸ§  ç­–ç•¥è§£é‡Šå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def interpret_strategy_to_actions(self, chosen_path, query: str, 
                                    mab_confidence: float, decision_context: Dict) -> List:
        """
        æ ¸å¿ƒæ–¹æ³•ï¼šå°†é€‰ä¸­çš„æ€ç»´è·¯å¾„ç­–ç•¥è§£é‡Šä¸ºå…·ä½“çš„å·¥å…·è°ƒç”¨è¡ŒåŠ¨
        
        Args:
            chosen_path: MABé€‰ä¸­çš„æœ€ä¼˜æ€ç»´è·¯å¾„
            query: åŸå§‹ç”¨æˆ·æŸ¥è¯¢
            mab_confidence: MABå¯¹è¿™ä¸ªé€‰æ‹©çš„ç½®ä¿¡åº¦
            decision_context: å†³ç­–ä¸Šä¸‹æ–‡
            
        Returns:
            å…·ä½“çš„Actionåˆ—è¡¨
        """
        logger.info(f"ğŸ¯ å¼€å§‹ç­–ç•¥è§£é‡Š: {chosen_path.path_type}")
        logger.info(f"   MABç½®ä¿¡åº¦: {mab_confidence:.2f}")
        
        # 1. è·å–ç­–ç•¥ç‰¹å¾
        strategy_features = self._extract_strategy_features(chosen_path)
        
        # 2. åˆ†ææŸ¥è¯¢ä¸Šä¸‹æ–‡
        query_context = self._analyze_query_context(query, decision_context)
        
        # 3. ç­–ç•¥é€‚é…å†³ç­–
        action_strategy = self._decide_action_strategy(
            strategy_features, query_context, mab_confidence
        )
        
        # 4. ç”Ÿæˆå…·ä½“è¡ŒåŠ¨
        actions = self._generate_concrete_actions(
            action_strategy, chosen_path, query, query_context
        )
        
        logger.info(f"âœ… ç­–ç•¥è§£é‡Šå®Œæˆ: ç”Ÿæˆ {len(actions)} ä¸ªè¡ŒåŠ¨")
        return actions
    
    def _extract_strategy_features(self, chosen_path) -> Dict[str, Any]:
        """æå–æ€ç»´è·¯å¾„çš„ç­–ç•¥ç‰¹å¾"""
        path_type = chosen_path.path_type.lower()
        
        # ä»æ˜ å°„è¡¨è·å–ç­–ç•¥ç‰¹å¾
        if path_type in self.strategy_feature_mappings:
            base_features = self.strategy_feature_mappings[path_type].copy()
        else:
            # æœªçŸ¥ç­–ç•¥ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤ç‰¹å¾
            logger.warning(f"âš ï¸ æœªçŸ¥ç­–ç•¥ç±»å‹: {path_type}ï¼Œä½¿ç”¨é»˜è®¤ç‰¹å¾")
            base_features = self.strategy_feature_mappings['practical_pragmatic'].copy()
        
        # å¢å¼ºç‰¹å¾ï¼šåˆ†æè·¯å¾„æè¿°ä¸­çš„è¯­ä¹‰ä¿¡æ¯
        description_features = self._analyze_path_description(chosen_path.description)
        base_features.update(description_features)
        
        # å¢å¼ºç‰¹å¾ï¼šä»prompt_templateä¸­æå–æ‰§è¡Œæç¤º
        template_features = self._analyze_prompt_template(getattr(chosen_path, 'prompt_template', ''))
        base_features.update(template_features)
        
        return base_features
    
    def _analyze_path_description(self, description: str) -> Dict[str, Any]:
        """åˆ†æè·¯å¾„æè¿°ä¸­çš„è¯­ä¹‰ç‰¹å¾"""
        features = {}
        description_lower = description.lower() if description else ""
        
        # ä¿¡æ¯æ”¶é›†å€¾å‘åˆ†æ
        if any(word in description_lower for word in ['æœç´¢', 'è°ƒç ”', 'æ¢ç´¢', 'æ”¶é›†', 'æŸ¥æ‰¾']):
            features['requires_information_gathering'] = True
            features['information_depth'] = 'deep' if 'æ·±å…¥' in description_lower else 'surface'
        
        # éªŒè¯éœ€æ±‚åˆ†æ
        if any(word in description_lower for word in ['éªŒè¯', 'ç¡®è®¤', 'æ£€æŸ¥', 'å®¡æŸ¥', 'è´¨ç–‘']):
            features['requires_verification'] = True
            features['verification_strictness'] = 'high' if 'ä¸¥æ ¼' in description_lower else 'moderate'
        
        # åˆ›æ–°éœ€æ±‚åˆ†æ
        if any(word in description_lower for word in ['åˆ›æ–°', 'åˆ›æ„', 'çªç ´', 'æ–°é¢–']):
            features['innovation_focus'] = True
            features['tool_dependency'] = 'low'  # åˆ›æ–°å‹è·¯å¾„è¾ƒå°‘ä¾èµ–å·¥å…·
        
        return features
    
    def _analyze_prompt_template(self, prompt_template: str) -> Dict[str, Any]:
        """åˆ†ææç¤ºæ¨¡æ¿ä¸­çš„æ‰§è¡ŒæŒ‡ç¤º"""
        features = {}
        template_lower = prompt_template.lower() if prompt_template else ""
        
        # åˆ†ææ¨¡æ¿ä¸­çš„å·¥å…·ä½¿ç”¨æš—ç¤º
        if 'æœç´¢' in template_lower or 'search' in template_lower:
            features['template_suggests_search'] = True
        
        if 'åˆ†æ' in template_lower or 'analyze' in template_lower:
            features['template_suggests_analysis'] = True
            
        if 'éªŒè¯' in template_lower or 'verify' in template_lower:
            features['template_suggests_verification'] = True
        
        return features
    
    def _analyze_query_context(self, query: str, decision_context: Dict) -> Dict[str, Any]:
        """ç»¼åˆåˆ†ææŸ¥è¯¢ä¸Šä¸‹æ–‡"""
        context = {}
        
        # åº”ç”¨æ‰€æœ‰ä¸Šä¸‹æ–‡åˆ†æå™¨
        for analyzer_name, analyzer_func in self.context_analyzers.items():
            try:
                context[analyzer_name] = analyzer_func(query, decision_context)
            except Exception as e:
                logger.warning(f"âš ï¸ ä¸Šä¸‹æ–‡åˆ†æå™¨ {analyzer_name} å¤±è´¥: {e}")
                context[analyzer_name] = {}
        
        return context
    
    def _analyze_domain_context(self, query: str, context: Dict) -> Dict[str, Any]:
        """åˆ†æé¢†åŸŸä¸Šä¸‹æ–‡"""
        query_lower = query.lower()
        
        domain_indicators = {
            'technical': ['æŠ€æœ¯', 'ç¼–ç¨‹', 'ä»£ç ', 'ç®—æ³•', 'ç³»ç»Ÿ', 'python', 'java'],
            'business': ['å•†ä¸š', 'å•†åŠ¡', 'å¸‚åœº', 'è¥é”€', 'é”€å”®', 'ç®¡ç†'],
            'academic': ['å­¦æœ¯', 'ç ”ç©¶', 'è®ºæ–‡', 'ç†è®º', 'åˆ†æ'],
            'general': []  # é»˜è®¤
        }
        
        for domain, keywords in domain_indicators.items():
            if any(keyword in query_lower for keyword in keywords):
                return {'domain': domain, 'specificity': 'high'}
        
        return {'domain': 'general', 'specificity': 'low'}
    
    def _analyze_urgency_context(self, query: str, context: Dict) -> Dict[str, Any]:
        """åˆ†æç´§æ€¥ç¨‹åº¦ä¸Šä¸‹æ–‡"""
        urgency_keywords = {
            'high': ['ç´§æ€¥', 'æ€¥éœ€', 'ç«‹å³', 'é©¬ä¸Š', 'urgent', 'asap'],
            'medium': ['å°½å¿«', 'è¾ƒå¿«', 'soon'],
            'low': ['ä»€ä¹ˆæ—¶å€™', 'æœ‰æ—¶é—´', 'æ…¢æ…¢']
        }
        
        query_lower = query.lower()
        for level, keywords in urgency_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                return {'level': level}
        
        return {'level': 'medium'}  # é»˜è®¤ä¸­ç­‰ç´§æ€¥ç¨‹åº¦
    
    def _analyze_complexity_context(self, query: str, context: Dict) -> Dict[str, Any]:
        """åˆ†æå¤æ‚ç¨‹åº¦ä¸Šä¸‹æ–‡"""
        # åŸºäºæŸ¥è¯¢é•¿åº¦å’Œå¤æ‚åº¦æŒ‡æ ‡è¯„ä¼°
        complexity_score = 0
        
        # é•¿åº¦å› ç´ 
        if len(query) > 100:
            complexity_score += 2
        elif len(query) > 50:
            complexity_score += 1
        
        # å¤æ‚åº¦å…³é”®è¯
        complex_keywords = ['å¦‚ä½•å®ç°', 'è®¾è®¡æ–¹æ¡ˆ', 'æ¶æ„', 'ç³»ç»Ÿ', 'è¯¦ç»†', 'å…¨é¢']
        complexity_score += sum(1 for keyword in complex_keywords if keyword in query)
        
        if complexity_score >= 3:
            return {'level': 'high', 'requires_comprehensive_approach': True}
        elif complexity_score >= 1:
            return {'level': 'medium', 'requires_balanced_approach': True}
        else:
            return {'level': 'low', 'requires_simple_approach': True}
    
    def _decide_action_strategy(self, strategy_features: Dict, query_context: Dict, 
                              mab_confidence: float) -> Dict[str, Any]:
        """åŸºäºç­–ç•¥ç‰¹å¾å’ŒæŸ¥è¯¢ä¸Šä¸‹æ–‡å†³å®šè¡ŒåŠ¨ç­–ç•¥"""
        
        # åŸºç¡€å·¥å…·é€‰æ‹©
        primary_tools = strategy_features.get('primary_tools', [])
        secondary_tools = strategy_features.get('secondary_tools', [])
        
        # æ ¹æ®MABç½®ä¿¡åº¦è°ƒæ•´å·¥å…·ä½¿ç”¨ç­–ç•¥
        confidence_threshold = strategy_features.get('confidence_threshold', 0.6)
        
        if mab_confidence < confidence_threshold:
            # ä½ç½®ä¿¡åº¦ï¼šæ›´ä¿å®ˆï¼Œä½¿ç”¨æ›´å¤šéªŒè¯å·¥å…·
            logger.info(f"ğŸ” MABç½®ä¿¡åº¦ ({mab_confidence:.2f}) ä½äºé˜ˆå€¼ ({confidence_threshold})ï¼Œé‡‡ç”¨ä¿å®ˆç­–ç•¥")
            if 'idea_verification' not in primary_tools:
                secondary_tools.append('idea_verification')
        
        # æ ¹æ®æŸ¥è¯¢å¤æ‚åº¦è°ƒæ•´ç­–ç•¥
        complexity = query_context.get('complexity_level', {}).get('level', 'medium')
        if complexity == 'high':
            # é«˜å¤æ‚åº¦ï¼šä½¿ç”¨æ›´å…¨é¢çš„å·¥å…·ç»„åˆ
            if 'web_search' not in primary_tools:
                primary_tools.append('web_search')
            if strategy_features.get('execution_pattern') != 'creative_direct':
                primary_tools.append('data_analysis')
        
        # æ ¹æ®ç´§æ€¥ç¨‹åº¦è°ƒæ•´ç­–ç•¥
        urgency = query_context.get('urgency_level', {}).get('level', 'medium')
        execution_pattern = strategy_features.get('execution_pattern', 'sequential')
        
        if urgency == 'high':
            # é«˜ç´§æ€¥ï¼šä¼˜åŒ–æ‰§è¡Œæ¨¡å¼ï¼Œå‡å°‘å·¥å…·æ•°é‡
            execution_pattern = 'direct'
            primary_tools = primary_tools[:2]  # é™åˆ¶æœ€å¤š2ä¸ªä¸»è¦å·¥å…·
        
        return {
            'primary_tools': primary_tools,
            'secondary_tools': secondary_tools,
            'execution_pattern': execution_pattern,
            'max_parallel_tools': 3 if urgency != 'high' else 1,
            'strategy_confidence': mab_confidence,
            'context_factors': {
                'complexity': complexity,
                'urgency': urgency,
                'domain': query_context.get('domain_specific', {}).get('domain', 'general')
            }
        }
    
    def _generate_concrete_actions(self, action_strategy: Dict, chosen_path, 
                                 query: str, query_context: Dict) -> List:
        """ç”Ÿæˆå…·ä½“çš„å·¥å…·è°ƒç”¨è¡ŒåŠ¨"""
        try:
            from neogenesis_system.abstractions import Action
        except ImportError:
            # å›é€€åˆ°ç®€å•çš„Actionå®šä¹‰
            class Action:
                def __init__(self, tool_name, tool_input):
                    self.tool_name = tool_name
                    self.tool_input = tool_input
                    self.execution_mode = 'sequential'
        
        actions = []
        primary_tools = action_strategy['primary_tools']
        execution_pattern = action_strategy['execution_pattern']
        
        logger.info(f"ğŸ”§ ç”Ÿæˆå…·ä½“è¡ŒåŠ¨: {len(primary_tools)} ä¸ªä¸»è¦å·¥å…·")
        logger.info(f"   æ‰§è¡Œæ¨¡å¼: {execution_pattern}")
        
        # ğŸš¨ æ–°å¢ï¼šå¯¹ç‰¹å®šæ‰§è¡Œæ¨¡å¼ä¼˜å…ˆé€‰æ‹©ç›´æ¥å›ç­”
        if execution_pattern in ['direct_creative', 'adaptive_direct', 'creative_direct']:
            logger.info(f"ğŸ¯ æ£€æµ‹åˆ°ç›´æ¥å›ç­”ä¼˜å…ˆæ¨¡å¼: {execution_pattern}")
            # è¿”å›ç©ºçš„actionsåˆ—è¡¨ï¼Œè®©plannerä½¿ç”¨ç›´æ¥å›ç­”
            return []
        
        for tool_name in primary_tools:
            try:
                action = self._create_tool_action(tool_name, query, chosen_path, query_context)
                if action:
                    actions.append(action)
            except Exception as e:
                logger.warning(f"âš ï¸ åˆ›å»ºå·¥å…·è¡ŒåŠ¨å¤±è´¥ {tool_name}: {e}")
        
        # æ ¹æ®æ‰§è¡Œæ¨¡å¼è°ƒæ•´è¡ŒåŠ¨å±æ€§
        if execution_pattern == 'parallel' and len(actions) > 1:
            # æ ‡è®°ä¸ºå¯å¹¶è¡Œæ‰§è¡Œ
            for action in actions:
                if hasattr(action, 'execution_mode'):
                    action.execution_mode = 'parallel'
        
        return actions
    
    def _create_tool_action(self, tool_name: str, query: str, chosen_path,
                          query_context: Dict):
        """ä¸ºç‰¹å®šå·¥å…·åˆ›å»ºè¡ŒåŠ¨"""
        try:
            from neogenesis_system.abstractions import Action
        except ImportError:
            class Action:
                def __init__(self, tool_name, tool_input):
                    self.tool_name = tool_name
                    self.tool_input = tool_input
        
        # æ ¹æ®å·¥å…·ç±»å‹ç”Ÿæˆåˆé€‚çš„è¾“å…¥å‚æ•°
        if tool_name == 'web_search' or tool_name == 'tavily_search':
            search_query = self._optimize_search_query(query, chosen_path, query_context)
            return Action(tool_name, {"query": search_query, "max_results": 5})
        
        elif tool_name == 'idea_verification':
            idea_to_verify = self._extract_verification_target(query, chosen_path)
            return Action(tool_name, {"idea_text": idea_to_verify})
        
        elif tool_name == 'knowledge_query':
            topic = self._extract_knowledge_topic(query, chosen_path)
            return Action(tool_name, {"topic": topic})
        
        elif tool_name == 'data_analysis':
            return Action(tool_name, {
                "data_type": "text",
                "data": query,
                "analysis_type": "comprehensive"
            })
        
        else:
            logger.warning(f"âš ï¸ æœªçŸ¥å·¥å…·ç±»å‹: {tool_name}")
            return None
    
    def _optimize_search_query(self, original_query: str, chosen_path, query_context: Dict) -> str:
        """ä¼˜åŒ–æœç´¢æŸ¥è¯¢"""
        # åŸºç¡€æŸ¥è¯¢
        optimized_query = original_query
        
        # æ ¹æ®ç­–ç•¥ç±»å‹ä¼˜åŒ–
        if chosen_path.path_type == 'exploratory_investigative':
            optimized_query += " æ·±å…¥åˆ†æ æœ€æ–°å‘å±•"
        elif chosen_path.path_type == 'critical_questioning':
            optimized_query += " é£é™© æŒ‘æˆ˜ é—®é¢˜"
        elif chosen_path.path_type == 'systematic_analytical':
            optimized_query += " ç³»ç»Ÿæ–¹æ³• è§£å†³æ–¹æ¡ˆ"
        
        # æ ¹æ®é¢†åŸŸä¼˜åŒ–
        domain = query_context.get('domain_specific', {}).get('domain', 'general')
        if domain == 'technical':
            optimized_query += " æŠ€æœ¯å®ç°"
        elif domain == 'business':
            optimized_query += " å•†ä¸šåº”ç”¨"
        
        return optimized_query
    
    def _extract_verification_target(self, query: str, chosen_path) -> str:
        """æå–éœ€è¦éªŒè¯çš„ç›®æ ‡"""
        # å¦‚æœæŸ¥è¯¢ä¸­åŒ…å«æ˜ç¡®çš„æƒ³æ³•æˆ–æ–¹æ¡ˆï¼Œæå–å‡ºæ¥
        verification_phrases = ['è¿™ä¸ªæƒ³æ³•', 'è¿™ä¸ªæ–¹æ¡ˆ', 'è¿™ç§æ–¹æ³•', 'å¯è¡Œå—', 'æ˜¯å¦å¯è¡Œ']
        
        for phrase in verification_phrases:
            if phrase in query:
                return query
        
        # å¦åˆ™åŸºäºè·¯å¾„ç±»å‹æ„é€ éªŒè¯ç›®æ ‡
        return f"å…³äº'{query}'çš„å¯è¡Œæ€§å’Œæ½œåœ¨é£é™©"
    
    def _extract_knowledge_topic(self, query: str, chosen_path) -> str:
        """æå–çŸ¥è¯†æŸ¥è¯¢ä¸»é¢˜"""
        return query[:100]  # é™åˆ¶é•¿åº¦
    
    def _extract_analysis_target(self, query: str) -> str:
        """æå–åˆ†æç›®æ ‡"""
        return query


class ImprovedMockNeogenesisPlanner:
    """
    æ”¹è¿›çš„Mockè§„åˆ’å™¨ - åœ¨ç®€åŒ–ç¯å¢ƒä¸‹ä¹Ÿä½“ç°å¤šé˜¶æ®µå†³ç­–æ€æƒ³
    
    å³ä½¿åœ¨Mockç¯å¢ƒä¸­ï¼Œä¹Ÿè¦ä½“ç°:
    1. ç­–ç•¥ç”Ÿæˆ (ç®€åŒ–ç‰ˆPathGenerator)
    2. ç­–ç•¥é€‰æ‹© (ç®€åŒ–ç‰ˆMAB)  
    3. ç­–ç•¥è§£æ (ä½¿ç”¨StrategyInterpreter)
    """
    
    def __init__(self):
        self.name = "ImprovedMockNeogenesisPlanner"
        self.strategy_interpreter = StrategyInterpreter()
        
        # ç®€åŒ–çš„ç­–ç•¥æ¨¡æ¿
        self.mock_strategy_templates = {
            'search_focused': {
                'path_type': 'exploratory_investigative',
                'description': 'ä¿¡æ¯æœç´¢å’Œè°ƒç ”å¯¼å‘çš„ç­–ç•¥',
                'prompt_template': 'æ·±å…¥æœç´¢å’Œç ”ç©¶å…³äº{task}çš„ä¿¡æ¯',
                'trigger_keywords': ['æœç´¢', 'æŸ¥æ‰¾', 'ä¿¡æ¯', 'èµ„æ–™', 'äº†è§£', 'ä»€ä¹ˆæ˜¯']
            },
            'verification_focused': {
                'path_type': 'critical_questioning',
                'description': 'éªŒè¯å’Œè´¨ç–‘å¯¼å‘çš„ç­–ç•¥',
                'prompt_template': 'æ‰¹åˆ¤æ€§åˆ†æå’ŒéªŒè¯{task}çš„å¯è¡Œæ€§',
                'trigger_keywords': ['éªŒè¯', 'å¯è¡Œ', 'é£é™©', 'é—®é¢˜', 'ç¼ºç‚¹', 'æ˜¯å¦']
            },
            'analysis_focused': {
                'path_type': 'systematic_analytical',
                'description': 'ç³»ç»Ÿåˆ†æå¯¼å‘çš„ç­–ç•¥',
                'prompt_template': 'ç³»ç»Ÿæ€§åˆ†æ{task}çš„å„ä¸ªæ–¹é¢',
                'trigger_keywords': ['åˆ†æ', 'å¦‚ä½•', 'æ–¹æ³•', 'æ­¥éª¤', 'å®ç°', 'è®¾è®¡']
            },
            'direct_answer': {
                'path_type': 'practical_pragmatic',
                'description': 'å®ç”¨ç›´æ¥å›ç­”ç­–ç•¥',
                'prompt_template': 'åŸºäºç°æœ‰çŸ¥è¯†ç›´æ¥å›ç­”{task}',
                'trigger_keywords': ['ä½ å¥½', 'hello', 'ä»‹ç»', 'å¸®åŠ©']
            }
        }
        
        # ç®€åŒ–çš„é€‰æ‹©ç»Ÿè®¡ (æ¨¡æ‹ŸMAB)
        self.strategy_success_stats = {
            'search_focused': {'success_count': 10, 'total_count': 15},
            'verification_focused': {'success_count': 8, 'total_count': 12},
            'analysis_focused': {'success_count': 12, 'total_count': 18},
            'direct_answer': {'success_count': 20, 'total_count': 25}
        }
        
        logger.info("ğŸ¤– æ”¹è¿›çš„Mockè§„åˆ’å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def create_plan(self, query: str, memory, context=None):
        """æ”¹è¿›çš„è®¡åˆ’åˆ›å»º - ä½“ç°ç®€åŒ–çš„å¤šé˜¶æ®µå†³ç­–"""
        try:
            from neogenesis_system.abstractions import Plan
        except ImportError:
            class Plan:
                def __init__(self, thought, final_answer=None, actions=None):
                    self.thought = thought
                    self.final_answer = final_answer
                    self.actions = actions or []
                    self.is_direct_answer = final_answer is not None
        
        logger.info(f"ğŸ¤– Mockè§„åˆ’å™¨å¼€å§‹å¤šé˜¶æ®µå†³ç­–: {query[:50]}...")
        
        # é˜¶æ®µ1: ç­–ç•¥å€™é€‰ç”Ÿæˆ (ç®€åŒ–çš„PathGenerator)
        candidate_strategies = self._generate_candidate_strategies(query)
        logger.info(f"ğŸ§  ç”Ÿæˆç­–ç•¥å€™é€‰: {[s['path_type'] for s in candidate_strategies]}")
        
        # é˜¶æ®µ2: ç­–ç•¥é€‰æ‹© (ç®€åŒ–çš„MAB)
        chosen_strategy = self._select_best_strategy(candidate_strategies, query)
        logger.info(f"ğŸ¯ é€‰æ‹©ç­–ç•¥: {chosen_strategy['path_type']}")
        
        # é˜¶æ®µ3: ç­–ç•¥è§£æä¸ºè¡ŒåŠ¨ (ä½¿ç”¨StrategyInterpreter)
        mock_reasoning_path = self._create_mock_reasoning_path(chosen_strategy, query)
        
        # ä½¿ç”¨ç­–ç•¥è§£é‡Šå™¨ç”Ÿæˆè¡ŒåŠ¨
        try:
            actions = self.strategy_interpreter.interpret_strategy_to_actions(
                chosen_path=mock_reasoning_path,
                query=query,
                mab_confidence=0.8,  # Mockç½®ä¿¡åº¦
                decision_context=context or {}
            )
        except Exception as e:
            logger.warning(f"âš ï¸ ç­–ç•¥è§£é‡Šå™¨è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–é€»è¾‘: {e}")
            actions = self._fallback_action_generation(chosen_strategy, query)
        
        # æ„å»ºæœ€ç»ˆè®¡åˆ’
        if not actions:
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ¢å¤ç›´æ¥å›ç­”æ¨¡å¼ï¼Œé’ˆå¯¹ç®€å•é—®å€™å’Œä»‹ç»ç±»é—®é¢˜
            # é¿å…æ‰€æœ‰é—®é¢˜éƒ½è¢«å¼ºåˆ¶è¿›å…¥å·¥å…·æ‰§è¡Œè·¯å¾„
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç®€å•çš„ç›´æ¥å›ç­”ç±»å‹
            query_lower = query.lower().strip()
            is_simple_greeting = any(greeting in query_lower for greeting in ['ä½ å¥½', 'hello', 'hi', 'æ‚¨å¥½'])
            is_simple_intro = "ä»‹ç»" in query_lower and ("è‡ªå·±" in query_lower or "ä½ " in query_lower)
            is_simple_thanks = any(thanks in query_lower for thanks in ['è°¢è°¢', 'thanks', 'thank you', 'æ„Ÿè°¢'])
            is_simple_help = any(help_word in query_lower for help_word in ['å¸®åŠ©', 'èƒ½åšä»€ä¹ˆ', 'åŠŸèƒ½'])
            
            if is_simple_greeting or is_simple_intro or is_simple_thanks or is_simple_help:
                # ä½¿ç”¨ç›´æ¥å›ç­”æ¨¡å¼ - ä¸éœ€è¦å·¥å…·è°ƒç”¨
                return Plan(
                    thought=f"åŸºäºå¤šé˜¶æ®µå†³ç­–ï¼Œè¯†åˆ«ä¸ºç®€å•é—®å€™/ä»‹ç»ç±»æŸ¥è¯¢ï¼Œé€‰æ‹©ç›´æ¥å›ç­”ç­–ç•¥",
                    final_answer=self._generate_direct_answer_for_simple_query(query)
                )
            
            # å¯¹äºå…¶ä»–å¤æ‚é—®é¢˜ï¼Œç”Ÿæˆå·¥å…·è°ƒç”¨
            if chosen_strategy['path_type'] == 'practical_pragmatic':
                actions = [Action("knowledge_query", {"topic": query})]
            elif chosen_strategy['path_type'] == 'exploratory_investigative':
                actions = [Action("web_search", {"query": query})]
            elif chosen_strategy['path_type'] == 'critical_questioning':
                actions = [Action("idea_verification", {"idea_text": query})]
            else:
                # é»˜è®¤ä½¿ç”¨knowledge_queryå·¥å…·
                actions = [Action("knowledge_query", {"topic": query})]
        
        # å·¥å…·æ‰§è¡Œæ¨¡å¼
        return Plan(
            thought=f"åŸºäºå¤šé˜¶æ®µå†³ç­–ï¼Œé€‰æ‹©'{chosen_strategy['path_type']}'ç­–ç•¥ï¼Œé€šè¿‡å·¥å…·è°ƒç”¨ç”Ÿæˆä¸“ä¸šå›ç­”ï¼ˆ{len(actions)}ä¸ªè¡ŒåŠ¨ï¼‰",
            actions=actions
        )
    
    def _generate_direct_answer_for_simple_query(self, query: str) -> str:
        """ä¸ºç®€å•æŸ¥è¯¢ç”Ÿæˆç›´æ¥å›ç­”"""
        query_lower = query.lower().strip()
        
        # é—®å€™ç±»
        if any(greeting in query_lower for greeting in ['ä½ å¥½', 'hello', 'hi', 'æ‚¨å¥½']):
            return "ä½ å¥½ï¼æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"
        
        # ä»‹ç»ç±»  
        if "ä»‹ç»" in query_lower and ("è‡ªå·±" in query_lower or "ä½ " in query_lower):
            return "æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œä¿¡æ¯æŸ¥è¯¢ã€é—®é¢˜åˆ†æã€åˆ›æ„æ€è€ƒç­‰å¤šç§ä»»åŠ¡ã€‚æˆ‘ä¼šæ ¹æ®ä¸åŒé—®é¢˜æ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„å¤„ç†æ–¹å¼ï¼Œä¸ºæ‚¨æä¾›å‡†ç¡®æœ‰ç”¨çš„å¸®åŠ©ã€‚"
        
        # æ„Ÿè°¢ç±»
        if any(thanks in query_lower for thanks in ['è°¢è°¢', 'thanks', 'thank you', 'æ„Ÿè°¢']):
            return "ä¸å®¢æ°”ï¼å¦‚æœè¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘ã€‚"
        
        # åŠŸèƒ½æŸ¥è¯¢ç±»
        if any(help_word in query_lower for help_word in ['å¸®åŠ©', 'èƒ½åšä»€ä¹ˆ', 'åŠŸèƒ½']):
            return "æˆ‘å¯ä»¥å¸®æ‚¨æœç´¢ä¿¡æ¯ã€åˆ†æé—®é¢˜ã€éªŒè¯æƒ³æ³•ã€å›ç­”å„é¢†åŸŸé—®é¢˜ç­‰ã€‚æˆ‘çš„ç‰¹ç‚¹æ˜¯èƒ½æ ¹æ®ä¸åŒé—®é¢˜æ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„å¤„ç†æ–¹å¼ï¼Œä¸ºæ‚¨æä¾›æœ‰ä»·å€¼çš„å¸®åŠ©ã€‚"
        
        # é»˜è®¤å›ç­” - ä½¿ç”¨LLMæˆ–è¯šå®è¯´æ˜é™åˆ¶ï¼Œé¿å…é¢„è®¾æ¨¡æ¿
        try:
            # å°è¯•ä½¿ç”¨LLMç”Ÿæˆç®€æ´å›ç­”
            from neogenesis_system.providers.impl.deepseek_client import DeepSeekClient, ClientConfig
            import os
            
            api_key = os.getenv('DEEPSEEK_API_KEY') or os.getenv('NEOGENESIS_API_KEY')
            if api_key:
                client_config = ClientConfig(
                    api_key=api_key,
                    model="deepseek-chat",
                    temperature=0.7,
                    max_tokens=300
                )
                client = DeepSeekClient(client_config)
                
                prompt = f"""è¯·ç®€æ´å›ç­”ç”¨æˆ·é—®é¢˜ï¼š{query}

å¦‚æœæ— æ³•å‡†ç¡®å›ç­”ï¼Œè¯·è¯šå®è¯´æ˜é™åˆ¶ã€‚ä¿æŒå‹å¥½è¯­æ°”ï¼š"""
                
                api_response = client.simple_chat(prompt=prompt, max_tokens=300, temperature=0.7)
                llm_response = api_response.content if hasattr(api_response, 'content') else str(api_response)
                
                if llm_response and llm_response.strip():
                    return llm_response.strip()
                    
        except Exception as e:
            logger.warning(f"âš ï¸ ç­–ç•¥è§£é‡Šå™¨é»˜è®¤LLMè°ƒç”¨å¤±è´¥: {e}")
        
        # æœ€ç»ˆè¯šå®å›ç­” - ä¸ä½¿ç”¨é¢„è®¾æ¨¡æ¿
        if "æ—¶é—´" in query_lower or "å‡ ç‚¹" in query_lower:
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è·å–å½“å‰çš„å®æ—¶æ—¶é—´ä¿¡æ¯ã€‚å»ºè®®æ‚¨æŸ¥çœ‹æ‚¨çš„è®¾å¤‡æ—¶é’Ÿæˆ–æœç´¢å¼•æ“è·å–å‡†ç¡®æ—¶é—´ã€‚"
        elif "å¤©æ°”" in query_lower:
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è·å–å®æ—¶å¤©æ°”ä¿¡æ¯ã€‚å»ºè®®æ‚¨æŸ¥çœ‹å¤©æ°”åº”ç”¨æˆ–ç½‘ç«™è·å–æœ€æ–°å¤©æ°”é¢„æŠ¥ã€‚"
        else:
            return f"å…³äºæ‚¨çš„é—®é¢˜ã€Œ{query}ã€ï¼Œæˆ‘å¾ˆæ„¿æ„å¸®åŠ©æ‚¨ï¼Œä½†æˆ‘å¯èƒ½éœ€è¦æ›´å¤šä¿¡æ¯æ‰èƒ½æä¾›å‡†ç¡®çš„å›ç­”ã€‚è¯·é—®æ‚¨èƒ½æä¾›æ›´å¤šå…·ä½“ç»†èŠ‚å—ï¼Ÿ"

    def _generate_candidate_strategies(self, query: str) -> List[Dict]:
        """ç”Ÿæˆå€™é€‰ç­–ç•¥ - ç®€åŒ–ç‰ˆPathGenerator"""
        candidates = []
        query_lower = query.lower()
        
        # ä¸ºæ¯ä¸ªç­–ç•¥æ¨¡æ¿è®¡ç®—ç›¸å…³åº¦
        for strategy_id, template in self.mock_strategy_templates.items():
            relevance_score = 0
            
            # åŸºäºå…³é”®è¯åŒ¹é…è®¡ç®—ç›¸å…³åº¦
            for keyword in template['trigger_keywords']:
                if keyword in query_lower:
                    relevance_score += 1
            
            # æ ‡å‡†åŒ–ç›¸å…³åº¦åˆ†æ•°
            max_possible_score = len(template['trigger_keywords'])
            normalized_score = relevance_score / max_possible_score if max_possible_score > 0 else 0.1
            
            candidates.append({
                'strategy_id': strategy_id,
                'relevance_score': normalized_score,
                **template
            })
        
        # æŒ‰ç›¸å…³åº¦æ’åº
        candidates.sort(key=lambda x: x['relevance_score'], reverse=True)
        
        # è¿”å›å‰3ä¸ªæœ€ç›¸å…³çš„ç­–ç•¥
        return candidates[:3]
    
    def _select_best_strategy(self, candidates: List[Dict], query: str) -> Dict:
        """é€‰æ‹©æœ€ä½³ç­–ç•¥ - ç®€åŒ–ç‰ˆMAB"""
        if not candidates:
            return self.mock_strategy_templates['direct_answer']
        
        best_strategy = None
        best_score = -1
        
        for candidate in candidates:
            strategy_id = candidate['strategy_id']
            
            # è·å–å†å²æˆåŠŸç‡ (æ¨¡æ‹ŸMABæ•°æ®)
            stats = self.strategy_success_stats.get(strategy_id, {'success_count': 1, 'total_count': 2})
            success_rate = stats['success_count'] / stats['total_count']
            
            # ç»“åˆç›¸å…³åº¦å’ŒæˆåŠŸç‡ (ç®€åŒ–çš„UCBç®—æ³•)
            exploration_bonus = 0.1  # ç®€åŒ–çš„æ¢ç´¢å¥–åŠ±
            combined_score = (
                candidate['relevance_score'] * 0.6 +  # ç›¸å…³åº¦æƒé‡
                success_rate * 0.3 +                  # æˆåŠŸç‡æƒé‡
                exploration_bonus * 0.1               # æ¢ç´¢å¥–åŠ±æƒé‡
            )
            
            if combined_score > best_score:
                best_score = combined_score
                best_strategy = candidate
        
        # æ›´æ–°é€‰æ‹©ç»Ÿè®¡ (æ¨¡æ‹ŸMABå­¦ä¹ )
        if best_strategy:
            strategy_id = best_strategy['strategy_id']
            self.strategy_success_stats[strategy_id]['total_count'] += 1
        
        return best_strategy or self.mock_strategy_templates['direct_answer']
    
    def _create_mock_reasoning_path(self, strategy: Dict, query: str):
        """åˆ›å»ºMockçš„ReasoningPathå¯¹è±¡"""
        try:
            from neogenesis_system.cognitive_engine.path_generator import ReasoningPath
        except ImportError:
            # ç®€å•çš„Mock ReasoningPath
            class ReasoningPath:
                def __init__(self, path_id, path_type, description, prompt_template, strategy_id):
                    self.path_id = path_id
                    self.path_type = path_type
                    self.description = description
                    self.prompt_template = prompt_template
                    self.strategy_id = strategy_id
        
        return ReasoningPath(
            path_id=f"mock_{strategy['strategy_id']}",
            path_type=strategy['path_type'],
            description=strategy['description'],
            prompt_template=strategy['prompt_template'].format(task=query),
            strategy_id=strategy['strategy_id']
        )
    
    def _fallback_action_generation(self, strategy: Dict, query: str) -> List:
        """ç®€åŒ–çš„è¡ŒåŠ¨ç”Ÿæˆå›é€€é€»è¾‘"""
        try:
            from neogenesis_system.abstractions import Action
        except ImportError:
            class Action:
                def __init__(self, tool_name, tool_input):
                    self.tool_name = tool_name
                    self.tool_input = tool_input
        
        actions = []
        strategy_type = strategy['path_type']
        
        if strategy_type == 'exploratory_investigative':
            actions.append(Action("web_search", {"query": query}))
        elif strategy_type == 'critical_questioning':
            actions.append(Action("idea_verification", {"idea_text": query}))
        elif strategy_type == 'systematic_analytical':
            actions.append(Action("knowledge_query", {"topic": query}))
        
        return actions
    
    def _generate_mock_direct_answer(self, strategy: Dict, query: str) -> str:
        """ç”ŸæˆMockç›´æ¥å›ç­” - ç§»é™¤é¢„è®¾å›ç­”ï¼Œç¡®ä¿ä½¿ç”¨çœŸå®çš„å¤šå†³ç­–é“¾æ¡"""
        strategy_type = strategy['path_type']
        
        # ğŸ”§ é‡è¦ä¿®æ”¹ï¼šç§»é™¤æ‰€æœ‰é¢„è®¾å›ç­”ï¼ŒåŒ…æ‹¬é—®å€™è¯­çš„é¢„è®¾å›å¤
        # ç¡®ä¿æ‰€æœ‰é—®é¢˜éƒ½é€šè¿‡çœŸæ­£çš„å¤šé˜¶æ®µå†³ç­–å’Œå·¥å…·è°ƒç”¨æ¥å¤„ç†
        
        # ä¸å†æä¾›é¢„è®¾çš„é—®å€™å›ç­”ï¼Œè€Œæ˜¯è¿”å›Noneæˆ–ç©ºå­—ç¬¦ä¸²ï¼Œ
        # è¿™æ ·ä¼šå¼ºåˆ¶ç³»ç»Ÿä½¿ç”¨å·¥å…·æ‰§è¡Œæµç¨‹
        return ""  # è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œå¼ºåˆ¶èµ°å·¥å…·æ‰§è¡Œæµç¨‹
    
    def validate_plan(self, plan):
        """éªŒè¯è®¡åˆ’"""
        return True
    
    def get_stats(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "name": self.name,
            "total_rounds": 0,
            "strategy_success_stats": self.strategy_success_stats
        }
