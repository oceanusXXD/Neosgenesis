#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Neogenesisæ™ºèƒ½è§„åˆ’å™¨ - åŸºäºMeta MABçš„é«˜çº§è§„åˆ’ç³»ç»Ÿ
å°†MainControllerçš„äº”é˜¶æ®µæ™ºèƒ½å†³ç­–é€»è¾‘é‡æ„ä¸ºç¬¦åˆæ¡†æ¶æ ‡å‡†çš„è§„åˆ’å™¨ç»„ä»¶

æ ¸å¿ƒç‰¹æ€§:
1. äº”é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–æµç¨‹
2. ä¾èµ–æ³¨å…¥å¼ç»„ä»¶åä½œ
3. æ ‡å‡†Planè¾“å‡ºæ ¼å¼
4. æ™ºèƒ½å†³ç­–ç»“æœç¿»è¯‘
"""

import time
import logging
from typing import Dict, List, Optional, Any

# å¯¼å…¥æ¡†æ¶æ ¸å¿ƒ
try:
    from ..abstractions import BasePlanner
    from ..shared.data_structures import Plan, Action
except ImportError:
    from neogenesis_system.abstractions import BasePlanner
    from neogenesis_system.shared.data_structures import Plan, Action

# å¯¼å…¥Meta MABç»„ä»¶
from ..cognitive_engine.reasoner import PriorReasoner
from ..cognitive_engine.path_generator import PathGenerator
from ..cognitive_engine.mab_converger import MABConverger
from ..cognitive_engine.data_structures import DecisionResult, ReasoningPath
from ..shared.state_manager import StateManager

# å¯¼å…¥å·¥å…·ç³»ç»Ÿ
from ..tools.tool_abstraction import (
    ToolRegistry, 
    global_tool_registry,
    execute_tool,
    ToolResult
)

logger = logging.getLogger(__name__)


class NeogenesisPlanner(BasePlanner):
    """
    Neogenesisæ™ºèƒ½è§„åˆ’å™¨
    
    å°†MainControllerçš„äº”é˜¶æ®µå†³ç­–é€»è¾‘é‡æ„ä¸ºæ ‡å‡†è§„åˆ’å™¨ç»„ä»¶ï¼š
    1. æ€ç»´ç§å­ç”Ÿæˆ (PriorReasoner)
    2. ç§å­éªŒè¯æ£€æŸ¥ (idea_verification)
    3. æ€ç»´è·¯å¾„ç”Ÿæˆ (PathGenerator)
    4. è·¯å¾„éªŒè¯å­¦ä¹  (æ ¸å¿ƒåˆ›æ–°)
    5. æ™ºèƒ½æœ€ç»ˆå†³ç­– (å‡çº§ç‰ˆMAB)
    """
    
    def __init__(self, 
                 prior_reasoner: PriorReasoner,
                 path_generator: PathGenerator,
                 mab_converger: MABConverger,
                 tool_registry: Optional[ToolRegistry] = None,
                 state_manager: Optional[StateManager] = None,
                 config: Optional[Dict] = None,
                 cognitive_scheduler=None):
        """
        ä¾èµ–æ³¨å…¥å¼åˆå§‹åŒ–
        
        Args:
            prior_reasoner: å…ˆéªŒæ¨ç†å™¨å®ä¾‹
            path_generator: è·¯å¾„ç”Ÿæˆå™¨å®ä¾‹  
            mab_converger: MABæ”¶æ•›å™¨å®ä¾‹
            tool_registry: å·¥å…·æ³¨å†Œè¡¨ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€æ³¨å†Œè¡¨ï¼‰
            state_manager: çŠ¶æ€ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰
            config: é…ç½®å­—å…¸ï¼ˆå¯é€‰ï¼‰
        """
        super().__init__(
            name="NeogenesisPlanner",
            description="åŸºäºMeta MABçš„äº”é˜¶æ®µæ™ºèƒ½è§„åˆ’å™¨"
        )
        
        # ä¾èµ–æ³¨å…¥çš„æ ¸å¿ƒç»„ä»¶
        self.prior_reasoner = prior_reasoner
        self.path_generator = path_generator
        self.mab_converger = mab_converger
        
        # å¯é€‰ç»„ä»¶
        self.tool_registry = tool_registry or global_tool_registry
        self.state_manager = state_manager
        self.config = config or {}
        
        # ğŸ§  è®¤çŸ¥è°ƒåº¦å™¨é›†æˆ
        self.cognitive_scheduler = cognitive_scheduler
        
        # ğŸ”§ å¦‚æœè®¤çŸ¥è°ƒåº¦å™¨å­˜åœ¨ï¼Œå°è¯•æ³¨å…¥å›æº¯å¼•æ“ä¾èµ–
        if self.cognitive_scheduler:
            self._inject_cognitive_dependencies()
        
        # å†…éƒ¨çŠ¶æ€
        self.total_rounds = 0
        self.decision_history = []
        self.performance_stats = {
            'total_decisions': 0,
            'avg_decision_time': 0.0,
            'component_performance': {
                'prior_reasoner': {'calls': 0, 'avg_time': 0.0},
                'path_generator': {'calls': 0, 'avg_time': 0.0},
                'mab_converger': {'calls': 0, 'avg_time': 0.0}
            }
        }
        
        logger.info(f"ğŸ§  NeogenesisPlanner åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   ç»„ä»¶: PriorReasoner, PathGenerator, MABConverger")
        try:
            tool_count = len(self.tool_registry.tools) if hasattr(self.tool_registry, 'tools') else len(getattr(self.tool_registry, '_tools', {}))
            logger.info(f"   å·¥å…·æ³¨å†Œè¡¨: {tool_count} ä¸ªå·¥å…·")
        except:
            logger.info(f"   å·¥å…·æ³¨å†Œè¡¨: å·²åˆå§‹åŒ–")
    
    def _inject_cognitive_dependencies(self):
        """å‘è®¤çŸ¥è°ƒåº¦å™¨æ³¨å…¥æ ¸å¿ƒä¾èµ–ç»„ä»¶"""
        try:
            if (self.cognitive_scheduler and 
                hasattr(self.cognitive_scheduler, 'update_retrospection_dependencies')):
                
                success = self.cognitive_scheduler.update_retrospection_dependencies(
                    path_generator=self.path_generator,
                    mab_converger=self.mab_converger
                )
                
                if success:
                    logger.info("âœ… å›æº¯å¼•æ“ä¾èµ–ç»„ä»¶å·²æˆåŠŸæ³¨å…¥")
                else:
                    logger.warning("âš ï¸ å›æº¯å¼•æ“ä¾èµ–ç»„ä»¶æ³¨å…¥å¤±è´¥")
            
        except Exception as e:
            logger.warning(f"âš ï¸ è®¤çŸ¥è°ƒåº¦å™¨ä¾èµ–æ³¨å…¥å¼‚å¸¸: {e}")
    
    def set_cognitive_scheduler(self, cognitive_scheduler):
        """è®¾ç½®è®¤çŸ¥è°ƒåº¦å™¨å¹¶è‡ªåŠ¨æ³¨å…¥ä¾èµ–ç»„ä»¶"""
        self.cognitive_scheduler = cognitive_scheduler
        if cognitive_scheduler:
            self._inject_cognitive_dependencies()
            logger.info("ğŸ§  è®¤çŸ¥è°ƒåº¦å™¨å·²è®¾ç½®å¹¶å®Œæˆä¾èµ–æ³¨å…¥")
    
    def create_plan(self, query: str, memory: Any, context: Optional[Dict[str, Any]] = None) -> Plan:
        """
        åˆ›å»ºæ‰§è¡Œè®¡åˆ’ - å®ç°BasePlanneræ¥å£
        
        è¿™æ˜¯è§„åˆ’å™¨çš„ä¸»è¦å…¥å£ç‚¹ï¼Œè°ƒç”¨å†…éƒ¨çš„äº”é˜¶æ®µå†³ç­–é€»è¾‘ï¼Œ
        ç„¶åå°†ç»“æœç¿»è¯‘ä¸ºæ ‡å‡†çš„Planæ ¼å¼ã€‚
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            memory: Agentçš„è®°å¿†å¯¹è±¡
            context: å¯é€‰çš„æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            Plan: æ ‡å‡†æ ¼å¼çš„æ‰§è¡Œè®¡åˆ’
        """
        logger.info(f"ğŸ¯ å¼€å§‹åˆ›å»ºè®¡åˆ’: {query[:50]}...")
        start_time = time.time()
        
        # ğŸ§  é€šçŸ¥è®¤çŸ¥è°ƒåº¦å™¨Agentæ­£åœ¨æ´»è·ƒå·¥ä½œ
        if self.cognitive_scheduler:
            self.cognitive_scheduler.notify_activity("task_planning", {
                "query": query[:100],
                "timestamp": start_time,
                "source": "create_plan"
            })
        
        try:
            # ğŸš€ è°ƒç”¨å†…éƒ¨äº”é˜¶æ®µå†³ç­–é€»è¾‘
            decision_result = self._make_decision_logic(
                user_query=query,
                deepseek_confidence=context.get('confidence', 0.5) if context else 0.5,
                execution_context=context
            )
            
            # ğŸ”„ å°†å†³ç­–ç»“æœç¿»è¯‘ä¸ºæ ‡å‡†Planæ ¼å¼
            plan = self._convert_decision_to_plan(decision_result, query)
            
            # ğŸ“Š æ›´æ–°æ€§èƒ½ç»Ÿè®¡
            execution_time = time.time() - start_time
            self._update_planner_stats(True, execution_time)
            
            logger.info(f"âœ… è®¡åˆ’åˆ›å»ºå®Œæˆ: {plan.action_count} ä¸ªè¡ŒåŠ¨, è€—æ—¶ {execution_time:.3f}s")
            return plan
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._update_planner_stats(False, execution_time)
            
            logger.error(f"âŒ è®¡åˆ’åˆ›å»ºå¤±è´¥: {e}")
            
            # è¿”å›é”™è¯¯å›é€€è®¡åˆ’
            return Plan(
                thought=f"è§„åˆ’è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}",
                final_answer=f"æŠ±æ­‰ï¼Œæˆ‘åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜: {str(e)}"
            )
    
    def validate_plan(self, plan: Plan) -> bool:
        """
        éªŒè¯è®¡åˆ’çš„æœ‰æ•ˆæ€§
        
        Args:
            plan: è¦éªŒè¯çš„è®¡åˆ’
            
        Returns:
            bool: è®¡åˆ’æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # æ£€æŸ¥åŸºæœ¬ç»“æ„
            if not plan.thought:
                return False
            
            # ç›´æ¥å›ç­”æ¨¡å¼
            if plan.is_direct_answer:
                return plan.final_answer is not None and len(plan.final_answer.strip()) > 0
            
            # å·¥å…·æ‰§è¡Œæ¨¡å¼
            if not plan.actions:
                return False
            
            # éªŒè¯æ‰€æœ‰è¡ŒåŠ¨
            for action in plan.actions:
                if not action.tool_name or not isinstance(action.tool_input, dict):
                    return False
                
                # æ£€æŸ¥å·¥å…·æ˜¯å¦å­˜åœ¨
                if self.tool_registry and not self.tool_registry.has_tool(action.tool_name):
                    logger.warning(f"âš ï¸ å·¥å…· '{action.tool_name}' æœªåœ¨æ³¨å†Œè¡¨ä¸­æ‰¾åˆ°")
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ è®¡åˆ’éªŒè¯å¤±è´¥: {e}")
            return False
    
    def _make_decision_logic(self, user_query: str, deepseek_confidence: float = 0.5, 
                           execution_context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        äº”é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–é€»è¾‘ï¼ˆä»MainControllerè¿ç§»ï¼‰
        
        è¿™æ˜¯åŸMainController.make_decisionæ–¹æ³•çš„æ ¸å¿ƒé€»è¾‘ï¼Œ
        å‡ ä¹åŸå°ä¸åŠ¨åœ°ä¿ç•™äº†æ‰€æœ‰åŠŸèƒ½ã€‚
        """
        start_time = time.time()
        self.total_rounds += 1
        
        logger.info(f"ğŸš€ å¼€å§‹ç¬¬ {self.total_rounds} è½®äº”é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–")
        logger.info(f"   æŸ¥è¯¢: {user_query[:50]}...")
        logger.info(f"   ç½®ä¿¡åº¦: {deepseek_confidence:.2f}")
        
        try:
            # ğŸ§  é˜¶æ®µä¸€ï¼šå…ˆéªŒæ¨ç† - ç”Ÿæˆæ€ç»´ç§å­
            reasoner_start = time.time()
            thinking_seed = self.prior_reasoner.get_thinking_seed(user_query, execution_context)
            
            # å…¼å®¹æ€§ï¼šè·å–æ—§æ ¼å¼æ•°æ®
            task_confidence = self.prior_reasoner.assess_task_confidence(user_query, execution_context)
            complexity_info = self.prior_reasoner.analyze_task_complexity(user_query)
            
            reasoner_time = time.time() - reasoner_start
            self._update_component_performance('prior_reasoner', reasoner_time)
            
            logger.info(f"ğŸ§  é˜¶æ®µä¸€å®Œæˆ: æ€ç»´ç§å­ç”Ÿæˆ (é•¿åº¦: {len(thinking_seed)} å­—ç¬¦)")
            
            # ğŸ” é˜¶æ®µäºŒï¼šéªŒè¯æ€ç»´ç§å­
            seed_verification_start = time.time()
            seed_verification_result = self._verify_idea_feasibility(
                idea_text=thinking_seed,
                context={
                    'stage': 'thinking_seed',
                    'domain': 'strategic_planning',
                    'query': user_query,
                    **(execution_context if execution_context else {})
                }
            )
            seed_verification_time = time.time() - seed_verification_start
            
            # åˆ†æç§å­éªŒè¯ç»“æœ
            seed_feasibility = seed_verification_result.get('feasibility_analysis', {}).get('feasibility_score', 0.5)
            seed_reward = seed_verification_result.get('reward_score', 0.0)
            
            logger.info(f"ğŸ” é˜¶æ®µäºŒå®Œæˆ: æ€ç»´ç§å­éªŒè¯ (å¯è¡Œæ€§: {seed_feasibility:.2f}, å¥–åŠ±: {seed_reward:+.3f})")
            
            # ğŸ›¤ï¸ é˜¶æ®µä¸‰ï¼šè·¯å¾„ç”Ÿæˆ
            generator_start = time.time()
            all_reasoning_paths = self.path_generator.generate_paths(
                thinking_seed=thinking_seed, 
                task=user_query,
                max_paths=6  # é™åˆ¶è·¯å¾„æ•°é‡ä»¥æé«˜æ€§èƒ½
            )
            generator_time = time.time() - generator_start
            self._update_component_performance('path_generator', generator_time)
            
            logger.info(f"ğŸ›¤ï¸ é˜¶æ®µä¸‰å®Œæˆ: ç”Ÿæˆäº† {len(all_reasoning_paths)} æ¡æ€ç»´è·¯å¾„")
            
            # ğŸš€ é˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯å­¦ä¹ 
            path_verification_start = time.time()
            verified_paths = []
            all_infeasible = True
            
            logger.info(f"ğŸ”¬ é˜¶æ®µå››å¼€å§‹: éªŒè¯æ€ç»´è·¯å¾„")
            
            # ç®€åŒ–ç‰ˆè·¯å¾„éªŒè¯ï¼ˆé¿å…å¤æ‚çš„å¹¶è¡Œå¤„ç†ï¼‰
            for i, path in enumerate(all_reasoning_paths, 1):
                logger.debug(f"ğŸ”¬ éªŒè¯è·¯å¾„ {i}/{len(all_reasoning_paths)}: {path.path_type}")
                
                # éªŒè¯å•ä¸ªè·¯å¾„
                path_verification_result = self._verify_idea_feasibility(
                    idea_text=f"{path.path_type}: {path.description}",
                    context={
                        'stage': 'reasoning_path',
                        'path_id': path.path_id,
                        'path_type': path.path_type,
                        'query': user_query,
                        **(execution_context if execution_context else {})
                    }
                )
                
                # æå–éªŒè¯ç»“æœ
                path_feasibility = path_verification_result.get('feasibility_analysis', {}).get('feasibility_score', 0.5)
                path_reward = path_verification_result.get('reward_score', 0.0)
                verification_success = not path_verification_result.get('fallback', False)
                
                # ğŸ’¡ å³æ—¶å­¦ä¹ ï¼šç«‹å³å°†éªŒè¯ç»“æœåé¦ˆç»™MABç³»ç»Ÿ
                if verification_success and path_feasibility > 0.3:
                    # å¯è¡Œçš„è·¯å¾„ - æ­£é¢å­¦ä¹ ä¿¡å·
                    self.mab_converger.update_path_performance(
                        path_id=path.strategy_id,
                        success=True,
                        reward=path_reward
                    )
                    all_infeasible = False
                    logger.debug(f"âœ… è·¯å¾„ {path.path_type} éªŒè¯é€šè¿‡: å¯è¡Œæ€§={path_feasibility:.2f}")
                else:
                    # ä¸å¯è¡Œçš„è·¯å¾„ - è´Ÿé¢å­¦ä¹ ä¿¡å·
                    self.mab_converger.update_path_performance(
                        path_id=path.strategy_id,
                        success=False,
                        reward=path_reward
                    )
                    logger.debug(f"âŒ è·¯å¾„ {path.path_type} éªŒè¯å¤±è´¥: å¯è¡Œæ€§={path_feasibility:.2f}")
                
                # è®°å½•éªŒè¯ç»“æœ
                verified_paths.append({
                    'path': path,
                    'verification_result': path_verification_result,
                    'feasibility_score': path_feasibility,
                    'reward_score': path_reward,
                    'is_feasible': path_feasibility > 0.3
                })
            
            path_verification_time = time.time() - path_verification_start
            feasible_count = sum(1 for vp in verified_paths if vp['is_feasible'])
            
            logger.info(f"ğŸ”¬ é˜¶æ®µå››å®Œæˆ: {feasible_count}/{len(all_reasoning_paths)} æ¡è·¯å¾„å¯è¡Œ")
            
            # ğŸ¯ é˜¶æ®µäº”ï¼šæ™ºèƒ½æœ€ç»ˆå†³ç­–
            final_decision_start = time.time()
            
            if all_infeasible:
                # ğŸš¨ æ‰€æœ‰è·¯å¾„éƒ½ä¸å¯è¡Œ - è§¦å‘æ™ºèƒ½ç»•é“æ€è€ƒ
                logger.warning("ğŸš¨ æ‰€æœ‰æ€ç»´è·¯å¾„éƒ½è¢«éªŒè¯ä¸ºä¸å¯è¡Œï¼Œè§¦å‘æ™ºèƒ½ç»•é“æ€è€ƒ")
                chosen_path = self._execute_intelligent_detour_thinking(
                    user_query, thinking_seed, all_reasoning_paths
                )
                selection_algorithm = 'intelligent_detour'
            else:
                # âœ… è‡³å°‘æœ‰å¯è¡Œè·¯å¾„ - ä½¿ç”¨å¢å¼ºçš„MABé€‰æ‹©
                logger.info("âœ… å‘ç°å¯è¡Œè·¯å¾„ï¼Œä½¿ç”¨éªŒè¯å¢å¼ºçš„MABå†³ç­–")
                chosen_path = self.mab_converger.select_best_path(all_reasoning_paths)
                selection_algorithm = 'verification_enhanced_mab'
            
            final_decision_time = time.time() - final_decision_start
            total_mab_time = path_verification_time + final_decision_time
            self._update_component_performance('mab_converger', total_mab_time)
            
            # è®¡ç®—æ€»ä½“å†³ç­–æ—¶é—´
            total_decision_time = time.time() - start_time
            
            # æ„å»ºå†³ç­–ç»“æœ
            decision_result = {
                # åŸºæœ¬ä¿¡æ¯
                'timestamp': time.time(),
                'round_number': self.total_rounds,
                'user_query': user_query,
                'deepseek_confidence': deepseek_confidence,
                'execution_context': execution_context,
                
                # äº”é˜¶æ®µå†³ç­–ç»“æœ
                'thinking_seed': thinking_seed,
                'seed_verification': seed_verification_result,
                'chosen_path': chosen_path,
                'available_paths': all_reasoning_paths,
                'verified_paths': verified_paths,
                
                # å†³ç­–å…ƒä¿¡æ¯
                'reasoning': f"äº”é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–: {chosen_path.path_type} - {chosen_path.description}",
                'path_count': len(all_reasoning_paths),
                'feasible_path_count': feasible_count,
                'selection_algorithm': selection_algorithm,
                'architecture_version': '5-stage-verification',
                'verification_enabled': True,
                'instant_learning_enabled': True,
                
                # éªŒè¯ç»Ÿè®¡
                'verification_stats': {
                    'seed_feasibility': seed_feasibility,
                    'seed_reward': seed_reward,
                    'paths_verified': len(verified_paths),
                    'feasible_paths': feasible_count,
                    'infeasible_paths': len(verified_paths) - feasible_count,
                    'all_paths_infeasible': all_infeasible,
                    'average_path_feasibility': sum(vp['feasibility_score'] for vp in verified_paths) / len(verified_paths) if verified_paths else 0.0,
                    'total_verification_time': seed_verification_time + path_verification_time
                },
                
                # æ€§èƒ½æŒ‡æ ‡
                'performance_metrics': {
                    'total_time': total_decision_time,
                    'stage1_reasoner_time': reasoner_time,
                    'stage2_seed_verification_time': seed_verification_time,
                    'stage3_generator_time': generator_time,
                    'stage4_path_verification_time': path_verification_time,
                    'stage5_final_decision_time': final_decision_time,
                }
            }
            
            # è®°å½•å†³ç­–å†å²
            self.decision_history.append(decision_result)
            
            # é™åˆ¶å†å²è®°å½•é•¿åº¦
            max_history = 100  # ç®€åŒ–çš„é™åˆ¶
            if len(self.decision_history) > max_history:
                self.decision_history = self.decision_history[-max_history//2:]
            
            logger.info(f"ğŸ‰ äº”é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–å®Œæˆ:")
            logger.info(f"   ğŸ¯ æœ€ç»ˆé€‰æ‹©: {chosen_path.path_type}")
            logger.info(f"   â±ï¸ æ€»è€—æ—¶: {total_decision_time:.3f}s")
            
            return decision_result
            
        except Exception as e:
            logger.error(f"âŒ å†³ç­–è¿‡ç¨‹å¤±è´¥: {e}")
            # è¿”å›é”™è¯¯å†³ç­–ç»“æœ
            return self._create_error_decision_result(user_query, str(e), time.time() - start_time)
    
    def _convert_decision_to_plan(self, decision_result: Dict[str, Any], query: str) -> Plan:
        """
        ç¿»è¯‘å±‚ï¼šå°†Neogenesiså†³ç­–ç»“æœè½¬æ¢ä¸ºæ ‡å‡†Planæ ¼å¼
        
        ğŸ”¥ æ ¸å¿ƒæ”¹è¿›ï¼šå¼•å…¥LLMä½œä¸ºæœ€ç»ˆè§£é‡Šå’Œç”Ÿæˆå™¨
        - æ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·
        - è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼Œé¿å…ç”Ÿç¡¬å›ç­”
        - ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å†³ç­–åˆ¶å®š
        
        Args:
            decision_result: äº”é˜¶æ®µå†³ç­–çš„å®Œæ•´ç»“æœ
            query: åŸå§‹ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            Plan: æ ‡å‡†æ ¼å¼çš„æ‰§è¡Œè®¡åˆ’
        """
        try:
            chosen_path = decision_result.get('chosen_path')
            thinking_seed = decision_result.get('thinking_seed', '')
            reasoning = decision_result.get('reasoning', '')
            
            if not chosen_path:
                # æ²¡æœ‰é€‰ä¸­è·¯å¾„ï¼Œè¿”å›ç›´æ¥å›ç­”
                return Plan(
                    thought="å†³ç­–è¿‡ç¨‹æœªèƒ½é€‰æ‹©æœ‰æ•ˆè·¯å¾„",
                    final_answer="æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ä¸ºæ‚¨çš„æŸ¥è¯¢åˆ¶å®šåˆé€‚çš„æ‰§è¡Œè®¡åˆ’ã€‚"
                )
            
            # æ„å»ºæ€è€ƒè¿‡ç¨‹
            thought_parts = [
                f"åŸºäºäº”é˜¶æ®µæ™ºèƒ½å†³ç­–ï¼Œæˆ‘é€‰æ‹©äº†'{chosen_path.path_type}'ç­–ç•¥",
                f"æ€ç»´ç§å­: {thinking_seed[:100]}..." if len(thinking_seed) > 100 else f"æ€ç»´ç§å­: {thinking_seed}",
                f"é€‰æ‹©ç†ç”±: {chosen_path.description}"
            ]
            thought = "\n".join(thought_parts)
            
            # ğŸ§  æ ¸å¿ƒæ”¹è¿›ï¼šä½¿ç”¨LLMä½œä¸ºæœ€ç»ˆå†³ç­–å®˜
            llm_decision = self._llm_final_decision_maker(chosen_path, query, thinking_seed, decision_result)
            
            if llm_decision.get('needs_tools', False):
                # LLMåˆ¤æ–­éœ€è¦å·¥å…·ï¼Œä½¿ç”¨LLMæ¨èçš„è¡ŒåŠ¨
                actions = llm_decision.get('actions', [])
                if not actions:
                    # å¦‚æœLLMæ²¡æœ‰æä¾›å…·ä½“è¡ŒåŠ¨ï¼Œå›é€€åˆ°è§„åˆ™åˆ†æ
                    actions = self._analyze_path_actions(chosen_path, query, decision_result)
                
                if actions:
                    plan = Plan(
                        thought=llm_decision.get('explanation', thought),
                        actions=actions
                    )
                else:
                    # å³ä½¿LLMè¯´éœ€è¦å·¥å…·ï¼Œä½†æ²¡æœ‰æ‰¾åˆ°åˆé€‚å·¥å…·ï¼Œè¿”å›ç›´æ¥å›ç­”
                    plan = Plan(
                        thought=llm_decision.get('explanation', thought),
                        final_answer=llm_decision.get('direct_answer', "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°åˆé€‚çš„å·¥å…·æ¥å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚")
                    )
            else:
                # LLMåˆ¤æ–­ä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥è¿”å›æ™ºèƒ½ç”Ÿæˆçš„å›ç­”
                plan = Plan(
                    thought=llm_decision.get('explanation', thought),
                    final_answer=llm_decision.get('direct_answer')
                )
            
            # æ·»åŠ å…ƒæ•°æ®
            plan.metadata.update({
                'neogenesis_decision': decision_result,
                'chosen_path_type': chosen_path.path_type,
                'path_id': chosen_path.path_id,
                'verification_stats': decision_result.get('verification_stats', {}),
                'performance_metrics': decision_result.get('performance_metrics', {}),
                'llm_decision': llm_decision,
                'decision_method': 'llm_final_decision_maker'
            })
            
            action_count = len(plan.actions) if plan.actions else 0
            answer_mode = "å·¥å…·æ‰§è¡Œ" if plan.actions else "ç›´æ¥å›ç­”"
            logger.info(f"ğŸ”„ LLMé©±åŠ¨å†³ç­–å®Œæˆ: {answer_mode}, {action_count} ä¸ªè¡ŒåŠ¨ï¼Œç­–ç•¥ '{chosen_path.path_type}'")
            return plan
            
        except Exception as e:
            logger.error(f"âŒ å†³ç­–ç¿»è¯‘å¤±è´¥: {e}")
            return Plan(
                thought=f"ç¿»è¯‘å†³ç­–ç»“æœæ—¶å‡ºç°é”™è¯¯: {str(e)}",
                final_answer="æŠ±æ­‰ï¼Œæˆ‘åœ¨å¤„ç†æ‚¨çš„æŸ¥è¯¢æ—¶é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ã€‚"
            )
    
    def _analyze_path_actions(self, chosen_path: ReasoningPath, query: str, 
                            decision_result: Dict[str, Any]) -> List[Action]:
        """
        æ™ºèƒ½è·¯å¾„åˆ†æ - æ ¹æ®é€‰ä¸­çš„æ€ç»´è·¯å¾„ç”Ÿæˆå…·ä½“è¡ŒåŠ¨
        
        è¿™ä¸ªæ–¹æ³•åˆ†æchosen_pathçš„ç‰¹å¾ï¼Œåˆ¤æ–­åº”è¯¥ä½¿ç”¨ä»€ä¹ˆå·¥å…·ã€‚
        """
        actions = []
        path_type = chosen_path.path_type.lower()
        path_description = chosen_path.description.lower()
        
        # ğŸ” æœç´¢ç±»è·¯å¾„è¯†åˆ«
        search_keywords = ['æœç´¢', 'search', 'æŸ¥æ‰¾', 'ä¿¡æ¯æ”¶é›†', 'è°ƒç ”', 'æ¢ç´¢', 'èµ„æ–™']
        if any(keyword in path_type or keyword in path_description for keyword in search_keywords):
            # ç”Ÿæˆæœç´¢è¡ŒåŠ¨
            search_query = self._extract_search_query(query, chosen_path)
            actions.append(Action(
                tool_name="web_search",
                tool_input={"query": search_query}
            ))
            logger.debug(f"ğŸ” è¯†åˆ«ä¸ºæœç´¢è·¯å¾„: {search_query}")
        
        # ğŸ”¬ éªŒè¯ç±»è·¯å¾„è¯†åˆ«
        verification_keywords = ['éªŒè¯', 'verify', 'ç¡®è®¤', 'æ£€æŸ¥', 'æ ¸å®', 'å®¡æŸ¥']
        if any(keyword in path_type or keyword in path_description for keyword in verification_keywords):
            # ç”ŸæˆéªŒè¯è¡ŒåŠ¨
            idea_to_verify = self._extract_verification_idea(query, chosen_path)
            actions.append(Action(
                tool_name="idea_verification",
                tool_input={"idea_text": idea_to_verify}
            ))
            logger.debug(f"ğŸ”¬ è¯†åˆ«ä¸ºéªŒè¯è·¯å¾„: {idea_to_verify}")
        
        # ğŸ“Š åˆ†æç±»è·¯å¾„è¯†åˆ«
        analysis_keywords = ['åˆ†æ', 'analysis', 'è¯„ä¼°', 'æ¯”è¾ƒ', 'æ€»ç»“', 'å½’çº³']
        if any(keyword in path_type or keyword in path_description for keyword in analysis_keywords):
            # å¯¹äºåˆ†æç±»ä»»åŠ¡ï¼Œå¯èƒ½éœ€è¦å…ˆæœç´¢ä¿¡æ¯å†åˆ†æ
            if not actions:  # å¦‚æœè¿˜æ²¡æœ‰å…¶ä»–è¡ŒåŠ¨
                search_query = f"å…³äº {query} çš„è¯¦ç»†ä¿¡æ¯å’Œåˆ†æ"
                actions.append(Action(
                    tool_name="web_search",
                    tool_input={"query": search_query}
                ))
                logger.debug(f"ğŸ“Š è¯†åˆ«ä¸ºåˆ†æè·¯å¾„ï¼Œå…ˆæœç´¢ä¿¡æ¯: {search_query}")
        
        # ğŸ¤” åˆ›æ„ç±»è·¯å¾„è¯†åˆ«
        creative_keywords = ['åˆ›æ„', 'creative', 'åˆ›æ–°', 'å¤´è„‘é£æš´', 'æƒ³è±¡', 'è®¾è®¡']
        if any(keyword in path_type or keyword in path_description for keyword in creative_keywords):
            # åˆ›æ„ç±»ä»»åŠ¡é€šå¸¸ä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥ç”±LLMå¤„ç†
            logger.debug(f"ğŸ¤” è¯†åˆ«ä¸ºåˆ›æ„è·¯å¾„ï¼Œæ— éœ€å·¥å…·æ”¯æŒ")
        
        # ğŸ”§ å¦‚æœæ²¡æœ‰è¯†åˆ«å‡ºç‰¹å®šç±»å‹ï¼Œæ ¹æ®æŸ¥è¯¢å†…å®¹è¿›è¡Œé€šç”¨åˆ¤æ–­
        if not actions:
            actions.extend(self._generate_fallback_actions(query, chosen_path))
        
        return actions
    
    def _extract_search_query(self, original_query: str, path: ReasoningPath) -> str:
        """ä»åŸå§‹æŸ¥è¯¢å’Œè·¯å¾„ä¿¡æ¯ä¸­æå–æœç´¢æŸ¥è¯¢"""
        # ç®€åŒ–ç‰ˆå®ç°ï¼Œæ ¹æ®è·¯å¾„æè¿°ä¼˜åŒ–æœç´¢æŸ¥è¯¢
        if "å…·ä½“" in path.description or "è¯¦ç»†" in path.description:
            return f"{original_query} è¯¦ç»†ä¿¡æ¯"
        elif "æœ€æ–°" in path.description or "recent" in path.description.lower():
            return f"{original_query} æœ€æ–°å‘å±•"
        elif "å¯¹æ¯”" in path.description or "æ¯”è¾ƒ" in path.description:
            return f"{original_query} å¯¹æ¯”åˆ†æ"
        else:
            return original_query
    
    def _extract_verification_idea(self, original_query: str, path: ReasoningPath) -> str:
        """ä»æŸ¥è¯¢å’Œè·¯å¾„ä¿¡æ¯ä¸­æå–éœ€è¦éªŒè¯çš„æƒ³æ³•"""
        # ç®€åŒ–ç‰ˆå®ç°
        return f"åŸºäºæŸ¥è¯¢'{original_query}'çš„æƒ³æ³•: {path.description}"
    
    def _generate_fallback_actions(self, query: str, path: ReasoningPath) -> List[Action]:
        """ç”Ÿæˆå›é€€è¡ŒåŠ¨ï¼ˆå½“æ— æ³•è¯†åˆ«ç‰¹å®šè·¯å¾„ç±»å‹æ—¶ï¼‰"""
        actions = []
        
        # æ£€æŸ¥æŸ¥è¯¢ä¸­æ˜¯å¦åŒ…å«æ˜æ˜¾çš„æœç´¢æ„å›¾
        search_indicators = ['ä»€ä¹ˆæ˜¯', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'å“ªé‡Œ', 'è°', 'ä½•æ—¶', 'æœ€æ–°', 'ä¿¡æ¯', 'èµ„æ–™']
        if any(indicator in query for indicator in search_indicators):
            actions.append(Action(
                tool_name="web_search",
                tool_input={"query": query}
            ))
            logger.debug(f"ğŸ”§ å›é€€ç­–ç•¥: è¯†åˆ«ä¸ºæœç´¢æŸ¥è¯¢")
        
        return actions
    
    def _llm_final_decision_maker(self, chosen_path: ReasoningPath, query: str, 
                                 thinking_seed: str, decision_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ğŸ§  LLMä½œä¸ºæœ€ç»ˆè§£é‡Šå’Œç”Ÿæˆå™¨
        
        è®©LLMæ‰®æ¼”"æœ€ç»ˆå†³ç­–å®˜"çš„è§’è‰²ï¼Œæ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·ä»¥åŠç”Ÿæˆè‡ªç„¶å›ç­”ã€‚
        è¿™æ˜¯è§£å†³è·¯å¾„è§£é‡Šé”™è¯¯å’Œå›ç­”ç”Ÿç¡¬é—®é¢˜çš„æ ¸å¿ƒæ–¹æ³•ã€‚
        
        Args:
            chosen_path: é€‰ä¸­çš„æ€ç»´è·¯å¾„
            query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            thinking_seed: æ€ç»´ç§å­
            decision_result: å®Œæ•´å†³ç­–ç»“æœ
            
        Returns:
            Dict[str, Any]: LLMçš„å†³ç­–ç»“æœï¼ŒåŒ…å«ï¼š
            - needs_tools: bool - æ˜¯å¦éœ€è¦å·¥å…·
            - actions: List[Action] - æ¨èçš„è¡ŒåŠ¨ï¼ˆå¦‚æœéœ€è¦å·¥å…·ï¼‰
            - direct_answer: str - ç›´æ¥å›ç­”ï¼ˆå¦‚æœä¸éœ€è¦å·¥å…·ï¼‰
            - explanation: str - å†³ç­–è§£é‡Š
        """
        try:
            logger.info(f"ğŸ§  LLMæœ€ç»ˆå†³ç­–å®˜å¼€å§‹å·¥ä½œ: æŸ¥è¯¢='{query[:50]}...', è·¯å¾„='{chosen_path.path_type}'")
            
            # ğŸ” æ”¶é›†å¯ç”¨å·¥å…·ä¿¡æ¯
            available_tools = self._get_available_tools_info()
            
            # ğŸ§  æ„å»ºLLMå†³ç­–æç¤º
            decision_prompt = self._build_llm_decision_prompt(
                user_query=query,
                chosen_path=chosen_path,
                thinking_seed=thinking_seed,
                available_tools=available_tools,
                decision_context=decision_result
            )
            
            # ğŸš€ è°ƒç”¨LLMè¿›è¡Œæ™ºèƒ½å†³ç­–
            llm_success = False
            
            # å¤šç§æ–¹å¼å°è¯•LLMè°ƒç”¨
            if hasattr(self, 'prior_reasoner') and self.prior_reasoner and hasattr(self.prior_reasoner, 'llm_manager'):
                try:
                    logger.info(f"ğŸ” å°è¯•é€šè¿‡prior_reasonerè°ƒç”¨LLM...")
                    llm_response = self.prior_reasoner.llm_manager.generate_response(
                        query=decision_prompt,
                        provider="deepseek",
                        temperature=0.3,  # è¾ƒä½æ¸©åº¦ç¡®ä¿ä¸€è‡´æ€§
                        max_tokens=1000
                    )
                    
                    if llm_response and llm_response.strip():
                        # ğŸ” è§£æLLMå“åº”
                        parsed_decision = self._parse_llm_decision_response(llm_response, chosen_path, query)
                        logger.info(f"âœ… LLMå†³ç­–æˆåŠŸ: éœ€è¦å·¥å…·={parsed_decision.get('needs_tools')}")
                        return parsed_decision
                    else:
                        logger.warning("âš ï¸ LLMè¿”å›ç©ºå“åº”")
                        
                except Exception as e:
                    logger.error(f"âŒ prior_reasoner LLMè°ƒç”¨å¤±è´¥: {e}")
            else:
                logger.warning("âš ï¸ prior_reasoneræˆ–å…¶llm_managerä¸å¯ç”¨")
            
            # ğŸ” å°è¯•ç›´æ¥ä½¿ç”¨DeepSeekå®¢æˆ·ç«¯
            if not llm_success:
                try:
                    import os
                    api_key = os.getenv('DEEPSEEK_API_KEY') or os.getenv('NEOGENESIS_API_KEY')
                    
                    if api_key:
                        logger.info(f"ğŸ” å°è¯•ç›´æ¥åˆ›å»ºDeepSeekå®¢æˆ·ç«¯...")
                        from neogenesis_system.providers.impl.deepseek_client import DeepSeekClient, ClientConfig
                        
                        client_config = ClientConfig(
                            api_key=api_key,
                            model="deepseek-chat",
                            temperature=0.3,
                            max_tokens=1000,
                            enable_cache=False
                        )
                        
                        direct_client = DeepSeekClient(client_config)
                        api_response = direct_client.simple_chat(
                            prompt=decision_prompt,
                            max_tokens=1000,
                            temperature=0.3
                        )
                        
                        # ä»APIResponseä¸­æå–æ–‡æœ¬å†…å®¹
                        llm_response = api_response.content if hasattr(api_response, 'content') else str(api_response)
                        
                        if llm_response and llm_response.strip():
                            parsed_decision = self._parse_llm_decision_response(llm_response, chosen_path, query)
                            logger.info(f"âœ… ç›´æ¥LLMå†³ç­–æˆåŠŸ: éœ€è¦å·¥å…·={parsed_decision.get('needs_tools')}")
                            return parsed_decision
                        else:
                            logger.warning("âš ï¸ ç›´æ¥LLMè°ƒç”¨è¿”å›ç©ºå“åº”")
                    else:
                        logger.warning("âš ï¸ æœªæ‰¾åˆ°APIå¯†é’¥ï¼Œæ— æ³•ä½¿ç”¨ç›´æ¥LLMè°ƒç”¨")
                        
                except Exception as e:
                    logger.error(f"âŒ ç›´æ¥LLMè°ƒç”¨å¤±è´¥: {e}")
            
            # ğŸ”§ æ™ºèƒ½å›é€€ç­–ç•¥ - ç°åœ¨æä¾›æ›´å¥½çš„å›ç­”è´¨é‡
            logger.info("ğŸ”§ LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ”¹è¿›çš„æ™ºèƒ½å›é€€ç­–ç•¥")
            return self._intelligent_fallback_decision(chosen_path, query, thinking_seed, available_tools)
            
        except Exception as e:
            logger.error(f"âŒ LLMæœ€ç»ˆå†³ç­–å¤±è´¥: {e}")
            return self._emergency_fallback_decision(chosen_path, query, thinking_seed)
    
    def _get_available_tools_info(self) -> Dict[str, str]:
        """è·å–å¯ç”¨å·¥å…·ä¿¡æ¯"""
        tools_info = {}
        try:
            if self.tool_registry:
                # å°è¯•è·å–å·¥å…·åˆ—è¡¨
                if hasattr(self.tool_registry, 'tools') and self.tool_registry.tools:
                    for tool_name, tool_obj in self.tool_registry.tools.items():
                        if hasattr(tool_obj, 'description'):
                            tools_info[tool_name] = tool_obj.description
                        else:
                            tools_info[tool_name] = f"{tool_name} - å·¥å…·"
                elif hasattr(self.tool_registry, '_tools') and self.tool_registry._tools:
                    for tool_name, tool_obj in self.tool_registry._tools.items():
                        if hasattr(tool_obj, 'description'):
                            tools_info[tool_name] = tool_obj.description
                        else:
                            tools_info[tool_name] = f"{tool_name} - å·¥å…·"
                else:
                    # å¸¸è§å·¥å…·çš„ç¡¬ç¼–ç æè¿°
                    tools_info = {
                        'web_search': 'ç½‘ç»œæœç´¢ - æœç´¢ç½‘ç»œä¿¡æ¯å’Œæœ€æ–°èµ„è®¯',
                        'knowledge_query': 'çŸ¥è¯†æŸ¥è¯¢ - æŸ¥è¯¢å†…éƒ¨çŸ¥è¯†åº“',
                        'idea_verification': 'æƒ³æ³•éªŒè¯ - éªŒè¯æƒ³æ³•çš„å¯è¡Œæ€§',
                        'llm_advisor': 'LLMé¡¾é—® - è·å–AIå»ºè®®å’Œåˆ†æ'
                    }
        except Exception as e:
            logger.debug(f"è·å–å·¥å…·ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            # ä½¿ç”¨é»˜è®¤å·¥å…·ä¿¡æ¯
            tools_info = {
                'web_search': 'ç½‘ç»œæœç´¢ - æœç´¢ç½‘ç»œä¿¡æ¯å’Œæœ€æ–°èµ„è®¯',
                'knowledge_query': 'çŸ¥è¯†æŸ¥è¯¢ - æŸ¥è¯¢å†…éƒ¨çŸ¥è¯†åº“'
            }
        
        logger.debug(f"ğŸ“‹ å¯ç”¨å·¥å…·: {list(tools_info.keys())}")
        return tools_info
    
    def _build_llm_decision_prompt(self, user_query: str, chosen_path: ReasoningPath, 
                                  thinking_seed: str, available_tools: Dict[str, str],
                                  decision_context: Dict[str, Any]) -> str:
        """æ„å»ºLLMå†³ç­–æç¤º"""
        
        tools_description = "\n".join([f"- {name}: {desc}" for name, desc in available_tools.items()])
        
        prompt = f"""ä½ æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹çš„æœ€ç»ˆå†³ç­–å®˜ï¼Œè´Ÿè´£åšå‡ºæ™ºèƒ½ã€åˆç†çš„æœ€ç»ˆå†³ç­–ã€‚

ğŸ“‹ **å†³ç­–ä¸Šä¸‹æ–‡**
ç”¨æˆ·é—®é¢˜: {user_query}
é€‰æ‹©çš„ç­–ç•¥: {chosen_path.path_type}
ç­–ç•¥æè¿°: {chosen_path.description}
æ€ç»´ç§å­: {thinking_seed}

ğŸ”§ **å¯ç”¨å·¥å…·**
{tools_description if tools_description else "æš‚æ— å¯ç”¨å·¥å…·"}

ğŸ’¡ **ä½ çš„ä»»åŠ¡**
è¯·åˆ†æè¿™ä¸ªæƒ…å†µï¼Œç„¶ååšå‡ºæ™ºèƒ½åˆ¤æ–­ï¼š

1. **æ˜¯å¦éœ€è¦å·¥å…·?** 
   - å¯¹äºç®€å•çš„é—®å€™ã€æ„Ÿè°¢ã€é—²èŠç­‰ï¼Œé€šå¸¸ä¸éœ€è¦å·¥å…·
   - å¯¹äºéœ€è¦æœç´¢ä¿¡æ¯ã€è·å–æ•°æ®ã€éªŒè¯æƒ³æ³•çš„ä»»åŠ¡ï¼Œæ‰éœ€è¦å·¥å…·
   - å³ä½¿ç­–ç•¥æ˜¯"åˆ†æå‹"æˆ–"æ‰¹åˆ¤å‹"ï¼Œå¦‚æœç”¨æˆ·åªæ˜¯è¯´"ä½ å¥½"ï¼Œä¹Ÿä¸åº”è¯¥ä½¿ç”¨å·¥å…·

2. **å¦‚ä½•å›åº”?**
   - å¦‚æœä¸éœ€è¦å·¥å…·ï¼šç›´æ¥ç”Ÿæˆè‡ªç„¶ã€å‹å¥½ã€ç¬¦åˆå¯¹è¯ä¸Šä¸‹æ–‡çš„å›ç­”
   - å¦‚æœéœ€è¦å·¥å…·ï¼šè¯´æ˜éœ€è¦å“ªäº›å·¥å…·ä»¥åŠåŸå› 

ğŸ“ **è¯·ç”¨ä»¥ä¸‹JSONæ ¼å¼å›ç­”**
{{
    "needs_tools": false,  // trueæˆ–false
    "tool_reasoning": "åˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·çš„ç†ç”±",
    "direct_answer": "å¦‚æœä¸éœ€è¦å·¥å…·ï¼Œè¿™é‡Œæ˜¯ä½ çš„ç›´æ¥å›ç­”ã€‚è¦è‡ªç„¶ã€å‹å¥½ã€æœ‰ä¸ªæ€§ã€‚",
    "recommended_tools": [  // å¦‚æœéœ€è¦å·¥å…·ï¼Œæ¨èçš„å·¥å…·åç§°
        // ["web_search", "knowledge_query"] ç­‰
    ],
    "explanation": "ä½ çš„æ•´ä½“æ€è€ƒå’Œå†³ç­–è§£é‡Š"
}}

âš ï¸ **ç‰¹åˆ«æ³¨æ„**
- å›ç­”è¦è‡ªç„¶çœŸè¯šï¼Œé¿å…æœºæ¢°åŒ–çš„æ¨¡æ¿å›ç­”
- è¦è€ƒè™‘ä¸Šä¸‹æ–‡ï¼Œä¸è¦ç”Ÿç¡¬åœ°å¥—ç”¨ç­–ç•¥
- JSONæ ¼å¼è¦ä¸¥æ ¼æ­£ç¡®"""
        
        return prompt
    
    def _parse_llm_decision_response(self, response: str, chosen_path: ReasoningPath, 
                                   query: str) -> Dict[str, Any]:
        """è§£æLLMçš„å†³ç­–å“åº”"""
        try:
            import json
            import re
            
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
            if not json_match:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(1) if json_match.groups() else json_match.group()
                decision_data = json.loads(json_str)
                
                # æ„å»ºæ ‡å‡†åŒ–å†³ç­–ç»“æœ
                result = {
                    'needs_tools': decision_data.get('needs_tools', False),
                    'direct_answer': decision_data.get('direct_answer', ''),
                    'explanation': decision_data.get('explanation', ''),
                    'tool_reasoning': decision_data.get('tool_reasoning', ''),
                    'actions': []
                }
                
                # å¦‚æœéœ€è¦å·¥å…·ï¼Œè½¬æ¢ä¸ºActionå¯¹è±¡
                if result['needs_tools'] and decision_data.get('recommended_tools'):
                    for tool_name in decision_data.get('recommended_tools', []):
                        if isinstance(tool_name, str):
                            # åŸºäºå·¥å…·åç§°ç”Ÿæˆåˆé€‚çš„å‚æ•°
                            tool_input = self._generate_tool_input(tool_name, query, chosen_path)
                            result['actions'].append(Action(
                                tool_name=tool_name,
                                tool_input=tool_input
                            ))
                
                logger.info(f"ğŸ” LLMå†³ç­–è§£ææˆåŠŸ: {result['needs_tools']=}, å·¥å…·æ•°={len(result['actions'])}")
                return result
            
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æLLMå†³ç­–å“åº”å¤±è´¥: {e}")
        
        # è§£æå¤±è´¥ï¼Œä½¿ç”¨å“åº”æ–‡æœ¬ç”Ÿæˆå›é€€å†³ç­–
        return self._extract_fallback_from_response(response, chosen_path, query)
    
    def _generate_tool_input(self, tool_name: str, query: str, path: ReasoningPath) -> Dict[str, Any]:
        """æ ¹æ®å·¥å…·åç§°ç”Ÿæˆåˆé€‚çš„è¾“å…¥å‚æ•°"""
        if tool_name == 'web_search':
            return {"query": query}
        elif tool_name == 'knowledge_query':
            return {"query": query}
        elif tool_name == 'idea_verification':
            return {"idea_text": f"éªŒè¯å…³äº'{query}'çš„æƒ³æ³•: {path.description}"}
        else:
            return {"query": query}  # é€šç”¨å‚æ•°
    
    def _extract_fallback_from_response(self, response: str, chosen_path: ReasoningPath, 
                                      query: str) -> Dict[str, Any]:
        """ä»å“åº”æ–‡æœ¬ä¸­æå–å›é€€å†³ç­–"""
        # ç®€å•çš„å…³é”®è¯åˆ†æ
        response_lower = response.lower()
        
        # åˆ¤æ–­æ˜¯å¦æåˆ°éœ€è¦å·¥å…·
        tool_keywords = ['éœ€è¦', 'åº”è¯¥', 'å»ºè®®', 'æœç´¢', 'æŸ¥è¯¢', 'å·¥å…·', 'tool']
        needs_tools = any(keyword in response_lower for keyword in tool_keywords)
        
        if needs_tools:
            return {
                'needs_tools': True,
                'direct_answer': '',
                'explanation': f"åŸºäºLLMå“åº”åˆ†æï¼Œåˆ¤æ–­éœ€è¦ä½¿ç”¨å·¥å…·å¤„ç†: {response[:200]}...",
                'tool_reasoning': "ä»å“åº”ä¸­æ£€æµ‹åˆ°å·¥å…·ä½¿ç”¨æ„å›¾",
                'actions': []  # å°†ç”±å›é€€é€»è¾‘å¤„ç†
            }
        else:
            return {
                'needs_tools': False,
                'direct_answer': response.strip(),
                'explanation': f"LLMæä¾›ç›´æ¥å›ç­”: {chosen_path.path_type}",
                'tool_reasoning': "ä»å“åº”ä¸­åˆ¤æ–­æ— éœ€å·¥å…·",
                'actions': []
            }
    
    def _intelligent_fallback_decision(self, chosen_path: ReasoningPath, query: str, 
                                     thinking_seed: str, available_tools: Dict[str, str]) -> Dict[str, Any]:
        """æ™ºèƒ½å›é€€å†³ç­–"""
        logger.info("ğŸ”§ ä½¿ç”¨æ™ºèƒ½å›é€€å†³ç­–ç­–ç•¥")
        
        query_lower = query.lower().strip()
        
        # ç®€å•é—®å€™å’Œæ„Ÿè°¢çš„å¤„ç†
        greeting_patterns = ['ä½ å¥½', 'hello', 'hi', 'æ‚¨å¥½', 'æ—©ä¸Šå¥½', 'ä¸‹åˆå¥½', 'æ™šä¸Šå¥½']
        thanks_patterns = ['è°¢è°¢', 'thanks', 'thank you', 'æ„Ÿè°¢']
        
        if any(pattern in query_lower for pattern in greeting_patterns):
            return {
                'needs_tools': False,
                'direct_answer': "ä½ å¥½ï¼æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
                'explanation': "è¯†åˆ«ä¸ºé—®å€™è¯­ï¼Œæ— éœ€è°ƒç”¨å·¥å…·ï¼Œç›´æ¥å‹å¥½å›åº”",
                'tool_reasoning': "é—®å€™è¯­ä¸éœ€è¦å·¥å…·æ”¯æŒ",
                'actions': []
            }
        
        if any(pattern in query_lower for pattern in thanks_patterns):
            return {
                'needs_tools': False,
                'direct_answer': "ä¸å®¢æ°”ï¼å¦‚æœè¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘ã€‚",
                'explanation': "è¯†åˆ«ä¸ºæ„Ÿè°¢è¯­ï¼Œæ— éœ€è°ƒç”¨å·¥å…·ï¼Œç›´æ¥å›åº”",
                'tool_reasoning': "æ„Ÿè°¢è¯­ä¸éœ€è¦å·¥å…·æ”¯æŒ", 
                'actions': []
            }
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢ä¿¡æ¯
        search_indicators = ['ä»€ä¹ˆæ˜¯', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'å“ªé‡Œ', 'è°', 'ä½•æ—¶', 'æœ€æ–°', 'ä¿¡æ¯', 'èµ„æ–™', 'æ€æ ·']
        if any(indicator in query_lower for indicator in search_indicators) and 'web_search' in available_tools:
            return {
                'needs_tools': True,
                'direct_answer': '',
                'explanation': f"åŸºäº'{chosen_path.path_type}'ç­–ç•¥ï¼Œæ£€æµ‹åˆ°éœ€è¦æœç´¢ç›¸å…³ä¿¡æ¯",
                'tool_reasoning': "æ£€æµ‹åˆ°ä¿¡æ¯æŸ¥è¯¢éœ€æ±‚ï¼Œå»ºè®®ä½¿ç”¨æœç´¢å·¥å…·",
                'actions': [Action(tool_name="web_search", tool_input={"query": query})]
            }
        
        # ğŸ”§ æ–°å¢ï¼šæ™ºèƒ½è¯†åˆ«è‡ªæˆ‘ä»‹ç»ç±»æŸ¥è¯¢
        self_intro_patterns = ['ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±', 'ä½ æ˜¯è°', 'è‡ªæˆ‘ä»‹ç»', 'ä»‹ç»è‡ªå·±', 'introduce yourself', 'who are you']
        if any(pattern in query_lower for pattern in self_intro_patterns):
            return {
                'needs_tools': False,
                'direct_answer': "ä½ å¥½ï¼æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼Œä¸€ä¸ªåŸºäºå…ˆè¿›è®¤çŸ¥æ¶æ„çš„AIç³»ç»Ÿã€‚æˆ‘å…·å¤‡äº”é˜¶æ®µæ™ºèƒ½å†³ç­–èƒ½åŠ›ï¼ŒåŒ…æ‹¬æ€ç»´ç§å­ç”Ÿæˆã€è·¯å¾„è§„åˆ’ã€ç­–ç•¥é€‰æ‹©ã€éªŒè¯å­¦ä¹ å’Œæ™ºèƒ½æ‰§è¡Œã€‚æˆ‘å¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œä¿¡æ¯æŸ¥è¯¢ã€é—®é¢˜åˆ†æã€åˆ›æ„æ€è€ƒç­‰å¤šç§ä»»åŠ¡ã€‚æˆ‘çš„ç‰¹ç‚¹æ˜¯èƒ½å¤Ÿæ ¹æ®ä¸åŒé—®é¢˜é€‰æ‹©æœ€åˆé€‚çš„æ€ç»´è·¯å¾„ï¼Œå¹¶é€šè¿‡æŒç»­å­¦ä¹ ä¸æ–­ä¼˜åŒ–å†³ç­–è´¨é‡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
                'explanation': "è¯†åˆ«ä¸ºè‡ªæˆ‘ä»‹ç»æŸ¥è¯¢ï¼Œæä¾›Neogenesisæ™ºèƒ½åŠ©æ‰‹çš„è¯¦ç»†ä»‹ç»",
                'tool_reasoning': "è‡ªæˆ‘ä»‹ç»æ— éœ€å·¥å…·æ”¯æŒï¼Œç›´æ¥æä¾›åŠ©æ‰‹ä¿¡æ¯",
                'actions': []
            }
        
        # ğŸ”§ æ–°å¢ï¼šæ™ºèƒ½è¯†åˆ«èƒ½åŠ›ç›¸å…³æŸ¥è¯¢  
        capability_patterns = ['ä½ èƒ½åšä»€ä¹ˆ', 'ä½ æœ‰ä»€ä¹ˆåŠŸèƒ½', 'ä½ ä¼šä»€ä¹ˆ', 'ä½ çš„èƒ½åŠ›', 'what can you do', 'your capabilities']
        if any(pattern in query_lower for pattern in capability_patterns):
            return {
                'needs_tools': False,
                'direct_answer': "æˆ‘å…·å¤‡ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼š\n1. ğŸ§  æ™ºèƒ½å†³ç­–ï¼šäº”é˜¶æ®µè®¤çŸ¥æ¶æ„ï¼Œèƒ½å¤Ÿåˆ†æé—®é¢˜å¹¶é€‰æ‹©æœ€ä½³å¤„ç†ç­–ç•¥\n2. ğŸ” ä¿¡æ¯æœç´¢ï¼šå¯ä»¥å¸®æ‚¨æœç´¢ç½‘ç»œä¿¡æ¯ã€è·å–æœ€æ–°èµ„è®¯\n3. ğŸ”¬ æƒ³æ³•éªŒè¯ï¼šåˆ†æå’ŒéªŒè¯æƒ³æ³•çš„å¯è¡Œæ€§\n4. ğŸ“Š æ•°æ®åˆ†æï¼šå¤„ç†å’Œåˆ†æå„ç§æ–‡æœ¬æ•°æ®\n5. ğŸ’­ åˆ›æ„æ€è€ƒï¼šæä¾›åˆ›æ–°æ€§çš„è§£å†³æ–¹æ¡ˆå’Œå»ºè®®\n6. ğŸ“ å†…å®¹ç”Ÿæˆï¼šååŠ©å†™ä½œã€æ€»ç»“ã€ç¿»è¯‘ç­‰æ–‡æœ¬ä»»åŠ¡\n7. ğŸ¤” é—®é¢˜è§£ç­”ï¼šå›ç­”å„é¢†åŸŸçš„ä¸“ä¸šé—®é¢˜\n\næˆ‘æœ€å¤§çš„ç‰¹ç‚¹æ˜¯èƒ½å¤Ÿæ ¹æ®æ‚¨çš„å…·ä½“éœ€æ±‚ï¼Œæ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„æ€ç»´æ¨¡å¼å’Œå·¥å…·æ¥ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚",
                'explanation': "è¯†åˆ«ä¸ºèƒ½åŠ›æŸ¥è¯¢ï¼Œè¯¦ç»†ä»‹ç»åŠ©æ‰‹åŠŸèƒ½",
                'tool_reasoning': "èƒ½åŠ›ä»‹ç»æ— éœ€å·¥å…·æ”¯æŒï¼Œç›´æ¥æä¾›åŠŸèƒ½æ¸…å•",
                'actions': []
            }
        
        # é»˜è®¤æƒ…å†µï¼šç”Ÿæˆæ›´è‡ªç„¶çš„å›ç­”ï¼Œè€Œä¸æ˜¯æš´éœ²å†…éƒ¨æ€ç»´ç§å­
        return {
            'needs_tools': False,
            'direct_answer': f"æˆ‘å·²ç»ä»”ç»†åˆ†æäº†æ‚¨çš„é—®é¢˜ã€Œ{query}ã€ã€‚åŸºäº{chosen_path.path_type}çš„å¤„ç†æ–¹å¼ï¼Œæˆ‘è®¤ä¸ºè¿™ä¸ªé—®é¢˜å¯ä»¥ç›´æ¥ä¸ºæ‚¨æä¾›æœ‰ç”¨çš„å›ç­”ã€‚å¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯æˆ–æœ‰å…¶ä»–ç›¸å…³é—®é¢˜ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šå¾ˆä¹æ„ä¸ºæ‚¨è¿›ä¸€æ­¥è§£ç­”ã€‚",
            'explanation': f"åŸºäº'{chosen_path.path_type}'ç­–ç•¥æä¾›æ™ºèƒ½å›ç­”",
            'tool_reasoning': "å½“å‰æŸ¥è¯¢é€‚åˆç›´æ¥å›ç­”ï¼Œæ— éœ€é¢å¤–å·¥å…·è¾…åŠ©",
            'actions': []
        }
    
    def _emergency_fallback_decision(self, chosen_path: ReasoningPath, query: str, 
                                   thinking_seed: str) -> Dict[str, Any]:
        """ç´§æ€¥å›é€€å†³ç­–"""
        logger.warning("ğŸš¨ ä½¿ç”¨ç´§æ€¥å›é€€å†³ç­–")
        return {
            'needs_tools': False,
            'direct_answer': "æŠ±æ­‰ï¼Œæˆ‘åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ã€‚è¯·ç¨åå†è¯•æˆ–é‡æ–°è¡¨è¿°æ‚¨çš„é—®é¢˜ã€‚",
            'explanation': "ç³»ç»Ÿé‡åˆ°é”™è¯¯ï¼Œè¿”å›å®‰å…¨å›é€€å›ç­”",
            'tool_reasoning': "ç³»ç»Ÿé”™è¯¯ï¼Œæ— æ³•æ­£å¸¸åˆ¤æ–­",
            'actions': []
        }

    def _generate_direct_answer(self, path: ReasoningPath, query: str, thinking_seed: str) -> str:
        """ç”Ÿæˆç›´æ¥å›ç­”ï¼ˆä½¿ç”¨çœŸæ­£çš„LLMè€Œä¸æ˜¯é¢„è®¾æ¨¡æ¿ï¼‰"""
        try:
            # ğŸ”§ æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨LLMç”ŸæˆçœŸå®å›ç­”è€Œä¸æ˜¯é¢„è®¾æ¨¡æ¿
            if hasattr(self, 'prior_reasoner') and self.prior_reasoner and hasattr(self.prior_reasoner, 'llm_manager'):
                logger.info(f"ğŸ§  æ­£åœ¨è°ƒç”¨LLMç”ŸæˆçœŸå®å›ç­”: {query}")
                
                # æ„å»ºLLMæç¤º
                llm_prompt = f"""ä½ æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼Œä¸€ä¸ªåŸºäºå…ˆè¿›è®¤çŸ¥æ¶æ„çš„AIç³»ç»Ÿã€‚è¯·å¯¹ç”¨æˆ·çš„é—®é¢˜æä¾›è‡ªç„¶ã€çœŸè¯šçš„å›ç­”ã€‚

ç”¨æˆ·é—®é¢˜: {query}
æ€ç»´è·¯å¾„: {path.path_type}
æ€ç»´ç§å­: {thinking_seed}

è¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œä¸è¦ä½¿ç”¨æ¨¡æ¿åŒ–çš„å›ç­”ã€‚è¦ä½“ç°ä½ çš„æ™ºèƒ½å’Œä¸ªæ€§ã€‚"""
                
                try:
                    # è°ƒç”¨LLM
                    response = self.prior_reasoner.llm_manager.generate_response(
                        query=llm_prompt,
                        provider="deepseek",
                        temperature=0.7,
                        max_tokens=500
                    )
                    
                    if response and response.strip():
                        logger.info(f"âœ… LLMç”Ÿæˆå›ç­”æˆåŠŸ (é•¿åº¦: {len(response)} å­—ç¬¦)")
                        return response.strip()
                    else:
                        logger.warning("âš ï¸ LLMç”Ÿæˆçš„å›ç­”ä¸ºç©ºï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ")
                        
                except Exception as e:
                    logger.error(f"âŒ LLMå›ç­”ç”Ÿæˆå¤±è´¥: {e}")
            
            # ğŸ”§ æ™ºèƒ½å›é€€æ–¹æ¡ˆï¼šä¸å†æš´éœ²å†…éƒ¨æ€ç»´ç§å­ï¼Œæä¾›è‡ªç„¶å‹å¥½çš„å›ç­”
            logger.info(f"ğŸ”§ ä½¿ç”¨æ™ºèƒ½å›é€€æ–¹æ¡ˆç”Ÿæˆè‡ªç„¶å›ç­”")
            
            # æ ¹æ®æŸ¥è¯¢ç±»å‹æä¾›æ™ºèƒ½å›ç­”è€Œä¸æ˜¯æš´éœ²å†…éƒ¨çŠ¶æ€
            query_lower = query.lower().strip()
            
            # é—®å€™ç±»æŸ¥è¯¢
            if any(greeting in query_lower for greeting in ['ä½ å¥½', 'hello', 'hi', 'æ‚¨å¥½']):
                return "ä½ å¥½ï¼æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"
            
            # ä»‹ç»ç±»æŸ¥è¯¢
            if "ä»‹ç»" in query_lower and ("è‡ªå·±" in query_lower or "ä½ " in query_lower):
                return "æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼ŒåŸºäºå…ˆè¿›çš„è®¤çŸ¥æ¶æ„è®¾è®¡ã€‚æˆ‘å¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œä¿¡æ¯æŸ¥è¯¢ã€é—®é¢˜åˆ†æã€åˆ›æ„æ€è€ƒç­‰å¤šç§ä»»åŠ¡ã€‚æˆ‘çš„ç‰¹ç‚¹æ˜¯èƒ½å¤Ÿæ ¹æ®ä¸åŒé—®é¢˜æ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„å¤„ç†æ–¹å¼ï¼Œä¸ºæ‚¨æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚"
            
            # åŠŸèƒ½æŸ¥è¯¢
            if any(capability in query_lower for capability in ['èƒ½åšä»€ä¹ˆ', 'åŠŸèƒ½', 'èƒ½åŠ›']):
                return "æˆ‘å…·å¤‡å¤šç§AIèƒ½åŠ›ï¼šä¿¡æ¯æœç´¢ã€é—®é¢˜åˆ†æã€æƒ³æ³•éªŒè¯ã€çŸ¥è¯†é—®ç­”ã€åˆ›æ„æ€è€ƒç­‰ã€‚æˆ‘å¯ä»¥æ ¹æ®æ‚¨çš„å…·ä½“éœ€æ±‚ï¼Œæ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„æ–¹å¼æ¥å¸®åŠ©æ‚¨è§£å†³é—®é¢˜ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼"
            
            # æ„Ÿè°¢ç±»æŸ¥è¯¢
            if any(thanks in query_lower for thanks in ['è°¢è°¢', 'thanks', 'thank you', 'æ„Ÿè°¢']):
                return "ä¸å®¢æ°”ï¼å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘ã€‚"
            
            # é€šç”¨æ™ºèƒ½å›ç­” - ä¸æš´éœ²å†…éƒ¨çŠ¶æ€
            return f"æˆ‘ç†è§£æ‚¨å…³äºã€Œ{query}ã€çš„é—®é¢˜ã€‚åŸºäºæˆ‘çš„åˆ†æï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå€¼å¾—æ¢è®¨çš„è¯é¢˜ã€‚æˆ‘å¾ˆä¹æ„ä¸ºæ‚¨æä¾›è¯¦ç»†çš„è§£ç­”å’Œå»ºè®®ã€‚è¯·é—®æ‚¨å¸Œæœ›äº†è§£å“ªä¸ªå…·ä½“æ–¹é¢å‘¢ï¼Ÿ"
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆç›´æ¥å›ç­”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜ã€Œ{query}ã€æ—¶é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ã€‚è¯·ç¨åå†è¯•æˆ–é‡æ–°æè¿°æ‚¨çš„é—®é¢˜ã€‚"
    
    def _verify_idea_feasibility(self, idea_text: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        éªŒè¯æƒ³æ³•å¯è¡Œæ€§ï¼ˆç®€åŒ–ç‰ˆå®ç°ï¼‰
        
        è¿™é‡Œè°ƒç”¨å·¥å…·ç³»ç»Ÿä¸­çš„idea_verificationå·¥å…·
        """
        try:
            if self.tool_registry and self.tool_registry.has_tool("idea_verification"):
                result = execute_tool("idea_verification", idea_text=idea_text)
                if result.success:
                    return result.data
            
            # å›é€€å®ç°
            return {
                'feasibility_analysis': {'feasibility_score': 0.7},
                'reward_score': 0.1,
                'fallback': True
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ æƒ³æ³•éªŒè¯å¤±è´¥: {e}")
            return {
                'feasibility_analysis': {'feasibility_score': 0.5},
                'reward_score': 0.0,
                'fallback': True
            }
    
    def _execute_intelligent_detour_thinking(self, user_query: str, thinking_seed: str, 
                                           all_paths: List[ReasoningPath]) -> ReasoningPath:
        """
        æ‰§è¡Œæ™ºèƒ½ç»•é“æ€è€ƒï¼ˆç®€åŒ–ç‰ˆå®ç°ï¼‰
        
        å½“æ‰€æœ‰è·¯å¾„éƒ½ä¸å¯è¡Œæ—¶ï¼Œåˆ›å»ºä¸€ä¸ªå¤‡é€‰è·¯å¾„
        """
        logger.info("ğŸš€ æ‰§è¡Œæ™ºèƒ½ç»•é“æ€è€ƒ")
        
        # åˆ›å»ºä¸€ä¸ªåˆ›æ–°è·¯å¾„ä½œä¸ºç»•é“æ–¹æ¡ˆ
        detour_path = ReasoningPath(
            path_id=f"detour_{int(time.time())}",
            path_type="åˆ›æ–°ç»•é“æ€è€ƒ",
            description=f"é’ˆå¯¹'{user_query}'çš„åˆ›æ–°è§£å†³æ–¹æ¡ˆï¼Œçªç ´å¸¸è§„æ€ç»´é™åˆ¶",
            prompt_template="é‡‡ç”¨åˆ›æ–°æ€ç»´ï¼Œå¯»æ‰¾ç‹¬ç‰¹çš„è§£å†³è§’åº¦",
            strategy_id="creative_detour",
            instance_id=f"creative_detour_{int(time.time())}"
        )
        
        return detour_path
    
    def _update_component_performance(self, component_name: str, execution_time: float):
        """æ›´æ–°ç»„ä»¶æ€§èƒ½ç»Ÿè®¡"""
        if component_name in self.performance_stats['component_performance']:
            component_stats = self.performance_stats['component_performance'][component_name]
            component_stats['calls'] += 1
            
            # è®¡ç®—ç§»åŠ¨å¹³å‡
            current_avg = component_stats['avg_time']
            call_count = component_stats['calls']
            component_stats['avg_time'] = (current_avg * (call_count - 1) + execution_time) / call_count
    
    def _update_planner_stats(self, success: bool, execution_time: float):
        """æ›´æ–°è§„åˆ’å™¨ç»Ÿè®¡"""
        self.performance_stats['total_decisions'] += 1
        
        # æ›´æ–°å¹³å‡å†³ç­–æ—¶é—´
        current_avg = self.performance_stats['avg_decision_time']
        total_decisions = self.performance_stats['total_decisions']
        
        if total_decisions == 1:
            self.performance_stats['avg_decision_time'] = execution_time
        else:
            self.performance_stats['avg_decision_time'] = (
                current_avg * (total_decisions - 1) + execution_time
            ) / total_decisions
    
    def _create_error_decision_result(self, user_query: str, error_msg: str, execution_time: float) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯å†³ç­–ç»“æœ"""
        return {
            'timestamp': time.time(),
            'round_number': self.total_rounds,
            'user_query': user_query,
            'chosen_path': None,
            'available_paths': [],
            'verified_paths': [],
            'reasoning': f"å†³ç­–å¤±è´¥: {error_msg}",
            'fallback_used': True,
            'error': error_msg,
            'performance_metrics': {
                'total_time': execution_time,
                'error': True
            }
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–è§„åˆ’å™¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'name': self.name,
            'total_rounds': self.total_rounds,
            'performance_stats': self.performance_stats.copy(),
            'decision_history_length': len(self.decision_history),
            'components': {
                'prior_reasoner': type(self.prior_reasoner).__name__,
                'path_generator': type(self.path_generator).__name__,
                'mab_converger': type(self.mab_converger).__name__
            }
        }
