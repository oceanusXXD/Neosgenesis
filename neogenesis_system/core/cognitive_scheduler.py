#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è®¤çŸ¥è°ƒåº¦å™¨ - Cognitive Scheduler
èµ‹äºˆ Agent "ç©ºé—²"æ¦‚å¿µçš„æ™ºèƒ½åå°è°ƒåº¦ç³»ç»Ÿ

è¿™ä¸ªæ¨¡å—å®ç°äº†ä»"è¢«åŠ¨åº”æ¿€"åˆ°"ä¸»åŠ¨è®¤çŸ¥"çš„èŒƒå¼è½¬æ¢ï¼š
- ç©ºé—²çŠ¶æ€æ£€æµ‹ï¼šç›‘æ§ç³»ç»ŸçŠ¶æ€ï¼Œè¯†åˆ«ä»»åŠ¡é—´éš™
- åå°è®¤çŸ¥å¾ªç¯ï¼šåœ¨ç©ºé—²æœŸé—´å¯åŠ¨ä¸»åŠ¨åæ€å’Œåˆ›æƒ³è¿‡ç¨‹  
- è®¤çŸ¥çŠ¶æ€ç®¡ç†ï¼šåè°ƒä»»åŠ¡é©±åŠ¨æ¨¡å¼ä¸è‡ªæˆ‘é©±åŠ¨æ¨¡å¼çš„åˆ‡æ¢
- çŸ¥è¯†æ²‰æ·€è§¦å‘ï¼šæ¿€æ´»ä»»åŠ¡å›æº¯å¼•æ“å’Œä¸»åŠ¨åˆ›æƒ³æ¨¡å—

æ ¸å¿ƒç†å¿µï¼šè®©AIä»"ä»»åŠ¡å¥´éš¶"å‡çº§ä¸º"è‡ªä¸»æ€è€ƒè€…"
"""

import time
import threading
import logging
import asyncio
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field
from enum import Enum
from queue import Queue, Empty
import json

from ..shared.state_manager import StateManager, TaskPhase, GoalStatus
from .retrospection_engine import TaskRetrospectionEngine, RetrospectionStrategy
from ..providers.knowledge_explorer import KnowledgeExplorer, ExplorationStrategy

logger = logging.getLogger(__name__)


class CognitiveMode(Enum):
    """è®¤çŸ¥æ¨¡å¼æšä¸¾"""
    TASK_DRIVEN = "task_driven"        # ä»»åŠ¡é©±åŠ¨æ¨¡å¼ï¼ˆæ­£å¸¸å·¥ä½œçŠ¶æ€ï¼‰
    COGNITIVE_IDLE = "cognitive_idle"  # è®¤çŸ¥ç©ºé—²æ¨¡å¼ï¼ˆæµ…å±‚åå°æ€è€ƒï¼‰
    DEEP_REFLECTION = "deep_reflection" # æ·±åº¦åæ€æ¨¡å¼ï¼ˆæ·±åº¦å¤ç›˜åˆ†æï¼‰
    CREATIVE_IDEATION = "creative_ideation" # ä¸»åŠ¨åˆ›æƒ³æ¨¡å¼ï¼ˆçªç ´æ€§æ€è€ƒï¼‰
    KNOWLEDGE_EXPLORATION = "knowledge_exploration" # çŸ¥è¯†æ¢ç´¢æ¨¡å¼ï¼ˆä¸»åŠ¨æ¢ç´¢å¤–éƒ¨ä¸–ç•Œï¼‰


@dataclass
class CognitiveTask:
    """è®¤çŸ¥ä»»åŠ¡æ•°æ®ç»“æ„"""
    task_id: str
    task_type: str  # "retrospection", "ideation", "knowledge_synthesis", "knowledge_exploration"
    priority: int   # 1-10, 10ä¸ºæœ€é«˜ä¼˜å…ˆçº§
    context: Dict[str, Any] = field(default_factory=dict)
    created_at: float = field(default_factory=time.time)
    estimated_duration: float = 30.0  # é¢„ä¼°æ‰§è¡Œæ—¶é—´(ç§’)
    
    def __post_init__(self):
        if not self.task_id:
            self.task_id = f"{self.task_type}_{int(time.time() * 1000)}"


class CognitiveScheduler:
    """
    ğŸ§  è®¤çŸ¥è°ƒåº¦å™¨ - Agentçš„"å†…åœ¨ç‹¬ç™½å¾ªç¯"
    
    æ ¸å¿ƒèŒè´£ï¼š
    1. ç©ºé—²çŠ¶æ€æ£€æµ‹ - åˆ¤æ–­ä½•æ—¶å¯ä»¥è¿›è¡Œåå°è®¤çŸ¥
    2. è®¤çŸ¥ä»»åŠ¡è°ƒåº¦ - ç®¡ç†å›æº¯ã€åˆ›æƒ³ç­‰è®¤çŸ¥ä»»åŠ¡é˜Ÿåˆ—
    3. æ¨¡å¼åˆ‡æ¢æ§åˆ¶ - åè°ƒä»»åŠ¡é©±åŠ¨ä¸è‡ªæˆ‘é©±åŠ¨æ¨¡å¼
    4. è®¤çŸ¥èµ„æºç®¡ç† - åˆç†åˆ†é…è®¡ç®—èµ„æºç»™åå°æ€è€ƒ
    
    è®¾è®¡åŸåˆ™ï¼š
    - éä¾µå…¥æ€§ï¼šä¸å½±å“æ­£å¸¸ä»»åŠ¡æ‰§è¡Œ
    - å¯é…ç½®æ€§ï¼šæ”¯æŒçµæ´»çš„è°ƒåº¦ç­–ç•¥
    - æ¸è¿›å¼ï¼šä»ç®€å•ç©ºé—²æ£€æµ‹åˆ°å¤æ‚è®¤çŸ¥è°ƒåº¦
    """
    
    def __init__(self, 
                 state_manager: StateManager,
                 llm_client=None,
                 config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–è®¤çŸ¥è°ƒåº¦å™¨
        
        Args:
            state_manager: çŠ¶æ€ç®¡ç†å™¨å®ä¾‹
            llm_client: LLMå®¢æˆ·ç«¯ï¼ˆç”¨äºè®¤çŸ¥ä»»åŠ¡ï¼‰
            config: è°ƒåº¦å™¨é…ç½®
        """
        self.state_manager = state_manager
        self.llm_client = llm_client
        
        # é…ç½®å‚æ•°
        self.config = {
            # ç©ºé—²æ£€æµ‹é…ç½®
            "idle_detection": {
                "min_idle_duration": 10.0,      # æœ€å°ç©ºé—²æ—¶é—´(ç§’)
                "max_idle_duration": 300.0,     # æœ€å¤§ç©ºé—²æ—¶é—´(ç§’)  
                "task_completion_buffer": 5.0,   # ä»»åŠ¡å®Œæˆåç¼“å†²æ—¶é—´
                "check_interval": 2.0            # çŠ¶æ€æ£€æŸ¥é—´éš”
            },
            
            # è®¤çŸ¥ä»»åŠ¡é…ç½®
            "cognitive_tasks": {
                "retrospection_interval": 60.0,     # å›æº¯ä»»åŠ¡é—´éš”
                "ideation_interval": 120.0,          # åˆ›æƒ³ä»»åŠ¡é—´éš”
                "exploration_interval": 180.0,       # çŸ¥è¯†æ¢ç´¢ä»»åŠ¡é—´éš”
                "max_concurrent_tasks": 2,           # æœ€å¤§å¹¶å‘è®¤çŸ¥ä»»åŠ¡æ•°
                "task_timeout": 180.0                # è®¤çŸ¥ä»»åŠ¡è¶…æ—¶æ—¶é—´
            },
            
            # ğŸŒ çŸ¥è¯†æ¢ç´¢é…ç½® - åŒè½¨æ¢ç´¢ç³»ç»Ÿ
            "knowledge_exploration": {
                # é€šç”¨é…ç½®
                "max_exploration_depth": 3,         # æœ€å¤§æ¢ç´¢æ·±åº¦
                "enable_web_search": True,          # å¯ç”¨ç½‘ç»œæœç´¢
                "enable_trend_analysis": True,      # å¯ç”¨è¶‹åŠ¿åˆ†æ
                "knowledge_threshold": 0.7,         # çŸ¥è¯†è´¨é‡é˜ˆå€¼
                
                # è‡ªä¸»æ¢ç´¢é…ç½®
                "exploration_strategies": [
                    "domain_expansion",      # é¢†åŸŸæ‰©å±•
                    "trend_monitoring",      # è¶‹åŠ¿ç›‘æ§
                    "gap_analysis",         # çŸ¥è¯†ç¼ºå£åˆ†æ
                    "cross_domain_learning" # è·¨åŸŸå­¦ä¹ 
                ],
                "exploration_timeout": 120.0,       # è‡ªä¸»æ¢ç´¢è¶…æ—¶
                
                # ğŸ¯ ç”¨æˆ·æŒ‡ä»¤é©±åŠ¨æ¢ç´¢é…ç½®
                "user_directed_timeout": 60.0,      # ç”¨æˆ·æŒ‡ä»¤æ¢ç´¢è¶…æ—¶ï¼ˆæ›´çŸ­ï¼‰
                "user_directed_strategies": [
                    "expert_knowledge",      # ä¸“å®¶çŸ¥è¯†è·å–
                    "domain_expansion",      # é¢†åŸŸæ‰©å±•
                    "competitive_intelligence", # ç«äº‰æƒ…æŠ¥
                    "trend_monitoring"       # è¶‹åŠ¿ç›‘æ§
                ],
                
                # ğŸ¯ åŒè½¨å¹³è¡¡æœºåˆ¶
                "dual_track_config": {
                    "user_directed_priority": 10,   # ç”¨æˆ·æŒ‡ä»¤æœ€é«˜ä¼˜å…ˆçº§
                    "autonomous_priority": 3,       # è‡ªä¸»æ¢ç´¢è¾ƒä½ä¼˜å…ˆçº§
                    "max_concurrent_user_tasks": 3, # æœ€å¤§å¹¶å‘ç”¨æˆ·ä»»åŠ¡
                    "max_concurrent_autonomous": 1, # æœ€å¤§å¹¶å‘è‡ªä¸»ä»»åŠ¡
                    "user_task_preemption": True,   # å…è®¸ç”¨æˆ·ä»»åŠ¡æŠ¢å 
                    "balance_threshold": 0.8         # å¹³è¡¡é˜ˆå€¼
                }
            },
            
            # èµ„æºç®¡ç†é…ç½®
            "resource_limits": {
                "max_cpu_usage": 0.3,               # æœ€å¤§CPUä½¿ç”¨ç‡
                "max_memory_usage": 0.2,             # æœ€å¤§å†…å­˜ä½¿ç”¨ç‡
                "enable_adaptive_scheduling": True    # å¯ç”¨è‡ªé€‚åº”è°ƒåº¦
            }
        }
        
        # åˆå¹¶ç”¨æˆ·é…ç½®
        if config:
            self._merge_config(self.config, config)
        
        # æ ¸å¿ƒçŠ¶æ€
        self.current_mode = CognitiveMode.TASK_DRIVEN
        self.is_running = False
        self.is_idle = False
        self.last_activity_time = time.time()
        self.last_task_completion_time = None
        
        # è®¤çŸ¥ä»»åŠ¡ç®¡ç†
        self.cognitive_task_queue = Queue()
        self.active_cognitive_tasks: Dict[str, CognitiveTask] = {}
        self.cognitive_history: List[Dict[str, Any]] = []
        
        # ğŸ” ä»»åŠ¡å›æº¯å¼•æ“ - æ–°å¢åŠŸèƒ½
        self.retrospection_engine = None
        if state_manager and llm_client:
            try:
                # åˆ›å»ºå›æº¯å¼•æ“éœ€è¦PathGeneratorå’ŒMABConverger
                # è¿™äº›é€šå¸¸åœ¨ä¸Šå±‚çš„Agentæˆ–Plannerä¸­å¯ç”¨
                self.retrospection_engine = TaskRetrospectionEngine(
                    llm_client=llm_client,
                    config=config.get('retrospection_config', {}) if config else {}
                )
                logger.info("ğŸ” ä»»åŠ¡å›æº¯å¼•æ“å·²é›†æˆ - æ·±åº¦è®°å¿†åˆ†æèƒ½åŠ›å°±ç»ª")
            except Exception as e:
                logger.warning(f"âš ï¸ ä»»åŠ¡å›æº¯å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
                logger.info("ğŸ’¡ å°†ä½¿ç”¨åŸºç¡€å›æº¯åˆ†æåŠŸèƒ½")
        
        # ğŸŒ çŸ¥è¯†æ¢å‹˜å™¨ - æ–°å¢æ ¸å¿ƒæ¨¡å—
        self.knowledge_explorer = None
        if llm_client:
            try:
                explorer_config = config.get('knowledge_exploration', {}) if config else {}
                self.knowledge_explorer = KnowledgeExplorer(
                    llm_client=llm_client,
                    web_search_client=None,  # å¯ä»¥ä»ä¸Šå±‚ä¼ å…¥
                    config=explorer_config
                )
                logger.info("ğŸŒ çŸ¥è¯†æ¢å‹˜å™¨å·²é›†æˆ - å¤–éƒ¨æ™ºæ…§è¿æ¥å™¨å°±ç»ª")
            except Exception as e:
                logger.warning(f"âš ï¸ çŸ¥è¯†æ¢å‹˜å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                logger.info("ğŸ’¡ å°†ä½¿ç”¨åŸºç¡€æ¢ç´¢åˆ†æåŠŸèƒ½")
        
        # çº¿ç¨‹ç®¡ç†
        self.scheduler_thread: Optional[threading.Thread] = None
        self.cognitive_workers: List[threading.Thread] = []
        self.stop_event = threading.Event()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_idle_periods": 0,
            "total_idle_time": 0.0,
            "cognitive_tasks_completed": 0,
            "retrospection_sessions": 0,
            "ideation_sessions": 0,
            "knowledge_synthesis_sessions": 0,
            "knowledge_exploration_sessions": 0  # æ–°å¢ï¼šçŸ¥è¯†æ¢ç´¢ä¼šè¯æ•°
        }
        
        # ğŸŒ çŸ¥è¯†æ¢ç´¢ç›¸å…³çŠ¶æ€ - æ–°å¢
        self.exploration_history: List[Dict[str, Any]] = []
        self.last_exploration_time = 0.0  # ä¸Šæ¬¡æ¢ç´¢æ—¶é—´
        self.exploration_topics_cache: List[str] = []  # æ¢ç´¢ä¸»é¢˜ç¼“å­˜
        self.discovered_knowledge: Dict[str, Any] = {}  # å‘ç°çš„æ–°çŸ¥è¯†
        
        # æ³¨å†ŒçŠ¶æ€å˜åŒ–ç›‘å¬å™¨
        self.state_manager.add_state_change_listener(self._on_state_change)
        
        logger.info("ğŸ§  CognitiveScheduler åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   ç©ºé—²æ£€æµ‹é—´éš”: {self.config['idle_detection']['check_interval']}s")
        logger.info(f"   æœ€å°ç©ºé—²è§¦å‘æ—¶é—´: {self.config['idle_detection']['min_idle_duration']}s")
        logger.info(f"   å›æº¯å¼•æ“: {'å·²é›†æˆ' if self.retrospection_engine else 'æœªé›†æˆ'}")
        logger.info(f"   çŸ¥è¯†æ¢å‹˜å™¨: {'å·²é›†æˆ' if self.knowledge_explorer else 'æœªé›†æˆ'}")
        logger.info("ğŸ’¡ ä¸»åŠ¨è®¤çŸ¥æ¨¡å¼å·²å°±ç»ª - ä»'ä»»åŠ¡å¥´éš¶'å‡çº§ä¸º'è‡ªä¸»æ€è€ƒè€…'")
    
    def start(self):
        """å¯åŠ¨è®¤çŸ¥è°ƒåº¦å™¨"""
        if self.is_running:
            logger.warning("âš ï¸ è®¤çŸ¥è°ƒåº¦å™¨å·²ç»åœ¨è¿è¡Œ")
            return
        
        self.is_running = True
        self.stop_event.clear()
        
        # å¯åŠ¨ä¸»è°ƒåº¦çº¿ç¨‹
        self.scheduler_thread = threading.Thread(
            target=self._scheduler_main_loop,
            name="CognitiveScheduler",
            daemon=True
        )
        self.scheduler_thread.start()
        
        # å¯åŠ¨è®¤çŸ¥å·¥ä½œçº¿ç¨‹
        max_workers = self.config["cognitive_tasks"]["max_concurrent_tasks"]
        for i in range(max_workers):
            worker = threading.Thread(
                target=self._cognitive_worker_loop,
                name=f"CognitiveWorker-{i+1}",
                daemon=True
            )
            worker.start()
            self.cognitive_workers.append(worker)
        
        logger.info("ğŸš€ è®¤çŸ¥è°ƒåº¦å™¨å·²å¯åŠ¨")
        logger.info(f"   ä¸»è°ƒåº¦çº¿ç¨‹: {self.scheduler_thread.name}")
        logger.info(f"   è®¤çŸ¥å·¥ä½œçº¿ç¨‹æ•°: {len(self.cognitive_workers)}")
    
    def stop(self):
        """åœæ­¢è®¤çŸ¥è°ƒåº¦å™¨"""
        if not self.is_running:
            logger.warning("âš ï¸ è®¤çŸ¥è°ƒåº¦å™¨æœªåœ¨è¿è¡Œ")
            return
        
        logger.info("ğŸ›‘ æ­£åœ¨åœæ­¢è®¤çŸ¥è°ƒåº¦å™¨...")
        
        self.is_running = False
        self.stop_event.set()
        
        # ç­‰å¾…ä¸»è°ƒåº¦çº¿ç¨‹ç»“æŸ
        if self.scheduler_thread and self.scheduler_thread.is_alive():
            self.scheduler_thread.join(timeout=5.0)
        
        # ç­‰å¾…å·¥ä½œçº¿ç¨‹ç»“æŸ
        for worker in self.cognitive_workers:
            if worker.is_alive():
                worker.join(timeout=5.0)
        
        logger.info("âœ… è®¤çŸ¥è°ƒåº¦å™¨å·²åœæ­¢")
        self._log_final_stats()
    
    def _scheduler_main_loop(self):
        """ä¸»è°ƒåº¦å¾ªç¯ - ç›‘æ§ç©ºé—²çŠ¶æ€å¹¶è§¦å‘è®¤çŸ¥ä»»åŠ¡"""
        logger.info("ğŸ”„ è®¤çŸ¥è°ƒåº¦ä¸»å¾ªç¯å·²å¯åŠ¨")
        
        while self.is_running and not self.stop_event.is_set():
            try:
                # æ£€æµ‹å½“å‰çŠ¶æ€
                self._detect_idle_state()
                
                # æ ¹æ®çŠ¶æ€æ‰§è¡Œç›¸åº”é€»è¾‘
                if self.is_idle:
                    self._handle_idle_state()
                else:
                    self._handle_active_state()
                
                # è°ƒåº¦è®¤çŸ¥ä»»åŠ¡
                self._schedule_cognitive_tasks()
                
                # æ¸…ç†è¿‡æœŸä»»åŠ¡
                self._cleanup_expired_tasks()
                
                # ç­‰å¾…ä¸‹ä¸€ä¸ªæ£€æŸ¥å‘¨æœŸ
                check_interval = self.config["idle_detection"]["check_interval"]
                self.stop_event.wait(check_interval)
                
            except Exception as e:
                logger.error(f"âŒ è®¤çŸ¥è°ƒåº¦å¾ªç¯å‡ºé”™: {e}")
                time.sleep(5.0)  # é”™è¯¯æ¢å¤å»¶è¿Ÿ
        
        logger.info("ğŸ”š è®¤çŸ¥è°ƒåº¦ä¸»å¾ªç¯å·²ç»“æŸ")
    
    def _detect_idle_state(self):
        """æ£€æµ‹ç³»ç»Ÿç©ºé—²çŠ¶æ€"""
        current_time = time.time()
        current_state = self.state_manager.get_current_state()
        
        # è·å–çŠ¶æ€ä¿¡æ¯
        current_phase = current_state.get("current_phase", "initialization")
        current_goal = current_state.get("current_goal", {})
        goal_status = current_goal.get("status", "pending")
        
        # åˆ¤æ–­æ˜¯å¦å¤„äºç©ºé—²çŠ¶æ€
        is_task_completed = (
            current_phase == "completion" or 
            goal_status in ["achieved", "failed"]
        )
        
        # è®¡ç®—ç©ºé—²æ—¶é—´
        if is_task_completed and self.last_task_completion_time is None:
            self.last_task_completion_time = current_time
        
        idle_duration = 0.0
        if self.last_task_completion_time:
            idle_duration = current_time - self.last_task_completion_time
        
        # æ›´æ–°ç©ºé—²çŠ¶æ€
        min_idle_duration = self.config["idle_detection"]["min_idle_duration"]
        was_idle = self.is_idle
        
        self.is_idle = (
            is_task_completed and 
            idle_duration >= min_idle_duration
        )
        
        # ç©ºé—²çŠ¶æ€å˜åŒ–æ—¶è®°å½•æ—¥å¿—
        if self.is_idle and not was_idle:
            self._enter_idle_state(idle_duration)
        elif not self.is_idle and was_idle:
            self._exit_idle_state()
    
    def _enter_idle_state(self, idle_duration: float):
        """è¿›å…¥ç©ºé—²çŠ¶æ€"""
        self.current_mode = CognitiveMode.COGNITIVE_IDLE
        self.stats["total_idle_periods"] += 1
        
        logger.info("ğŸ˜´ ç³»ç»Ÿè¿›å…¥è®¤çŸ¥ç©ºé—²çŠ¶æ€")
        logger.info(f"   ç©ºé—²æ—¶é•¿: {idle_duration:.1f}s")
        logger.info("ğŸ’­ å¼€å§‹ä¸»åŠ¨è®¤çŸ¥æ¨¡å¼...")
        
        # ç«‹å³å®‰æ’ä¸€ä¸ªå›æº¯ä»»åŠ¡
        self._schedule_retrospection_task()
    
    def _exit_idle_state(self):
        """é€€å‡ºç©ºé—²çŠ¶æ€"""
        idle_start_time = self.last_task_completion_time
        if idle_start_time:
            idle_duration = time.time() - idle_start_time
            self.stats["total_idle_time"] += idle_duration
            
            logger.info("ğŸ”„ ç³»ç»Ÿé€€å‡ºç©ºé—²çŠ¶æ€")
            logger.info(f"   æœ¬æ¬¡ç©ºé—²æ—¶é•¿: {idle_duration:.1f}s")
        
        self.current_mode = CognitiveMode.TASK_DRIVEN
        self.last_task_completion_time = None
        
        # æš‚åœä½ä¼˜å…ˆçº§è®¤çŸ¥ä»»åŠ¡
        self._pause_low_priority_cognitive_tasks()
    
    def _handle_idle_state(self):
        """å¤„ç†ç©ºé—²çŠ¶æ€é€»è¾‘"""
        current_time = time.time()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å®‰æ’åˆ›æƒ³ä»»åŠ¡
        ideation_interval = self.config["cognitive_tasks"]["ideation_interval"]
        if (current_time - self.last_activity_time) >= ideation_interval:
            if not self._has_active_task_type("ideation"):
                self._schedule_ideation_task()
        
        # ğŸŒ æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦å®‰æ’çŸ¥è¯†æ¢ç´¢ä»»åŠ¡
        exploration_interval = self.config["cognitive_tasks"]["exploration_interval"]
        if (current_time - self.last_exploration_time) >= exploration_interval:
            if not self._has_active_task_type("knowledge_exploration"):
                self._schedule_knowledge_exploration_task()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦çŸ¥è¯†ç»¼åˆ
        if self._should_trigger_knowledge_synthesis():
            self._schedule_knowledge_synthesis_task()
    
    def _handle_active_state(self):
        """å¤„ç†æ´»è·ƒçŠ¶æ€é€»è¾‘"""
        self.last_activity_time = time.time()
    
    def _schedule_cognitive_tasks(self):
        """è°ƒåº¦è®¤çŸ¥ä»»åŠ¡"""
        # è¿™é‡Œæ˜¯ä»»åŠ¡è°ƒåº¦çš„æ ¸å¿ƒé€»è¾‘
        # å½“å‰åªæ˜¯åŸºç¡€æ¡†æ¶ï¼Œåç»­ä¼šæ‰©å±•
        pass
    
    def _schedule_retrospection_task(self):
        """å®‰æ’å›æº¯ä»»åŠ¡"""
        task = CognitiveTask(
            task_id="",
            task_type="retrospection", 
            priority=7,
            context={
                "session_state": self.state_manager.get_current_state(),
                "trigger_reason": "idle_detection"
            },
            estimated_duration=45.0
        )
        
        self.cognitive_task_queue.put(task)
        logger.info("ğŸ“š å·²å®‰æ’ä»»åŠ¡å›æº¯åˆ†æ")
    
    def _schedule_ideation_task(self):
        """å®‰æ’åˆ›æƒ³ä»»åŠ¡"""
        task = CognitiveTask(
            task_id="",
            task_type="ideation",
            priority=5, 
            context={
                "session_insights": self._extract_session_insights(),
                "trigger_reason": "periodic_ideation"
            },
            estimated_duration=60.0
        )
        
        self.cognitive_task_queue.put(task)
        logger.info("ğŸ’¡ å·²å®‰æ’ä¸»åŠ¨åˆ›æƒ³ä»»åŠ¡")
    
    def _schedule_knowledge_synthesis_task(self):
        """å®‰æ’çŸ¥è¯†ç»¼åˆä»»åŠ¡"""
        task = CognitiveTask(
            task_id="",
            task_type="knowledge_synthesis",
            priority=6,
            context={
                "cognitive_history": self.cognitive_history[-10:],  # æœ€è¿‘10æ¬¡è®¤çŸ¥ç»“æœ
                "trigger_reason": "knowledge_accumulation"
            },
            estimated_duration=90.0
        )
        
        self.cognitive_task_queue.put(task)
        logger.info("ğŸ§© å·²å®‰æ’çŸ¥è¯†ç»¼åˆä»»åŠ¡")
    
    def _schedule_knowledge_exploration_task(self, user_query: Optional[str] = None, user_context: Optional[Dict[str, Any]] = None):
        """ğŸŒ å®‰æ’çŸ¥è¯†æ¢ç´¢ä»»åŠ¡ - åŒè½¨æ¢ç´¢ç›®æ ‡ç³»ç»Ÿ
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢ï¼Œå¦‚æœæä¾›åˆ™åˆ›å»ºç”¨æˆ·æŒ‡ä»¤é©±åŠ¨çš„é«˜ä¼˜å…ˆçº§æ¢ç´¢ä»»åŠ¡
            user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        """
        current_time = time.time()
        
        # ğŸ¯ åŒè½¨æ¢ç´¢æ¨¡å¼åˆ¤æ–­
        if user_query:
            # ç”¨æˆ·æŒ‡ä»¤é©±åŠ¨çš„é«˜ä¼˜å…ˆçº§æ¢ç´¢æ¨¡å¼
            logger.info(f"ğŸ¯ å¯åŠ¨ç”¨æˆ·æŒ‡ä»¤é©±åŠ¨æ¢ç´¢æ¨¡å¼: {user_query[:50]}...")
            
            task = CognitiveTask(
                task_id="",
                task_type="knowledge_exploration",
                priority=10,  # æœ€é«˜ä¼˜å…ˆçº§ - ç”¨æˆ·æŒ‡ä»¤é©±åŠ¨
                context={
                    "exploration_mode": "user_directed",
                    "user_query": user_query,
                    "user_context": user_context or {},
                    "trigger_reason": "user_instruction",
                    "immediate_priority": True,
                    # åŸºäºç”¨æˆ·æŸ¥è¯¢ç”Ÿæˆçš„æ¢ç´¢ä¸Šä¸‹æ–‡
                    "exploration_opportunities": self._analyze_user_query_exploration_opportunities(user_query, user_context),
                    "exploration_strategies": self._select_user_directed_strategies(user_query),
                    "session_insights": self._extract_session_insights(),
                    "current_knowledge_gaps": self._identify_knowledge_gaps(),
                    "created_at": current_time
                },
                estimated_duration=self.config["knowledge_exploration"]["user_directed_timeout"]
            )
            
            # ğŸš€ ç«‹å³æ’å…¥åˆ°é˜Ÿåˆ—å‰ç«¯ï¼Œç¡®ä¿ä¼˜å…ˆæ‰§è¡Œ
            self._insert_high_priority_task(task)
            
            logger.info("ğŸ¯ ç”¨æˆ·æŒ‡ä»¤é©±åŠ¨æ¢ç´¢ä»»åŠ¡å·²åˆ›å»º - æœ€é«˜ä¼˜å…ˆçº§")
            logger.info(f"   ç”¨æˆ·æŸ¥è¯¢: {user_query[:100]}...")
            logger.info(f"   æ¢ç´¢ç­–ç•¥: {task.context.get('exploration_strategies', [])[:2]}")
            
        else:
            # ç³»ç»Ÿè‡ªä¸»æ¢ç´¢çš„ä½ä¼˜å…ˆçº§æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            logger.info("ğŸ”„ å¯åŠ¨ç³»ç»Ÿè‡ªä¸»æ¢ç´¢æ¨¡å¼")
            
            # åˆ†æå½“å‰çŸ¥è¯†çŠ¶æ€ï¼Œç¡®å®šæ¢ç´¢æ–¹å‘
            exploration_context = self._analyze_exploration_opportunities()
            
            task = CognitiveTask(
                task_id="",
                task_type="knowledge_exploration",
                priority=3,  # è¾ƒä½ä¼˜å…ˆçº§ - ç³»ç»Ÿè‡ªä¸»æ¢ç´¢
                context={
                    "exploration_mode": "autonomous",
                    "exploration_opportunities": exploration_context,
                    "session_insights": self._extract_session_insights(),
                    "current_knowledge_gaps": self._identify_knowledge_gaps(),
                    "exploration_strategies": self.config["knowledge_exploration"]["exploration_strategies"],
                    "trigger_reason": "proactive_exploration",
                    "immediate_priority": False,
                    "created_at": current_time
                },
                estimated_duration=self.config["knowledge_exploration"]["exploration_timeout"]
            )
            
            self.cognitive_task_queue.put(task)
            
            logger.info("ğŸ”„ è‡ªä¸»æ¢ç´¢ä»»åŠ¡å·²å®‰æ’ - å¸¸è§„ä¼˜å…ˆçº§")
            logger.info(f"   æ¢ç´¢æœºä¼šæ•°é‡: {len(exploration_context)}")
            logger.info(f"   æ¢ç´¢ç­–ç•¥: {task.context['exploration_strategies'][:2]}...")
        
        self.last_exploration_time = current_time
    
    def _analyze_user_query_exploration_opportunities(self, user_query: str, user_context: Optional[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ğŸ¯ åˆ†æç”¨æˆ·æŸ¥è¯¢ä¸­çš„æ¢ç´¢æœºä¼š - ç”¨æˆ·æŒ‡ä»¤é©±åŠ¨æ¨¡å¼"""
        opportunities = []
        
        try:
            # åŸºç¡€å…³é”®è¯æå–
            query_keywords = self._extract_query_keywords(user_query)
            
            # è¯†åˆ«ç”¨æˆ·æŸ¥è¯¢ä¸­çš„é¢†åŸŸå’Œä¸»é¢˜
            query_domains = self._identify_query_domains(user_query)
            
            # æ„å»ºé’ˆå¯¹ç”¨æˆ·æŸ¥è¯¢çš„æ¢ç´¢æœºä¼š
            for domain in query_domains:
                opportunities.append({
                    "type": "user_query_domain",
                    "domain": domain,
                    "query": user_query,
                    "keywords": query_keywords,
                    "priority": "high",
                    "exploration_focus": f"æ·±å…¥äº†è§£ç”¨æˆ·å…³äº'{domain}'çš„å…·ä½“éœ€æ±‚",
                    "search_terms": self._generate_user_focused_search_terms(user_query, domain)
                })
            
            # æ·»åŠ ç›¸å…³ä¸»é¢˜æ¢ç´¢
            if len(opportunities) < 3:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ¢ç´¢æ–¹å‘
                opportunities.extend([
                    {
                        "type": "related_topics",
                        "query": user_query,
                        "keywords": query_keywords,
                        "priority": "medium",
                        "exploration_focus": f"å¯»æ‰¾ä¸'{user_query[:30]}...'ç›¸å…³çš„ä¿¡æ¯å’Œæ¡ˆä¾‹",
                        "search_terms": query_keywords[:5]
                    }
                ])
            
            logger.debug(f"ğŸ¯ ç”¨æˆ·æŸ¥è¯¢æ¢ç´¢æœºä¼šåˆ†æå®Œæˆ: {len(opportunities)} ä¸ªæœºä¼š")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ç”¨æˆ·æŸ¥è¯¢æ¢ç´¢æœºä¼šåˆ†æå¤±è´¥: {e}")
            # æä¾›åŸºç¡€çš„æ¢ç´¢æœºä¼š
            opportunities.append({
                "type": "basic_user_query",
                "query": user_query,
                "priority": "high",
                "exploration_focus": f"åŸºäºç”¨æˆ·æŸ¥è¯¢çš„åŸºç¡€ä¿¡æ¯æ”¶é›†"
            })
        
        return opportunities
    
    def _select_user_directed_strategies(self, user_query: str) -> List[str]:
        """ğŸ¯ ä¸ºç”¨æˆ·æŒ‡ä»¤é€‰æ‹©æœ€é€‚åˆçš„æ¢ç´¢ç­–ç•¥"""
        query_lower = user_query.lower()
        strategies = []
        
        # åŸºäºæŸ¥è¯¢å†…å®¹é€‰æ‹©ç­–ç•¥
        if any(keyword in query_lower for keyword in ['æœ€æ–°', 'è¶‹åŠ¿', 'å‘å±•', 'åŠ¨æ€', 'latest', 'trend']):
            strategies.extend(['trend_monitoring', 'domain_expansion'])
        
        if any(keyword in query_lower for keyword in ['å¦‚ä½•', 'æ–¹æ³•', 'è§£å†³', 'how', 'solution', 'method']):
            strategies.extend(['expert_knowledge', 'gap_analysis'])
        
        if any(keyword in query_lower for keyword in ['æ¯”è¾ƒ', 'å¯¹æ¯”', 'compare', 'versus', 'vs']):
            strategies.extend(['competitive_intelligence', 'cross_domain_learning'])
        
        if any(keyword in query_lower for keyword in ['åˆ›æ–°', 'æ–°é¢–', 'innovative', 'creative', 'novel']):
            strategies.extend(['serendipity_discovery', 'cross_domain_learning'])
        
        # é»˜è®¤ç­–ç•¥
        if not strategies:
            strategies = ['domain_expansion', 'expert_knowledge']
        
        # é™åˆ¶ç­–ç•¥æ•°é‡ï¼Œé¿å…è¿‡åº¦æ¢ç´¢
        return strategies[:3]
    
    def _insert_high_priority_task(self, task: CognitiveTask):
        """ğŸš€ æ’å…¥é«˜ä¼˜å…ˆçº§ä»»åŠ¡åˆ°é˜Ÿåˆ—å‰ç«¯"""
        try:
            # ç”±äºQueueä¸æ”¯æŒä¼˜å…ˆçº§æ’å…¥ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªä¸´æ—¶åˆ—è¡¨æ¥é‡ç»„é˜Ÿåˆ—
            temp_tasks = []
            
            # å…ˆå–å‡ºæ‰€æœ‰ç°æœ‰ä»»åŠ¡
            while not self.cognitive_task_queue.empty():
                try:
                    existing_task = self.cognitive_task_queue.get_nowait()
                    temp_tasks.append(existing_task)
                except Empty:
                    break
            
            # é¦–å…ˆæ’å…¥é«˜ä¼˜å…ˆçº§ä»»åŠ¡
            self.cognitive_task_queue.put(task)
            
            # ç„¶åæŒ‰ä¼˜å…ˆçº§é‡æ–°æ’å…¥å…¶ä»–ä»»åŠ¡
            temp_tasks.sort(key=lambda t: t.priority, reverse=True)
            for existing_task in temp_tasks:
                self.cognitive_task_queue.put(existing_task)
            
            logger.debug(f"ğŸš€ é«˜ä¼˜å…ˆçº§ä»»åŠ¡å·²æ’å…¥é˜Ÿåˆ—å‰ç«¯: {task.task_id}")
            
        except Exception as e:
            logger.error(f"âŒ æ’å…¥é«˜ä¼˜å…ˆçº§ä»»åŠ¡å¤±è´¥: {e}")
            # å›é€€åˆ°æ™®é€šæ’å…¥
            self.cognitive_task_queue.put(task)
    
    def _extract_query_keywords(self, user_query: str) -> List[str]:
        """æå–ç”¨æˆ·æŸ¥è¯¢ä¸­çš„å…³é”®è¯"""
        import re
        
        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå¯ä»¥åç»­ç”¨æ›´é«˜çº§çš„NLPæ–¹æ³•æ›¿æ¢ï¼‰
        words = re.findall(r'\b\w+\b', user_query.lower())
        
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        stop_words = {'çš„', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'æˆ–', 'ä½†', 'ç„¶è€Œ', 'å› æ­¤', 'the', 'is', 'in', 'and', 'or', 'but', 'how', 'what', 'where', 'when', 'why'}
        keywords = [word for word in words if len(word) > 2 and word not in stop_words]
        
        return keywords[:8]  # è¿”å›å‰8ä¸ªå…³é”®è¯
    
    def _identify_query_domains(self, user_query: str) -> List[str]:
        """è¯†åˆ«ç”¨æˆ·æŸ¥è¯¢æ‰€å±çš„é¢†åŸŸ"""
        query_lower = user_query.lower()
        domains = []
        
        domain_keywords = {
            "æŠ€æœ¯": ['api', 'ç®—æ³•', 'ç¼–ç¨‹', 'ä»£ç ', 'ç³»ç»Ÿ', 'æ¶æ„', 'æ•°æ®åº“', 'æœºå™¨å­¦ä¹ ', 'ai', 'python', 'java'],
            "å•†ä¸š": ['å¸‚åœº', 'è¥é”€', 'é”€å”®', 'å•†ä¸š', 'ç®¡ç†', 'ç­–ç•¥', 'æŠ•èµ„', 'åˆ›ä¸š', 'å…¬å¸'],
            "å­¦æœ¯": ['ç ”ç©¶', 'è®ºæ–‡', 'ç†è®º', 'å­¦æœ¯', 'ç§‘å­¦', 'å®éªŒ', 'åˆ†æ', 'æ–¹æ³•'],
            "å¥åº·": ['å¥åº·', 'åŒ»ç–—', 'ç–¾ç—…', 'æ²»ç–—', 'ä¿å¥', 'åŒ»å­¦', 'è¯ç‰©'],
            "æ•™è‚²": ['å­¦ä¹ ', 'æ•™è‚²', 'åŸ¹è®­', 'è¯¾ç¨‹', 'çŸ¥è¯†', 'æŠ€èƒ½', 'å­¦æ ¡'],
            "ç”Ÿæ´»": ['ç”Ÿæ´»', 'æ—¥å¸¸', 'å®¶å±…', 'æ—…è¡Œ', 'ç¾é£Ÿ', 'å¨±ä¹', 'ä¼‘é—²']
        }
        
        for domain, keywords in domain_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                domains.append(domain)
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ç‰¹å®šé¢†åŸŸï¼Œè¿”å›é€šç”¨é¢†åŸŸ
        if not domains:
            domains = ["é€šç”¨"]
        
        return domains[:2]  # æœ€å¤šè¿”å›2ä¸ªä¸»è¦é¢†åŸŸ
    
    def _generate_user_focused_search_terms(self, user_query: str, domain: str) -> List[str]:
        """ä¸ºç”¨æˆ·æŸ¥è¯¢ç”Ÿæˆé’ˆå¯¹æ€§çš„æœç´¢è¯æ¡"""
        base_terms = self._extract_query_keywords(user_query)
        
        # æ ¹æ®é¢†åŸŸæ·»åŠ ç›¸å…³çš„æœç´¢å¢å¼ºè¯
        domain_enhancers = {
            "æŠ€æœ¯": ["æœ€ä½³å®è·µ", "æ•™ç¨‹", "æ¡ˆä¾‹", "è§£å†³æ–¹æ¡ˆ"],
            "å•†ä¸š": ["æ¡ˆä¾‹ç ”ç©¶", "å¸‚åœºåˆ†æ", "æˆåŠŸæ¡ˆä¾‹", "ç­–ç•¥"],
            "å­¦æœ¯": ["æœ€æ–°ç ”ç©¶", "æ–‡çŒ®ç»¼è¿°", "æ–¹æ³•è®º", "å®è¯åˆ†æ"],
            "å¥åº·": ["ä¸“ä¸šå»ºè®®", "ä¸´åºŠç ”ç©¶", "é¢„é˜²æ–¹æ³•", "æ²»ç–—æ–¹æ¡ˆ"],
            "æ•™è‚²": ["å­¦ä¹ èµ„æº", "æ•™å­¦æ–¹æ³•", "å®è·µæŒ‡å—", "æŠ€èƒ½åŸ¹å…»"],
            "ç”Ÿæ´»": ["å®ç”¨æŒ‡å—", "ç»éªŒåˆ†äº«", "æ¨è", "è¯„ä»·"]
        }
        
        enhancers = domain_enhancers.get(domain, ["è¯¦ç»†ä¿¡æ¯", "æŒ‡å—", "å»ºè®®"])
        
        # ç»„åˆç”Ÿæˆæœç´¢è¯æ¡
        search_terms = base_terms[:3]  # åŸºç¡€å…³é”®è¯
        search_terms.extend(enhancers[:2])  # å¢å¼ºè¯
        
        return search_terms
    
    def schedule_user_directed_exploration(self, user_query: str, user_context: Optional[Dict[str, Any]] = None):
        """ğŸ¯ å…¬å…±æ¥å£ï¼šä¸ºç”¨æˆ·æŒ‡ä»¤å®‰æ’é«˜ä¼˜å…ˆçº§æ¢ç´¢ä»»åŠ¡"""
        logger.info(f"ğŸ¯ æ¥æ”¶åˆ°ç”¨æˆ·æŒ‡ä»¤é©±åŠ¨çš„æ¢ç´¢è¯·æ±‚: {user_query[:50]}...")
        
        # è®°å½•ç”¨æˆ·æŒ‡ä»¤ç»Ÿè®¡
        if "user_directed_explorations" not in self.stats:
            self.stats["user_directed_explorations"] = 0
        self.stats["user_directed_explorations"] += 1
        
        # è°ƒç”¨å†…éƒ¨æ–¹æ³•åˆ›å»ºæ¢ç´¢ä»»åŠ¡
        self._schedule_knowledge_exploration_task(user_query=user_query, user_context=user_context)
        
        logger.info("ğŸ¯ ç”¨æˆ·æŒ‡ä»¤é©±åŠ¨æ¢ç´¢ä»»åŠ¡å·²å®‰æ’å®Œæˆ")
    
    def _cognitive_worker_loop(self):
        """è®¤çŸ¥å·¥ä½œçº¿ç¨‹å¾ªç¯"""
        worker_name = threading.current_thread().name
        logger.info(f"ğŸ”¨ {worker_name} è®¤çŸ¥å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨")
        
        while self.is_running and not self.stop_event.is_set():
            try:
                # è·å–è®¤çŸ¥ä»»åŠ¡ï¼ˆé˜»å¡ç­‰å¾…ï¼Œè¶…æ—¶5ç§’ï¼‰
                task = self.cognitive_task_queue.get(timeout=5.0)
                
                # æ‰§è¡Œè®¤çŸ¥ä»»åŠ¡
                self._execute_cognitive_task(task, worker_name)
                
                # æ ‡è®°ä»»åŠ¡å®Œæˆ
                self.cognitive_task_queue.task_done()
                
            except Empty:
                # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­ç­‰å¾…
                continue
            except Exception as e:
                logger.error(f"âŒ {worker_name} æ‰§è¡Œè®¤çŸ¥ä»»åŠ¡å‡ºé”™: {e}")
        
        logger.info(f"ğŸ”š {worker_name} è®¤çŸ¥å·¥ä½œçº¿ç¨‹å·²ç»“æŸ")
    
    def _execute_cognitive_task(self, task: CognitiveTask, worker_name: str):
        """æ‰§è¡Œå…·ä½“çš„è®¤çŸ¥ä»»åŠ¡"""
        start_time = time.time()
        
        try:
            logger.info(f"ğŸ§  {worker_name} å¼€å§‹æ‰§è¡Œè®¤çŸ¥ä»»åŠ¡: {task.task_type}")
            
            # è®°å½•æ´»è·ƒä»»åŠ¡
            self.active_cognitive_tasks[task.task_id] = task
            
            # æ ¹æ®ä»»åŠ¡ç±»å‹æ‰§è¡Œä¸åŒé€»è¾‘
            result = {}
            if task.task_type == "retrospection":
                result = self._execute_retrospection_task(task)
            elif task.task_type == "ideation":  
                result = self._execute_ideation_task(task)
            elif task.task_type == "knowledge_synthesis":
                result = self._execute_knowledge_synthesis_task(task)
            elif task.task_type == "knowledge_exploration":  # ğŸŒ æ–°å¢
                result = self._execute_knowledge_exploration_task(task)
            else:
                logger.warning(f"âš ï¸ æœªçŸ¥è®¤çŸ¥ä»»åŠ¡ç±»å‹: {task.task_type}")
                return
            
            # è®°å½•è®¤çŸ¥ç»“æœ
            execution_time = time.time() - start_time
            cognitive_result = {
                "task_id": task.task_id,
                "task_type": task.task_type,
                "result": result,
                "execution_time": execution_time,
                "worker_name": worker_name,
                "timestamp": time.time()
            }
            
            self.cognitive_history.append(cognitive_result)
            self.stats["cognitive_tasks_completed"] += 1
            
            logger.info(f"âœ… {worker_name} å®Œæˆè®¤çŸ¥ä»»åŠ¡ {task.task_type} (è€—æ—¶: {execution_time:.1f}s)")
            
        except Exception as e:
            logger.error(f"âŒ {worker_name} è®¤çŸ¥ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        finally:
            # æ¸…ç†æ´»è·ƒä»»åŠ¡è®°å½•
            self.active_cognitive_tasks.pop(task.task_id, None)
    
    def _execute_retrospection_task(self, task: CognitiveTask) -> Dict[str, Any]:
        """æ‰§è¡Œå›æº¯ä»»åŠ¡ - åˆ†æè¿‡å¾€å†³ç­–æ¨¡å¼å’Œç»éªŒæ•™è®­"""
        self.stats["retrospection_sessions"] += 1
        
        # ğŸ” ä½¿ç”¨ä¸“ä¸šå›æº¯å¼•æ“è¿›è¡Œæ·±åº¦åˆ†æ
        if self.retrospection_engine:
            try:
                logger.info("ğŸ” å¯åŠ¨ä¸“ä¸šå›æº¯å¼•æ“è¿›è¡Œæ·±åº¦åˆ†æ...")
                
                # ä»ä»»åŠ¡ä¸Šä¸‹æ–‡è·å–è§¦å‘åŸå› ï¼Œé€‰æ‹©åˆé€‚çš„å›æº¯ç­–ç•¥
                trigger_reason = task.context.get("trigger_reason", "idle_detection")
                strategy = self._determine_retrospection_strategy(trigger_reason, task.context)
                
                # æ‰§è¡Œå®Œæ•´çš„ä¸‰é˜¶æ®µå›æº¯æµç¨‹
                retrospection_result = self.retrospection_engine.perform_retrospection(
                    state_manager=self.state_manager,
                    strategy=strategy
                )
                
                # è½¬æ¢ä¸ºè®¤çŸ¥è°ƒåº¦å™¨çš„åˆ†ææ ¼å¼
                analysis = self._convert_retrospection_result(retrospection_result)
                
                logger.info("âœ… ä¸“ä¸šå›æº¯å¼•æ“åˆ†æå®Œæˆ")
                logger.info(f"   LLMç»´åº¦: {len(retrospection_result.llm_dimensions)} ä¸ª")
                logger.info(f"   åˆ›æ„è·¯å¾„: {len(retrospection_result.aha_moment_paths)} æ¡")
                logger.info(f"   æ²‰æ·€ç­–ç•¥: {len(retrospection_result.assimilated_strategies)} ä¸ª")
                
                return analysis
                
            except Exception as e:
                logger.error(f"âŒ ä¸“ä¸šå›æº¯å¼•æ“æ‰§è¡Œå¤±è´¥: {e}")
                logger.info("ğŸ”„ å›é€€åˆ°åŸºç¡€å›æº¯åˆ†æ...")
        
        # åŸºç¡€åˆ†æï¼ˆå›é€€æœºåˆ¶ï¼‰
        session_state = task.context.get("session_state", {})
        conversation_history = session_state.get("conversation", {})
        mab_stats = session_state.get("mab", {})
        
        analysis = {
            "session_insights": {
                "total_turns": conversation_history.get("total_turns", 0),
                "success_patterns": self._identify_success_patterns(session_state),
                "failure_patterns": self._identify_failure_patterns(session_state),
                "decision_efficiency": mab_stats.get("decision_patterns", {})
            },
            "improvement_suggestions": [
                "åŸºç¡€å›æº¯åˆ†æå®Œæˆï¼Œå»ºè®®å¯ç”¨ä¸“ä¸šå›æº¯å¼•æ“è·å¾—æ›´æ·±å…¥æ´å¯Ÿ"
            ],
            "golden_templates": self._extract_golden_decision_templates(session_state)
        }
        
        logger.info("ğŸ” å®ŒæˆåŸºç¡€ä»»åŠ¡å›æº¯åˆ†æ")
        logger.debug(f"   åˆ†æè§è§£: {len(analysis['session_insights'])} é¡¹")
        
        return analysis
    
    def _execute_ideation_task(self, task: CognitiveTask) -> Dict[str, Any]:
        """æ‰§è¡Œåˆ›æƒ³ä»»åŠ¡ - ä¸»åŠ¨äº§ç”Ÿåˆ›æ–°æ€è·¯å’Œçªç ´æ€§æƒ³æ³•"""
        self.stats["ideation_sessions"] += 1
        
        # è·å–ä¼šè¯è§è§£
        session_insights = task.context.get("session_insights", {})
        
        # åŸºç¡€åˆ›æƒ³ï¼ˆåç»­ä¼šç”±ProactiveIdeationModuleå¤„ç†ï¼‰
        ideation_result = {
            "creative_dimensions": [
                "åŸºäºå†å²æ¨¡å¼çš„åˆ›æ–°ç»´åº¦",
                "è·¨é¢†åŸŸæ€ç»´è¿ç§»æ–¹å‘", 
                "çªç ´æ€§é—®é¢˜é‡æ„è§’åº¦"
            ],
            "novel_approaches": [
                "å¾…LLMDrivenDimensionCreatoråœ¨ä¸»åŠ¨æ¨¡å¼ä¸‹ç”Ÿæˆ"
            ],
            "breakthrough_concepts": {
                "concept_seeds": ["åˆ›æ–°æ¦‚å¿µç§å­1", "åˆ›æ–°æ¦‚å¿µç§å­2"],
                "application_domains": ["åº”ç”¨é¢†åŸŸå»ºè®®"]
            }
        }
        
        logger.info("ğŸ’¡ å®Œæˆä¸»åŠ¨åˆ›æƒ³åˆ†æ")
        logger.debug(f"   ç”Ÿæˆåˆ›æ„ç»´åº¦: {len(ideation_result['creative_dimensions'])} ä¸ª")
        
        return ideation_result
    
    def _execute_knowledge_synthesis_task(self, task: CognitiveTask) -> Dict[str, Any]:
        """æ‰§è¡ŒçŸ¥è¯†ç»¼åˆä»»åŠ¡ - æ•´åˆå’Œæ²‰æ·€è®¤çŸ¥æˆæœ"""
        self.stats["knowledge_synthesis_sessions"] += 1
        
        cognitive_history = task.context.get("cognitive_history", [])
        
        # åŸºç¡€çŸ¥è¯†ç»¼åˆ
        synthesis_result = {
            "synthesized_knowledge": {
                "core_patterns": self._synthesize_core_patterns(cognitive_history),
                "meta_insights": self._extract_meta_insights(cognitive_history), 
                "knowledge_graph": "çŸ¥è¯†å›¾è°±æ„å»ºå°†åœ¨åç»­ç‰ˆæœ¬å®ç°"
            },
            "actionable_recommendations": [
                "åŸºäºç»¼åˆåˆ†æçš„å¯æ‰§è¡Œå»ºè®®"
            ]
        }
        
        logger.info("ğŸ§© å®ŒæˆçŸ¥è¯†ç»¼åˆä»»åŠ¡")
        
        return synthesis_result
    
    def _execute_knowledge_exploration_task(self, task: CognitiveTask) -> Dict[str, Any]:
        """ğŸŒ æ‰§è¡ŒçŸ¥è¯†æ¢ç´¢ä»»åŠ¡ - ä¸»åŠ¨æ¢ç´¢å¤–éƒ¨ä¸–ç•Œï¼Œå‘ç°æ–°çš„æ€ç»´ç§å­"""
        self.stats["knowledge_exploration_sessions"] += 1
        
        logger.info("ğŸŒ å¼€å§‹çŸ¥è¯†æ¢ç´¢ - æ’­ä¸‹æ¢ç´¢çš„ç§å­")
        
        exploration_opportunities = task.context.get("exploration_opportunities", [])
        knowledge_gaps = task.context.get("current_knowledge_gaps", [])
        exploration_strategies = task.context.get("exploration_strategies", [])
        
        # ğŸŒ ä½¿ç”¨ä¸“ä¸šçŸ¥è¯†æ¢å‹˜å™¨æ‰§è¡Œæ¢ç´¢
        if self.knowledge_explorer:
            try:
                logger.info("ğŸ” å¯åŠ¨ä¸“ä¸šçŸ¥è¯†æ¢å‹˜å™¨è¿›è¡Œæ·±åº¦æ¢ç´¢...")
                
                # åˆ›å»ºæ¢ç´¢ç›®æ ‡
                targets = self.knowledge_explorer.create_exploration_targets_from_context(task.context)
                
                # é€‰æ‹©æ¢ç´¢ç­–ç•¥
                strategy = self._map_to_exploration_strategy(exploration_strategies)
                
                # æ‰§è¡Œä¸“ä¸šæ¢ç´¢
                explorer_result = self.knowledge_explorer.explore_knowledge(targets, strategy)
                
                # è½¬æ¢ä¸ºè®¤çŸ¥è°ƒåº¦å™¨æ ¼å¼
                exploration_results = self._convert_explorer_result_to_scheduler_format(
                    explorer_result, task.task_id
                )
                
                logger.info("âœ… ä¸“ä¸šçŸ¥è¯†æ¢å‹˜å™¨æ¢ç´¢å®Œæˆ")
                logger.info(f"   æ¢ç´¢è´¨é‡è¯„åˆ†: {explorer_result.quality_score:.2f}")
                logger.info(f"   æ¢ç´¢æˆåŠŸç‡: {explorer_result.success_rate:.2f}")
                
            except Exception as e:
                logger.error(f"âŒ ä¸“ä¸šçŸ¥è¯†æ¢å‹˜å™¨æ‰§è¡Œå¤±è´¥: {e}")
                logger.info("ğŸ”„ å›é€€åˆ°åŸºç¡€æ¢ç´¢åˆ†æ...")
                exploration_results = self._execute_basic_exploration(task)
        else:
            # åŸºç¡€æ¢ç´¢ï¼ˆå›é€€æœºåˆ¶ï¼‰
            logger.info("ğŸ’¡ ä½¿ç”¨åŸºç¡€æ¢ç´¢åˆ†æåŠŸèƒ½...")
            exploration_results = self._execute_basic_exploration(task)
        
        # æ›´æ–°æ¢ç´¢å†å²å’Œç¼“å­˜
        self._update_exploration_caches(exploration_results)
        
        # å°†å‘ç°çš„çŸ¥è¯†åŠ å…¥è®¤çŸ¥é£è½®
        self._integrate_discovered_knowledge_to_flywheel(exploration_results)
        
        logger.info("ğŸŒ çŸ¥è¯†æ¢ç´¢å®Œæˆ")
        logger.info(f"   å‘ç°æ–°çŸ¥è¯†é¡¹: {len(exploration_results['discovered_knowledge'])}")
        logger.info(f"   ç”Ÿæˆæ€ç»´ç§å­: {len(exploration_results['generated_thinking_seeds'])}")
        logger.info(f"   è¯†åˆ«è¶‹åŠ¿æ•°é‡: {len(exploration_results['identified_trends'])}")
        logger.info(f"   è·¨åŸŸè¿æ¥æ•°é‡: {len(exploration_results['cross_domain_connections'])}")
        
        return exploration_results
    
    def _execute_basic_exploration(self, task: CognitiveTask) -> Dict[str, Any]:
        """åŸºç¡€æ¢ç´¢å®ç°ï¼ˆå›é€€æœºåˆ¶ï¼‰"""
        exploration_opportunities = task.context.get("exploration_opportunities", [])
        knowledge_gaps = task.context.get("current_knowledge_gaps", [])
        exploration_strategies = task.context.get("exploration_strategies", [])
        
        # åŸºç¡€æ¢ç´¢å®ç°
        exploration_results = {
            "exploration_metadata": {
                "exploration_session_id": task.task_id,
                "strategies_used": exploration_strategies,
                "opportunities_explored": len(exploration_opportunities),
                "gaps_addressed": len(knowledge_gaps),
                "execution_mode": "basic_exploration"
            },
            
            # æ¢ç´¢å‘ç°çš„æ–°çŸ¥è¯†
            "discovered_knowledge": self._discover_new_knowledge(
                exploration_opportunities, 
                knowledge_gaps,
                exploration_strategies
            ),
            
            # ç”Ÿæˆçš„æ€ç»´ç§å­
            "generated_thinking_seeds": self._generate_exploration_based_seeds(
                exploration_opportunities,
                knowledge_gaps
            ),
            
            # è¯†åˆ«çš„è¶‹åŠ¿å’Œæ¨¡å¼
            "identified_trends": self._identify_domain_trends(exploration_opportunities),
            
            # è·¨åŸŸè¿æ¥
            "cross_domain_connections": self._find_cross_domain_connections(
                exploration_opportunities
            ),
            
            # å¾…è¿›ä¸€æ­¥æ¢ç´¢çš„æ–¹å‘
            "future_exploration_directions": self._suggest_future_explorations(
                exploration_opportunities,
                knowledge_gaps
            )
        }
        
        return exploration_results
    
    def _map_to_exploration_strategy(self, strategy_names: List[str]) -> Optional[ExplorationStrategy]:
        """å°†ç­–ç•¥åç§°æ˜ å°„åˆ°ExplorationStrategyæšä¸¾"""
        if not strategy_names:
            return None
        
        strategy_mapping = {
            "domain_expansion": ExplorationStrategy.DOMAIN_EXPANSION,
            "trend_monitoring": ExplorationStrategy.TREND_MONITORING,
            "gap_analysis": ExplorationStrategy.GAP_ANALYSIS,
            "cross_domain_learning": ExplorationStrategy.CROSS_DOMAIN_LEARNING,
            "serendipity_discovery": ExplorationStrategy.SERENDIPITY_DISCOVERY
        }
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç­–ç•¥
        for strategy_name in strategy_names:
            if strategy_name in strategy_mapping:
                return strategy_mapping[strategy_name]
        
        return ExplorationStrategy.DOMAIN_EXPANSION  # é»˜è®¤ç­–ç•¥
    
    def _convert_explorer_result_to_scheduler_format(self, 
                                                   explorer_result, 
                                                   task_id: str) -> Dict[str, Any]:
        """å°†KnowledgeExplorerçš„ç»“æœè½¬æ¢ä¸ºCognitiveScheduleræ ¼å¼"""
        
        # è½¬æ¢å‘ç°çš„çŸ¥è¯†
        discovered_knowledge = []
        for knowledge_item in explorer_result.discovered_knowledge:
            discovered_knowledge.append({
                "knowledge_id": knowledge_item.knowledge_id,
                "content": knowledge_item.content,
                "source": knowledge_item.source,
                "quality": knowledge_item.quality.value,
                "confidence_score": knowledge_item.confidence_score,
                "relevance_score": knowledge_item.relevance_score,
                "novelty_score": knowledge_item.novelty_score,
                "tags": knowledge_item.tags,
                "discovered_at": knowledge_item.discovered_at
            })
        
        # è½¬æ¢ç”Ÿæˆçš„ç§å­
        generated_thinking_seeds = []
        for seed in explorer_result.generated_seeds:
            generated_thinking_seeds.append({
                "seed_id": seed.seed_id,
                "seed_content": seed.seed_content,
                "creativity_level": seed.creativity_level,
                "confidence": seed.confidence,
                "potential_applications": seed.potential_applications,
                "source_knowledge": seed.source_knowledge,
                "suggested_reasoning_paths": seed.suggested_reasoning_paths,
                "cross_domain_connections": seed.cross_domain_connections,
                "generated_at": seed.generated_at
            })
        
        # æ„å»ºå®Œæ•´ç»“æœ
        scheduler_result = {
            "exploration_metadata": {
                "exploration_session_id": task_id,
                "explorer_id": explorer_result.exploration_id,
                "strategy_used": explorer_result.strategy.value,
                "targets_explored": len(explorer_result.targets),
                "execution_time": explorer_result.execution_time,
                "success_rate": explorer_result.success_rate,
                "quality_score": explorer_result.quality_score,
                "execution_mode": "professional_explorer"
            },
            
            "discovered_knowledge": discovered_knowledge,
            "generated_thinking_seeds": generated_thinking_seeds,
            "identified_trends": explorer_result.identified_trends,
            "cross_domain_connections": [
                {
                    "connection_id": insight.get("insight_id", "unknown"),
                    "description": insight.get("description", ""),
                    "confidence": insight.get("confidence", 0.5)
                }
                for insight in explorer_result.cross_domain_insights
            ],
            
            # ä¿æŒåŸæœ‰æ ¼å¼çš„å­—æ®µ
            "future_exploration_directions": self._suggest_future_explorations_from_explorer_result(
                explorer_result
            )
        }
        
        return scheduler_result
    
    def _suggest_future_explorations_from_explorer_result(self, 
                                                        explorer_result) -> List[Dict[str, Any]]:
        """åŸºäºæ¢å‹˜å™¨ç»“æœå»ºè®®æœªæ¥æ¢ç´¢æ–¹å‘"""
        directions = []
        
        # åŸºäºå‘ç°çš„çŸ¥è¯†å»ºè®®åç»­æ¢ç´¢
        high_quality_knowledge = [
            k for k in explorer_result.discovered_knowledge 
            if k.confidence_score > 0.7
        ]
        
        for knowledge in high_quality_knowledge[:2]:
            direction = {
                "direction_id": f"future_{knowledge.knowledge_id}",
                "exploration_focus": f"æ·±å…¥æ¢ç´¢{knowledge.tags[0] if knowledge.tags else 'ç›¸å…³é¢†åŸŸ'}",
                "recommended_strategies": ["deep_dive_analysis", "expert_consultation"],
                "priority": knowledge.confidence_score,
                "estimated_effort": "medium",
                "expected_outcomes": [
                    f"æ·±åŒ–{knowledge.tags[0] if knowledge.tags else 'ç›¸å…³'}é¢†åŸŸçŸ¥è¯†",
                    "å‘ç°æ›´å¤šåˆ›æ–°æœºä¼š"
                ]
            }
            directions.append(direction)
        
        return directions
    
    # ==================== è¾…åŠ©æ–¹æ³• ====================
    
    def _on_state_change(self, event_type: str, event_data: Dict[str, Any], state_manager):
        """çŠ¶æ€å˜åŒ–ç›‘å¬å™¨å›è°ƒ"""
        if event_type == "goal_progress":
            self.last_activity_time = time.time()
        elif event_type == "turn_completed":
            success = event_data.get("success", False)
            if success:
                self.last_activity_time = time.time()
    
    def _merge_config(self, base_config: Dict, user_config: Dict):
        """é€’å½’åˆå¹¶é…ç½®"""
        for key, value in user_config.items():
            if key in base_config and isinstance(base_config[key], dict) and isinstance(value, dict):
                self._merge_config(base_config[key], value)
            else:
                base_config[key] = value
    
    def _has_active_task_type(self, task_type: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æŒ‡å®šç±»å‹çš„æ´»è·ƒè®¤çŸ¥ä»»åŠ¡"""
        return any(task.task_type == task_type for task in self.active_cognitive_tasks.values())
    
    def _should_trigger_knowledge_synthesis(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘çŸ¥è¯†ç»¼åˆ"""
        # ç®€å•å®ç°ï¼šå½“è®¤çŸ¥å†å²è¾¾åˆ°ä¸€å®šæ•°é‡æ—¶è§¦å‘
        return len(self.cognitive_history) > 0 and len(self.cognitive_history) % 5 == 0
    
    def _extract_session_insights(self) -> Dict[str, Any]:
        """ä»å½“å‰ä¼šè¯ä¸­æå–è§è§£"""
        current_state = self.state_manager.get_current_state()
        return {
            "recent_patterns": "ä¼šè¯æ¨¡å¼åˆ†æ",
            "decision_trends": "å†³ç­–è¶‹åŠ¿åˆ†æ",
            "context_evolution": "ä¸Šä¸‹æ–‡æ¼”åŒ–åˆ†æ"
        }
    
    def _identify_success_patterns(self, session_state: Dict) -> List[str]:
        """è¯†åˆ«æˆåŠŸæ¨¡å¼"""
        return ["æˆåŠŸæ¨¡å¼1", "æˆåŠŸæ¨¡å¼2"]  # ç®€åŒ–å®ç°
    
    def _identify_failure_patterns(self, session_state: Dict) -> List[str]:
        """è¯†åˆ«å¤±è´¥æ¨¡å¼"""  
        return ["å¤±è´¥æ¨¡å¼1", "å¤±è´¥æ¨¡å¼2"]  # ç®€åŒ–å®ç°
    
    def _extract_golden_decision_templates(self, session_state: Dict) -> List[str]:
        """æå–é»„é‡‘å†³ç­–æ¨¡æ¿"""
        return ["é»„é‡‘æ¨¡æ¿1", "é»„é‡‘æ¨¡æ¿2"]  # ç®€åŒ–å®ç°
    
    def _synthesize_core_patterns(self, cognitive_history: List) -> List[str]:
        """ç»¼åˆæ ¸å¿ƒæ¨¡å¼"""
        return ["æ ¸å¿ƒæ¨¡å¼1", "æ ¸å¿ƒæ¨¡å¼2"]  # ç®€åŒ–å®ç°
        
    def _extract_meta_insights(self, cognitive_history: List) -> List[str]:
        """æå–å…ƒè§è§£"""
        return ["å…ƒè§è§£1", "å…ƒè§è§£2"]  # ç®€åŒ–å®ç°
    
    # ğŸŒ ==================== çŸ¥è¯†æ¢ç´¢è¾…åŠ©æ–¹æ³• ====================
    
    def _analyze_exploration_opportunities(self) -> List[Dict[str, Any]]:
        """åˆ†æå½“å‰çš„çŸ¥è¯†æ¢ç´¢æœºä¼š"""
        current_state = self.state_manager.get_current_state()
        conversation_history = current_state.get("conversation", {})
        
        # åŸºç¡€æœºä¼šè¯†åˆ«ï¼ˆåç»­å¯é€šè¿‡LLMå¢å¼ºï¼‰
        opportunities = [
            {
                "opportunity_id": "domain_trends",
                "type": "trend_monitoring",
                "description": "ç›‘æ§ç›¸å…³é¢†åŸŸçš„æœ€æ–°å‘å±•è¶‹åŠ¿",
                "priority": 0.8,
                "exploration_keywords": ["AI trends", "technology developments", "emerging patterns"]
            },
            {
                "opportunity_id": "knowledge_gaps",
                "type": "gap_analysis",
                "description": "è¯†åˆ«å½“å‰çŸ¥è¯†ä½“ç³»ä¸­çš„ç©ºç™½åŒºåŸŸ",
                "priority": 0.7,
                "exploration_keywords": ["missing concepts", "unexplored areas", "knowledge boundaries"]
            },
            {
                "opportunity_id": "cross_domain",
                "type": "cross_domain_learning",
                "description": "å¯»æ‰¾è·¨é¢†åŸŸçš„çŸ¥è¯†è¿æ¥å’Œå¯å‘",
                "priority": 0.6,
                "exploration_keywords": ["interdisciplinary", "cross-field applications", "analogies"]
            }
        ]
        
        return opportunities
    
    def _identify_knowledge_gaps(self) -> List[Dict[str, Any]]:
        """è¯†åˆ«å½“å‰çŸ¥è¯†ä½“ç³»ä¸­çš„ç¼ºå£"""
        # åˆ†æå†å²å¯¹è¯å’Œå†³ç­–ï¼Œæ‰¾å‡ºçŸ¥è¯†ç›²åŒº
        gaps = [
            {
                "gap_id": "emerging_tech",
                "area": "æ–°å…´æŠ€æœ¯",
                "description": "å¯¹æœ€æ–°æŠ€æœ¯å‘å±•çš„äº†è§£ä¸è¶³",
                "impact": "high",
                "exploration_priority": 0.9
            },
            {
                "gap_id": "domain_best_practices",
                "area": "é¢†åŸŸæœ€ä½³å®è·µ", 
                "description": "ç¼ºä¹ç‰¹å®šé¢†åŸŸçš„æœ€ä½³å®è·µçŸ¥è¯†",
                "impact": "medium",
                "exploration_priority": 0.7
            }
        ]
        
        return gaps
    
    def _discover_new_knowledge(self, 
                               opportunities: List[Dict[str, Any]], 
                               gaps: List[Dict[str, Any]], 
                               strategies: List[str]) -> List[Dict[str, Any]]:
        """å‘ç°æ–°çŸ¥è¯†ï¼ˆåŸºç¡€å®ç°ï¼Œåç»­å¯é›†æˆç½‘ç»œæœç´¢å’ŒLLMåˆ†æï¼‰"""
        discovered_knowledge = []
        
        # å¯¹æ¯ä¸ªæ¢ç´¢æœºä¼šè¿›è¡ŒçŸ¥è¯†å‘ç°
        for opportunity in opportunities[:2]:  # é™åˆ¶æ¢ç´¢æ•°é‡
            knowledge_item = {
                "knowledge_id": f"discovery_{opportunity['opportunity_id']}_{int(time.time())}",
                "source_opportunity": opportunity["opportunity_id"],
                "knowledge_type": opportunity["type"],
                "content": f"åŸºäº{opportunity['description']}çš„æ–°å‘ç°",
                "confidence_score": 0.6,
                "exploration_method": "cognitive_analysis",
                "discovery_timestamp": time.time(),
                "potential_applications": [
                    "æ€ç»´è·¯å¾„ä¼˜åŒ–",
                    "å†³ç­–ç­–ç•¥æ”¹è¿›",
                    "åˆ›æ–°æ€ç»´æ¿€å‘"
                ]
            }
            discovered_knowledge.append(knowledge_item)
        
        return discovered_knowledge
    
    def _generate_exploration_based_seeds(self, 
                                        opportunities: List[Dict[str, Any]], 
                                        gaps: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """åŸºäºæ¢ç´¢ç»“æœç”Ÿæˆæ–°çš„æ€ç»´ç§å­"""
        thinking_seeds = []
        
        # ä¸ºæ¯ä¸ªæ¢ç´¢æœºä¼šç”Ÿæˆå¯¹åº”çš„æ€ç»´ç§å­
        for opportunity in opportunities[:3]:  # ç”Ÿæˆå‰3ä¸ªæœºä¼šçš„ç§å­
            seed = {
                "seed_id": f"exploration_seed_{opportunity['opportunity_id']}_{int(time.time())}",
                "seed_content": f"åŸºäº{opportunity['description']}çš„æ¢ç´¢æ€§æ€ç»´ç§å­",
                "source_type": "knowledge_exploration",
                "creativity_level": "high",
                "potential_paths": [
                    f"{opportunity['type']}_analytical_path",
                    f"{opportunity['type']}_creative_path",
                    f"{opportunity['type']}_systematic_path"
                ],
                "confidence": 0.7,
                "generated_timestamp": time.time()
            }
            thinking_seeds.append(seed)
        
        return thinking_seeds
    
    def _identify_domain_trends(self, opportunities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è¯†åˆ«é¢†åŸŸè¶‹åŠ¿"""
        trends = []
        
        for opportunity in opportunities:
            if opportunity["type"] == "trend_monitoring":
                trend = {
                    "trend_id": f"trend_{opportunity['opportunity_id']}",
                    "trend_name": f"åŸºäº{opportunity['description']}çš„è¶‹åŠ¿",
                    "confidence": 0.6,
                    "time_horizon": "short_term",
                    "impact_areas": ["cognitive_strategies", "decision_making"],
                    "identified_at": time.time()
                }
                trends.append(trend)
        
        return trends
    
    def _find_cross_domain_connections(self, opportunities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å‘ç°è·¨åŸŸè¿æ¥"""
        connections = []
        
        # å¯»æ‰¾æœºä¼šä¹‹é—´çš„æ½œåœ¨è¿æ¥
        for i, opp1 in enumerate(opportunities):
            for opp2 in opportunities[i+1:]:
                connection = {
                    "connection_id": f"cross_{opp1['opportunity_id']}_{opp2['opportunity_id']}",
                    "domain1": opp1["type"],
                    "domain2": opp2["type"],
                    "connection_strength": 0.5,
                    "potential_synergies": [
                        f"ç»“åˆ{opp1['type']}å’Œ{opp2['type']}çš„ç»¼åˆæ–¹æ³•"
                    ],
                    "discovered_at": time.time()
                }
                connections.append(connection)
        
        return connections
    
    def _suggest_future_explorations(self, 
                                   opportunities: List[Dict[str, Any]], 
                                   gaps: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å»ºè®®æœªæ¥çš„æ¢ç´¢æ–¹å‘"""
        future_directions = []
        
        # åŸºäºå½“å‰æ¢ç´¢ç»“æœï¼Œæ¨èä¸‹ä¸€æ­¥æ¢ç´¢æ–¹å‘
        for gap in gaps[:2]:  # é’ˆå¯¹å‰2ä¸ªçŸ¥è¯†ç¼ºå£
            direction = {
                "direction_id": f"future_{gap['gap_id']}",
                "exploration_focus": gap["area"],
                "recommended_strategies": ["deep_dive_analysis", "expert_consultation"],
                "priority": gap["exploration_priority"],
                "estimated_effort": "medium",
                "expected_outcomes": [
                    f"å¡«è¡¥{gap['area']}çš„çŸ¥è¯†ç©ºç™½",
                    "å¢å¼ºç›¸å…³é¢†åŸŸçš„å†³ç­–èƒ½åŠ›"
                ]
            }
            future_directions.append(direction)
        
        return future_directions
    
    def _update_exploration_caches(self, exploration_results: Dict[str, Any]):
        """æ›´æ–°æ¢ç´¢å†å²å’Œç¼“å­˜"""
        # æ›´æ–°æ¢ç´¢å†å²
        exploration_record = {
            "exploration_id": exploration_results["exploration_metadata"]["exploration_session_id"],
            "timestamp": time.time(),
            "knowledge_discovered": len(exploration_results["discovered_knowledge"]),
            "seeds_generated": len(exploration_results["generated_thinking_seeds"]),
            "trends_identified": len(exploration_results["identified_trends"])
        }
        self.exploration_history.append(exploration_record)
        
        # æ›´æ–°å‘ç°çš„çŸ¥è¯†ç¼“å­˜
        for knowledge_item in exploration_results["discovered_knowledge"]:
            self.discovered_knowledge[knowledge_item["knowledge_id"]] = knowledge_item
        
        # æ›´æ–°æ¢ç´¢ä¸»é¢˜ç¼“å­˜
        for seed in exploration_results["generated_thinking_seeds"]:
            if seed["seed_content"] not in self.exploration_topics_cache:
                self.exploration_topics_cache.append(seed["seed_content"])
        
        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self.exploration_history) > 50:
            self.exploration_history = self.exploration_history[-30:]
        
        if len(self.exploration_topics_cache) > 100:
            self.exploration_topics_cache = self.exploration_topics_cache[-60:]
    
    def _integrate_discovered_knowledge_to_flywheel(self, exploration_results: Dict[str, Any]):
        """ğŸ”„ å°†å‘ç°çš„çŸ¥è¯†æ•´åˆåˆ°è®¤çŸ¥é£è½®ä¸­"""
        logger.info("ğŸ”„ å¼€å§‹å°†æ¢ç´¢çŸ¥è¯†æ•´åˆåˆ°è®¤çŸ¥é£è½®...")
        
        # 1. å°†ç”Ÿæˆçš„æ€ç»´ç§å­æ·»åŠ åˆ°ç§å­åº“
        thinking_seeds = exploration_results.get("generated_thinking_seeds", [])
        for seed in thinking_seeds:
            # è¿™é‡Œå°†ä¸å›æº¯å¼•æ“å’ŒMABç³»ç»Ÿé›†æˆ
            # å°†æ–°ç§å­ä½œä¸ºå€™é€‰è·¯å¾„åŠ å…¥å†³ç­–ç³»ç»Ÿ
            logger.debug(f"   é›†æˆæ€ç»´ç§å­: {seed['seed_id']}")
        
        # 2. å°†å‘ç°çš„è¶‹åŠ¿æ›´æ–°åˆ°çŸ¥è¯†åº“
        trends = exploration_results.get("identified_trends", [])
        for trend in trends:
            # è¶‹åŠ¿ä¿¡æ¯å¯ä»¥å½±å“æœªæ¥çš„è·¯å¾„é€‰æ‹©æƒé‡
            logger.debug(f"   é›†æˆè¶‹åŠ¿ä¿¡æ¯: {trend['trend_id']}")
        
        # 3. è·¨åŸŸè¿æ¥ä¿¡æ¯å¯ä»¥å¢å¼ºåˆ›æ„çªç ´èƒ½åŠ›
        connections = exploration_results.get("cross_domain_connections", [])
        for connection in connections:
            # è·¨åŸŸè¿æ¥å¯ä»¥è§¦å‘æ–°çš„Aha-Momentè·¯å¾„
            logger.debug(f"   é›†æˆè·¨åŸŸè¿æ¥: {connection['connection_id']}")
        
        logger.info(f"ğŸ”„ è®¤çŸ¥é£è½®æ•´åˆå®Œæˆ: {len(thinking_seeds)} ç§å­, {len(trends)} è¶‹åŠ¿, {len(connections)} è¿æ¥")
    
    def _determine_retrospection_strategy(self, 
                                       trigger_reason: str, 
                                       context: Dict[str, Any]) -> RetrospectionStrategy:
        """
        æ ¹æ®è§¦å‘åŸå› ç¡®å®šå›æº¯ç­–ç•¥
        
        Args:
            trigger_reason: è§¦å‘åŸå› 
            context: ä»»åŠ¡ä¸Šä¸‹æ–‡
            
        Returns:
            åˆé€‚çš„å›æº¯ç­–ç•¥
        """
        # æ ¹æ®ä¸åŒçš„è§¦å‘åŸå› é€‰æ‹©æœ€ä½³å›æº¯ç­–ç•¥
        if trigger_reason == "idle_detection":
            # ç©ºé—²æ£€æµ‹è§¦å‘ï¼šä½¿ç”¨éšæœºé‡‡æ ·è·å¾—å¤šæ ·æ€§
            return RetrospectionStrategy.RANDOM_SAMPLING
        
        elif trigger_reason == "failure_analysis":
            # å¤±è´¥åˆ†æè§¦å‘ï¼šä¸“æ³¨åˆ†æå¤±è´¥æ¡ˆä¾‹
            return RetrospectionStrategy.FAILURE_FOCUSED
        
        elif trigger_reason == "performance_review":
            # æ€§èƒ½è¯„ä¼°è§¦å‘ï¼šåŸºäºå¤æ‚åº¦é€‰æ‹©
            return RetrospectionStrategy.COMPLEXITY_BASED
        
        elif trigger_reason == "periodic_ideation":
            # å®šæœŸåˆ›æƒ³è§¦å‘ï¼šé€‰æ‹©æœ€è¿‘çš„ä»»åŠ¡
            return RetrospectionStrategy.RECENT_TASKS
        
        else:
            # é»˜è®¤ç­–ç•¥
            return RetrospectionStrategy.RANDOM_SAMPLING
    
    def _convert_retrospection_result(self, 
                                    retrospection_result) -> Dict[str, Any]:
        """
        å°†TaskRetrospectionEngineçš„ç»“æœè½¬æ¢ä¸ºCognitiveSchedulerçš„åˆ†ææ ¼å¼
        
        Args:
            retrospection_result: å›æº¯å¼•æ“çš„ç»“æœ
            
        Returns:
            è½¬æ¢åçš„åˆ†æç»“æœ
        """
        if not retrospection_result or not retrospection_result.task:
            return {
                "status": "no_analysis",
                "message": "å›æº¯å¼•æ“æœªèƒ½äº§ç”Ÿæœ‰æ•ˆåˆ†æç»“æœ"
            }
        
        # æå–æ ¸å¿ƒä¿¡æ¯
        task_info = retrospection_result.task
        original_turn = task_info.original_turn
        
        # æ„å»ºè¯¦ç»†åˆ†æ
        analysis = {
            "retrospection_metadata": {
                "retrospection_id": retrospection_result.retrospection_id,
                "selected_task_id": task_info.task_id,
                "selection_strategy": task_info.selection_strategy.value,
                "execution_time": retrospection_result.execution_time,
                "complexity_score": task_info.complexity_score
            },
            
            "task_analysis": {
                "original_question": original_turn.user_input,
                "original_success": original_turn.success,
                "tool_calls_count": len(original_turn.tool_calls),
                "mab_decisions_count": len(original_turn.mab_decisions),
                "task_phase": original_turn.phase.value
            },
            
            "creative_insights": {
                "llm_dimensions": [
                    {
                        "dimension_id": dim.get("dimension_id", "unknown"),
                        "description": dim.get("description", "æ–°æ€ç»´ç»´åº¦"),
                        "creativity_level": dim.get("creativity_level", "medium")
                    }
                    for dim in retrospection_result.llm_dimensions
                ],
                "aha_moment_paths": [
                    {
                        "path_id": getattr(path, "path_id", "unknown"),
                        "path_type": getattr(path, "path_type", "creative"),
                        "confidence": getattr(path, "confidence_score", 0.5)
                    }
                    for path in retrospection_result.aha_moment_paths
                ]
            },
            
            "extracted_insights": retrospection_result.insights,
            "success_patterns": retrospection_result.success_patterns,
            "failure_causes": retrospection_result.failure_causes,
            "improvement_suggestions": retrospection_result.improvement_suggestions,
            
            "knowledge_assimilation": {
                "assimilated_strategies": retrospection_result.assimilated_strategies,
                "mab_updates_count": len(retrospection_result.mab_updates),
                "total_new_knowledge_items": (
                    len(retrospection_result.llm_dimensions) + 
                    len(retrospection_result.aha_moment_paths)
                )
            },
            
            "retrospection_summary": {
                "total_insights": len(retrospection_result.insights),
                "actionable_improvements": len(retrospection_result.improvement_suggestions),
                "creative_breakthroughs": (
                    len(retrospection_result.llm_dimensions) + 
                    len(retrospection_result.aha_moment_paths)
                ),
                "knowledge_integration_success": len(retrospection_result.assimilated_strategies) > 0
            }
        }
        
        return analysis
    
    def update_retrospection_dependencies(self, 
                                        path_generator=None, 
                                        mab_converger=None):
        """
        æ›´æ–°å›æº¯å¼•æ“çš„ä¾èµ–ç»„ä»¶
        
        è¿™ä¸ªæ–¹æ³•å…è®¸å¤–éƒ¨ï¼ˆå¦‚Agentæˆ–Plannerï¼‰å‘è®¤çŸ¥è°ƒåº¦å™¨æä¾›
        å›æº¯å¼•æ“æ‰€éœ€çš„PathGeneratorå’ŒMABConvergerç»„ä»¶
        
        Args:
            path_generator: è·¯å¾„ç”Ÿæˆå™¨å®ä¾‹
            mab_converger: MABæ”¶æ•›å™¨å®ä¾‹
        """
        if not self.retrospection_engine:
            logger.warning("âš ï¸ å›æº¯å¼•æ“æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ›´æ–°ä¾èµ–")
            return False
        
        updated_components = []
        
        if path_generator:
            self.retrospection_engine.path_generator = path_generator
            updated_components.append("PathGenerator")
        
        if mab_converger:
            self.retrospection_engine.mab_converger = mab_converger
            updated_components.append("MABConverger")
        
        if updated_components:
            logger.info(f"ğŸ”§ å›æº¯å¼•æ“ä¾èµ–ç»„ä»¶å·²æ›´æ–°: {', '.join(updated_components)}")
            logger.info("âœ… å›æº¯å¼•æ“ç°å¯æ‰§è¡Œå®Œæ•´çš„ä¸‰é˜¶æ®µæµç¨‹")
            return True
        
        return False
    
    def update_knowledge_explorer_dependencies(self, 
                                             web_search_client=None,
                                             additional_config: Optional[Dict[str, Any]] = None):
        """
        æ›´æ–°çŸ¥è¯†æ¢å‹˜å™¨çš„ä¾èµ–ç»„ä»¶
        
        è¿™ä¸ªæ–¹æ³•å…è®¸å¤–éƒ¨ï¼ˆå¦‚Agentæˆ–Plannerï¼‰å‘è®¤çŸ¥è°ƒåº¦å™¨æä¾›
        çŸ¥è¯†æ¢å‹˜å™¨æ‰€éœ€çš„ä¾èµ–ç»„ä»¶
        
        Args:
            web_search_client: ç½‘ç»œæœç´¢å®¢æˆ·ç«¯å®ä¾‹
            additional_config: é¢å¤–çš„é…ç½®å‚æ•°
        """
        if not self.knowledge_explorer:
            logger.warning("âš ï¸ çŸ¥è¯†æ¢å‹˜å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ›´æ–°ä¾èµ–")
            return False
        
        updated_components = []
        
        if web_search_client:
            self.knowledge_explorer.web_search_client = web_search_client
            updated_components.append("WebSearchClient")
        
        if additional_config:
            self.knowledge_explorer._merge_config(
                self.knowledge_explorer.config, 
                additional_config
            )
            updated_components.append("Config")
        
        if updated_components:
            logger.info(f"ğŸ”§ çŸ¥è¯†æ¢å‹˜å™¨ä¾èµ–ç»„ä»¶å·²æ›´æ–°: {', '.join(updated_components)}")
            logger.info("âœ… çŸ¥è¯†æ¢å‹˜å™¨ç°å¯æ‰§è¡Œå®Œæ•´çš„å¤–éƒ¨æ™ºæ…§è¿æ¥")
            return True
        
        return False
    
    def _pause_low_priority_cognitive_tasks(self):
        """æš‚åœä½ä¼˜å…ˆçº§è®¤çŸ¥ä»»åŠ¡"""
        # ç®€åŒ–å®ç°ï¼Œåç»­å¯ä»¥æ·»åŠ ä»»åŠ¡ä¼˜å…ˆçº§ç®¡ç†
        pass
    
    def _cleanup_expired_tasks(self):
        """æ¸…ç†è¿‡æœŸä»»åŠ¡"""
        current_time = time.time()
        timeout = self.config["cognitive_tasks"]["task_timeout"]
        
        expired_tasks = []
        for task_id, task in self.active_cognitive_tasks.items():
            if (current_time - task.created_at) > timeout:
                expired_tasks.append(task_id)
        
        for task_id in expired_tasks:
            self.active_cognitive_tasks.pop(task_id, None)
            logger.warning(f"â° è®¤çŸ¥ä»»åŠ¡è¶…æ—¶è¢«æ¸…ç†: {task_id}")
    
    def _log_final_stats(self):
        """è®°å½•æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        logger.info("ğŸ“Š è®¤çŸ¥è°ƒåº¦å™¨æœ€ç»ˆç»Ÿè®¡:")
        logger.info(f"   æ€»ç©ºé—²å‘¨æœŸ: {self.stats['total_idle_periods']}")
        logger.info(f"   æ€»ç©ºé—²æ—¶é—´: {self.stats['total_idle_time']:.1f}s") 
        logger.info(f"   å®Œæˆè®¤çŸ¥ä»»åŠ¡: {self.stats['cognitive_tasks_completed']}")
        logger.info(f"   å›æº¯ä¼šè¯: {self.stats['retrospection_sessions']}")
        logger.info(f"   åˆ›æƒ³ä¼šè¯: {self.stats['ideation_sessions']}")
        logger.info(f"   çŸ¥è¯†ç»¼åˆ: {self.stats['knowledge_synthesis_sessions']}")
        logger.info(f"   ğŸŒ çŸ¥è¯†æ¢ç´¢: {self.stats['knowledge_exploration_sessions']}")  # æ–°å¢
        
        # ğŸŒ æ–°å¢ï¼šçŸ¥è¯†æ¢ç´¢è¯¦ç»†ç»Ÿè®¡
        if hasattr(self, 'exploration_history') and self.exploration_history:
            total_knowledge_discovered = sum(record.get('knowledge_discovered', 0) for record in self.exploration_history)
            total_seeds_generated = sum(record.get('seeds_generated', 0) for record in self.exploration_history)
            logger.info(f"   æ¢ç´¢å‘ç°çŸ¥è¯†: {total_knowledge_discovered} é¡¹")
            logger.info(f"   ç”Ÿæˆæ€ç»´ç§å­: {total_seeds_generated} ä¸ª")
            logger.info(f"   æ¢ç´¢ä¸»é¢˜ç¼“å­˜: {len(self.exploration_topics_cache)} ä¸ª")
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–è°ƒåº¦å™¨çŠ¶æ€"""
        return {
            "is_running": self.is_running,
            "current_mode": self.current_mode.value,
            "is_idle": self.is_idle,
            "active_cognitive_tasks": len(self.active_cognitive_tasks),
            "queued_cognitive_tasks": self.cognitive_task_queue.qsize(),
            "stats": self.stats.copy()
        }
