#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è®¤çŸ¥æˆé•¿å®Œæ•´é›†æˆæ¼”ç¤º - çŸ¥è¯†æ¢ç´¢å™¨ + åŠ¨æ€è·¯å¾„ç”Ÿæˆå™¨
Integrated Cognitive Growth Demo - Knowledge Explorer + Dynamic Path Generator

è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº†çŸ¥è¯†æ¢ç´¢å™¨å’ŒåŠ¨æ€è·¯å¾„ç”Ÿæˆå™¨å¦‚ä½•ååŒå·¥ä½œï¼Œ
å®ç°çœŸæ­£çš„è®¤çŸ¥é£è½®"å­¦ä¹ -è¿›åŒ–"é—­ç¯ï¼š

1. çŸ¥è¯†æ¢ç´¢å™¨å‘ç°æ–°çš„æ€ç»´ç§å­
2. åŠ¨æ€è·¯å¾„ç”Ÿæˆå™¨å­¦ä¹ å¹¶è½¬åŒ–ä¸ºæ–°è·¯å¾„
3. æ–°è·¯å¾„å‚ä¸æœªæ¥çš„å†³ç­–ç”Ÿæˆ
4. æ€§èƒ½åé¦ˆä¼˜åŒ–æ•´ä¸ªå¾ªç¯

è¿™æ˜¯è®¤çŸ¥é£è½®"å¤–éƒ¨æ™ºæ…§â†’å†…éƒ¨è¿›åŒ–"çš„å®Œæ•´æ¼”ç¤ºã€‚
"""

import sys
import os
import time
import logging
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from neogenesis_system.cognitive_engine.path_generator import PathGenerator
from neogenesis_system.providers.knowledge_explorer import (
    KnowledgeExplorer, ExplorationStrategy, ExplorationTarget,
    KnowledgeItem, ThinkingSeed
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MockLLMClient:
    """æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯"""
    
    def call_api(self, prompt: str, temperature: float = 0.8, **kwargs) -> str:
        return f"[LLMåˆ†æ] åŸºäºæç¤ºçš„æ™ºèƒ½å“åº” (æ¸©åº¦={temperature})"


class MockWebSearchClient:
    """æ¨¡æ‹Ÿç½‘ç»œæœç´¢å®¢æˆ·ç«¯"""
    
    def search(self, query: str, max_results: int = 5):
        """æ¨¡æ‹Ÿæœç´¢ç»“æœ"""
        return [
            {
                "title": f"å…³äº'{query}'çš„æœ€æ–°ç ”ç©¶",
                "snippet": f"æœ€æ–°ç ”ç©¶è¡¨æ˜ï¼Œ{query}åœ¨å¤šä¸ªé¢†åŸŸéƒ½æœ‰é‡è¦åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨åˆ›æ–°æ€ç»´å’Œç³»ç»Ÿåˆ†ææ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›...",
                "link": f"https://example.com/research/{query.replace(' ', '-')}",
                "source": "academic_paper"
            },
            {
                "title": f"{query}æœ€ä½³å®è·µæŒ‡å—", 
                "snippet": f"åŸºäºå¤§é‡å®è·µæ¡ˆä¾‹ï¼Œæˆ‘ä»¬å‘ç°{query}çš„å…³é”®åœ¨äºç»“åˆç†è®ºåˆ†æä¸å®é™…åº”ç”¨ï¼Œå½¢æˆç³»ç»Ÿæ€§çš„è§£å†³æ–¹æ¡ˆ...",
                "link": f"https://example.com/guide/{query.replace(' ', '-')}",
                "source": "best_practices"
            },
            {
                "title": f"{query}åˆ›æ–°æ–¹æ³•æ¢è®¨",
                "snippet": f"é€šè¿‡è·¨é¢†åŸŸçš„æ–¹æ³•æ•´åˆï¼Œ{query}å±•ç°äº†å¼ºå¤§çš„åˆ›æ–°æ½œåŠ›ï¼Œå¯ä»¥é€šè¿‡å¤šç»´åº¦æ€è€ƒå®ç°çªç ´æ€§è¿›å±•...",
                "link": f"https://example.com/innovation/{query.replace(' ', '-')}",
                "source": "innovation_study"
            }
        ]


def demonstrate_cognitive_growth_cycle():
    """æ¼”ç¤ºå®Œæ•´çš„è®¤çŸ¥æˆé•¿å‘¨æœŸ"""
    print("ğŸŒŸ è®¤çŸ¥æˆé•¿å®Œæ•´é›†æˆæ¼”ç¤º")
    print("=" * 60)
    
    # 1. åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
    print("\n1ï¸âƒ£ åˆå§‹åŒ–è®¤çŸ¥ç³»ç»Ÿæ ¸å¿ƒç»„ä»¶...")
    
    llm_client = MockLLMClient()
    search_client = MockWebSearchClient()
    
    # åˆ›å»ºçŸ¥è¯†æ¢ç´¢å™¨
    knowledge_explorer = KnowledgeExplorer(
        llm_client=llm_client,
        web_search_client=search_client,
        config={
            "exploration_strategies": {
                "max_parallel_explorations": 2,
                "exploration_timeout": 30.0
            },
            "seed_generation": {
                "max_seeds_per_exploration": 3,
                "creativity_boost_factor": 1.5
            }
        }
    )
    
    # åˆ›å»ºåŠ¨æ€è·¯å¾„ç”Ÿæˆå™¨
    path_generator = PathGenerator(llm_client=llm_client)
    
    print("âœ… è®¤çŸ¥ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
    print(f"   çŸ¥è¯†æ¢ç´¢å™¨: {'å·²å°±ç»ª' if knowledge_explorer else 'æœªå°±ç»ª'}")
    print(f"   è·¯å¾„ç”Ÿæˆå™¨: {'å·²å°±ç»ª' if path_generator else 'æœªå°±ç»ª'}")
    
    # 2. è·å–ç³»ç»Ÿåˆå§‹çŠ¶æ€
    print("\n2ï¸âƒ£ ç³»ç»Ÿåˆå§‹çŠ¶æ€...")
    
    initial_stats = path_generator.get_path_library_stats()
    print(f"ğŸ“Š åˆå§‹è·¯å¾„åº“çŠ¶æ€:")
    print(f"   æ€»è·¯å¾„æ•°: {initial_stats['total_paths']}")
    print(f"   å­¦ä¹ è·¯å¾„æ•°: {initial_stats['learned_paths']}")
    print(f"   å­¦ä¹ æ¯”ä¾‹: {initial_stats['learned_paths']/max(initial_stats['total_paths'],1):.2%}")
    
    # 3. ç¬¬ä¸€è½®ï¼šçŸ¥è¯†æ¢ç´¢
    print("\n3ï¸âƒ£ ç¬¬ä¸€è½®è®¤çŸ¥å¾ªç¯ - çŸ¥è¯†æ¢ç´¢...")
    
    exploration_targets = [
        ExplorationTarget(
            target_id="creative_problem_solving",
            target_type="methodology",
            description="åˆ›é€ æ€§é—®é¢˜è§£å†³æ–¹æ³•è®º",
            keywords=["åˆ›æ–°æ€ç»´", "é—®é¢˜è§£å†³", "è®¾è®¡æ€ç»´", "ç³»ç»Ÿæ€è€ƒ"],
            priority=0.9
        ),
        ExplorationTarget(
            target_id="ai_human_collaboration",
            target_type="trend",
            description="äººå·¥æ™ºèƒ½ä¸äººç±»åä½œè¶‹åŠ¿",
            keywords=["äººæœºåä½œ", "AIåº”ç”¨", "ååŒæ™ºèƒ½", "æœªæ¥è¶‹åŠ¿"],
            priority=0.8
        )
    ]
    
    # æ‰§è¡ŒçŸ¥è¯†æ¢ç´¢
    print("ğŸ” æ‰§è¡ŒçŸ¥è¯†æ¢ç´¢...")
    exploration_result = knowledge_explorer.explore_knowledge(
        targets=exploration_targets,
        strategy=ExplorationStrategy.CROSS_DOMAIN_LEARNING
    )
    
    print(f"âœ… çŸ¥è¯†æ¢ç´¢å®Œæˆ:")
    print(f"   æ¢ç´¢ID: {exploration_result.exploration_id}")
    print(f"   å‘ç°çŸ¥è¯†: {len(exploration_result.discovered_knowledge)} é¡¹")
    print(f"   ç”Ÿæˆç§å­: {len(exploration_result.generated_seeds)} ä¸ª")
    print(f"   è¯†åˆ«è¶‹åŠ¿: {len(exploration_result.identified_trends)} ä¸ª")
    print(f"   è´¨é‡è¯„åˆ†: {exploration_result.quality_score:.2f}")
    
    # å±•ç¤ºå‘ç°çš„æ€ç»´ç§å­
    print("\nğŸŒ± å‘ç°çš„æ€ç»´ç§å­:")
    for i, seed in enumerate(exploration_result.generated_seeds, 1):
        print(f"   {i}. {seed.seed_id}")
        print(f"      åˆ›æ„ç­‰çº§: {seed.creativity_level}")
        print(f"      ç½®ä¿¡åº¦: {seed.confidence:.2f}")
        print(f"      å†…å®¹: {seed.seed_content[:80]}...")
    
    # 4. è·¯å¾„å­¦ä¹ å’Œè½¬åŒ–
    print("\n4ï¸âƒ£ æ€ç»´è·¯å¾„å­¦ä¹ å’Œè½¬åŒ–...")
    
    # è½¬æ¢æ¢ç´¢ç»“æœä¸ºè·¯å¾„ç”Ÿæˆå™¨æ ¼å¼
    formatted_exploration_result = {
        "exploration_metadata": {
            "exploration_session_id": exploration_result.exploration_id,
            "strategy_used": exploration_result.strategy.value,
            "targets_explored": len(exploration_result.targets),
            "quality_score": exploration_result.quality_score,
            "execution_mode": "professional_explorer"
        },
        "generated_thinking_seeds": [
            {
                "seed_id": seed.seed_id,
                "seed_content": seed.seed_content,
                "creativity_level": seed.creativity_level,
                "confidence": seed.confidence,
                "potential_applications": seed.potential_applications,
                "cross_domain_connections": seed.cross_domain_connections,
                "generated_at": seed.generated_at
            }
            for seed in exploration_result.generated_seeds
        ],
        "identified_trends": [
            {
                "trend_id": trend.get("trend_id", "unknown"),
                "trend_name": trend.get("trend_name", "æœªå‘½åè¶‹åŠ¿"),
                "confidence": trend.get("confidence", 0.5)
            }
            for trend in exploration_result.identified_trends
        ],
        "cross_domain_connections": [
            {
                "connection_id": insight.get("insight_id", "unknown"),
                "description": insight.get("description", "è·¨åŸŸè¿æ¥"),
                "confidence": insight.get("confidence", 0.5)
            }
            for insight in exploration_result.cross_domain_insights
        ]
    }
    
    # è·¯å¾„ç”Ÿæˆå™¨ä»æ¢ç´¢ç»“æœå­¦ä¹ 
    print("ğŸ§  è·¯å¾„ç”Ÿæˆå™¨å­¦ä¹ æ–°æ€ç»´æ¨¡å¼...")
    learned_paths_count = path_generator.learn_path_from_exploration(formatted_exploration_result)
    
    print(f"âœ… å­¦ä¹ è½¬åŒ–å®Œæˆ:")
    print(f"   æ–°å¢è·¯å¾„æ•°: {learned_paths_count}")
    
    if learned_paths_count > 0:
        # åˆ·æ–°è·¯å¾„æ¨¡æ¿
        path_generator.refresh_path_templates()
        print("âœ… è·¯å¾„æ¨¡æ¿å·²æ›´æ–°")
        
        # è·å–æ›´æ–°åçš„çŠ¶æ€
        updated_stats = path_generator.get_path_library_stats()
        print(f"ğŸ“Š æ›´æ–°åè·¯å¾„åº“çŠ¶æ€:")
        print(f"   æ€»è·¯å¾„æ•°: {updated_stats['total_paths']} (+{updated_stats['total_paths'] - initial_stats['total_paths']})")
        print(f"   å­¦ä¹ è·¯å¾„æ•°: {updated_stats['learned_paths']} (+{updated_stats['learned_paths'] - initial_stats['learned_paths']})")
        print(f"   å­¦ä¹ æ¯”ä¾‹: {updated_stats['learned_paths']/max(updated_stats['total_paths'],1):.2%}")
    
    # 5. æ–°è·¯å¾„çš„å®é™…åº”ç”¨
    print("\n5ï¸âƒ£ æ–°å­¦ä¹ è·¯å¾„çš„å®é™…åº”ç”¨æµ‹è¯•...")
    
    test_scenarios = [
        {
            "thinking_seed": "éœ€è¦è·¨é¢†åŸŸæ•´åˆçš„åˆ›æ–°è§£å†³æ–¹æ¡ˆ",
            "task": "è®¾è®¡ä¸€ä¸ªèåˆAIä¸äººæ–‡çš„æ•™è‚²äº§å“",
            "expected_improvement": "åº”è¯¥èƒ½ä½¿ç”¨æ–°å­¦ä¹ çš„è·¨åŸŸæ€ç»´è·¯å¾„"
        },
        {
            "thinking_seed": "äººæœºåä½œçš„æœªæ¥æ¨¡å¼æ¢ç´¢",
            "task": "æ„å»ºä¸‹ä¸€ä»£æ™ºèƒ½åŠå…¬ç³»ç»Ÿ",
            "expected_improvement": "åº”è¯¥èåˆäººæœºåä½œçš„æ–°æ´å¯Ÿ"
        }
    ]
    
    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\nğŸ§ª æµ‹è¯•åœºæ™¯ {i}: {scenario['task']}")
        print(f"   æ€ç»´ç§å­: {scenario['thinking_seed']}")
        
        # ç”Ÿæˆè·¯å¾„ï¼ˆåŒ…å«æ–°å­¦ä¹ çš„è·¯å¾„ï¼‰
        generated_paths = path_generator.generate_paths(
            thinking_seed=scenario['thinking_seed'],
            task=scenario['task'],
            max_paths=4
        )
        
        print(f"   ç”Ÿæˆè·¯å¾„æ•°: {len(generated_paths)}")
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æ–°å­¦ä¹ çš„è·¯å¾„
        learned_path_used = False
        for path in generated_paths:
            if "å­¦ä¹ " in path.path_type or "æ¢ç´¢" in path.path_type or "è·¨åŸŸ" in path.path_type:
                print(f"   âœ¨ å‘ç°æ–°å­¦ä¹ è·¯å¾„: {path.path_type}")
                learned_path_used = True
                break
        
        if not learned_path_used:
            print("   ğŸ“ ç”Ÿæˆçš„è·¯å¾„:")
            for j, path in enumerate(generated_paths, 1):
                print(f"     {j}. {path.path_type}")
    
    # 6. æ€§èƒ½åé¦ˆå’Œä¼˜åŒ–
    print("\n6ï¸âƒ£ æ€§èƒ½åé¦ˆå’Œç³»ç»Ÿä¼˜åŒ–...")
    
    # æ¨¡æ‹Ÿä¸€äº›æ€§èƒ½åé¦ˆæ•°æ®
    performance_feedback = [
        ("systematic_analytical", True, 2.3, 0.88),
        ("creative_innovative", True, 3.1, 0.92),
        ("learned_cross_domain", True, 2.8, 0.85),  # å‡è®¾è¿™æ˜¯æ–°å­¦ä¹ çš„è·¯å¾„
        ("practical_pragmatic", False, 1.9, 0.45)
    ]
    
    print("ğŸ“Š æ”¶é›†æ€§èƒ½åé¦ˆ...")
    for strategy_id, success, exec_time, rating in performance_feedback:
        path_generator.update_path_performance(
            path_id=strategy_id,
            success=success,
            execution_time=exec_time,
            user_rating=rating
        )
        
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        print(f"   {strategy_id}: {status}, {exec_time}s, è¯„åˆ†{rating}")
    
    # 7. æ™ºèƒ½æ¨èéªŒè¯
    print("\n7ï¸âƒ£ åŸºäºå­¦ä¹ ç»“æœçš„æ™ºèƒ½æ¨è...")
    
    recommendation_contexts = [
        {
            "task_type": "innovation",
            "complexity": "high", 
            "domain": "cross_disciplinary",
            "tags": ["creative", "systematic", "collaborative"]
        },
        {
            "task_type": "analysis",
            "complexity": "medium",
            "domain": "technology",
            "tags": ["ai", "human_centered", "future_oriented"]
        }
    ]
    
    for i, context in enumerate(recommendation_contexts, 1):
        print(f"\nğŸ’¡ æ¨èåœºæ™¯ {i}: {context}")
        
        recommended_paths = path_generator.get_recommended_paths_by_context(
            task_context=context,
            max_recommendations=3
        )
        
        print(f"   æ¨èè·¯å¾„:")
        for j, path in enumerate(recommended_paths, 1):
            is_learned = "å­¦ä¹ " in path.path_type or "æ¢ç´¢" in path.path_type
            marker = "ğŸŒŸ" if is_learned else "ğŸ“‹"
            print(f"     {j}. {marker} {path.path_type}")
    
    # 8. æˆé•¿æ´å¯Ÿåˆ†æ
    print("\n8ï¸âƒ£ ç³»ç»Ÿæˆé•¿æ´å¯Ÿåˆ†æ...")
    
    growth_insights = path_generator.get_growth_insights()
    
    print("ğŸŒ± æˆé•¿çŠ¶å†µåˆ†æ:")
    library_growth = growth_insights["library_growth"]
    print(f"   æ€»è·¯å¾„æ•°: {library_growth['total_paths']}")
    print(f"   å­¦ä¹ è·¯å¾„æ•°: {library_growth['learned_paths']}")
    print(f"   å­¦ä¹ æ¯”ä¾‹: {library_growth['learning_ratio']:.2%}")
    
    usage_patterns = growth_insights["usage_patterns"]
    print(f"ğŸ”„ ä½¿ç”¨æ¨¡å¼åˆ†æ:")
    print(f"   æ€»ç”Ÿæˆæ¬¡æ•°: {usage_patterns['total_generations']}")
    print(f"   å¹³å‡è·¯å¾„æ•°/æ¬¡: {usage_patterns['avg_paths_per_generation']:.1f}")
    
    if usage_patterns["most_used_paths"]:
        print("ğŸ“Š æœ€å¸¸ç”¨è·¯å¾„:")
        for path_type, count in usage_patterns["most_used_paths"]:
            print(f"   - {path_type}: {count} æ¬¡")
    
    print("ğŸ’¡ ç³»ç»Ÿæˆé•¿å»ºè®®:")
    for recommendation in growth_insights["growth_recommendations"]:
        print(f"   - {recommendation}")
    
    # 9. ç¬¬äºŒè½®å¾ªç¯é¢„è§ˆ
    print("\n9ï¸âƒ£ ç¬¬äºŒè½®è®¤çŸ¥å¾ªç¯é¢„è§ˆ...")
    
    print("ğŸ”„ åŸºäºç¬¬ä¸€è½®å­¦ä¹ æˆæœï¼Œç³»ç»Ÿç°åœ¨å…·å¤‡äº†:")
    print("   âœ… æ›´ä¸°å¯Œçš„æ€ç»´è·¯å¾„åº“")
    print("   âœ… è·¨åŸŸè¿æ¥çš„è®¤çŸ¥èƒ½åŠ›")
    print("   âœ… åŸºäºå®é™…æ•ˆæœçš„è·¯å¾„ä¼˜åŒ–")
    print("   âœ… æ™ºèƒ½æ¨èç³»ç»Ÿçš„æŒç»­æ”¹è¿›")
    
    print("\nğŸ”® ä¸‹ä¸€è½®å¾ªç¯å°†èƒ½å¤Ÿ:")
    print("   ğŸŒŸ åŸºäºæ–°è·¯å¾„å‘ç°æ›´æ·±å±‚çš„æ´å¯Ÿ")
    print("   ğŸŒŸ åœ¨æ›´å¤šé¢†åŸŸå±•ç°åˆ›æ–°æ€ç»´èƒ½åŠ›")
    print("   ğŸŒŸ æä¾›æ›´ç²¾å‡†çš„ä¸ªæ€§åŒ–æ¨è")
    print("   ğŸŒŸ å®ç°çœŸæ­£çš„è‡ªä¸»è®¤çŸ¥è¿›åŒ–")


def demonstrate_exploration_stats():
    """å±•ç¤ºçŸ¥è¯†æ¢ç´¢ç»Ÿè®¡"""
    print("\nğŸ”Ÿ çŸ¥è¯†æ¢ç´¢ç³»ç»Ÿç»Ÿè®¡...")
    
    llm_client = MockLLMClient()
    search_client = MockWebSearchClient()
    
    knowledge_explorer = KnowledgeExplorer(
        llm_client=llm_client,
        web_search_client=search_client
    )
    
    stats = knowledge_explorer.get_exploration_stats()
    print("ğŸ“Š çŸ¥è¯†æ¢ç´¢ç»Ÿè®¡:")
    print(f"   æ€»æ¢ç´¢æ¬¡æ•°: {stats['total_explorations']}")
    print(f"   æˆåŠŸæ¢ç´¢æ¬¡æ•°: {stats['successful_explorations']}")
    print(f"   å‘ç°çŸ¥è¯†æ€»æ•°: {stats['total_knowledge_discovered']}")
    print(f"   ç”Ÿæˆç§å­æ€»æ•°: {stats['total_seeds_generated']}")
    print(f"   å¹³å‡è´¨é‡è¯„åˆ†: {stats['average_quality_score']:.2f}")
    print(f"   å¹³å‡æ‰§è¡Œæ—¶é—´: {stats['average_execution_time']:.2f}s")
    
    if "strategy_performance" in stats:
        print("ğŸ¯ ç­–ç•¥æ€§èƒ½è¡¨ç°:")
        for strategy, performance in stats["strategy_performance"].items():
            print(f"   {strategy}:")
            print(f"     æˆåŠŸç‡: {performance['success_rate']:.2%}")
            print(f"     å¹³å‡è´¨é‡: {performance['avg_quality']:.2f}")
            print(f"     ç”Ÿæˆç§å­æ•°: {performance['total_seeds']}")


if __name__ == "__main__":
    try:
        # æ‰§è¡Œå®Œæ•´çš„è®¤çŸ¥æˆé•¿å¾ªç¯æ¼”ç¤º
        demonstrate_cognitive_growth_cycle()
        
        # å±•ç¤ºæ¢ç´¢ç³»ç»Ÿç»Ÿè®¡
        demonstrate_exploration_stats()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ è®¤çŸ¥æˆé•¿å®Œæ•´é›†æˆæ¼”ç¤ºæˆåŠŸ!")
        print("\nğŸ“‹ æ¼”ç¤ºæ€»ç»“:")
        print("   ğŸŒ çŸ¥è¯†æ¢ç´¢å™¨: ä¸»åŠ¨å‘ç°å¤–éƒ¨æ™ºæ…§å’Œè¶‹åŠ¿")
        print("   ğŸ§  åŠ¨æ€è·¯å¾„ç”Ÿæˆå™¨: å­¦ä¹ å¹¶è½¬åŒ–ä¸ºå†…éƒ¨æ€ç»´æ¨¡å¼")
        print("   ğŸ”„ å­¦ä¹ é—­ç¯: æ¢ç´¢â†’å­¦ä¹ â†’åº”ç”¨â†’åé¦ˆâ†’ä¼˜åŒ–")
        print("   ğŸ“Š æ€§èƒ½é©±åŠ¨: åŸºäºå®é™…æ•ˆæœçš„æŒç»­æ”¹è¿›")
        print("   ğŸ’¡ æ™ºèƒ½æ¨è: ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è·¯å¾„é€‰æ‹©")
        print("   ğŸŒ± è‡ªä¸»æˆé•¿: ç³»ç»Ÿæ€§çš„è®¤çŸ¥èƒ½åŠ›è¿›åŒ–")
        
        print("\nğŸš€ è®¤çŸ¥é£è½®å®Œæ•´é—­ç¯å·²å®ç°!")
        print("   ä»'è¢«åŠ¨å“åº”'åˆ°'ä¸»åŠ¨è®¤çŸ¥'")
        print("   ä»'é™æ€æ¨¡æ¿'åˆ°'åŠ¨æ€è¿›åŒ–'")
        print("   ä»'å•æ¬¡å†³ç­–'åˆ°'æŒç»­å­¦ä¹ '")
        
        print("\nğŸ¯ è¿™æ ‡å¿—ç€AIç³»ç»Ÿè®¤çŸ¥æ¶æ„çš„é‡å¤§çªç ´:")
        print("   âœ¨ å…·å¤‡çœŸæ­£çš„è‡ªä¸»å­¦ä¹ èƒ½åŠ›")
        print("   âœ¨ å®ç°å¤–éƒ¨æ™ºæ…§çš„å†…åŒ–è½¬æ¢")
        print("   âœ¨ å»ºç«‹æŒç»­è¿›åŒ–çš„è®¤çŸ¥æœºåˆ¶")
        print("   âœ¨ å½¢æˆå®Œæ•´çš„æ™ºèƒ½æˆé•¿é—­ç¯")
        
    except Exception as e:
        logger.error(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
