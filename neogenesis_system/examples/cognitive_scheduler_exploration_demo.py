#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è®¤çŸ¥è°ƒåº¦å™¨çŸ¥è¯†æ¢ç´¢åŠŸèƒ½æ¼”ç¤º
Cognitive Scheduler Knowledge Exploration Demo

è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº†æ‰©å±•åçš„è®¤çŸ¥è°ƒåº¦å™¨å¦‚ä½•ï¼š
1. ä¸»åŠ¨æ¢ç´¢å¤–éƒ¨ä¸–ç•Œï¼Œæ’­ä¸‹æ¢ç´¢çš„ç§å­
2. å‘ç°æ–°çš„æ€ç»´ç§å­å¹¶æ•´åˆåˆ°è®¤çŸ¥é£è½®ä¸­
3. æ”¯æŒé¢†åŸŸè¶‹åŠ¿ç›‘æ§ã€è·¨åŸŸå­¦ä¹ ç­‰æ¢ç´¢ç­–ç•¥
"""

import sys
import os
import time
import logging

# æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„åˆ°ç³»ç»Ÿè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from core.cognitive_scheduler import CognitiveScheduler, CognitiveMode
from shared.state_manager import StateManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class MockLLMClient:
    """æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯ç”¨äºæ¼”ç¤º"""
    
    def call_api(self, prompt: str, temperature: float = 0.8) -> str:
        """æ¨¡æ‹ŸLLM APIè°ƒç”¨"""
        return f"æ¨¡æ‹ŸLLMå“åº”ï¼šåŸºäºæ¸©åº¦{temperature}çš„åˆ›æ„è¾“å‡º"


def demonstrate_knowledge_exploration():
    """æ¼”ç¤ºçŸ¥è¯†æ¢ç´¢åŠŸèƒ½"""
    logger.info("ğŸš€ å¼€å§‹è®¤çŸ¥è°ƒåº¦å™¨çŸ¥è¯†æ¢ç´¢åŠŸèƒ½æ¼”ç¤º")
    
    # 1. åˆ›å»ºçŠ¶æ€ç®¡ç†å™¨
    logger.info("ğŸ“‹ åˆ›å»ºçŠ¶æ€ç®¡ç†å™¨...")
    state_manager = StateManager()
    
    # æ·»åŠ ä¸€äº›æ¨¡æ‹Ÿçš„å¯¹è¯å†å²
    state_manager._conversation_history = []  # ç®€åŒ–æ¼”ç¤º
    
    # 2. åˆ›å»ºæ¨¡æ‹ŸLLMå®¢æˆ·ç«¯
    logger.info("ğŸ§  åˆ›å»ºæ¨¡æ‹ŸLLMå®¢æˆ·ç«¯...")
    mock_llm_client = MockLLMClient()
    
    # 3. åˆ›å»ºè®¤çŸ¥è°ƒåº¦å™¨ï¼ˆåŒ…å«çŸ¥è¯†æ¢ç´¢é…ç½®ï¼‰
    logger.info("ğŸ”§ åˆ›å»ºæ‰©å±•çš„è®¤çŸ¥è°ƒåº¦å™¨...")
    exploration_config = {
        "idle_detection": {
            "min_idle_duration": 2.0,  # ç¼©çŸ­æ¼”ç¤ºæ—¶é—´
            "check_interval": 1.0
        },
        "cognitive_tasks": {
            "exploration_interval": 5.0,  # 5ç§’åè§¦å‘æ¢ç´¢
        },
        "knowledge_exploration": {
            "exploration_strategies": [
                "domain_expansion",
                "trend_monitoring", 
                "gap_analysis",
                "cross_domain_learning"
            ],
            "max_exploration_depth": 2,
            "exploration_timeout": 30.0,
            "enable_web_search": False,  # æ¼”ç¤ºä¸­å…³é—­ç½‘ç»œæœç´¢
            "enable_trend_analysis": True,
            "knowledge_threshold": 0.6
        }
    }
    
    scheduler = CognitiveScheduler(
        state_manager=state_manager,
        llm_client=mock_llm_client,
        config=exploration_config
    )
    
    # 4. æ¼”ç¤ºçŸ¥è¯†æ¢ç´¢åŠŸèƒ½
    logger.info("ğŸŒ æ¼”ç¤ºçŸ¥è¯†æ¢ç´¢ä»»åŠ¡è°ƒåº¦...")
    
    # æ‰‹åŠ¨è§¦å‘çŸ¥è¯†æ¢ç´¢ä»»åŠ¡
    scheduler._schedule_knowledge_exploration_task()
    
    # è·å–é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡å¹¶æ‰§è¡Œ
    if not scheduler.cognitive_task_queue.empty():
        exploration_task = scheduler.cognitive_task_queue.get()
        logger.info(f"ğŸ“‹ æ‰§è¡ŒçŸ¥è¯†æ¢ç´¢ä»»åŠ¡: {exploration_task.task_id}")
        
        # æ‰§è¡Œæ¢ç´¢ä»»åŠ¡
        result = scheduler._execute_knowledge_exploration_task(exploration_task)
        
        # å±•ç¤ºç»“æœ
        logger.info("âœ… çŸ¥è¯†æ¢ç´¢ç»“æœå±•ç¤º:")
        logger.info(f"   æ¢ç´¢ä¼šè¯ID: {result['exploration_metadata']['exploration_session_id']}")
        logger.info(f"   ä½¿ç”¨ç­–ç•¥: {result['exploration_metadata']['strategies_used']}")
        logger.info(f"   æ¢ç´¢æœºä¼šæ•°: {result['exploration_metadata']['opportunities_explored']}")
        
        logger.info(f"ğŸ” å‘ç°çš„çŸ¥è¯† ({len(result['discovered_knowledge'])} é¡¹):")
        for knowledge in result['discovered_knowledge']:
            logger.info(f"   - {knowledge['knowledge_id']}: {knowledge['content']}")
        
        logger.info(f"ğŸŒ± ç”Ÿæˆçš„æ€ç»´ç§å­ ({len(result['generated_thinking_seeds'])} ä¸ª):")
        for seed in result['generated_thinking_seeds']:
            logger.info(f"   - {seed['seed_id']}: {seed['seed_content']}")
        
        logger.info(f"ğŸ“ˆ è¯†åˆ«çš„è¶‹åŠ¿ ({len(result['identified_trends'])} ä¸ª):")
        for trend in result['identified_trends']:
            logger.info(f"   - {trend['trend_id']}: {trend['trend_name']}")
        
        logger.info(f"ğŸ”— è·¨åŸŸè¿æ¥ ({len(result['cross_domain_connections'])} ä¸ª):")
        for connection in result['cross_domain_connections']:
            logger.info(f"   - {connection['connection_id']}: {connection['domain1']} â†” {connection['domain2']}")
    
    # 5. å±•ç¤ºè®¤çŸ¥é£è½®æ•´åˆæ•ˆæœ
    logger.info("ğŸ”„ è®¤çŸ¥é£è½®æ•´åˆçŠ¶æ€:")
    logger.info(f"   æ¢ç´¢å†å²è®°å½•: {len(scheduler.exploration_history)} æ¡")
    logger.info(f"   å‘ç°çš„çŸ¥è¯†ç¼“å­˜: {len(scheduler.discovered_knowledge)} é¡¹")
    logger.info(f"   æ¢ç´¢ä¸»é¢˜ç¼“å­˜: {len(scheduler.exploration_topics_cache)} ä¸ª")
    
    # 6. æ¼”ç¤ºè°ƒåº¦å™¨çŠ¶æ€
    status = scheduler.get_status()
    logger.info("ğŸ“Š è°ƒåº¦å™¨å½“å‰çŠ¶æ€:")
    for key, value in status["stats"].items():
        logger.info(f"   {key}: {value}")
    
    logger.info("âœ… çŸ¥è¯†æ¢ç´¢åŠŸèƒ½æ¼”ç¤ºå®Œæˆ!")
    logger.info("ğŸ’¡ è®¤çŸ¥é£è½®ç°åœ¨èƒ½å¤Ÿä¸»åŠ¨æ¢ç´¢å¤–éƒ¨ä¸–ç•Œï¼Œå‘ç°æ–°çš„æ€ç»´ç§å­")


def demonstrate_exploration_opportunities_analysis():
    """æ¼”ç¤ºæ¢ç´¢æœºä¼šåˆ†æ"""
    logger.info("\nğŸ” æ¼”ç¤ºæ¢ç´¢æœºä¼šåˆ†æåŠŸèƒ½...")
    
    state_manager = StateManager()
    scheduler = CognitiveScheduler(state_manager=state_manager)
    
    # åˆ†ææ¢ç´¢æœºä¼š
    opportunities = scheduler._analyze_exploration_opportunities()
    
    logger.info("å‘ç°çš„æ¢ç´¢æœºä¼š:")
    for opp in opportunities:
        logger.info(f"   ğŸ¯ {opp['opportunity_id']}")
        logger.info(f"      ç±»å‹: {opp['type']}")
        logger.info(f"      æè¿°: {opp['description']}")
        logger.info(f"      ä¼˜å…ˆçº§: {opp['priority']}")
        logger.info(f"      å…³é”®è¯: {opp['exploration_keywords']}")
        logger.info("")
    
    # è¯†åˆ«çŸ¥è¯†ç¼ºå£
    gaps = scheduler._identify_knowledge_gaps()
    
    logger.info("è¯†åˆ«çš„çŸ¥è¯†ç¼ºå£:")
    for gap in gaps:
        logger.info(f"   ğŸ“Š {gap['gap_id']}")
        logger.info(f"      é¢†åŸŸ: {gap['area']}")
        logger.info(f"      æè¿°: {gap['description']}")
        logger.info(f"      å½±å“: {gap['impact']}")
        logger.info(f"      æ¢ç´¢ä¼˜å…ˆçº§: {gap['exploration_priority']}")
        logger.info("")


if __name__ == "__main__":
    print("ğŸŒ è®¤çŸ¥è°ƒåº¦å™¨çŸ¥è¯†æ¢ç´¢åŠŸèƒ½æ¼”ç¤º")
    print("=" * 50)
    
    try:
        # ä¸»è¦æ¼”ç¤º
        demonstrate_knowledge_exploration()
        
        # è¯¦ç»†åŠŸèƒ½æ¼”ç¤º
        demonstrate_exploration_opportunities_analysis()
        
        print("\nğŸ‰ æ¼”ç¤ºæˆåŠŸå®Œæˆ!")
        print("ğŸ“ æ€»ç»“:")
        print("   âœ… çŸ¥è¯†æ¢ç´¢æ¨¡å¼å·²æˆåŠŸé›†æˆåˆ°è®¤çŸ¥è°ƒåº¦å™¨")
        print("   âœ… ä¸»åŠ¨æ¢ç´¢æœºåˆ¶èƒ½å¤Ÿå‘ç°æ–°çš„æ€ç»´ç§å­")
        print("   âœ… è®¤çŸ¥é£è½®ç°åœ¨æ”¯æŒå¤–éƒ¨ä¸–ç•Œæ¢ç´¢")
        print("   âœ… è¶‹åŠ¿ç›‘æ§å’Œè·¨åŸŸå­¦ä¹ åŠŸèƒ½å·²å°±ç»ª")
        
    except Exception as e:
        logger.error(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
