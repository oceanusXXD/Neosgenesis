#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
åŠ¨æ€è·¯å¾„ç”Ÿæˆå™¨å®Œæ•´åŠŸèƒ½æ¼”ç¤º
Dynamic Path Generator Complete Feature Demo

è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº†æ”¹é€ åçš„ path_generator.py çš„å…¨éƒ¨æ–°åŠŸèƒ½ï¼š
1. åŠ¨æ€æ€ç»´è·¯å¾„åº“çš„æŒä¹…åŒ–å­˜å‚¨
2. ä»é™æ€æ¨¡æ¿åˆ°åŠ¨æ€ç®¡ç†çš„å‡çº§
3. å­¦ä¹ å’Œæˆé•¿æ¥å£çš„ä½¿ç”¨
4. ä¸çŸ¥è¯†æ¢ç´¢å™¨çš„å®Œæ•´é›†æˆ
5. æ€§èƒ½è·Ÿè¸ªå’Œæ™ºèƒ½æ¨èç³»ç»Ÿ
"""

import sys
import os
import time
import logging
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„åˆ°ç³»ç»Ÿè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from neogenesis_system.cognitive_engine.path_generator import PathGenerator, ReasoningPathTemplates
from neogenesis_system.cognitive_engine.path_library import (
    DynamicPathLibrary, StorageBackend, ExplorationTarget, KnowledgeItem,
    ThinkingSeed, EnhancedReasoningPath, PathMetadata, PathCategory, PathStatus
)
from neogenesis_system.cognitive_engine.data_structures import ReasoningPath

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class MockLLMClient:
    """æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯"""
    
    def call_api(self, prompt: str, temperature: float = 0.8, system_message: str = "") -> str:
        """æ¨¡æ‹ŸLLM APIè°ƒç”¨"""
        return f"æ¨¡æ‹ŸLLMå“åº”ï¼šåŸºäºæ¸©åº¦{temperature}çš„æ™ºèƒ½åˆ†æè¾“å‡º (ç³»ç»Ÿæ¶ˆæ¯: {system_message[:20]}...)"


def demonstrate_dynamic_library_initialization():
    """æ¼”ç¤ºåŠ¨æ€è·¯å¾„åº“çš„åˆå§‹åŒ–"""
    logger.info("ğŸ§  æ¼”ç¤ºåŠ¨æ€è·¯å¾„åº“åˆå§‹åŒ–")
    
    # æµ‹è¯•ä¸åŒçš„å­˜å‚¨åç«¯
    backends_to_test = [
        (StorageBackend.MEMORY, "å†…å­˜å­˜å‚¨ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰"),
        (StorageBackend.JSON, "JSONæ–‡ä»¶å­˜å‚¨"),
        # (StorageBackend.SQLITE, "SQLiteæ•°æ®åº“å­˜å‚¨")  # å¯é€‰
    ]
    
    for backend, description in backends_to_test:
        logger.info(f"\nğŸ“ æµ‹è¯•å­˜å‚¨åç«¯: {description}")
        
        try:
            # åˆ›å»ºåŠ¨æ€è·¯å¾„åº“
            library = DynamicPathLibrary(
                storage_backend=backend,
                storage_path=f"demo_data/test_paths_{backend.value}",
                auto_backup=True
            )
            
            # æ˜¾ç¤ºåˆå§‹çŠ¶æ€
            stats = library.get_library_stats()
            logger.info(f"   åˆå§‹è·¯å¾„æ•°é‡: {stats['total_paths']}")
            logger.info(f"   å­˜å‚¨åç«¯: {stats['storage_backend']}")
            
            # æ·»åŠ ä¸€ä¸ªæµ‹è¯•è·¯å¾„
            test_path = EnhancedReasoningPath(
                path_id=f"test_path_{int(time.time())}",
                path_type="æµ‹è¯•è·¯å¾„å‹",
                description="ç”¨äºæ¼”ç¤ºçš„æµ‹è¯•è·¯å¾„",
                prompt_template="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•è·¯å¾„ï¼š{task}",
                strategy_id="test_strategy",
                metadata=PathMetadata(
                    author="demo_system",
                    category=PathCategory.EXPERIMENTAL,
                    tags=["demo", "test"]
                )
            )
            
            success = library.add_path(test_path)
            if success:
                logger.info(f"   âœ… æˆåŠŸæ·»åŠ æµ‹è¯•è·¯å¾„")
            
            # æ˜¾ç¤ºæ›´æ–°åçŠ¶æ€
            updated_stats = library.get_library_stats()
            logger.info(f"   æ›´æ–°åè·¯å¾„æ•°é‡: {updated_stats['total_paths']}")
            
        except Exception as e:
            logger.error(f"   âŒ {description} æµ‹è¯•å¤±è´¥: {e}")


def demonstrate_template_migration():
    """æ¼”ç¤ºé™æ€æ¨¡æ¿è¿ç§»"""
    logger.info("\nğŸšš æ¼”ç¤ºé™æ€æ¨¡æ¿è¿ç§»åˆ°åŠ¨æ€åº“")
    
    # åˆ›å»ºåŠ¨æ€è·¯å¾„æ¨¡æ¿ç®¡ç†å™¨
    template_manager = ReasoningPathTemplates.get_instance(
        storage_backend="memory",  # ä½¿ç”¨å†…å­˜å­˜å‚¨ä»¥ä¾¿æ¼”ç¤º
        storage_path="demo_data/migrated_paths"
    )
    
    # è·å–è¿ç§»åçš„æ¨¡æ¿
    all_templates = template_manager.get_all_templates()
    
    logger.info(f"ğŸ“š è¿ç§»å®Œæˆï¼Œå…±æœ‰ {len(all_templates)} ä¸ªè·¯å¾„æ¨¡æ¿:")
    for template_id, template in list(all_templates.items())[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
        logger.info(f"   - {template_id}: {template.path_type}")
        logger.debug(f"     æè¿°: {template.description}")
    
    # æ˜¾ç¤ºåº“ç»Ÿè®¡ä¿¡æ¯
    stats = template_manager.get_library_stats()
    logger.info(f"ğŸ“Š è·¯å¾„åº“ç»Ÿè®¡:")
    logger.info(f"   æ€»è·¯å¾„æ•°: {stats['total_paths']}")
    logger.info(f"   æ¿€æ´»è·¯å¾„: {stats['active_paths']}")
    logger.info(f"   å­¦ä¹ è·¯å¾„: {stats['learned_paths']}")


def demonstrate_path_generator_integration():
    """æ¼”ç¤ºè·¯å¾„ç”Ÿæˆå™¨ä¸åŠ¨æ€åº“çš„é›†æˆ"""
    logger.info("\nğŸ›¤ï¸ æ¼”ç¤ºåŠ¨æ€è·¯å¾„ç”Ÿæˆå™¨")
    
    # åˆ›å»ºæ¨¡æ‹ŸLLMå®¢æˆ·ç«¯
    mock_llm = MockLLMClient()
    
    # åˆ›å»ºè·¯å¾„ç”Ÿæˆå™¨ï¼ˆè‡ªåŠ¨é›†æˆåŠ¨æ€è·¯å¾„åº“ï¼‰
    path_generator = PathGenerator(llm_client=mock_llm)
    
    # æµ‹è¯•æ€ç»´ç§å­åˆ°è·¯å¾„çš„ç”Ÿæˆ
    test_seeds_and_tasks = [
        ("éœ€è¦åˆ›æ–°çªç ´çš„äº§å“è®¾è®¡æ€è·¯", "è®¾è®¡ä¸€ä¸ªæ™ºèƒ½å®¶å±…äº§å“"),
        ("ç³»ç»Ÿæ€§åˆ†æå¤æ‚é—®é¢˜çš„æ–¹æ³•", "åˆ†æä¼ä¸šæ•°å­—åŒ–è½¬å‹ç­–ç•¥"),
        ("å¿«é€Ÿå®ç”¨çš„è§£å†³æ–¹æ¡ˆ", "è§£å†³å›¢é˜Ÿæ²Ÿé€šæ•ˆç‡é—®é¢˜")
    ]
    
    for thinking_seed, task in test_seeds_and_tasks:
        logger.info(f"\nğŸŒ± æµ‹è¯•æ€ç»´ç§å­: {thinking_seed}")
        logger.info(f"ğŸ¯ å…³è”ä»»åŠ¡: {task}")
        
        try:
            # ç”Ÿæˆè·¯å¾„ï¼ˆæ™®é€šæ¨¡å¼ï¼‰
            normal_paths = path_generator.generate_paths(
                thinking_seed=thinking_seed,
                task=task,
                max_paths=3,
                mode='normal'
            )
            
            logger.info(f"ğŸ“‹ æ™®é€šæ¨¡å¼ç”Ÿæˆ {len(normal_paths)} ä¸ªè·¯å¾„:")
            for i, path in enumerate(normal_paths, 1):
                logger.info(f"   {i}. {path.path_type}")
                logger.debug(f"      ç­–ç•¥ID: {path.strategy_id}")
                logger.debug(f"      æè¿°: {path.description[:60]}...")
            
            # ç”Ÿæˆè·¯å¾„ï¼ˆåˆ›é€ æ€§ç»•é“æ¨¡å¼ï¼‰
            creative_paths = path_generator.generate_paths(
                thinking_seed=thinking_seed,
                task=task,
                max_paths=2,
                mode='creative_bypass'
            )
            
            logger.info(f"ğŸ’¡ åˆ›é€ æ€§æ¨¡å¼ç”Ÿæˆ {len(creative_paths)} ä¸ªè·¯å¾„:")
            for i, path in enumerate(creative_paths, 1):
                logger.info(f"   {i}. {path.path_type}")
        
        except Exception as e:
            logger.error(f"âŒ è·¯å¾„ç”Ÿæˆå¤±è´¥: {e}")


def demonstrate_learning_capabilities():
    """æ¼”ç¤ºå­¦ä¹ èƒ½åŠ›"""
    logger.info("\nğŸŒ± æ¼”ç¤ºå­¦ä¹ å’Œæˆé•¿èƒ½åŠ›")
    
    # åˆ›å»ºè·¯å¾„ç”Ÿæˆå™¨
    mock_llm = MockLLMClient()
    path_generator = PathGenerator(llm_client=mock_llm)
    
    # æ¨¡æ‹ŸçŸ¥è¯†æ¢ç´¢ç»“æœ
    mock_exploration_result = {
        "exploration_metadata": {
            "exploration_session_id": "demo_exploration_001",
            "strategy_used": "trend_monitoring",
            "execution_mode": "professional_explorer"
        },
        "generated_thinking_seeds": [
            {
                "seed_id": "seed_trend_001",
                "seed_content": "åŸºäºAIæŠ€æœ¯å‘å±•è¶‹åŠ¿ï¼Œæå‡ºå¤šæ¨¡æ€èåˆçš„åˆ›æ–°è§£å†³æ–¹æ¡ˆ",
                "creativity_level": "high",
                "confidence": 0.8,
                "potential_applications": ["æŠ€æœ¯åˆ›æ–°", "äº§å“è®¾è®¡", "å¸‚åœºç­–ç•¥"],
                "cross_domain_connections": ["äººå·¥æ™ºèƒ½", "ç”¨æˆ·ä½“éªŒ", "å•†ä¸šæ¨¡å¼"],
                "generated_at": time.time()
            },
            {
                "seed_id": "seed_analysis_002", 
                "seed_content": "é€šè¿‡ç³»ç»Ÿæ€§åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œå‘ç°æ½œåœ¨çš„æœåŠ¡ä¼˜åŒ–æœºä¼š",
                "creativity_level": "medium",
                "confidence": 0.7,
                "potential_applications": ["éœ€æ±‚åˆ†æ", "æœåŠ¡ä¼˜åŒ–", "ç”¨æˆ·ä½“éªŒ"],
                "cross_domain_connections": ["æ•°æ®åˆ†æ", "ç”¨æˆ·ç ”ç©¶"],
                "generated_at": time.time()
            }
        ],
        "identified_trends": [
            {
                "trend_id": "trend_multimodal_ai",
                "trend_name": "å¤šæ¨¡æ€AIæŠ€æœ¯è¶‹åŠ¿",
                "confidence": 0.9
            }
        ],
        "cross_domain_connections": [
            {
                "connection_id": "ai_ux_fusion",
                "description": "AIæŠ€æœ¯ä¸ç”¨æˆ·ä½“éªŒè®¾è®¡çš„æ·±åº¦èåˆ",
                "confidence": 0.8
            }
        ]
    }
    
    # ä»æ¢ç´¢ç»“æœä¸­å­¦ä¹ 
    logger.info("ğŸ” ä»çŸ¥è¯†æ¢ç´¢ç»“æœä¸­å­¦ä¹ æ–°è·¯å¾„...")
    learned_count = path_generator.learn_path_from_exploration(mock_exploration_result)
    logger.info(f"ğŸŒŸ æˆåŠŸå­¦ä¹ åˆ° {learned_count} ä¸ªæ–°è·¯å¾„")
    
    # æ‰‹åŠ¨æ·»åŠ è‡ªå®šä¹‰è·¯å¾„
    logger.info("\nâ• æ¼”ç¤ºæ‰‹åŠ¨æ·»åŠ è‡ªå®šä¹‰è·¯å¾„...")
    custom_path = ReasoningPath(
        path_id="custom_demo_path_001",
        path_type="æ¼”ç¤ºè‡ªå®šä¹‰å‹",
        description="ä¸“ä¸ºæ¼”ç¤ºåˆ›å»ºçš„è‡ªå®šä¹‰æ€ç»´è·¯å¾„",
        prompt_template="""è¯·ä½¿ç”¨è‡ªå®šä¹‰æ¼”ç¤ºæ–¹æ³•è§£å†³ä»»åŠ¡ï¼š{task}

ğŸ¯ **è‡ªå®šä¹‰ç­–ç•¥**:
1. **éœ€æ±‚ç†è§£**: æ·±å…¥ç†è§£å…·ä½“éœ€æ±‚å’Œçº¦æŸ
2. **åˆ›æ„æ¿€å‘**: æ¿€å‘å¤šå…ƒåŒ–çš„è§£å†³æ€è·¯
3. **æ–¹æ¡ˆæ•´åˆ**: æ•´åˆæœ€ä½³å…ƒç´ å½¢æˆå®Œæ•´æ–¹æ¡ˆ
4. **å®æ–½è§„åˆ’**: åˆ¶å®šå¯è¡Œçš„å®æ–½è®¡åˆ’

åŸºäºæ€ç»´ç§å­ï¼š{thinking_seed}
è¯·æä¾›åˆ›æ–°ä¸”å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚""",
        strategy_id="custom_demo"
    )
    
    success = path_generator.add_custom_path(
        path=custom_path,
        learning_source="manual_demo",
        effectiveness_score=0.7
    )
    
    if success:
        logger.info("âœ… è‡ªå®šä¹‰è·¯å¾„æ·»åŠ æˆåŠŸ")
        
        # æµ‹è¯•æ–°è·¯å¾„çš„ä½¿ç”¨
        logger.info("ğŸ§ª æµ‹è¯•æ–°è·¯å¾„çš„ç”Ÿæˆèƒ½åŠ›...")
        
        # åˆ·æ–°è·¯å¾„æ¨¡æ¿ä»¥ç¡®ä¿æ–°è·¯å¾„å¯ç”¨
        path_generator.refresh_path_templates()
        
        # ç”ŸæˆåŒ…å«æ–°è·¯å¾„çš„ç»“æœ
        test_paths = path_generator.generate_paths(
            thinking_seed="æµ‹è¯•æ–°å­¦ä¹ çš„è‡ªå®šä¹‰è·¯å¾„",
            task="éªŒè¯è·¯å¾„å­¦ä¹ åŠŸèƒ½",
            max_paths=4
        )
        
        logger.info(f"ğŸ”„ ç”Ÿæˆçš„è·¯å¾„ä¸­åŒ…å« {len(test_paths)} ä¸ªï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ–°å­¦ä¹ çš„è·¯å¾„:")
        for path in test_paths:
            if "è‡ªå®šä¹‰" in path.path_type or "æ¼”ç¤º" in path.path_type:
                logger.info(f"   âœ¨ å‘ç°æ–°å­¦ä¹ çš„è·¯å¾„: {path.path_type}")
                break


def demonstrate_performance_tracking():
    """æ¼”ç¤ºæ€§èƒ½è·Ÿè¸ªå’Œæ¨èç³»ç»Ÿ"""
    logger.info("\nğŸ“Š æ¼”ç¤ºæ€§èƒ½è·Ÿè¸ªå’Œæ™ºèƒ½æ¨è")
    
    mock_llm = MockLLMClient()
    path_generator = PathGenerator(llm_client=mock_llm)
    
    # æ¨¡æ‹Ÿè·¯å¾„ä½¿ç”¨å’Œæ€§èƒ½æ›´æ–°
    logger.info("ğŸ“ˆ æ¨¡æ‹Ÿè·¯å¾„æ€§èƒ½æ•°æ®...")
    
    performance_data = [
        ("systematic_analytical", True, 2.5, 0.9),    # æˆåŠŸï¼Œè€—æ—¶2.5ç§’ï¼Œè¯„åˆ†0.9
        ("creative_innovative", True, 3.1, 0.8),      # æˆåŠŸï¼Œè€—æ—¶3.1ç§’ï¼Œè¯„åˆ†0.8
        ("practical_pragmatic", False, 1.2, 0.4),     # å¤±è´¥ï¼Œè€—æ—¶1.2ç§’ï¼Œè¯„åˆ†0.4
        ("systematic_analytical", True, 2.8, 0.85),   # å†æ¬¡æˆåŠŸ
        ("critical_questioning", True, 3.5, 0.75),    # æˆåŠŸï¼Œä½†è€—æ—¶è¾ƒé•¿
    ]
    
    for strategy_id, success, exec_time, rating in performance_data:
        updated = path_generator.update_path_performance(
            path_id=strategy_id,
            success=success,
            execution_time=exec_time,
            user_rating=rating
        )
        
        if updated:
            status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
            logger.debug(f"   {strategy_id}: {status}, {exec_time}s, è¯„åˆ†{rating}")
    
    # è·å–æ™ºèƒ½æ¨è
    logger.info("\nğŸ’¡ åŸºäºæ€§èƒ½æ•°æ®çš„æ™ºèƒ½æ¨è:")
    
    test_contexts = [
        {
            "task_type": "analysis", 
            "complexity": "high",
            "urgency": "normal",
            "tags": ["systematic", "thorough"]
        },
        {
            "task_type": "innovation",
            "complexity": "medium", 
            "urgency": "high",
            "tags": ["creative", "breakthrough"]
        }
    ]
    
    for i, context in enumerate(test_contexts, 1):
        logger.info(f"ğŸ“‹ æµ‹è¯•åœºæ™¯ {i}: {context}")
        
        recommended_paths = path_generator.get_recommended_paths_by_context(
            task_context=context,
            max_recommendations=3
        )
        
        logger.info(f"   æ¨èè·¯å¾„:")
        for j, path in enumerate(recommended_paths, 1):
            logger.info(f"     {j}. {path.path_type}")


def demonstrate_growth_insights():
    """æ¼”ç¤ºæˆé•¿æ´å¯Ÿåˆ†æ"""
    logger.info("\nğŸ”® æ¼”ç¤ºæˆé•¿æ´å¯Ÿå’Œå‘å±•å»ºè®®")
    
    mock_llm = MockLLMClient()
    path_generator = PathGenerator(llm_client=mock_llm)
    
    # è·å–æˆé•¿æ´å¯Ÿ
    insights = path_generator.get_growth_insights()
    
    logger.info("ğŸ“Š è·¯å¾„åº“æˆé•¿æƒ…å†µ:")
    library_growth = insights["library_growth"]
    logger.info(f"   æ€»è·¯å¾„æ•°: {library_growth['total_paths']}")
    logger.info(f"   å­¦ä¹ è·¯å¾„æ•°: {library_growth['learned_paths']}")
    logger.info(f"   å­¦ä¹ æ¯”ä¾‹: {library_growth['learning_ratio']:.2%}")
    
    logger.info("ğŸ“ˆ ä½¿ç”¨æ¨¡å¼åˆ†æ:")
    usage_patterns = insights["usage_patterns"]
    logger.info(f"   æ€»ç”Ÿæˆæ¬¡æ•°: {usage_patterns['total_generations']}")
    logger.info(f"   å¹³å‡è·¯å¾„æ•°/æ¬¡: {usage_patterns['avg_paths_per_generation']:.1f}")
    
    if usage_patterns["most_used_paths"]:
        logger.info("   æœ€å¸¸ç”¨è·¯å¾„:")
        for path_type, usage_count in usage_patterns["most_used_paths"]:
            logger.info(f"     - {path_type}: {usage_count} æ¬¡")
    
    logger.info("ğŸ’¡ æˆé•¿å»ºè®®:")
    for recommendation in insights["growth_recommendations"]:
        logger.info(f"   - {recommendation}")
    
    # è·å–è·¯å¾„åº“è¯¦ç»†ç»Ÿè®¡
    library_stats = path_generator.get_path_library_stats()
    logger.info(f"\nğŸ“š è·¯å¾„åº“è¯¦ç»†ç»Ÿè®¡:")
    logger.info(f"   å­˜å‚¨åç«¯: {library_stats['storage_backend']}")
    logger.info(f"   ç¼“å­˜æ•ˆç‡: {library_stats.get('cache_efficiency', 0):.2%}")
    
    if "top_performers" in library_stats:
        logger.info("ğŸ† è¡¨ç°æœ€ä½³è·¯å¾„:")
        for performer in library_stats["top_performers"]:
            logger.info(f"   - {performer['path_type']}: æ•ˆæœ{performer['effectiveness_score']:.2f}")


def demonstrate_backup_and_management():
    """æ¼”ç¤ºå¤‡ä»½å’Œç®¡ç†åŠŸèƒ½"""
    logger.info("\nğŸ’¾ æ¼”ç¤ºå¤‡ä»½å’Œç®¡ç†åŠŸèƒ½")
    
    mock_llm = MockLLMClient()
    path_generator = PathGenerator(llm_client=mock_llm)
    
    # åˆ›å»ºå¤‡ä»½
    backup_path = f"demo_data/backup_paths_{int(time.time())}"
    success = path_generator.backup_path_library(backup_path)
    
    if success:
        logger.info(f"âœ… è·¯å¾„åº“å¤‡ä»½æˆåŠŸ: {backup_path}")
    else:
        logger.warning("âš ï¸ è·¯å¾„åº“å¤‡ä»½å¤±è´¥")
    
    # æ˜¾ç¤ºç”Ÿæˆç»Ÿè®¡
    generation_stats = path_generator.get_generation_statistics()
    logger.info(f"ğŸ“Š ç”Ÿæˆç»Ÿè®¡:")
    logger.info(f"   ç¼“å­˜ç”Ÿæˆæ•°: {generation_stats['total_generations']}")
    logger.info(f"   å¹³å‡è·¯å¾„æ•°: {generation_stats['avg_paths_per_generation']:.1f}")
    logger.info(f"   å›é€€ä½¿ç”¨ç‡: {generation_stats['fallback_usage_rate']:.2%}")
    
    # æ˜¾ç¤ºåˆ›é€ æ€§ç»•é“ç»Ÿè®¡
    creative_stats = path_generator.get_creative_bypass_stats()
    logger.info(f"ğŸ’¡ åˆ›é€ æ€§æ¨¡å¼ç»Ÿè®¡:")
    logger.info(f"   åˆ›é€ æ€§ä½¿ç”¨æ¯”ä¾‹: {creative_stats['creative_ratio']:.2%}")
    if creative_stats['most_used_creative_path']:
        logger.info(f"   æœ€å¸¸ç”¨åˆ›é€ æ€§è·¯å¾„: {creative_stats['most_used_creative_path']}")


if __name__ == "__main__":
    print("ğŸ§  åŠ¨æ€è·¯å¾„ç”Ÿæˆå™¨å®Œæ•´åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæ¼”ç¤ºæ•°æ®ç›®å½•
        demo_data_dir = "demo_data"
        if not os.path.exists(demo_data_dir):
            os.makedirs(demo_data_dir)
        
        # 1. åŠ¨æ€åº“åˆå§‹åŒ–æ¼”ç¤º
        demonstrate_dynamic_library_initialization()
        
        # 2. é™æ€æ¨¡æ¿è¿ç§»æ¼”ç¤º
        demonstrate_template_migration()
        
        # 3. è·¯å¾„ç”Ÿæˆå™¨é›†æˆæ¼”ç¤º
        demonstrate_path_generator_integration()
        
        # 4. å­¦ä¹ èƒ½åŠ›æ¼”ç¤º
        demonstrate_learning_capabilities()
        
        # 5. æ€§èƒ½è·Ÿè¸ªæ¼”ç¤º
        demonstrate_performance_tracking()
        
        # 6. æˆé•¿æ´å¯Ÿæ¼”ç¤º
        demonstrate_growth_insights()
        
        # 7. å¤‡ä»½ç®¡ç†æ¼”ç¤º
        demonstrate_backup_and_management()
        
        print("\nğŸ‰ æ¼”ç¤ºæˆåŠŸå®Œæˆ!")
        print("ğŸ“ æ€»ç»“:")
        print("   âœ… åŠ¨æ€è·¯å¾„åº“åˆ›å»ºå’Œç®¡ç†")
        print("   âœ… é™æ€æ¨¡æ¿æ— ç¼è¿ç§»")
        print("   âœ… æ™ºèƒ½è·¯å¾„ç”Ÿæˆå’Œæ¨è")
        print("   âœ… å­¦ä¹ å’Œè‡ªæˆ‘æˆé•¿èƒ½åŠ›")
        print("   âœ… æ€§èƒ½è·Ÿè¸ªå’Œä¼˜åŒ–å»ºè®®")
        print("   âœ… å®Œæ•´çš„å¤‡ä»½å’Œç®¡ç†ç³»ç»Ÿ")
        print("   ğŸ§  è·¯å¾„ç”Ÿæˆå™¨å·²å®Œå…¨å‡çº§ä¸ºå¯æˆé•¿çš„'å¤§è„‘çš®å±‚'")
        
    except Exception as e:
        logger.error(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # æ¸…ç†æ¼”ç¤ºæ•°æ®ï¼ˆå¯é€‰ï¼‰
        import shutil
        demo_data_dir = "demo_data"
        if os.path.exists(demo_data_dir):
            try:
                shutil.rmtree(demo_data_dir)
                logger.info("ğŸ§¹ æ¼”ç¤ºæ•°æ®å·²æ¸…ç†")
            except Exception as e:
                logger.debug(f"æ¸…ç†æ¼”ç¤ºæ•°æ®æ—¶å‡ºç°è­¦å‘Š: {e}")
